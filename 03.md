Well, know a thing or two about research recruiting around here
(including how to make it less of a chore). And we're excited to share
that knowledge with you!
In this module, we're spilling everything we know about UX research
recruitment. You'll learn how to:
-   **Recruit participants for research studies.** Whether you're
    looking to refine your recruiting strategy or DIY the whole thing,
    this step-by-step guide will help you recruit like a pro.
-   **Write effective screener surveys** that will help you find and
    filter the right participants who can answer your research
    questions.
-   **Choose the right incentive type and amount**, depending on your
    methodology, participant profile, and research goals.
[Start
reading](/ux-research-field-guide-chapter/find-good-research-participants){.button-new
.teal .w-button}[Start
reading](/ux-research-field-guide-module/user-research-methods){.button-new
.teal .intro-only .w-condition-invisible .w-button}
This step-by-step guide to user research recruiting will teach you [how
to find participants for UX
research](https://www.userinterviews.com/blog/strategies-for-customer-research-recruitment),
full stop. It is meant to be agnostic---meaning you'll be able to apply
this knowledge regardless of experience, budget, type of research, user
testing tools you plan to use, and the kinds of participants you hope to
recruit.
That being said, [User Interviews *is* a research recruiting
tool](https://www.userinterviews.com/). We exist to solve the pain point
of user research recruiting---especially qualitative research
recruiting, in which researchers are looking for participants who meet
highly specific criteria relevant to their research question.¬†
As such, we'll be name-dropping ourselves a few times in this
chapter---but only when we think it makes sense for you to know about
how our product can help during the recruitment process.
##### **üëã Read the User Interviews** [**origin story**](https://www.userinterviews.com/blog/from-failure-to-a-venture-backed-startup-through-meta-user-research)
‚Äç
### In this chapter:
-   Why is user research recruiting so hard?
-   Who are the right participants for different types of research?
-   How many participants do you need?
-   A foolproof framework for user research recruiting
-   UX research recruiting tools¬†
-   More channels for recruiting participants
-   Tips to avoid participant burnout
Why is user research recruiting so hard?
----------------------------------------
User research recruiting is a pain. For many researchers, it's *the*
pain that takes up time and energy they'd rather be spending talking to
users.
Whether you're an experienced researcher or new to the game, recruiting
research participants for a study remains a challenge. Why?¬†
-   There are so many (too many!) channels and methods you can use to
    find participants, but different channels will work better for
    different projects.
-   Many user testing tools offer [participant
    panels](https://www.userinterviews.com/blog/build-manage-research-participant-panel)
    to recruit from---but you can only test on their platform.
-   Repeatedly using the same channels and methods will result in
    diminishing returns (i.e. burning out participants).
-   It's difficult to find eligible participants who meet the criteria
    for niche studies.
-   It's a lengthy and complex process, and some projects don't have the
    luxury of time.
-   Offering the right incentives and distributing them is
    time-consuming.
-   It's hard to manage participants during long-term or recurring
    studies, such as customer research projects.
These challenges are very real and very frustrating---but none of them
are insurmountable. Over the course of this chapter, we'll explain how
to overcome these challenges and make the research recruiting process (a
lot) less painful.
First, let's talk about your participants. Who are they? Or, rather, who
should they be?
Who are the right participants for different types of research?
---------------------------------------------------------------
As you'll see in the research recruiting framework below, the first step
to a successful recruit is clarifying the goals of your research and
which methods you intend to use.¬†Ask yourself:
‚Äç
###### What do you want to learn? How do you plan to learn that? 
The next step is to define your ideal research participant profile. What
criteria do participants need to have? Who, exactly, is going to have
the answers to your questions?
We'll dig into ways to define participant criteria in more detail later
in this chapter. But first, let's go over a couple of the broader
considerations that will influence your recruitment strategy.
Namely, let's talk about the differences between recruiting for
qualitative and quantitative research, as well as the differences
between recruiting external participants and recruiting among your own
customers.
### Recruiting for qualitative vs. quantitative research
Should you seek out your ideal user or cast a wide net? Do you need your
participants to be articulate, expressive, and have experience relative
to your product? Do you need a lot of people to achieve accurate
results?
#### Sampling for quantitative research
Quantitative research recruiting is a numbers game. For data analysis to
be meaningful and statistically significant, you need a lot of data.
Which means you need to do a lot of research with a lot of people.
When deciding [who to recruit for quantitative
research](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods),
you first have to define the population (the entire group you want to
study). A population can be extremely broad ("doctors," "women between
the ages of 18-35") or slightly more specific ("doctors in California,"
"unmarried Australian women between the ages of 18-35").¬†
From there, you will choose a sampling method that allows you to create
a sample---a randomly selected subset of the population who will
participate in your study.
#### Qualitative research recruiting
In qualitative research, which involves far fewer participants, you need
to be a bit of a Goldilocks. You're looking for the *perfect*
participants---people who meet specific demographic, geographic,
psychographic, and behavioral criteria relevant to your study.¬†
[Recruiting participants for qualitative
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
involves non-random sampling, screening, and a lot of communication.
### Recruiting your own customers for research studies
Your research goals will determine whether it makes sense to use your
existing customers, recruit a representative audience, or use a mix of
both.¬†
More often than not, if you're updating an existing product with new
power features, your existing users will be your best audience. If
you're building a brand new feature or product, non-users can provide a
fresh perspective.¬†
#### It makes sense to recruit your own customers when:
-   You're updating an existing product.
-   Your research requires extensive experience with your product.
-   You want to test for usability among experts rather than novices
    (for example, to test advanced features for power users).
If you choose to work with your existing customers, a lot of the work of
finding a representative audience is done for you. That's a big plus!¬†
It may be possible to access recruits by emailing existing customers,
posting a request for participants on your website or social media, or
having account managers, sales people, or customer service reps make
direct requests---just be mindful not to inundate your valued customers
with too many requests for input, and don't forget to make it clear
what's in it for them.
In some cases you may not need to offer financial incentives to your own
customers. Instead, consider emphasizing how much their feedback will
improve the product that they're already using or offering early access
to the new feature.
#### It makes sense to recruit external participants (non-customers/users) when:
-   You're developing a brand new product.
-   You need to test for usability among novices (who are more likely to
    stumble on usability issues that an experienced user of your product
    might not).
-   You want to test potential new customer groups.
-   You want to understand your competitors' customers.
####  
Non-users are an excellent resource if you want to understand the people
who might benefit from your product if your product isn't on the market
yet. They also tend to be useful for identifying usability issues that
people familiar with the product may have already overcome.
####  
Talking to your competitors' customers may help you understand how to
adapt your product to cater to a gap in the market or gain a competitive
edge based on your respective strengths and weaknesses.
Customer research and user research aren't mutually exclusive. Depending
on the goals of your research, it is often useful to talk to both groups
for a broader range of insights. Just be sure to differentiate between
groups and adapt your methods accordingly.
A foolproof framework for user research recruiting
--------------------------------------------------
### 1. Define your research goals and methodology
Defining your purpose and clarifying your objectives is a prerequisite
to any user research project. By the time you get to the recruitment
phase, you should already have clearly stated goals and reasons for
doing this research.¬†¬†
Planning your recruitment strategy is part of [UX research
design](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)---it
should happen before recruiting and research kicks off, and the 'whos,'
'whens,' 'hows,' and 'whys' should be outlined in a concise user
research plan ([like this
one](https://docs.google.com/document/d/e/2PACX-1vT7MAwQSR4pjvaqUnuCOGLuz3Eg3e3zBqVq8s7CYmx5gcVsDe6BxsyUBBsLIjCEKLIWnJcs3WPtBiGf/pub)).
Capisce?
‚Äç
### 2. Decide who to recruit for your research¬†
Generally speaking, you need to know what you're looking for in order to
find it. When it comes to finding the right user research participants,
this means taking the time to figure out what your research question is
and who, exactly, can best help you answer it.¬†
While this step may seem like a no-brainer, it's often overlooked.
Taking time to do it right can make a huge difference in the quality of
your research.
Targeting should typically be defined by using a mixture of the
following criteria:
-   Psychographics: Activities, hobbies, interests, and opinions
-   Behaviors: What they do (e.g. 'regularly commutes by car')
-   Demographics: Age, gender, education, income, marital status, etc.
-   Geographics: Country, city, region, or radius around an area
The first way to improve the quality and suitability of participants
when recruiting for a study is to clearly define your intended
participants.
If you're doing research for a company or a product, the target audience
is usually representative of your eventual---or existing---customers.
To determine who to recruit, ask yourself:
#### What is the goal of your research?¬†
What you want to learn from your study will determine who you should
study. Consider what insight would be most useful, then work backward to
figure out who can best provide that insight.
‚Äç
#### Are you in the discovery, testing and validating, or post-launch phase of product development?
Research can be useful at [every stage of the product development
cycle](https://www.userinterviews.com/ux-research-field-guide-chapter/what-is-user-research).
In the early stages, think broad---you'll want a variety of opinions and
perspectives during discovery. Further along in the process, a more
precise target audience will provide the richer insight you need to
optimize your product for current users.
‚Äç
#### What is your research question?
[According to Erika
Hall](https://medium.com/mule-design/research-questions-are-not-interview-questions-7f90602eb533),
a good research question is "specific, actionable, and practical."
‚Äç
In other words, an effective research question is one that can be
answered with a reasonable amount of certainty, using the tools at
hand.
‚Äç
For example, you could not reasonably find an answer to the question:
"What does my cat think about all day?" I can't ask my cat what it
thinks about, so any answer to this question would just be a guess. I
could, however, answer the question: "What does my cat do while I'm
working?" I could monitor behavior over a period of time and eventually
wind up with a definitive answer.
Here are some examples of specific, actionable, and practical research
questions:
-   "Does our pricing page accurately address our customer's questions
    about our pricing?"
-   "What tools do 20-somethings use to manage their finances?"
-   "How are enterprise users currently addressing the problem this new
    feature is intended to solve?"
Questions like these are specific enough that you will know when you
have found an answer, practical in the sense that you could reasonably
find answers in the scope of a research project, and actionable in that
you can act on the answer that you find.
‚Äç
#### Who can answer that question?
A specific, actionable, and practical research question will also help
you identify the kinds of participants you need to answer that question.
For example, to answer the question "What tools do 20-somethings use to
learn how to manage their finances?" you would need to talk to people in
their twenties who are interested in actively managing their money.¬†
Think through the specific traits a potential participant would need to
have.¬†
Sometimes, when you're getting started with research, it's easy to get
hung up on requirements that don't really matter to your study.¬† We
always encourage researchers to narrow their list to the minimum
requirements needed.¬†
Let's use the pricing page question as an example. To answer "Does our
pricing page accurately address our customer's questions about our
pricing?," we may start off with the following list of criteria:
-   Active customers
-   Ages 25-50
-   Has a college degree¬†
-   Signed up over 6 months ago
Investigating each of our requirements further can help us to narrow
them down a little and focus on why each requirement is there.
We would want to talk to current customers because they can help us best
understand the questions our target audience will ask about our pricing.
We also want to talk to people who signed up over 6 months ago because
(in this hypothetical example) that was the last time we changed our
pricing page. People who signed up within the past 6 months may have
already seen this version of the pricing page and may already have had
their questions answered.¬†
As far as eliminating requirements goes, there's nothing about age that
would prevent someone from being helpful with feedback on our pricing
page, so we can cut that requirement. Ditto education level, unless your
pricing page uses some seriously highfalutin language (which, fyi, it
shouldn't).
So our new requirements are:¬†
-   Active customers
-   Signed up over 6 months ago
This process can help you narrow down your ideal participants and cut
out requirements that may slow down your recruit for no reason. It's
also a good way to gut-check your research question. If you find
yourself with requirements that aren't reflected in your question, this
process can help you think about why those requirements are there and if
you need to alter your research question.
Some more examples of target groups are:
-   40- to 60-year-old men who live in small New England towns and drive
    to work
-   Georgia parents who use childcare at home
-   Tennis players in England who are active on Instagram
-   Unemployed recent high-school graduates who live in big US cities
#### Who can't answer your research question?
It's equally important to define who you're *not* looking for.¬†
For example, if you want to know which day of the week people in San
Francisco drink the most wine, your recruitment efforts would be wasted
on participants who are under the age of 21 (in theory).¬†
It's important to define these targets and non-targets at the outset,
because it helps you create a solid screening process.¬†
### 3. Determine how many participants you need¬†
The right number of participants will depend on the [type of research
you're
doing](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
and the specific methods you plan to use.
The UX experts at [Nielsen Norman Group famously
advised](https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/)
that for usability studies, you only need 5 good participants---and
people have been parroting that advice ever since.
And for most usability studies, 5 is an ideal number---beyond that
you'll get diminishing returns. (Unless of course you recruited the
wrong people in the first place. So... don't do that.)
But what about user interviews? Diary studies? Quantitative studies?¬†
As a rule of thumb, the right number of participants for quantitative
research = however many people you need to achieve the level of
statistical significance your study requires.¬†
For academic researchers, that could mean finding 1,000 to 2,000
participants to achieve maximum reliability. But for most quantitative
usability studies, 20 users is often plenty---although [the ideal
number](https://www.uxmatters.com/mt/archives/2016/01/how-to-determine-the-right-number-of-participants-for-usability-studies.php)
still depends on the type of study you're conducting.
For qualitative research, it really is a matter of quality over
quantity. To give an extreme example:
###### [Before Sara Blakely launched Spanx](https://www.npr.org/transcripts/493312213), she only needed insight from one person---a sales associate at Neiman Marcus---to understand that there was a market fit for her new pantyhose design.¬†That one person told her that several customers had been making a homemade version of the product she wanted to create because there was nothing else on the market at the time that met their needs. Running with that one piece of insight, Blakely was able to create a prototype, and guess who her first customer was? Neiman Marcus. 
In general, though, we recommend talking to more than one person before
making any major decisions.¬†
Here are some suggested sample sizes for different types of UX
research:
-   Interviews -- 3 to 10 participants¬†
-   A/B tests -- 5 to 8 users
-   Focus groups -- 5 to 10 participants per group
-   Diary studies -- 10 to 15 participants
-   Card sorting -- at least 15 users per group
-   Quantitative studies -- at least 20 participants
-   Surveys -- at least 100 participants¬†
Nielsen Norman Group has found that the [average no-show
rate](https://www.nngroup.com/articles/recruiting-test-participants-for-usability-studies/)
for a usability study is 11%. That means that for every 10 participants
you recruit, 1 of them is likely to be a no-show. You can reduce the
risk of no-shows with good communication and the right incentives, but
it's always a good idea to recruit a few extra participants that you can
call on, just in case.
If you're using [User
Interviews](https://www.userinterviews.com/recruit), we'll do this for
you so you never find yourself without backup if someone doesn't show up
for their session.¬†
### 4. Create an incentive plan
We cover incentives in more depth [later in this
module](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives).
But the ¬†gist is that you should compensate participants for their time,
and do it in a timely manner.
Setting an appropriate incentive increases the likelihood of a great
recruit. It shows that you respect participants' time and that you value
their expertise.
Monetary incentives, including gift cards, are the most popular form of
incentive, but incentives can also take the form of charitable
donations, account credits, or swag. (Seriously, don't underestimate the
power of good swag: There's a whole community of people dedicated to
buying, selling, and trading Mailchimp monkeys, after all.)¬†
The most important thing about your incentives is that they are valuable
to your participants and that they get people excited about
participating in your research.¬†
Here are our [incentive
recommendations](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
in a nutshell:
-   In-person studies demand higher incentives than remote studies.
-   Higher income earners expect higher incentives than lower income
    earners.
-   The longer the time commitment, the higher the incentive.
We've also found that moderated research---which requires more
coordination and communication between researchers and
participants---generally warrants a higher incentive than unmoderated
research.¬†
For a detailed breakdown of how much to pay your research study
participants for in-person and phone interviews, consult [this handy
cheat
sheet](https://docs.google.com/document/d/e/2PACX-1vQYgHN7gqHflkZAIRwr_C4KQNoU8aeqeaRgcXJn4IgehUFmeb0pu3X2ZdP6ReoRksmBmMUQeZQu-gOG/pub).
And check out the [UX¬†Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
for personalized, data-backed incentive recommendations.
Once you determine what and how much your incentives will be, you should
also have a plan for distributing them soon or immediately after each
session.
üìñ **Read more about** [**User Research
Incentives**](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
‚Äç
### 5. Find participants
Finding participants is a consistent and frequently cited pain point
among just about everyone who does user research. Companies with big
research teams have entire research ops divisions to help them manage
the logistics of recruiting and managing participants for all those
projects. Smaller research teams either go it alone with a recruitment
tool or use research agencies to handle recruiting for them.¬†
The good news is there are lots of tools out there to help you recruit
participants for your research. You can use low-cost user research
recruiting tools like User Interviews to recruit vetted participants, go
it alone on Craigslist or social media, or turn to a research recruiting
agency for a totally hands-off (but expensive) process.¬†
We'll go over the different channels and tools for recruiting research
participants in more detail at the end of this chapter.¬†
‚Äç
In a nutshell, your options are:
-   **User research recruiting platforms** (like ours). These tools
    offer a large pool of participants and let you filter by target
    criteria to fill niche studies, regardless of where they'll be
    conducted.
-   **Your customers.** If you're doing research about an existing
    product or service, recruiting from your own customer base is always
    a good place to start. Depending on the goals of your project, you
    could look at things like user analytics, customer support tickets,
    NPS scores, etc. to identify customers that are a good fit for your
    study.
-   **User research recruiting agencies**. There are good ones and bad
    ones, and typically cost a pretty penny. But if you're looking to
    outsource the whole, unpleasant process and can afford to do so, an
    agency can help take recruiting off your plate in a big way.
-   **Social media.** Posting a Google Form on LinkedIn, Facebook,
    Twitter, or even Slack groups can be a good way to find research
    participants---just make sure you have a robust screener prepared to
    weed through unqualified candidates, since you'll likely get a lot
    of them.¬†
-   **Your website.** Intercept surveys, popup modals, and banners can
    be effective ways to reach site visitors. Just make sure you're not
    interrupting an important workflow or task---otherwise you'll end up
    recruiting a lot of annoyed participants.
‚Äç
### 6. Screen participants¬†
This next step puts the work you did in step 2---defining a research
question and key participant traits---into action to separate the good
participants from, well, the not-so-good.
The best way to do this is with [a screener
survey](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys),
which is a (typically brief) survey participants take before they
qualify for your study. You can think of a screener survey as a sieve
that captures the people who hit all your 'must have' criteria and
filters out the ones who don't quite fit the bill.
Again, these criteria are usually a mix of:
-   Psychographics: Activities, hobbies, interests, and opinions
-   Behaviors: What they do (e.g. "regularly commutes by car").
-   Demographics: Age, gender, education, income, marital status, etc.
-   Geographics: Country, city, region, or radius around an area
This is a deceptively straightforward concept---many (many!) researchers
struggle to create the perfect screener survey. And getting this part of
the process wrong can have far-reaching implications for the entire
research project.
Because screener surveys are so important, we've dedicated an entire
chapter to the topic, which you can read here. User Interviews customers
also have access to our knowledgeable [Project
Coordinators](https://www.userinterviews.com/blog/cs-support-operations-team-guide),
who can help you craft a standout screener survey.
Short on time/patience? Here are our recommendations in a nutshell:
‚Äç
#### Filter by behaviors > demographics
Demographics are the low hanging fruit of screener surveys, and it often
makes sense to include a few demographics questions either at the
beginning or at the end of your survey. But don't let age, gender, and
location questions be the end-all be-all.
You'll want to start by identifying which demographics, if any, really
define your audience conclusively.¬†
###### **Remember:** your screener survey and the research that follows should help you tap into what people really want and need from your product---and demographics alone won't get you there.
#### Eliminate unqualified people early
Don't make prospective participants complete your entire screener before
finding out they don't qualify. Start with the questions that are most
likely to weed out large groups of unqualified participants. The easiest
way to do this is to write out your questions, rank them in order of
importance, and look for any interdependencies.¬†
For example, before diving into questions about how people use apps on
their smartphones, find out if they use a smartphone at all. Then, move
on to the questions that tap into specific behaviors, interests, and
preferences.¬†¬†
#### Avoid tipping your hand
A screener survey is meant to help you find the candidates who are a
perfect fit for your study. Giving away the plot too early---by, say,
telling participants what your study is about---can devalue the
screening process and make your research less effective.
To avoid tipping your hand at this stage:
-   Don't reveal the purpose of your research study.
-   Don't reveal the name of your company or product.
-   Don't ask leading questions.
#### Look for expressive people
Don't you just *love* conversations where you have to drag answers out
of the other person?
Of course you don't. People who make terrible dinner party guests also
tend to be less-than-optimal candidates for qualitative research.¬†
Screen for high-quality participants by asking "articulation questions."
These are open-ended questions designed to test a user's capacity to
communicate. If a person can express their ideas with depth of thought,
they're likely to be a helpful participant.¬†
Including open-ended questions also helps weed out "professional
participants" who are just looking to make a quick buck by qualifying
for any and every study.
#### Provide an "other" option
If you create multiple choice responses, don't assume that you've
presented the user with every possible option. As Gandalf once said,
"even the very wise[st survey designers] cannot see all ends."¬†
Include a 'none of the above,' 'I don't know,' or 'other' option to
account for any outliers.¬†
Otherwise you could end up with someone in your survey who doesn't
belong there because they were forced to choose an answer that didn't
apply to them. Likewise, you might screen good participants out because
they didn't quite fit the answers you provided.
#### Remember to keep it brief
Lastly, it's important to keep screener surveys short and sweet. We've
seen some screener surveys get so long that participants mistake them
for a (paid) research survey! If you're looking for a rough guideline on
length, try to keep your screener to fewer than 10 questions.¬†
‚Äç
### 6. Schedule participants for a mutually convenient time
Don't you just love emailing back and forth to "find a time that works
best for everyone?" Yeah, neither do we. That's why we built scheduling
right into [the User Interviews
interface](https://www.userinterviews.com/), so you can just choose the
times you're available and your participants can select from
the¬†available time slots.¬†
If you're not using User Interviews to schedule your sessions, you may
need a dedicated scheduling tool to help you coordinate your
sessions---especially when coordinating multiple interviews‚Å†.¬†
Tools like Calendly, Doodle, and YouCanBookMe help take the hassle out
of scheduling sessions by allowing your participants to select an
available time slot on your calendar, similar to our scheduling
function.
Make sure to include a calendar invite when each booking is confirmed.
If they accept the invite, the participant may get notifications on
their phone in addition to your emails and other outreach---all of which
help them remember to show up!¬†¬†¬†¬†
Be respectful of your own time, too. Limit the number of sessions you
conduct each day, and give yourself *at least* 15 minutes between
sessions in case you have a particularly talkative participant. If you
can, aim for a 30 minute buffer---this will give you time to polish your
notes from the previous session while they're fresh in your mind, and
will give you time to prepare for the next one.
### 7. Communicate with participants to reduce no-shows
After a participant signs up for a user research session, send them a
confirmation email right away. To help your participants remember the
interview and get to the right place at the right time, be sure to
include 3 key pieces of information:¬†
-   Time and date---if doing remote research, make sure you give the
    time and date in your participant's time zone.
-   Location---include a map and directions if the test is in person, or
    a link to a video call and instructions for joining.
-   Research topic---don't give too much information away, but do remind
    users what the research will be about.
It never hurts to be enthusiastic, thank the interviewee, and
re-emphasize the impact of the interview.¬†
And while you don't want to bombard your participants with a constant
stream of messages, do plan to follow up multiple times for interviews
scheduled a week or more in advance.
A typical outreach cadence may be:
-   On the day of sign-up---this will be your first opportunity to give
    them all the details so they can plan effectively.¬†
-   A week in advance---if you scheduled more than a week in advance,
    follow up 7 days before the interview.¬†
-   The day before---follow up the day before the interview with all
    relevant details to make sure your participant can plan accurately.¬†
-   The day of the test---send a final follow-up a few hours before the
    interview. Again, include all details, especially directions and
    access information, to make sure your user can reach you without
    trouble. You may want to provide a phone number or way to contact
    the researcher in case your participant needs real-time assistance.¬†
By the way, you can automate all of this outreach in User Interviews,
whether you're contacting your own users via [Research
Hub](https://www.userinterviews.com/research-hub) or sourcing new
participants through [Recruit](https://www.userinterviews.com/recruit).¬†
For longer research like [diary
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies),
periodic reminders may be needed to keep motivation high. You might also
consider spreading your incentives distribution out over time to promote
and reward continued engagement.
‚Äç
### 8. After the session, thank participants for their time
The incentive plan that you put together in step 4 should include a
strategy for distributing incentives to participants as soon as possible
once the session wraps up.
We recommend researchers use popular digital payment platforms like
PayPal for cash-based incentives. If you use User Interviews for
recruiting participants for a study, we can instantly process incentive
payments through gift cards. We will also automatically issue 1099s for
your tax records. Or you can handle incentives independently---it's up
to you.¬†
Just remember, while compensation is important, incentives aren't enough
to guarantee high-quality and happy participants---people need to have
clear instructions, and they need to know you're truly grateful for
their time.¬†
User research recruiting tools
------------------------------
Look, User Interviews is a user research recruiting and management
platform. We're a little biased when it comes to [UXR recruiting
tools](https://www.userinterviews.com/blog/ux-research-tools-map-2021)...
but that's only because we're the best.
All jokes aside, User Interviews is one of just a few tools fully
dedicated to solving this part of the user research process. It's why we
exist---and we're good at what we do.
Our platform is [a one-stop shop for recruiting
participants](https://www.userinterviews.com/)---whether you want to
draw from your current user list or recruit from our audience of over
700,000 ready, willing, and vetted research participants from seven
countries. You can also target over 140 different industries, job
titles, demographics, and custom screener criteria. If you incentivize
your participants with Amazon gift cards, we'll manage the incentives
for you.
User Interviews also includes screener surveys, scheduling for
interviews, and participation tracking for your existing users. Don't
feel like handling incentives? If you choose to have them distributed as
digital gift cards, we'll manage the distribution for you.¬†
The median turnaround time to match you with your first participant is 3
hours, though it can vary based on the project.¬†
If you're looking for a solution to manage your own participant
population, we can do that too! Our Research Hub Free Forever plan
stores up to 100 of your own participants and lets you keep track of
when they last participated and even how much you've paid them in
incentives.
#### Other popular research recruiting tools (the honorable mentions):
-   [TestingTime](https://www.testingtime.com/en/)---Zurich-based
    TestingTime is a good solution if you're looking to recruit
    participants from Europe. They also offer a UX research service for
    companies looking to outsource the entire user research process.
-   [Askable](https://www.askable.com/)---based in Australia, Askable is
    a solid option if you're looking to recruit participants from
    Australia and New Zealand. They also offer a remote testing suite
    with video,¬† text chat, screen sharing, and session recording.
-   [Respondent](https://www.respondent.io/marketplace)---a popular
    option for researchers who want to recruit business professionals,
    Respondent is especially useful for B2B research (although they do
    offer B2C recruiting as well).
-   [UserZoom](https://www.userzoom.com/participant-recruitment/)---if
    you've been in user research for a few years, there's a good chance
    at least one of your favorite products has since been acquired by
    UserZoom. They offer a suite of user research and usability testing
    tools, as well as a large pool of participants. This can be an
    efficient option if¬† you're planning on doing research through the
    UserZoom platform.
‚Äç
[üßô‚ú® Discover more tools in the 2022 UX Research Tools
Map](https://www.userinterviews.com/ux-research-tools-map-2022), a
fantastical guide to the UXR software landscape.
More channels for recruiting participants¬†
------------------------------------------
If you decide to DIY your research recruiting, you have several options,
depending on who it is you're trying to recruit.
‚Äç
### Researching your own users
‚Äç
#### Live intercepts
Messages can be delivered in real time within your website or app based
on the user's actions or engagement, their background account
information, and/or other criteria. You can recruit at the flick of a
switch, but you'll need to contend with third-party integrations and
potential complexity in managing the tool.¬†
‚Äç
#### Organic social media
If you've built an active and engaged social following from your own
customer base, you can recruit people directly through these profiles.
It's free and straightforward, but some platforms (e.g., Facebook &
Instagram) are making it hard for brands to get by on organic reach
alone---so you might struggle to capture enough eyeballs. You can
navigate this by boosting posts to an audience of your own page
followers (this requires budget allocation).
‚Äç
#### Customer service
Your support staff are in touch with customers every day, and these are
the customers who have something to say. This makes them great
candidates for qualitative user research---if you can align with the
support team.
‚Äç
#### Your email list
If you're doing research with your own customers, turning your email
list into a participant recruitment tool is relatively simple and can be
very effective. These are people who are already invested in your
product, and may have great insights to share. Work with your marketing
or sales team so your research efforts don't overlap with existing
outreach.¬†
###### **Pro tip:** Use a research CRM to manage your own participant panel. You can build your own research panel using any of these channels, and import your database into [Research Hub](https://www.userinterviews.com/research-hub). There, you can manage the whole research process from within one platform: profile building, scheduling, tracking responses, incentive payments, and more.
‚Äç
### Researching with non-customers
‚Äç
#### UX research agencies
If you want a completely hands-off recruitment process, you can enlist
the help of a specialized [research recruitment
agency](https://www.userinterviews.com/blog/user-research-recruiting-agency-vs-in-house).
Specialist market research companies or participant recruitment agencies
are often very good at what they do, but their help comes at a high
price (around $107 per participant, on average). That can be a hefty
price tag for small businesses to handle, especially since you typically
need at least 5 participants to complete a research study.¬†
‚Äç
#### Manual outreach
This is a highly targeted and customizable approach, but it's
time-intensive to crawl through LinkedIn profiles, send out speculative
messages, and follow up on conversations. Frankly, few people have time
for this and it doesn't scale well
‚Äç
#### Paid social media
[Performance marketing
techniques](https://www.userinterviews.com/blog/research-recruiting-on-facebook-and-other-strategies)can
be directly applied to the research recruitment process, and if you have
a savvy and helpful marketing team, you can recruit participants through
paid Facebook, Instagram, LinkedIn, or other social advertising.¬†
Defining your audience is especially important here, because your ad
targeting strategy will determine whether you get relevant respondents
for your screening survey.¬†
‚Äç
#### LinkedIn and Facebook groups
Organic reach for posts is limited nowadays. But groups and community
pages are still a hive of activity, packed with people who are actively
talking about shared interests, ideas, professions, hobbies, and more.¬†
The challenge is that many of these groups are closed or invite-only, so
you may need the admin's approval to recruit there. If you're able to
get approval, some of your best participants could come from these
hyper-specific groups.¬†
‚Äç
#### Slack
Slack isn't just a great tool for communication with your
colleagues---you can also use it to connect with research participants!
Many specialized communities have Slack workspaces where people get
together and talk about their industry. These communities can be a good
place to connect with participants for a hard-to-recruit study.¬†
Just make sure you are asking for research participation in the right
channel, communicate the details of your study clearly, and abide by any
community rules that exist.¬†
¬†You can use [Slofile](https://slofile.com), an online database of Slack
communities, to find ones that align with your target audience.¬†
‚Äç
#### Reddit
Another social media network you may not think of for participant
recruitment is Reddit. Like Slack, it primarily consists of specialized
subgroups (subreddits) that center around a theme, idea, hobby,
location, etc. Because of this, Reddit can be a good place to find
people who fit niche recruitment criteria.¬†
When posting your research project on Reddit, remember to provide a
clear description of your research project, why you need help from the
people in this subreddit, and engage with any comments or questions
people might have.¬†
You can also use research-specific Reddit communities to find
participants for your research. These communities are devoted to
participating in research or finding ways to make a little extra pocket
money. They're not as targeted as posting in a subreddit specifically
for your target participant, but can still yield good results.¬†¬†
-   r/SampleSize
-   r/BeerMoney
-   r/Assistance
‚Äç
#### Craigslist
Finally, recruiting participants through classified ads like Craigslist
can be a cheap way to recruit participants. Craigslist limits the amount
of ads you can post, so if you have a few studies to recruit for we
recommend sticking with the free posts.¬†
The quality of participants you get from this channel can be hit or
miss, but it can be worth working into your recruitment checklist and
letting your screener survey sort out the good participants from the
bad.
Tips to avoid participant burnout
---------------------------------
If you keep hitting the same audiences time and time again for different
research studies, you will experience the law of diminishing returns.
Repeat participants will eventually get fatigued, and your research will
be based on interviewing the same people with the same views.
There are 2 possible ways to avoid this problem:
-   Use a huge database of potential participant targets.
-   Use a mixture of different recruitment strategies and channels.
Of course, it might be unavoidable to hit the same audience repeatedly
when you're testing product development among your most engaged current
customers.¬†
So, how can you keep things fresh?
-   Try the [RITE
    method](https://uxmag.com/articles/the-rite-way-to-prototype) (Rapid
    Iterative Testing and Evaluation) for product research. This means
    you only speak to tiny groups of one or two people, before iterating
    on designs and speaking to the next group. This approach will burn
    through fewer of your users.
-   Keep studies short and sweet. Get the insights you need without
    overburdening users.¬†
-   Mix up your methods to keep the structure and process of your
    research studies fresh.
-   Sustain long-term advocacy by thanking participants and showing them
    the direct results of their participation (e.g., a new feature
    addition).¬†
A quick recap
-------------
The quality of your participants directly impacts the outcome of your
research project, which is why it's so important to get off to a good
start by specifying targets, building a bulletproof screening process,
and offering incentives that match the expectations of your target
audience.
We know we packed a lot of information into this chapter, so let's take
a moment to recap.¬†
In this chapter we went over how to:
-   **Decide who to recruit for your research.** You learned how to
    establish an effective research question and create recruitment
    requirements to help you identify who can help you best answer that
    question.
-   **Find user research participants.** You discovered different ways
    to use social media, classifieds, user research tools, and even your
    own email list to find participants.
-   **Screen your user research participants.** You learned about the
    importance of writing screening questions that focus on the right
    criteria, filter out unqualified people from your study, don't lead
    participants, and ensure you're recruiting the right people for your
    research.
-   **Incentivize research participants.** You got the low-down on the
    different types of research incentives, how the right incentives can
    attract quality participants, and the importance of distributing
    these in a timely manner at the end of a session.
-   **Schedule research sessions.** We're all beholden to our
    calendars---you found out how to create shared calendar invites so
    everyone has the information they need to show up and succeed.
-   **Check in with participants to reduce no-shows.** You now know to
    check in with your participants before a session to reduce no-shows.
    (Because hey, everyone forgets sometimes.)
-   **Avoid participant burnout.** Finally, repeatedly recruiting from
    the same small pool of users is a great way to burn participants out
    on the whole idea of user research. You learned a few ways to avoid
    participant fatigue and keep things fresh.
And there you have it---everything you need to know to recruit great
participants for your UX research study!
> *Note to the reader:*
> 
> This part of the field guide comes from our 2019 version of the UX
> Research Field Guide. Updated content for this chapter is coming
> soon!
> 
> Want to know when it's released?
> [Subscribe to our newsletter!](#){.para-link-new .fg-coming-soon}
Why do we keep harping on about screeners?
Because they're important! Screener surveys are what stand in the way of
you and hoards of unscrupulous, unqualified, uncommunicative
participants. (That's a bit dramatic, but you get the point.
Screener surveys are essential tools for qualitative research. And while
they sound simple, they're actually very easy to get wrong. Which is why
we've dedicated a whole chapter to them!
### In this chapter
-   What is a screener survey and why do you need one?
-   How to create an effective screener survey
-   Examples of common screener questions and formats
-   When double-screening makes sense
-   Avoiding no-shows
What is a screener survey and why do you need one?
--------------------------------------------------
Screener surveys, or just 'screeners,' are surveys people take *before*
participating in a research study. They're made up of a few questions,
designed to weed out the folks who aren't your intended audience and
capture the ones who are.¬†
You can think of a screener survey as a sieve that captures the people
who hit all your 'must have' criteria and filters out the ones who don't
quite fit the bill.
‚Äç
How to create an effective screener survey
------------------------------------------
If you want the right participants, you've got to design smart screening
questions.
That's not always as straightforward as you might think. You have to ask
questions in a somewhat roundabout way to avoid leading people to
certain responses, but also in a clear way to make sure you're
universally understood.
The devil is in the details, but luckily there are some pro strategies
that anyone can learn and put to use right away.¬†
The guiding principles explained in this chapter will help get you
there.
###### **Tip:** If you haven't already got your ideal participant profile nailed down, review the previous chapter on [finding the right participants](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants) for your study before reading further.
‚Äç
### 1. Know your goals¬†
We covered this bit in previous chapters, and the advice here is the
same as the last.¬†
Clearly defined goals and objectives are must-have requirements for any
user research project. These goals---aka your reason for doing
research---should be hammered out well before you start writing your
screener surveys. (If they're not, head on back to the chapter on
[planning
research](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
to get some clarity. Go on, we'll wait...)¬†
‚Äç
### 2. Define specific target audience criteria
This is the part where you consider your research question, imagine the
ideal participant who can give you the answers you need, and identify
the targeting criteria (the things that must be true about them) needed
to qualify for your study.
Your targeting criteria will typically be defined by using a mixture of:
-   Psychographics: Activities, hobbies, interests, and opinions
-   Behaviors: What they do (e.g. 'regularly commutes by car')
-   Demographics: Age, gender, education, income, marital status, etc.
-   Geographics: Country, city, region, or radius around an area
So... how do you decide what criteria to target by?¬†
‚Äç
#### To figure out who to recruit for UX research, ask yourself:
-   **What is the goal of your research?** Consider what insight would
    be most useful, then work backward to figure out who can best
    provide that insight.
-   **Are you in the discovery, testing and validating, or post-launch
    phase of product development?** In general, your audience should be
    broad in the early stages and get more targeted as development
    progresses.
-   **What is your research question?** [A good research
    question](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
    like "What tools do 20-somethings use to manage their finances?" has
    much of the targeting criteria already baked in.
-   **Who can answer that question?** Think through the specific traits
    a potential participant would need to have. In the example above,
    you'd want to talk to people in their twenties who are interested in
    actively managing their money.
-   **Who *can't* answer that question?** Don't ask retirees how their
    grandchildren manage their finances. Likewise, if a 25-year old says
    'nah, I'm not really interested in having a budget,' they are the
    wrong person for your study.
We covered all of those points in finer detail [in the last
chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants).
If you're still struggling to pin down who to recruit, we recommend
revisiting those recommendations before moving onto the next steps.
### 3. Screen for behaviors and psychographics over demographics
Take a closer look at your targeting criteria. Do they include
demographic criteria like age, gender, race, income, etc? Do they need
to?
Demographics are the low-hanging fruit of screener surveys, but these
characteristics have their limitations.
For instance, where people live is important if you're doing an
in-person study, or if your app will only serve certain locations. But
if you don't have a clear reason to target based on geography... don't.
The same thing applies to demographics. In many cases, a person's gender
or how much they earn per year won't determine how they interact with a
product.¬†
Our assumptions about these characteristics are prone to bias, which can
invalidate your study and do real harm to the people your research will
ultimately impact.
Also, it's just bad form to waste valuable screener questions on
criteria that aren't absolutely essential.
Screening for psychographics and behaviors lets you group people based
on *how* they live, what they value, and how they relate to your product
or category. That's the juicy stuff!
###### **Rule of thumb:** Worry less about how people are categorized on a census and more about how they think, feel, and behave.
#### When asking demographic questions makes sense
Let's say you want to test for accessibility with a mix of gender
identities, age ranges, and educational backgrounds. In this case,
adding demographic criteria will allow you to target a diverse audience.
Not every question on your screener has to result in an automatic in or
out, but can be used to filter for a variety of participants as a final
step. Accept anyone who could be a fit based on any given question.¬†
###### **Tip:** Some recruiting services ([User Interviews included](https://www.userinterviews.com/)) will automatically provide basic demographic, geographic, and technographic information for you, so you don't need to include it in your screener survey. Win for you and your participants!
:::
::: {.fg-cta ._1}
### Recruit from our panel of 700k+ participants or bring your own {#recruit-from-our-panel-of-700k-participants-or-bring-your-own .h3-new .fieldg-cta}
[Sign up for free](https://www.userinterviews.com){.button-new .outline
.fieldguide-cta .w-button}
:::
::: {.fg-rich-text .w-richtext}
### 4. Write precise, carefully worded questions
Once you know the characteristics of your target participants and you've
broken that down into specific criteria for how you'll identify the
people who qualify, it's time to write the questions that will help you
filter out the good'uns.
The language you use in your screener is important. When writing
screener questions:
-   Avoid double negatives.
-   Keep the questions short and sweet.
-   Leave out industry jargon (unless knowledge of it is a requirement
    for participation).
-   Be specific.
The more clearly worded and specific your questions are, the less likely
participants will be to get confused and answer inaccurately. Leave no
room for misinterpretation!
Similarly, make sure the multiple choice options you provide are
carefully worded. Being clear in your responses is just as important as
being clear with your questions.
Have you ever taken a survey where, on a certain question, you found
yourself forced to choose between more than one answer that applied to
you?
To avoid putting your audience in that position, make sure your answers
have clear borders without any overlap. For example, when asking for
numerical values (age, size, frequency etc.), make sure your values are
mutually exclusive:
-   Correct: 0-3, 4-7, 8-12
-   Incorrect: 0-3, 3-7, 7-12
For less definitive answers or for answers that can't be made mutually
exclusive, ask participants to select the answer that is *most* true or
give them the option to select all that apply, rather than a single
answer.
### 5. Put your screener questions in the right order
Don't make prospective participants complete your entire screener before
finding out they don't qualify. Eliminate unqualified people early.
Think of the process as a funnel. You're refining your participants, and
refining them further. Or, think of it like weeding a grown-over garden.
The biggest, tallest, most obvious weeds come out first, simply because
they're the easiest to grab. Start with the questions that are most
likely to weed people out.¬†
The easiest way to do this is to write out your questions, rank them in
order of importance, and look for any interdependencies.¬†
For example, if you're doing an in-person study, ask about location
right away. Location here is a must and must-have criteria go first.
Before diving into questions about how people use apps on their
smartphones, find out if they use a smartphone at all. Then, move on to
the questions that tap into specific behaviors, interests, and
preferences.¬†¬†
If you're not working with a recruiting service that gathers
demographics for you, ask any demographic questions that you need to
ensure a diverse recruit pool.
### 6. Avoid leading or loaded questions
You know how some folks add a "right?" at the end of every sentence, so
that you have no choice but to nod or shrug in agreement? Right?¬†
That's an example of 'leading.' Leading questions will influence people
to answer in a certain way.¬†
It's a handy conversational device if, say,¬† you're a dogged prosecutor
in a courtroom TV series and the judge will allow it (for the drama,
obviously). But leading questions have no place in user research---and
definitely not in your screener survey. This is not the place to try to
validate your assumptions. You'll end up with skewed results or the
wrong kind of participants.
Here's an example:
-   **Leading:** Would you like it if there was a feature that did
    [X]?
-   **Not leading:** Are there any features that don't currently exist
    in the product that would help you do [X]? If so, what are they?
A good way to identify whether a question might be leading is if it
includes a hint or excludes possible answers.
Another way to avoid leading questions is to provide a series of
unrelated options as answers.¬†
For example, if you want to screen users who have a high level of
concern around internet privacy issues, rather than diving right into
questions about internet privacy by asking:
-   **Leading:** Are you concerned about internet privacy?
... you can create a question like this **(not leading)**: Which of the
following topics is most concerning to you regarding internet use in
your life?
-   How much time my kids spend online. - *Reject*‚Äç
-   Data privacy issues. - *Accept*‚Äç
-   False information appearing in search results. *- Reject*‚Äç
-   I don't have any concerns about the internet. *- Reject¬†*‚Äç
-   I don't know. / None of the above. *- Reject*
Likewise, avoid yes/no or true/false questions, which tend to be
leading. Users might answer in the way they believe will entitle them to
participate in the study. Whenever possible, replace these questions
with multiple choice options or provide a scale for degree of agreement
with a given question.¬†
**Exception:** In cases where a black and white answer is required---for
example, when asking if a person is willing or able to participate under
the conditions of your study---a binary question will be your best bet.
'Loaded questions' are similar to leading questions (and the two are
often conflated), in they push the participant to answer a certain way.
Loaded questions do this by making assumptions, which are implicit in
the question itself.
Here's an example:
-   **Loaded:** On a scale of 0-100, how much do you despise pistachio
    ice cream with every fiber of your being?
-   **Not loaded:** On a scale from 1-10 where 1 is 'gross,' 5 is
    'neutral,' and¬† 10 is 'delicious', please rank how you regard
    pistachio ice cream.¬†
A good way to identify whether a question might be loaded is if it
includes strong language or excludes possible answers.
-   **Loaded:** What is your favorite thing about the new, improved app?
-   **Not loaded:** How does your experience with this version of the
    app compare to your experience with the previous version?
### 7. Provide a catchall alternative option
If you create multiple choice responses, don't assume that you've
presented the user with every possible option. Even the best survey
designers have their limitations. As Gandalf once said, "even the very
wise[st survey designers] cannot see all ends."¬†üßô
Include a 'none of the above,' 'I don't know,' or 'other' option to
account for any outliers.¬†
Otherwise, you could end up with someone in your study who doesn't
belong there because they were forced to choose an answer that didn't
apply to them. Likewise, you might screen good participants out because
they didn't quite fit the answers you provided.
### 8. Include an open-ended question to screen for articulation
Spare yourself the pain of having to drag answers out of a reticent
participant by screening uncommunicative people out of your study.
Screener surveys help you to get more value for your time and money on a
per-participant basis. Sometimes that means excluding certain people who
otherwise perfectly fit your ideal audience profile.
Screen for expressive participants by asking 'articulation questions.'
These are open-ended questions designed to test a user's capacity to
communicate. If a person can express their ideas with depth of thought,
they're likely to be a helpful participant.¬†
Including open-ended questions also helps weed out "professional
participants" who are just looking to make a quick buck by qualifying
for any and every study.
### 9. Don't reveal too much
A screener survey is meant to help you find the candidates who are a
perfect fit for your study.¬†
Giving away too much information about the purpose of your study---by,
say, revealing the name of your company to non-users or telling
participants who you're looking to interview (which is a real mistake
that we've seen)---can devalue the screening process and make your
research less effective.
And this advice doesn't just apply to your screener. The title and
description you give your study, the way you talk about it when you're
recruiting participants, and the things you reveal in the lead-up to the
session itself---it all matters.¬†
For instance, let's say you are doing research on (yet another) photo
editor app for influencers and people who actively post photos on social
media. You might tell participants it's a study related to social media
habits. That way they have some context (which can help them decide to
click into the screener), but they don't know what type of social media
habits (editing photos) you're looking for.
This will make it harder for professional testers to guess what you
want, making it more likely you'll get authentic responses.
#### To avoid tipping your hand, don't:
-   Reveal the purpose of your research study.
-   Reveal the name of your company or product.
-   Ask leading questions.
###### **Pro tip:** If you're struggling to write descriptive titles and copy that don't give away too much information, see if there's a friendly wordsmith on your marketing team who can lend a hand.
‚Äç
### 10. Manage the expectations of survey takers
Make sure your participants are clear about what they're doing, and at
what stage of the process they're at.¬†
The screener survey is a sort of dress rehearsal, and it will help the
participant to know they're not yet in the final round. Be sure the
candidate knows what they're in for if they do make it.¬†
‚Äç
If there are any possible deal-breakers (like [NDA
agreements](https://www.userinterviews.com/blog/ndas-and-informed-consent-for-user-research),
for example) let them know up front.¬†
And of course, be clear that they won't be paid until they make it
through to complete the actual survey.
### 11. Remember to keep it brief
Finally, keep your screener surveys short and sweet. We've seen some
screener surveys get so long that participants mistake them for a (paid)
research survey! If you're looking for a rough guideline on length, try
to keep your screener to fewer than 10 questions.¬†
Examples of common screener questions and formats
-------------------------------------------------
Remember, the point of a screener survey is to help you find the right
participants for *your* research. This list of screener questions is
meant to be used for inspiration, and to help you get a gut check on
your own screener. It's *not* a library of general use questions to copy
and paste from in all circumstances.¬†
With that caveat out of the way, here are some sample screening
questions to ask, depending on the type of criteria you're filtering
for.
### Sample screening questions for different types of criteria
##### Industry or occupation¬†
Ask employment questions when you want to screen for people with a
certain level of familiarity with a particular industry, or exclude
those who work for competitors.
**Example question:** What industry do you work in?¬†¬†
**Answers:** A list of industries (retail, IT, healthcare, education,
etc.)
**Format:** Single select¬†
**Example question:** Which category best describes your job function?
**Answers:** A list of job functions (marketing, accounting,
engineering, product design)
**Format:** Single select¬†
##### Familiarity with a product or service
If you need to test with novices, experienced users, or some combination
of each, ask about familiarity with a given product.
**Example question:** Please rank your experience with {name of
product}.
**Answer:** A range from expert to novice
**Format:** Scale rating or single select
**Example question:** Which of these tools do you use for work? (Select
all that apply)
**Answer:** A list of software products
**Format:** Multiple select
##### Frequency of performing specific tasks
Asking about frequency of use or action is useful when you're screening
for users who regularly do a specific task, or who used to behave in a
certain way and then stopped.
Consider defining terms like often (every day) and rarely (once a year)
so there's no guesswork.
**Example question:** Please tell us how often you {name the task}.
**Answer:** A range of time from often to rarely.
**Format:** Scale rating or single select
**Example question:** When was the last time you {name the task}.
**Answer:** A range of time from today to never.
**Format:** Scale rating or single select
##### Comfort with sharing personal information
Just because someone meets your screening criteria doesn't mean they're
actually going to be willing to participate, especially if your study
touches on sensitive topics like health, income, lifestyle, marital
status, etc. Ask participants directly if they're willing and able to
answer personal questions.
**Example question:** This study will require you to share openly about
{examples}. Do you agree to share honestly about these subjects?
**Answer:** Agree or disagree
**Format:** Single select.
‚Äç
### A note on extra requirements for medical researchers
If you're conducting medical research, the recruitment process and
screening process are considered separate activities. Recruitment---in
which you reach out to research candidates and tell them about the
planned study---is a pre-screening activity that can be done without
informed consent. But even your pre-screening process may have to be
submitted to your Institutional Review Board (IRB) before you can
proceed.
Before you gather protected health information or obtain medical records
to determine study eligibility, you'll need patients to sign a consent
form to proceed with screening activities. Your screening script for
interacting with possible participants and gathering information also
has to be submitted for IRB review.
For more information about IRBs, refer to the [FDA
website](https://www.fda.gov/about-fda/center-drug-evaluation-and-research-cder/institutional-review-boards-irbs-and-protection-human-subjects-clinical-trials).
For your institution's specific rules regarding screening and research
procedures, refer to its specific IRB.
‚Äç
When double-screening makes sense
---------------------------------
If you want, your screening procedures can include a phone call to
potential candidates who seem most promising. Double-screening like this
typically isn't necessary, but it can be a good way to be absolutely
sure that you're getting the right people to talk to during your study.
We've seen researchers use double-screening when the study they're doing
is high-profile (visible to important stakeholders in their
organizations) or when they have a highly specific research need.¬†
Avoiding no-shows
-----------------
‚Äã‚ÄãPeople who promise to show up for your study and don't will cost you
time, and likely a moment of discomfort with colleagues and bosses who
are forced to sit around waiting. Save yourself some trouble and work to
prepare your participants and yourself to avoid the dreaded no-show.
-   Get your users contact information including email and cell phone.
-   Send reminder emails from an individual (not a generic group email).
-   Give participants your number or the number of the testing office so
    they can get in touch if they'll be late.
-   Send great instructions for how to get where they're going.
-   Most of all, stress the importance of their participation so that
    they're incentivized to show up because they're able to perceive
    their own value in the project.
Also consider being prepared by recruiting a few extra folks who you can
call in at the last minute, if need be.
‚Äç
In summary
----------
Long story short, envision your [ideal
participant](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)---know
who they are, know who they aren't---and build a screener survey that
allows you to filter out the right people to answer your research
question.¬†
The specifics of how to get there are outlined above. Just remember to
keep an open mind as to who these study participants might be, and don't
limit yourself with prejudgements mired in demographics.
We'll leave you with a few rules of thumb:
### Screener survey best practices
-   Eliminate people early---get the big, must-have criteria out of the
    way first.
-   Don't reveal what the study is about or who you're trying to
    recruit.
-   Don't screen for demographics unless *strictly* necessary.
-   Ask open-ended questions about behaviors, feelings, habits, and past
    actions..
-   Don't ask leading questions that hint at what the 'correct' answer
    might be.
-   Avoid 'yes' or 'no' questions.
-   Provide an 'other' option on multiple choice questions.
-   Keep it brief---10 (or fewer) screener questions is typically
    plenty.
Oh, and did we mention that you can build and fully customize screener
surveys with User Interviews? [Launch a research
project](https://www.userinterviews.com/) and easily build your
screener---we'll give you 3 free participants to get started.
What is a research incentive?
-----------------------------
An incentive is a reward that you offer participants in exchange for
taking part in your research. Incentives encourage participation, can
help you recruit a broader pool of participants, and thank people for
their time.
Incentives can be anything---from company swag to cold, hard cash. While
cash and cash-like rewards are the most common type of incentive, what
you offer should be based on who you're looking to recruit.¬†
Why participant compensation matters
------------------------------------
When it comes right down to it, incentives are a tool for attracting
quality applicants, getting a large volume of applications, and
encouraging people to show up for your study.¬†
What's more, as 18F, a digital consultancy for the US government
[explains](https://methods.18f.gov/fundamentals/incentives/):
> Incentives often result in a more diverse, representative set of
> participants. Without incentives, you often end up recruiting people
> with a strong intrinsic interest in your website. These people may not
> have the same needs and experiences as a less interested pool of
> users. With incentives, you can encourage less interested, more
> representative people to participate.¬†
But it's well worth mentioning that people ought to be compensated
simply because their time and their input are valuable. You probably
wouldn't bother inviting them to participate in your research
otherwise.¬†
And your time is valuable too! That's why it's so important to structure
your incentives appropriately so that your participants don't end up
leaving you and your team hanging at the last minute.
‚Äç
### Are there drawbacks to paying participants?
Some people worry that offering incentives to participate in user
research can compromise the results of a study. The argument goes that
doing so will:
-   Introduce bias and oversampling of certain groups.
-   Attract professional participants who lie about their eligibility to
    qualify.
-   Exclude people who aren't interested in the type of incentive you're
    offering.
-   Create a conflict of interest.
Laura Klein, user experience expert and author of *Build Better
Products* and *UX for Lean Startups* (and [Awkward
Silences](https://www.userinterviews.com/blog/laura-klein-on-building-products-that-dont-cause-emotional-trauma)
guest!),
[writes](https://guides.co/g/how-to-recruit-participants-for-user-research-ux-tests/8660):
> A lot of people ask whether offering some sort of incentive for people
> to participate in a study will bias the results. The answer is, "not
> if done correctly."¬†
And luckily, that's what this chapter is about---how to create a great
incentives plan!
###### **Note:** Certain participants simply cannot accept compensation for their time---government officials, for example. If you're recruiting participants who you know can't accept an incentive, don't offer one (just make sure you take extra care to thank them for their time).
How to create a UX research incentives plan
-------------------------------------------
Now that you know your options, let's go over how to create a plan for
user research incentives---including how to calculate the right amount
to pay, how to communicate about incentives, and how to distribute them
(which you should be prepared to do soon or immediately after each
session).
Firstly, know your audience...
‚Äç
### 1. Be clear about who you're trying to recruit (and why)
Before you can hammer out the specifics of your incentives plan, you
need to establish:
-   Clearly defined research goals and study objectives
-   Must-have participant criteria
-   Screener questions to filter out the right participants
We covered the first two items in-depth in the chapter on [How to
Recruit Participants for User Research
Studies](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants),
and we went deeper on [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
in the last chapter. If you haven't already, we recommend pausing to
read those before finalizing any incentive plans.
As a refresher, to figure out who to recruit for a study, you should
think about your research question, imagine the ideal participant who
can give you the answers you need, and identify the criteria that must
be true about them in order to qualify for your study.
‚Äç
#### To figure out who to recruit for UX research, ask yourself:
-   What phase of product development are you in?¬†
-   What is the goal of your research?¬†
-   What is your research question?¬†
-   Who can answer that question?¬†
-   Who *can't* answer that question?
The answers to these questions will help you create a profile of the
type of participant you're looking for---aka the folks you're trying to
attract and motivate with an incentive.
‚Äç
### 2. Choose the right type of incentive
To get really useful results you need to capture the right audience. So
how should you incentivize people to participate in your study?
Monetary incentives, including gift cards, are the most popular form of
incentive, but incentives can also be:
-   Account credits or discounts
-   Charitable donations
-   Swag
-   Early access to a feature
The most important thing about your incentives is that they are valuable
to your participants and that they get people excited about
participating in your research.¬†
‚Äç
#### Types of incentives and when to offer them
‚Äç
##### Cash-based incentives
Cash-based incentives are an understandably popular incentive format
from the participant side. Cash is straightforward---it's easy to pay
out, appeals to customers and non-customers, and gives participants the
flexibility to spend it however they want.
There are drawbacks to cash incentives, however. For one thing, some
participants are not able to accept cash---with government employees,
for example, cash might be considered a bribe. Other participants---such
as very high-income earners, current customers, or B2B prospects---might
not be as motivated by cash as they would be by account credits, swag,
or other types of incentives.
Cash-based incentives can also come with tax implications, depending on
how much you're paying and where both parties are located.
We recommend researchers use digital payment platforms like PayPal for
cash-based incentives (rather than, you know, sending participants a
stack of $20s). If you use [User Interviews for recruiting
participants](https://www.userinterviews.com/) for a study, you can
choose to have us instantly process incentive payments through gift
cards---we'll also automatically issue 1099s for your tax records.¬†
**Use cash-based incentives when you:**
-   Want a simple rewards payout
-   Are looking to attract a diverse audience, including non-users
-   Are recruiting for B2C studies
-   Need a lot of participants for a quick study
**Consider different methods if you:**
-   Are recruiting internationally and don't have a plan for converting
    currencies
-   Are looking to appeal to high-income earners or current customers
-   Are recruiting for B2B research
-   Want to include people like¬† government employees who cannot accept
    cash
-   Don't want to deal with the tax implications
##### Gift cards
Gift cards are cash equivalents, redeemable at particular retailers and
websites. They're another popular incentive format.¬†
They appeal to both customers and non-customers, may be permissible in
cases where people can't accept cash, and---while they don't offer
participants the same flexibility on where to spend them---still give
participants a degree of control over how to redeem their reward. And
sometimes gift cards can be more appealing to high income earners than
straight up cash.
But there are drawbacks here as well. If you're recruiting from an
international audience, bear in mind that the value of gift cards often
doesn't translate from country to country--- participants in San
Francisco are unlikely to appreciate a ‚Ç¨50 gift card to Dutch
supermarket chain Albert Heijn, just as users in the Netherlands would
find your generous offer of a $300 Applebee's gift card rather
worthless.¬†
In fact, many gift cards simply won't appeal to some people at all,
which is why we recommend offering participants the ability to choose
their own gift card from a list of popular retailers. Incentives are
always more valuable when they're relevant to the recipient.
Another thing to consider is that many of the same bribery and ethical
rules about not accepting cash incentives will apply to gift cards as
well. And as cash-equivalents, gift cards can have the same tax
implications as cash.
**Use gift cards incentives when you:**
-   Have a way to provide multiple gift card options
-   Are looking to attract a diverse audience, including non-users¬†
-   Want to broaden your study appeal to high-income participants
-   Are recruiting for B2C studies
-   Need a lot of participants for a quick study
**Consider different methods if you:**
-   Are recruiting internationally
-   Are recruiting for B2B research, especially with current customers
-   Want to include people who cannot accept cash equivalents
-   Don't want to deal with the tax implications
##### Account credits or product discounts
Product discounts or account credits can often trump cash-based
incentives when it comes to recruiting current customers.
If you're recruiting consumers, this can be as straightforward as a
coupon code for future purchases, or a reduced subscription price for
services.¬†
With B2B research, you'll want to consider whether the people you're
hoping to talk to are your users (people who actually use your product
day to day) or the people in charge of making purchasing decisions or
both.
If your users aren't the same people involved in purchasing decisions
for their team, they may be less motivated by account credits (they
won't personally see the reward---their company will). In this case,
other types of incentives may be more motivating. But account credits
can be a great way to appeal to B2B customers higher up the ladder.¬†
One benefit of using discounts and credits to incentivize participation
in research is that it costs nothing upfront and there's much less
administrative overhead---you don't have to worry about distributing
cash or gift cards to individuals. It can also be a great way to
encourage ongoing customer engagement with research.
But of course, this strategy is much less appealing to
non-customers---and unhappy customers, too, for that matter.
**Offer account credits or product discounts when you:**
-   Want to cut down on upfront costs and tedious administrative work¬†
-   Are looking to recruit (satisfied) customers
-   Want to speak to people with direct purchasing power¬†
-   Have a plan for keeping track of credits
**Consider different methods if you:**
-   Want to recruit non-customers and B2B users without purchasing power
-   Are looking for a diversity of feedback, including from unhappy
    customers
-   Don't have the authority or stakeholder approval to offer discounted
    rates
##### Swag
Don't underestimate the power of good swag. There is, after all, a whole
community of people dedicated to buying, selling, and trading Mailchimp
monkeys. (Related side note: Do any other New England kids remember
Dunkin Donuts' [Coolatta
bears](https://goodstuff1976.com/coolatta-bears)? Oh, to be a child in
2000...).
Swag---branded products that you give away for free---can be a great way
to motivate die-hard fans and current customers. And if you already have
swag on hand (hint: ask your marketing team), there's minimal (new) cost
to this strategy. Plus, it's free advertising for your company.
However, like account credits and discounts, swag won't appeal to
everyone. Non-customers are less likely to be motivated by branded
products, and no matter how cool your T-shirts are, they won't pay the
bills.
**Offer account credits or product discounts when you:**
-   Have swag to offer!
-   Are looking for a no (new) cost incentive strategy
-   Want to appeal to customers and fans
-   Are recruiting people who can't accept cash or cash equivalents
**Consider different methods if you:**
-   Want to recruit a diverse group of participants that includes
    non-customers
-   Believe your audience is motivated by cash or cash-equivalents
-   Need longer time commitments from participants (in-depth interviews,
    diary studies)
##### Other incentive types
If none of the common incentive types outlined above feel like the right
fit for your ideal participant profile, it may be time to get creative.¬†
Here are a few alternative incentive formats to consider:
-   **Charitable donations**---If your audience can't accept cash or
    cash equivalents, donations can be a meaningful way to reward their
    time. Consider offering participants a choice between several
    charities to make this option even more relevant. Of course, this
    strategy only works if your audience is motivated by social impact.
-   **Exclusive perks**---You might consider offering participants
    exclusive or early access to things like beta versions of an app, a
    sneak preview of upcoming releases, customer workshops, etc. This
    strategy is similar to swag and product discounts, in that it will
    primarily appeal to engaged customers and users.
-   **Large, lottery style rewards**---Rather than offering many smaller
    incentives, you might consider entering participants into a lottery
    style drawing for a few larger rewards. (i.e., instead of paying 50
    participants $75 each, you could offer participants a chance to
    earn one of three $1250 payouts).¬†
### 3. Calculate the correct incentive amount
Incentives are best when they're tailored to the task you're requesting
your participants to complete, the time commitment involved, and how
(in)convenient it is for users to participate.¬†
Some studies require more effort, time, and thought than others. For
example, if you're conducting a quick, unmoderated usability test, a
lower incentive is probably enough to compensate your participants. On
the other hand, if you're conducting a weeks-long diary study that
requires multiple interviews and diary entries, prepare to spend more on
your incentives.¬†
As a rule, moderated user research studies warrant a higher incentive
than unmoderated studies. That's because unmoderated research can often
be completed on the participant's own time, while moderated research
takes place at a specific time and requires more coordination and
communication between the researcher and participants.¬†
Essentially, the longer it takes participants to complete a study, the
higher their compensation should be. Ditto goes for effort---if
participants have to commute to an in-person study, download new
software, or make significant adjustments to their schedules, that
effort should be reflected in the incentive amount.
We also recommend participants be paid different amounts based on their
expertise. For example, if you need to talk to people about their
grocery shopping preferences, you don't need to recruit participants
with any kind of specialized experience. You just need general consumers
who buy groceries.¬†
But if you need to do research on the usability of a new EEG technology,
you need to talk to neuroscientists with specialized training. Because
you're drawing on this very niche skill, you'll have to pay more in
incentives to make it worth your participant's time.¬†
#### So wait... how much should user research participants get paid?
In our experience---and based on the number crunching we did to create
our [UX Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)---we've
found that the most successful researchers are the ones who pay the best
incentive they can reasonably afford.¬†
But if you're looking for a quick-and-dirty answer:
‚Äç
###### For most studies you should **aim for $60 - $100/hr.**
That's a threshold, after which you may need to adjust your incentive
amount based on things like how tricky it is to recruit your specific
participants, how meaningful cash or cash-like incentives are to them,
the nature of your study, and so on.¬†
For more detailed guidelines, see the quick reference guide below or use
the [UX Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
to get personalized recommendations based on your study's unique
criteria.
‚Äç
#### User research incentives recommendations
Use this [quick reference
guide](https://docs.google.com/document/d/e/2PACX-1vQYgHN7gqHflkZAIRwr_C4KQNoU8aeqeaRgcXJn4IgehUFmeb0pu3X2ZdP6ReoRksmBmMUQeZQu-gOG/pub)
to plan your incentives depending on the type, length, and audience for
your study. But remember: Our recommendations aren't hard-and-fast
rules. They're meant to be starting points for a larger conversation
about what incentive you should offer to get the best results from your
research.¬†
##### Moderated studies with general consumers
For studies that require specific behaviors or demographics but do not
require expertise in specific industries:
![](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a99f235eb4bfb896a7dd30_general-consumers_opt.png)
‚Äç
##### Moderated studies with professionals
For studies that require experts in specific fields or with specific job
titles.¬†
![](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a99f7f2903236416df57e0_professionals_opt.png)
‚Äç
##### For unmoderated studies:
![](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a99faf22edd999a1afb733_unmod_opt.png)
To really dig into the weeds of this topic, check out our report, [The
Ultimate Guide to User Research
Incentives](https://www.userinterviews.com/blog/the-ultimate-guide-to-user-research-incentives),
compiled from data from over 25,000 completed research sessions.
‚Äç
### 3. Decide how you're going to distribute incentives¬†
Incentives should be distributed as soon as possible after each session.
In fact, part of the appeal of digital gift cards and cash-based
incentives is that it's possible to send them to participants within
seconds of wrapping up a session.
For longer projects like diary studies, compensation can be broken up
and distributed at different times throughout the study to keep
participant motivation high over a longer period of time.
Details of how and when you'll distribute incentives should be clearly
communicated in the study description and in emails to participants
before and after the session.
To make sure the promised payout goes off without a hitch, you'll need a
plan for distributing incentives in a timely manner. This means
collecting the information you'll need ahead of time---email, address
(if sending swag), etc---and keeping track of who has received what (and
how much).
Or, if you're using [User Interviews](https://www.userinterviews.com/)
and you choose to distribute incentives as gift cards, you can opt to
have us handle distribution for you. Easy peasy.
Paying your participants appropriately is important, but a little
kindness and hospitality can go a long way too.
Treat each participant like an important guest, rather than an anonymous
test subject. Always emphasize the value of their contributions, and
thank them sincerely before and after the study.¬†
And do sweat the details. Make sure participants are aware of what's
required of them before the study, including any deal breakers such as
an NDA. Be clear and professional in all of your communications, ask for
consent before recording audio or video, and let people know they can
take a break or leave if necessary.
Part of being an effective researcher is showing participants their
input has value. Payment is one way of doing that, but don't discount
the impact of a good old fashioned 'thank you' as well.
