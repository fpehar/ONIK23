welcome to the UX¬†Research Field Guide

## Welcome!

Hi, hello, thank you. We're so---genuinely---glad you're here.¬† The UX
Research Field Guide is a comprehensive how-to guide to user research.
By the time you finish reading, you'll be a total pro at doing user
research---from planning it to conducting sessions to analyzing and
reporting your findings.¬† This is actually the second edition of the UX
Research Field Guide. With the help of our own User Research team, we've
refreshed, redesigned, and expanded on the original... and we're proud
to say we think this version is even better than the first! ‚Äç We\'ve
relaunched with 4 fresh and refreshed modules---UX¬†Research
Fundamentals, Planning UX¬†Research, Recruiting for UX¬†Research, and
UX¬†Research Methodologies. We'll be rolling out some pretty major
updates to modules 5-9, including fresh templates and resources for
doing UX research. We'll also be publishing lots of brand new chapters
in 2022. Sign up, stay tuned, and happy researching!

![person standing next to a cluster of graphs, charts, and
diagrams](https://global-uploads.webflow.com/59ace8427353c50001765cbd/61a4f7bccce40318c5106f25_intro-image%402x.png)

what\'s inside

## Table of Contents

[](/ux-research-field-guide-module/ux-research-basics)

### Introduction

[](/ux-research-field-guide-module/user-research-fundamentals)

01\.

### UX Research Fundamentals

[](/ux-research-field-guide-module/planning-user-research)

02\.

### Planning UX Research

[](/ux-research-field-guide-module/recruiting)

03\.

### Recruiting for UX Research

[](/ux-research-field-guide-module/user-research-methods)

04\.

### UX Research Methodologies

[](/ux-research-field-guide-module/discovery-methods)

05\.

### Discovery Research Methods

[](/ux-research-field-guide-module/evaluative-methods)

06\.

### Evaluative Research Methods

[](/ux-research-field-guide-module/continuous-research-methods)

07\.

### Continuous Research Methods

[](/ux-research-field-guide-module/research-analysis-synthesis)

08\.

### UX Research Analysis and Synthesis

[](/ux-research-field-guide-module/research-deliverables-reporting)

09\.

### UX Research Reports & Deliverables

[](/ux-research-field-guide-module/more-resources)

### Appendix

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Introduction](/ux-research-field-guide-module/ux-research-basics)

![a person navigating a collage of browser windows and graphs
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f0a74b421176517ca6ef_UI_CHAPTER_INTRO_ARTWORK.jpg)

# Introduction

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Here's the thing about user research. It's incredibly important, but it
doesn't have to be that hard.¬†

‚Äç

Hear us out: We know it's hard to find the time, and the budget, and
manage the logistics, and do the recruiting, gather and analyze
insights, run presentations, and the list goes on. Those things are hard
and this field guide exists in large part to make those things a little
easier.

‚Äç

What doesn't need to be that hard is getting started, doing something
instead of nothing, regularly practicing the bold act of actually
talking to your users, customers, and would-be users and customers.¬†

‚Äç

If you read nothing else, and we really hope you WILL read something
else, read this. If you are already humming along with a kickass
research program, feel free to subscribe to more targeted chapters that
suit your needs by clicking anywhere you see \"Subscribe.\" Or just
navigate to the Field Guide index and explore.

‚Äç

Without further ado, here are some well-loved tips among the UX research
community to conduct effective user research and interviews. Consider
this your MVR (minimum viable research) cheat sheet.

‚Äç

"A professional researcher might do better interviews, but most people
are capable of research that is good enough." --- Jonny Schneider,
Finding the Fastest Path to Feedback

‚Äç

## Minimum viable user research tips

### Recruit about 5 "good" people

While qualitative research can be time consuming, the good news is you
really only need to talk to about 5 people before you hit a point of
diminishing returns in terms of insights. Of course, that entirely
hinges on finding the right people. This doesn't have to be complicated.

-   **Know your learning goals** for research. Use that to determine
    your right audience.
-   **Determine if you need existing or target users**---a good rule of
    thumb is for new power features of your existing product, talk to
    existing users, for out-of-the-box perspective on a brand new
    feature or product, talk to your target users
-   **Build a simple screener survey** to identify and filter out people
    who will give you diversity and relevance of insight. Pro tip: Don't
    over-screen. We see this a lot.
-   **Distribute your survey** to a list you manage or using a
    third-party service or platform.
-   **Contact 5 people** to set up in-person or remote sessions with the
    relevant directions, web meeting links, etc. You might do a second
    round if you get a couple no-shows or you didn't get the insights
    you were looking for. It does happen.
-   **Compress the timeframe of sessions** so you can focus, build
    momentum, and get to action faster.

‚Äç

Here's where we subtly throw in that [User Interviews](#) makes all this
that much easier and sometimes cheaper, but of course you can do this
manually if you like. Google Sheets + Craigslist + Mail merge FTW!

##### **üìñ Learn more about** [**Recruiting for UX¬†Research**](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)

### Write a quick moderator guide

This need not take more than 15 minutes or so for MVR. Don't go into a
session without a simple set of questions.

-   **Plop your research mission and learning goals on top of your
    guide** for a steady reminder and thing to go back to as your
    session progresses. Make sure whatever else happens---sessions are
    predictable in their unpredictability if nothing else---you get back
    to the matter at hand.
-   **Have a hypothesis or assumption you want to test**, but be totally
    prepared to be wrong and watch out for unconscious bias. The below
    point is your friend here.
-   **Use open ended, why oriented questions**, focus on past behavior
    vs hypothetical future behavior, and avoid adjectives---let your
    participant decide on the adjectives that describe their experience.
-   **Write your opening and closing, verbatim.** Choose something warm,
    authentic to how you actually talk, that puts the participant at
    ease. If you get flustered or things go off script, you can just
    read this in the moment.

‚Äç

### Run an effective session

You are a human, talking to another human. What an amazing opportunity
to get permission to connect with someone you wouldn't otherwise. Be
warm, be authentic, be yourself, just don't get too chummy or start
influencing the participant's ideas with your own enthusiasm. Be a
professional.

-   **Listen lots, talk little**, get comfy with silence. Watch people
    too. What do they do with your prototype, site? Behavior, behavior,
    behavior.
-   **Show something if you have something to show,** but focus on one
    thing at a time.
-   **Probe, give context, set expectations** about why you're here and
    what you're trying to accomplish. Don't share your assumptions or
    hypothesis.
-   **Take notes.** If you can spare someone to take notes for you or
    use a transcription or recording service, that means you can really
    focus on being present in the session, which will help you pick up
    on all those juicy micro-moments.

‚Äç

### Review, and share, results

Don't let your research die in the session itself. Again, don't
over-complicate this if time is not a luxury you have.

-   **Highlight key insights**, quotes, thoughts from each session
    immediately after, if you can.
-   **Review all your notes.** Look for themes. Highlight those themes
    and supporting evidence in a document of your choosing, something
    that is easy for you and acceptable to your audience of
    stakeholders.
-   **Share your insights!** Different organizations do this in
    different ways, and we'll cover this in depth later. At a minimum,
    shoot a Slack or email linking to your document and host it
    somewhere people can access it on demand. You've done important
    work. Don't hide it.
-   **Connect with your stakeholders** (product, sprint, design team,
    whoever you're working with on the research) ASAP with your insights
    and move things forward!

‚Äç

That's it. Of course there's much more to cover, and cover it we will,
but hopefully the above tips empower you to just get out there and do
some research today. Building a regular research habit is the best way
to build discipline in yourself, your organization, and to consistently
show its importance to your product and customers.

##### **üìñ Learn more about** [**UX¬†Research Reports and Deliverables**](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)

‚Äç

## What does User Interviews know about UX research?

Quite a lot, as it happens.

‚Äç

For starters, we're a UX research tool---more specifically, User
Interviews is a user research recruiting and participant management
platform. We exist to solve the pain point of user research
recruiting---especially for qualitative research studies with niche
requirements.¬†

‚Äç

For another thing, User Interviews exists in large part because our
founders needed to recruit participants for their own research---and
they hated it. After doing some user research, they found out other
people hated it, too.

‚Äç

And so, the idea that eventually became User Interviews was born.¬†

‚Äç

You can read all about how our founders pivoted from a failed startup to
a \$10 million Series A through (meta) user research in [this
article](https://www.userinterviews.com/blog/from-failure-to-a-venture-backed-startup-through-meta-user-research).
In addition to being our origin story, it's also a compelling case study
on the power of user research!

‚Äç

##### **üëã Read the User Interviews** [**origin story**](#)

## How to use this Field Guide

The UX Research Field Guide is meant to be read cover-to-cover---the
outline roughly follows the UX research process, and the knowledge you
acquire in one module can be applied and built upon in the next.

‚Äç

Over the course of this Field Guide, we'll dive deeper into the various
UX research methods, as well as the foundational knowledge and research
skills you'll need to effectively plan, recruit for, execute, and report
on your user research efforts.

‚Äç

But you don't need to read the full Field Guide to get started, and many
of you out there might be seasoned pros just looking to brush up on a
couple topics (hence "Field Guide"). Each chapter is designed to stand
on its own, so you can also skip around to the chapters that are
relevant to you.

‚Äç

We're relaunching the UX Research Field Guide with 4 refresh and
refreshed modules:

1.  [UX Research
    Fundamentals](https://www.userinterviews.com/ux-research-field-guide-module/user-research-fundamentals)
2.  [Planning UX
    Research](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)
3.  [Recruiting for UX
    Research](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
4.  [UX Research
    Methodologies](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods)

‚Äç

You'll notice that the later modules include a note about upcoming
release dates. Over the coming weeks, we'll be rolling out some pretty
major updates to the content in those modules, including fresh templates
and resources for doing UX research.

‚Äç

You can still read and find a ton of value in the original chapters, but
we highly recommend signing up to receive the UX Research Field Guide
over the course of 10 weekly emails. You'll get the latest edition of
each chapter, along with a top-level summary of the module topic and a
special email-exclusive pearl of user research wisdom from the User
Interviews UXR team.

‚Äç

You'll also receive brand new chapters as they're published. Those
chapters---like the ones on co-design, preference testing, and research
synthesis---are denoted by a "Coming Soon" tag in the Field Guide
itself.¬†¬†

‚Äç

Don't see one of your favorite methods or a need-to-know topic on our
list of upcoming chapters? Hit me up at <katryna@userinterviews.com> to
request future content.

‚Äç

And with that... happy researching, folks!

[Start reading](#)[Start
reading](/ux-research-field-guide-module/user-research-fundamentals)

In this module:

[](#)

[](#)

[](#)

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/user-research-fundamentals)

01\.

### UX Research Fundamentals

[](/ux-research-field-guide-module/planning-user-research)

02\.

### Planning UX Research

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Fundamentals](/ux-research-field-guide-module/user-research-fundamentals)

![a woman searching a landscape with binoculars that also mimics a
search
bar](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f0b6abed596e4c9106c8_UI_CHAPTER_01_ARTWORK.jpg)

01\.

# UX Research Fundamentals

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

When in doubt, talk to people.

‚Äç

It's a simple principle underlying user research---but in practice?
Designing, conducting, and analyzing user research requires skill,
forethought, and flexibility.¬†

‚Äç

In this module, you'll find all the knowledge you need to begin
practicing user research like a pro, including:

-   **The definition and benefits** of user research (aka UX research or
    user experience research)
-   **An end-to-end overview** of the UX research process, from choosing
    your method to analyzing and reporting results¬†
-   **An intro to the different types of user research**, including
    qualitative and quantitative, generative and evaluative, attitudinal
    and behavioral, and moderated and unmoderated
-   **Tips and best practices** for recruiting research participants,
    conducting stakeholder interviews, designing screener surveys, and
    distributing incentives

‚Äç

Regardless of methodology, the big-picture goal of user research is
always: to understand and build empathy for users in order to make
better decisions, build better product experiences, and create solutions
people actually want.

[Start
reading](/ux-research-field-guide-chapter/what-is-user-research)[Start
reading](/ux-research-field-guide-module/planning-user-research)

In this module:

[What Is User
Research?](/ux-research-field-guide-chapter/what-is-user-research)

An essential primer to user experience research and why it matters

[The User Research
Process](/ux-research-field-guide-chapter/user-research-process-fundamentals)

How to do user research in 7(ish) steps---an overview of the UXR process

[User Research
Questions](/ux-research-field-guide-chapter/user-research-questions)

New

New

New

Ask better questions, get better answers. It's as simple as that.

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### What Is User Research?

An essential primer to user experience research and why it matters

##### The User Research Process

How to do user research in 7(ish) steps---an overview of the UXR process

##### User Research Questions

New

New

New

Ask better questions, get better answers. It's as simple as that.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/planning-user-research)

02\.

### Planning UX Research

[](/ux-research-field-guide-module/recruiting)

03\.

### Recruiting for UX Research

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Fundamentals](/ux-research-field-guide-module/user-research-fundamentals)

\>

[What Is User
Research?](/ux-research-field-guide-chapter/what-is-user-research)

# What Is User Research?

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

The UX Research Field Guide is a comprehensive how-to guide to user
research. By the time you finish reading, you'll be a total pro at doing
user research---from planning it to conducting sessions to analyzing and
reporting your findings.¬†

‚Äç

Okay, actually that's a bit of a fib. To become a total pro, you need to
actually put the learnings from this Field Guide into practice (aka, do
some research). But this Field Guide does contain all the knowledge you
need to design, conduct, and analyze user research.

‚Äç

Before we get into all of that, however, let's take a step back and
answer the essential question:

‚Äç

## What is user research?¬†¬†

**User research** is the practice of researching users. Pretty
straightforward, right?¬†

‚Äç

Well, yes and no.¬†

‚Äç

As we'll see in this Field Guide, user research---or **UX research**, or
**user experience research**---takes many different forms. The methods
can be [qualitative or
quantitative](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
(and indeed the most impactful research studies often combine both types
of methods), and can range from observing people in their environment to
tracking their eye movements in a lab.

‚Äç

Regardless of methodology, the big-picture goal of user research is the
same: to understand and build empathy for users in order to make better
decisions, build better product experiences, and create solutions people
actually want.¬†

‚Äç

And businesses invest in user research because creating solutions people
want is a great way to make money.

‚Äç

### Is user research the same thing as user testing?

User testing, also called **usability testing**, is a type of user
research in which participants are asked to perform tasks, typically
within a specific interface. These sessions can be unmoderated (the user
is prompted by a testing tool, and is not observed in real time) or
moderated by a facilitator.¬†

[Usability
testing](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing)---which
we will discuss in-depth in the aptly named Usability Testing
chapter---can be either qualitative or quantitative in nature.

‚Äç

## Types of user research¬†¬†

As we mentioned, user research comes in all shapes and sizes---from
months-long diary studies to five-second tests.¬†

There are many different kinds of UX research, depending on how you
slice it. We give a more thorough primer on the different categories [in
a later
chapter.](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
For now, here's what you need to know\...

User research can be:

‚Äç

#### Qualitative or quantitative (or both)

The primary difference between [qualitative and quantitative UX
research](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
lies in the nature of the data.¬†

**Quantitative UX research** produces quantifiable data, aka numbers. It
typically involves collecting and analyzing data from a large number of
people to unambiguously answer questions like "how much?", "how many?",
and "how often?"

**Examples of quantitative research methods:**

-   [Usability
    studies](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing)
-   Surveys
-   [First click
    tests](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing)
-   [Tree
    tests](https://www.userinterviews.com/ux-research-field-guide-chapter/tree-testing)
-   [A/B
    tests](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing)

**Qualitative UX research**, on the other hand, involves directly
assessing behaviors and beliefs to produce data on user preferences,
motivations, and pain points. Due to its often subjective nature,
qualitative methods ultimately rely on researcher analysis and
interpretation to uncover patterns and answer the question: "Why?"

**Examples of qualitative research methods:**

-   [Usability
    studies](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing)
-   [Interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
-   [Focus
    groups](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups)
-   [Field
    studies](https://www.userinterviews.com/ux-research-field-guide-chapter/field-studies)
-   [Diary/camera
    studies](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies)
-   Co-design

**Mixed methods research** is exactly what it sounds like---the practice
of using multiple kinds of research methods to answer research
questions. Quant and qual are complementary---used together, they
provide nuanced, data-backed insights that can help teams make more
confident, user-centric decisions.

**Note:** The term mixed methods is used when the methods you're mixing
are both quantitative and qualitative.¬† If you're blending multiple
qualitative methods (and you often will), that's called **hybrid
research.**

#### Generative or evaluative

The difference between generative and evaluative methods lies in when
the data is collected---and why.¬†

**Generative UX research** (also called **discovery research** or
**exploratory research**) involves direct observation, deep inquiry, and
careful analysis to develop a rounded understanding of users---who they
are, what they care about, what drives their behavior and decisions, and
so on. The data from this type of research helps generate ideas and
discover opportunities for improvement.

**Examples of generative research methods:**

-   [Stakeholder
    interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)
-   In-depth user interviews
-   Focus groups (sometimes)
-   Diary studies
-   Card sorting

**Evaluative UX research** helps teams figure out if an existing (or
in-development) solution is on the right track---is it meeting user
expectations, is it addressing their needs, is it desirable? Although
evaluative UX research comes after discovery work, don't wait until you
have a polished product to test your ideas---validate early and often.

**Examples of evaluative research methods:**

-   Usability tests
-   Surveys
-   Preference tests
-   First click tests
-   A/B tests
-   Tree tests
-   [Task
    analysis](https://www.userinterviews.com/ux-research-field-guide-chapter/task-analysis)

#### Attitudinal or behavioral

The difference between attitudinal and behavioral research methods lies
in who is describing the user.

**Attitudinal UX research methods** rely on self-reported data---in
these methods, study participants tell researchers what they think. The
data reflects people's stated beliefs, perceptions, and expectations.
Because some people aren't able to fully articulate their
perceptions---and because human beings are notoriously bad at predicting
their own behavior---attitudinal data requires careful interpretation,
and cannot always be taken at face value.

**Examples of attitudinal research methods:**

-   In-depth interviews
-   Surveys (including [feedback
    surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys))
-   Focus groups
-   Card sorts

**Behavioral UX research methods** involve observing user behavior,
either in the field or during prototype and product testing. Behavioral
research data is reported by the user researcher (or by a usability
testing tool).

**Examples of behavioral research methods:**

-   [Ethnographic field
    studies](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography)
-   Eye tracking
-   A/B tests
-   First click tests
-   [User
    analytics](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics)

Many research methods produce both attitudinal and behavioral
data---when interviewing users, for example, researchers may also take
note of body language and non-verbal cues.

#### Moderated or unmoderated

The difference between moderated and unmoderated research methods lies
in the role of the researcher.¬†

In moderated research, the researcher is involved during the research
session. Depending on the method, they may be observers or may take a
more active role as facilitators. Real-time moderation allows
researchers to adapt their script and process in response to participant
actions and engagement, and also to ask follow-up questions that probe
more deeply into why participants make certain choices.¬†

**Examples of research methods that are typically moderated:**

-   Interviews
-   Ethnographic field studies
-   Focus groups
-   Task analysis

In unmoderated research, researchers sit on the sidelines as
participants complete unobserved tests using testing platforms or tools
that play the role of the researcher, prompting them to answer specific
questions or perform specific tasks. Because it's hands-off and can be
conducted asynchronously, unmoderated testing is often faster and less
expensive on a per-participant basis.

**Examples of research methods that are typically unmoderated:**

-   Surveys
-   First click tests
-   A/B tests
-   User analytics

‚Äç

## When in the product development cycle should UX research happen?

User research is sometimes thought of as a process that happens
pre-design and development, with a bit of market research thrown in at
the end.

But really, research has a valuable role to play at every stage of
product development. The goals of your research---the questions you're
trying to answer, the decisions you're trying to facilitate---will
change over the course of the product development cycle, as will the
methods you use.

‚Äç

### Discovery (pre-prototype) stage

Most projects begin with some
[discovery](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods),
in which you're trying to pinpoint the problem and get a clearer picture
of who you're solving it for.¬†

Your goals at this stage should be aimed at developing a detailed
understanding of potential users, their needs, and their context. To do
this, researchers use generative research methods like internal
stakeholder interviews, user interviews, diary studies, card sorts, or
even ethnographic field studies.

You might also use methods like surveys (with open-ended questions),
existing product data, competitive analysis, literature reviews, and
other fact-finding methods to gain a more detailed understanding of the
context.

#### Why research is so important in the discovery phase

A great product that doesn't solve a market need is not a great product.
Don't rely on your instincts (trust us), don't try to copy what's worked
in the past, and don't hang your hat on a bunch of quant that doesn't
provide context for the 'why' behind the 'what'. When in doubt, talk to
people.

#### Key discovery methods:

-   **Stakeholder interviews** help you understand your key
    stakeholders' goals, needs, and existing knowledge.¬†
-   **Ethnography** is all about observing people and their habits in
    context. What people do is so often different from what they report,
    and ethnographic studies can be a great way of getting around this
    issue.
-   **Diary studies** provide insights into user habits, changes over
    time, motivations, and long-term customer journeys.¬†
-   **Focus groups** allow you to observe a lot of people relatively
    quickly. In the early stages of research, this method can be a
    useful way to get a broad-strokes view of your target audience.¬†
-   **Generative user interviews** involve talking to participants
    one-on-one, asking them a set of non-leading questions, with an
    emphasis on past behaviors and perceptions.¬†

‚Äç

##### üìñ **Read more about** [**Discovery Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)

### Validation and testing (prototype)

Once you're actively building, you'll want to [evaluate your
solutions](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods)
and validate your decisions. At this point, you have a good sense of
your market, user needs and pain points, and will have a concept of what
kind of solution you can offer. You've taken those ideas and built some
wireframes, high fidelity mockups, or interactive prototypes.¬†

Now, you need to understand if these designs help users solve their
problems, how they interact with them, and where they get hung up.

Your goal at this stage will be to answer questions about conceptual fit
and the usability of the product using¬† evaluative research methods like
usability tests, preference tests, A/B tests, tree tests, first click
tests (so many tests!), and task analysis.¬†

#### Why research is so important in the validation and testing phase

If knowing what product to build in the first place is the most
important aspect of research, understanding whether or not you're
succeeding in building that product is certainly a close runner up.¬†

The more variety you can present in your prototypes the better. Try a
few out of the box ideas next to what feels "safe." Truly, you never
know how users will react unless you test.¬†

And that's why this stage is so very important. You may even be missing
key features you haven\'t thought of. Once you have your analysis in,
you can refine your prototypes and re-test until you've found a solution
you (and your participants) are happy with.

‚Äç

#### Key validation and testing methods

-   ‚Äç**Qualitative usability testing** involves having participants think
    aloud as they interact with a prototype or product, which allows
    researchers to evaluate implicit and explicit cues and find patterns
    quickly.¬†**‚Äç**
-   **Task analysis** helps you better understand your user's goals, and
    how they go about achieving them. It is often coupled with other
    methods.**‚Äç**
-   **A/B testing and multivariate testing** is used to collect
    quantitative data on which version of your product performs better
    or best achieves the goal of the test.**‚Äç**
-   **First click testing** is just what it sounds like. It's a popular
    way to assess the user's ability to efficiently and effectively
    complete a task.**‚Äç**
-   **Card sorting and tree testing** are methods for testing your
    information architecture (IA), i.e. how you categorize and label
    content.¬†**‚Äç**
-   **Accessibility testing** is used to stress test prototypes or
    products that, ideally, have already been designed based on input
    from a diverse group of participants in the discovery phase. In
    addition to running your product through accessibility checking
    tools, consider conducting qualitative usability studies with
    participants with disabilities.

‚Äç

##### üìñ **Read more about** [**Evaluative Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods)

### On-going listening (post-launch)¬†

User research doesn't (or shouldn't) stop once you've launched a product
or feature.¬†

‚Äç

For one thing, you'll need to monitor user feedback to understand how
well your product continues to meet customer needs. And what's more,
those user needs will likely change---and you'll need to keep your
finger on the pulse of that, too.

‚Äç

To do this, researchers conduct ongoing UX research. This often involves
partnering with product, marketing, and support teams to implement and
monitor things like intercept surveys, user analytics, NPS scores, and
support tickets.

‚Äç

[Continuous
research](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods)
might also involve interviewing or re-interviewing customers to provide
additional context to quantitative ongoing listening methods.¬†

‚Äç

#### Why research is so important in the post-launch stage

You've been testing throughout the previous stages of product
development. You have a good sense of who your users are, and the
context they live in when using your product. You know which solutions
will best solve their problems and empower them to complete tasks they
value. You've built those solutions and they are live. You are done!

Except, you are not done.¬†

Here's why: First, if you've focused on qualitative data to date (good
for you, we love qualitative data) you have not thoroughly tested your
actual product in the wild with a multitude of quantitative data. You'll
want to make sure what you put out there is accomplishing the goals you
set for it in the first place.¬†

Second, things change. What worked well a year ago or more may no longer
be the best solution. You may get hints of this through ad hoc user
feedback, NPS scores, proactive surveys, or other channels. You'll want
to adapt.¬†

Finally, you create a very good solution to the user's problem---yet
it's very possible that you did not create the perfect solution.

Keep testing and optimizing until you hit a point of diminishing
returns. Some features are less critical than others, and good enough
may very well be good enough. Others are essential to the success of
your product.¬† In any case, "set it and forget it" is not a smart
product strategy. Ongoing listening methods help keep your product
useful, impactful, and relevant over the long-haul.

#### Key ongoing listening methods

-   ‚Äç**Surveys---**which include user intercept (in-app) surveys, NPS
    surveys, and longer surveys that dig into specific aspects of the
    user experience---are a scalable method for collecting attitudinal
    data on a continuous basis.**‚Äç**
-   **Analytics** provide quantitative data about things like key user
    flows, in-app behaviors, and business metrics that can be a treasure
    trove if you know how to analyze them and connect insight to
    action.¬†**‚Äç**
-   **Bug and support tickets** can help you understand where current or
    historical frustrations may have impacted the user experience in
    ways you wouldn't have known otherwise. Similarly, FAQ and support
    desk reporting can help you understand where users are getting
    stuck.¬†

‚Äç

##### üìñ **Read more about** [**Continuous Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods)

‚Äç

## Why do user research

This is the first question many stakeholders will ask. Since user
research costs the company time and money, early champions for UXR often
find themselves having to justify its value to others in the
organization.

The fact is, research isn't an add-on or a nice-to-have, it's an
essential part of the product development process. There are plenty of
very good reasons to do user research---here are some of the big
ones....

### The benefits of user research¬†

#### 1. UX research reveals gaps in your knowledge

User researchers are human beings and human beings are flawed. Very,
very flawed. In fact, user researchers often refer to a huge [cognitive
bias
map](https://betterhumans.pub/cognitive-bias-cheat-sheet-55a472476b18)
to keep track of the various ways our brain can trick us into making
decisions without enough information. One of these cognitive biases is
called false consensus---that little voice in your head that says "it's
ok, everyone will interact with this thing the same way I do."¬†

![cognitive bias codex
map](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a9807dce1aca565d84161d_bias%20map.jpeg)

[Image
source](https://betterhumans.pub/cognitive-bias-cheat-sheet-55a472476b18)

But the truth is, no matter how smart your people are, no matter how
much they all personally use your product, no matter how long they've
all worked on this project, you need to talk to the people outside of
your organization who will eventually buy or use your product.¬†

Because you don't know what you don't know, and you can't build what
people want if you don't know what they want.

‚Äç

#### 2. UX research helps you create better customer experiences

User research can help you understand the motivations behind user
behaviors, uncover problems that need solving, and develop relevant
solutions with market appeal. It can also give your team invaluable
insight into the customer experience, and identify opportunities to
improve it.

Conducting UX research can teach you:

-   The real-world context in which people use (or could use) your
    product.
-   How people are currently solving the problem you're designing for.
-   What the customer journey looks like.
-   Whether or not your design is intuitive.
-   Which version of a design people prefer.
-   Where---and why---users are getting stuck.
-   How customers really use your product.
-   What they'd change about it.
-   Whether or not the UX is truly accessible to real users.
-   And so on.

Whether you're shipping a new feature, iterating on an existing
interface, or launching a new product into the market, a dash of user
research can help make it better.

‚Äç

#### 3. UX research is good for business¬†

User research is a risk mitigation strategy---it can help save companies
from wasting heaps of precious time (and therefore money!) on misguided
projects.¬†

Dr. Susan Weinschenk, in partnership with Human Factors International,
[calculated](https://www.youtube.com/watch?v=O94kYyzqvTc) that the cost
of fixing a problem post-development was 100x that of fixing it
beforehand, and developers spent 50% of their time on rework that could
have been avoided.

Fixing a problem post-development at 100x cost is a big deal---it can
even mean the problem doesn't get fixed at all, if there's no time or
budget left to devote to that project.¬†

Even though user research can have modest upfront costs, it's much
better (and cheaper!) than spending more time and money later on a
problem that could have been avoided from the beginning.

And we should know---User Interviews actually began as MobileSuites, an
app that helped people staying in hotels check in and access amenities
straight from their phone. Our founders thought it was a really cool
idea and they started building. There was just one problem\... Once it
actually made it out into the world, it wasn't as valuable to customers
as they thought it would be. So, with a failed idea and 100k left in the
bank, [they
pivoted](https://www.userinterviews.com/blog/from-failure-to-a-venture-backed-startup-through-meta-user-research).¬†

Our founders started testing new product ideas. In the process, they
discovered that trying to find people to talk to about product ideas was
actually pretty difficult. They started hearing this from other people,
too---and realized there was an opportunity here.

So they set a benchmark to prove that this problem actually existed and
people would pay them to solve it: If more than 50% of the people they
talked to brought up "participant recruitment" or "scheduling" naturally
as one of their top 3 user research pain points, our founders would be
in business.¬†

The key was waiting for participants to bring up these problems on their
own---our founders asked what people's biggest problems were, based on
real past experiences, and let them tell us what they needed.¬†

Sure enough, user researchers needed a better way to recruit
participants. Fast forward 6 years, 50,000 projects launched and one
\$10 million Series A later and we can confidently say that UX research
is good for business.

‚Äç

##### **üëã Read the User Interviews** [**origin story**](https://www.userinterviews.com/blog/from-failure-to-a-venture-backed-startup-through-meta-user-research)

## So.. how do you do user research?

That's what the UX Research Field Guide is all about!¬†

We shared a framework for Minimum Viable Research in the
[Introduction](https://www.userinterviews.com/ux-research-field-guide-module/ux-research-basics),
if you're looking for the TL;DR "I've got to do user research like,
right this second" version.¬†

Otherwise, head to the next chapter for a closer look at the [UX
research
process](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-process-fundamentals),
step by step.

[](#) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/user-research-process-fundamentals)

Next:

The User Research Process

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Fundamentals](/ux-research-field-guide-module/user-research-fundamentals)

\>

[The User Research
Process](/ux-research-field-guide-chapter/user-research-process-fundamentals)

# The User Research Process

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Whether you're an experienced UX researcher, a product manager who plays
researcher from time to time, or someone new to the field entirely, we
hope this guide has a little something for everyone.¬†

In this chapter, we'll focus on the UX research process as we'll
describe it throughout the Field Guide. Think of it as a framework for
infusing research throughout the product development cycle. Your product
development cycle might look a bit different---but no matter. Details
aren't critical here and the framework is flexible.

Here it is, the UX research process in 7(ish) steps:

‚Äç

## Step 1. Identify your research goals

This is the first and most important step in any user research study.
Without clear goals and objectives, you're just fumbling in the dark.
And that's no way to conduct user research.

When launching a research project or sprint, work backwards. Why are we
doing this research? What do the internal stakeholders need to learn to
move the product forward? What information would be actionable?¬†

‚Äç

#### To identify your research goals, consider:

-   **What do I want to know?** This is the core question, and will be
    further refined into¬† specific, actionable, and practical research
    questions.¬†
-   **What don't I know?** Identify knowledge gaps and limitations
    early, so you can aim to correct for them.
-   **How will I know when I've learned it?** What must be true in order
    for this research to be considered "done"?
-   **What company goals will this work support?** It's always a good
    idea to be familiar with your organization's business model and key
    performance metrics.¬†
-   **Where am I in the product development process?** Your research
    goals will look different depending on whether you're in the
    discovery, validation and testing, launch, or ongoing listening
    phase.¬†
-   **What decision will this research enable?** How will stakeholders
    act on the information you learn through your research?¬†
-   **What are the anticipated outcomes of this research?** What would
    success look like for you?¬†

‚Äç

###### **Pro tip:** Once I determine research is, in fact, needed around a particular area, I'll involve my team by hosting a brainstorm session where we start to tease apart facts, opinions & guesses related to the research area. This helps us to think holistically about any existing research we can use and gives us a chance to think broadly about the problem space before jumping into a specific method. -- Roberta Dombrowski, VP of User Research at User Interviews

‚Äç

### Conduct stakeholder interviews

Your stakeholders are people who have a vested interest in the outcomes
of your research. There are external stakeholders (your users,
customers) and internal stakeholders (your boss, the product design
team, clients if you work at agency).¬†

When we talk about stakeholder research, we're talking about internal
stakeholders. These are the people within your organization (or client's
organization) who:

-   Have influence within their company and department
-   Make decisions about time, money, and resources
-   Are involved in the UX and product design process
-   Have information relevant to your project
-   Will be expected to act on research insights

‚Äç

People don't have to tick every one of those boxes to be considered a
stakeholder---not at all, in fact. Any one of those criteria makes
someone a qualified candidate for [stakeholder
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)
(though in many cases you'll need to narrow the list down to someone who
does, indeed tick multiple boxes on that list).

‚Äç

Once you've identified the people you need to talk to, you're going to
want to put together a plan for interviewing them. This doesn't need to
be intricate.¬†

‚Äç

Start with your research question. In the case of stakeholder
interviews, the key question to ask yourself will be:

What do I need to learn in order to move forward with this research
project?

Your answers to that question---i.e., the things you don't yet know and
need to learn---can then be spun up into a loose moderator guide.¬†

Here's an example of a stakeholder interview moderator guide:

-   Introductions (state your purpose)
-   Why is this project important?¬†
-   What does success look like for this project? How does it fit into
    the broader context of the business?
-   What is your role in this project? What would you like it to be?
-   How will this project impact your day-to-day and your overall job?
-   What challenges do you foresee this project possibly running into?
-   What questions do you have for me?
-   Wrap it up (thank people for their time)

And here\'s a
[template](https://docs.google.com/document/d/e/2PACX-1vQB_Q5SMRfIneojzHmcp99tdecaPgDzoyxdXPNAuuCZr1t-ORQr3fc-Q4Ih8yqiL3X_C4AoIhIXmkLp/pub)
for you to adapt!

We use the term 'guide' rather than 'script' intentionally---remember to
leave time for asking follow-up questions and room in the conversation
for it to flow naturally. Refer back to your guide if things start going
off-track, but don't let sticking to your list of questions keep you
from hearing the really interesting answers!

‚Äç

### Develop the right research questions

Your [research
questions](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)
should stem from the goals you identified in the previous steps. What is
it that you're trying to learn?

**Good research questions are:**

-   Specific---so you'll know when you have found an answer.¬†
-   Practical---i.e. they can realistically be answered by your research
    project¬†
-   Actionable---so your team can act on the results.

**For example:**

-   Are our customers able to successfully navigate to the support page
    on our site?
-   Which websites do people over the age of 55 use to look up
    information about health?
-   Do people understand our blog categories and what content might
    belong in them?
-   What tools do college students use to keep track of their schedules?
-   Which CTA has a higher conversion rate?

Each of these questions could be answered through targeted research, and
each would require different kinds of research and scopes of work.¬†

A note on why we start with a question instead of a statement or
hypothesis: Starting with a question ensures that you are focused on
investigating (exploring and searching for an answer) rather than
validating your ideas (working to prove that the solution you created is
the right one).¬†

‚Äç

##### **üìñ Read more about** [**Planning UX¬†Research**](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)

‚Äç

## Step 2: Choose your research methods

There are a lot of different user research methods out there. If you
haven't already taken time to familiarize yourself with them, we
recommend reading the chapters on [Types of User Research
Methods](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
and [Qualitative vs. Quantitative
Research](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods).

A solid understanding of which methods to use for any given study is one
of the most powerful strategic skills a user researcher can develop. But
you don't have to rely on your memory alone to figure out which method
you choose---that's what UX research frameworks are for.

For now, what you need to know is that some UX research methods are
better suited than others to the:

-   Stage of¬†product development you're at (discovery, concept
    validation and testing, launch, and post-launch)
-   Research questions you're trying to answer (what?, why?, how?)
-   Type of data you need to round out your inquiry (qualitative or
    quantitative, attitudinal or behavioral)
-   Decisions you want to enable (how are people going to act on your
    findings?)

We'll go over all that in depth in the [UX¬†Research Methodologies
module](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods),
by the end of which you'll feel like a seasoned pro when it comes to
choosing the right method for any research study.

‚Äç

##### **üìñ Read more about** [**UX¬†Research Methodologies**](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods)

### Assemble your research toolkit

Once you've figured out your methodology, you can start assembling your
toolkit.¬†¬†

You will need a way to recruit good participants, talk with them and/or
conduct tests, record and take notes, run your analysis, and present
your research at the end of it all.¬†

Our most recommended toolset for most people starting out is: User
Interviews + Zoom + Google Docs + Google Sheets (or the Microsoft Office
equivalent) + Google Drive or your internal wiki.¬†

That toolkit will enable you to conduct interviews and other moderated
studies effectively, cheaply, and without the need to adopt new
software. Because chances are, you already use most of these in your day
to day.

From there, you can layer in tools made especially for user testing,
surveys, card sorting, and so on as you need them.

There are a lot (like, a lot a lot) of user research tools out there, so
once again, we won't be covering the full list in this chapter. You can
read more about [user research tools in the
Appendix](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-tools).
And do check out the [UX Research Tools
Map](https://www.userinterviews.com/blog/ux-research-tools-map-2021) for
a visual overview of the current UXR tools landscape.

‚Äç

## Step 3. Create a user research plan

A research plan creates alignments, prevents careless slip ups, and
helps keep your research focused on its goals.

-   Title (descriptive, clear)
-   Team (author/research runner, other stakeholders)
-   Goals (that whole start with why thing)
-   Methodology (which research method and evaluation criteria will you
    use?)
-   Participants (who do you need to survey, test, talk to to reach your
    research goals?)
-   Schedule (the when and where).
-   Budget (how tight are those purse strings?)
-   Next steps (what happens when this study is over)

Put it all together in a document (feel free to borrow our [UX research
plan
template](https://docs.google.com/document/d/e/2PACX-1vT7MAwQSR4pjvaqUnuCOGLuz3Eg3e3zBqVq8s7CYmx5gcVsDe6BxsyUBBsLIjCEKLIWnJcs3WPtBiGf/pub))
and share with your stakeholders and other members of your team.

‚Äç

## Step 4. Recruit participants¬†

Research recruiting is something we know a lot about here at [User
Interviews](#). We exist to help user researchers find, recruit, and
manage participants for their studies.

The module on [recruiting for UX
research](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
includes everything you need to know about:

-   Identifying your ideal participants
-   Crafting screener surveys¬†
-   Sampling for different research methods
-   Finding prospective participants
-   Calculating research incentives
-   Scheduling and communicating with participants
-   And doing it all like a pro.

As you can tell from that list, there's a lot to teach and a lot to
learn about this critical step in the research process!¬†

Here's what you need to know about UX research recruiting in the
smallest of nutshells:

### Be crystal clear about who you're trying to recruit

Think about the person(s) who would be able to answer the specific,
practical, and actionable research questions you defined in step 1.
Write down a list of criteria that come to mind.¬†

Be critical of any demographic or geographic criteria you've listed out.
Unless someone's gender, race, religion, marital status, or zip code are
truly relevant to your inquiry, don't include those details in your
ideal participant profile---you'll only end up biasing your research and
limiting the number of people you can recruit.¬†

‚Äç

### Create a screener survey

[A screener
survey](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
is a brief questionnaire that people take to determine whether or not
they qualify for your study.

Take your list of participant criteria and reverse engineer it into a
series of questions. Looking to recruit people who have purchased olive
oil in the last 6 months? Ask questions that will allow you to filter
out anyone who hasn't made that kind of purchase---without hinting at
the correct answer.¬†

For example, don't come straight out and ask: "Have you purchased olive
oil in the last 6 months?"¬†

Instead, offer survey takers a list of options. For example:

Which of these pantry items have you purchased in the last 6 months:

-   Balsamic vinegar - reject
-   Soy sauce - reject
-   Fish sauce - reject
-   Olive oil - accept
-   Canola oil - reject
-   None of the above¬† - reject

‚Äç

### Choose the right incentives for your audience

Now that you know who you're going to recruit, ask yourself what kind of
reward these participants would consider fair compensation for their
time.¬†

Consumers typically go in for cash-equivalent or gift card incentives.
Government employees, meanwhile, can't touch those with a ten-foot pole.
Diehard fans of your product (your happiest customers) might be thrilled
to receive swag in exchange for their time. Or you might offer account
credits or product discounts instead.

The right incentive depends on the nature of your study, the type of
users you're recruiting, and (of course) your budget. You can read more
about our incentive recommendations in the chapter [User Research
Incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives).
(Clever title, we know.)

‚Äç

### Find and attract participants¬†

Okay, so this is where we come in.¬†

[User Interviews](https://www.userinterviews.com) is a one-stop shop for
participant recruitment---whether you want to recruit from your current
customer list or from our audience of over 700,000 ready, willing, and
vetted research participants.

(You can also target over 140 different industries, job titles,
demographics, and custom screener criteria. If you incentivize your
participants with Amazon gift cards, we'll manage the incentives for
you.)

Prefer to go the DIY route? The chapter on [how to recruit participants
for user research
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)
includes advice on recruiting people via social media, forums, Slack,
email, and in-app messaging.

‚Äç

##### üìñ **Read more about** [**Recruiting for UX¬†Research**](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)‚Äç

### Start talking to users today

[Sign up for free](https://www.userinterviews.com/recruit)

## Step 5. Conduct some research!¬†¬†

This is the really fun part.

A good rule of thumb is to research as early and as often as possible.
(This will save you from wasting time going in the wrong directions,
building prototypes for solutions no one needs.) That means there'll be
plenty of opportunities for you to practice and hone your moderating
skills. And it does take some practice!¬†

If you're new to research or are here to dust off your skills, we
recommend warming up your moderating muscles with a few members of your
team first.

Here are some rules of thumb for conducting moderated user research:

-   **Be authentic, be kind.** You're a human, they're a human. Treat
    participants with warmth, respect, and sensitivity (especially if
    you're asking about personal topics).
-   **Get comfortable with the awkward silences**. Listen, let people
    pause for thought, give them space to expand on their responses. And
    watch what people do---observe behaviors and non-verbal cues.
-   **Give context and set expectations** about the outcomes of your
    research. But don't share your assumptions or hypotheses---that's a
    surefire way to bias participant responses.
-   **Take notes.** Ask a colleague to be a notetaker and/or use a
    transcription tool to transcribe your sessions. This will allow you
    to be really present and attentive to all the interesting
    micro-moments that might occur.

‚Äç

## Step 6. Analyze and synthesize results¬†

Raw research data is no use to anyone.¬†

[User research analysis and
synthesis](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
are the processes by which data is transformed into insights. This is
the step that gives meaning to all the steps before it.

How you analyze your data will depend on the methods you used to collect
it. The biggest variable here is whether the data is qualitative or
quantitative.

Quantitative data analysis is about crunching numbers to identify
patterns. Qualitative data analysis is equal part art and science---it
requires interpretation by the researcher.¬†

**When analyzing qualitative data, ask questions like:**

1.  What are the major patterns and common themes in users' responses?
2.  In what context did users express the greatest emotional response to
    questions?
3.  What interesting user stories emerged from the responses?
4.  What features were most important to these users?
5.  How are these users different from other users?
6.  Are there any use-cases not adequately supported by the current
    interface?

###### **Remember:** You don't have to wait until a study is over to start analyzing the data---doing periodic analysis can save you loads of time at the end of a project. Roberta Dombrowski, our VP of User Research, [recommends](https://www.userinterviews.com/blog/better-ux-research-reporting-habits-framework) analyzing, synthesizing, and sharing highlights of each session as you go.¬†

‚Äç

##### üìñ **Read more about** [**UX¬†Research Analysis and Synthesis**](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)‚Äç

‚Äç

## Step 7. Share your research findings

Hopefully you don't need any encouragement to share your research
findings---if all went well, you're probably feeling excited about the
insights you uncovered and are eager to share them with your team.

But you may be wondering: How? What's the best way to communicate user
research results to stakeholders?

First of all, you should know that there is no single best way to report
on user research. The best format for [sharing UX
research](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)
is the format that is most relevant, useful, and interesting to your
audience.

Unlike academic researchers who are expected to write up formal research
reports, UX researchers have a lot of options when it comes to reporting
on their findings.¬†

**UX research reports can be communicated as:**

-   [Written reports or
    summaries](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)
    (here's a copy of the [UX research summary
    template](https://docs.google.com/document/d/e/2PACX-1vQpOHxT5nkiliX76vYgrXaR_mnuxHW1gzGXy2PEeTHWpbZOKT8P0h_HmiglWxNDhISclmbzJGSDOea6/pub)
    we use at User Interviews)
-   Slideshows (here's [another
    template](https://docs.google.com/presentation/d/1N8qpXAMiwi-yYEneIZFCBy1_kqQ7KWE1dwSUPRsq948/edit?usp=sharing)
    for ya)---these can be presented live in a meeting, or
    asynchronously as a video recording or slide deck.
-   Interactive workshops¬†
-   Emails and/or Slack messages
-   Internal wiki articles¬†
-   [Atomic research
    nuggets](https://www.userinterviews.com/ux-research-field-guide-chapter/atomic-research-nuggets)
-   Case studies

It's also a good idea to include research artifacts and deliverables
like:

-   [Customer journey
    maps](https://www.userinterviews.com/ux-research-field-guide-chapter/customer-journey-maps)
-   [User
    personas](https://www.userinterviews.com/ux-research-field-guide-chapter/personas)
-   Mental models
-   Storyboards
-   Affinity diagrams
-   Prototypes
-   Audio and video clips
-   Co-designed materials

Once again, the right one for any given study depends on your
stakeholders, as well as the type of data you've collected.

And the truth is most people only need a high-level summary that
highlights key insights and takeaways (luckily, you should have a good
sense of which insights stakeholders will care about from the
stakeholder interviews you conducted in step 1).

‚Äç

##### üìñ **Read more about** [**UX¬†Research Reports and Deliverables**](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)

‚Äç

## Finally, a word on demonstrating value

And that's it! The UX research process in 7(ish) steps.

Of course, knowing what to do and how to technically do it is a huge
part of the user research battle. But actually making things happen in a
real organization can yield a whole new set of challenges.¬†

Your job here is to continually sell and prove the idea that research is
indispensable to the product development process at every stage. Begin
by finding someone willing to listen to you, start small, do your
homework, share your insights widely.

In addition to highlighting the value research has added---creating or
tweaking the perfect prototype, building the right product in the first
place---make sure to highlight the mistakes that would have been made
without research.¬†

Without this step, research can be ignored, be taken as unseen and hence
an unimportant aspect of product development. Often its value is in
avoiding disaster (or at least unnecessary missteps). Share these
moments too.¬†

Once you start building the story that research is imperative within and
outside product teams, start doing more of it, sharing it more widely,
perhaps even training other teams to do it.

You've got this!

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/what-is-user-research)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/user-research-questions)

Next:

User Research Questions

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Fundamentals](/ux-research-field-guide-module/user-research-fundamentals)

\>

[User Research
Questions](/ux-research-field-guide-chapter/user-research-questions)

# User Research Questions

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

‚Äç

Egypt's Valley of the Kings contains hundreds of tombs, including the
tomb of King Tutankhamen, notable for being the only royal burial found
fully intact. But British archaeologist, Howard Carter, had searched the
area for over a decade before discovering King Tut's tomb---and it's
likely there are others yet to be uncovered.¬†

‚Äç

That means hoards of valuable artifacts and insights into the ancient
world are still underground, waiting for someone to dig in just the
right place to reveal them.¬†

‚Äç

An archaeologist digging in the wrong location is akin to a UX
researcher asking the wrong research question. The answers are all there
to be found, but it's the questions we ask that make the difference
between a breakthrough discovery of long-buried insights and an empty
hole in the ground.

‚Äç

That's why a carefully-crafted research question is one of the most
important components of a successful study.¬†

‚Äç

## In this chapter:

-   What is a user research question?
-   Benefits of asking good research questions
-   Examples of good research questions
-   How to write an effective research question
-   Mixed methods research questions

‚Äç

## What is a user research question?¬†

Let's start with what a user research question is not: It is not the
same thing as a user interview question and we'll go over the difference
in more detail below. If you're searching for advice on how to write
great interview questions for user research, check out the [User
Interviews
chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
or [this podcast episode on mastering user interviews with Therese
Fessenden of Nielsen Norman
Group](https://www.userinterviews.com/blog/leveling-up-user-interviews-therese-fessenden-nng);
otherwise, read on!

‚Äç

Now, what do we mean when we talk about your "research question"?¬†

‚Äç

A **user research question** articulates what, exactly, you want to
learn over the course of your study. Research questions act as the
catalyst for research projects, determining the methods you use, the
insights you uncover, and the decisions you make based on those
insights.¬†¬†

‚Äç

They should be documented in your [UX research
plan](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)
and referenced throughout [the research
process](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-process-fundamentals)
to maintain the focus and direction of your study.¬†

‚Äç

‚Äç

#### What makes a good research question?

Good [user
research](https://www.userinterviews.com/ux-research-field-guide-chapter/what-is-user-research)
questions are specific, practical, and actionable. They should be:

‚Äç

-   **Specific** enough that you know when you've found an answer, and
    you can find that answer within the scope of a study.¬†

‚Äç

For example, "how do university students use Linkedin?" may not be
specific enough for a single study, because there are many different
sub-populations of university students who may have different needs,
goals, and behaviors regarding the site. Instead, you might ask: "How do
American university students use Linkedin for career-related research?"¬†

‚Äç

-   **Practical** enough that you can reasonably answer the question
    with the time and resources you have available.¬†

‚Äç

For example, "to what extent does anti-gravity affect the severity of
adult migraines?" is a wildly impractical question that couldn't be
answered within the scope of most research teams. Instead, you'll want
to ask a question that can be reasonably answered within scope, such as
"to what extent do heavy rains affect the severity of adult migraines?"

‚Äç

-   **Actionable** enough that whatever you learn will be used to make
    decisions or changes.¬†

‚Äç

For example, if your brand colors are green, then a study that asks
"what percentage of customers prefer red over blue?" probably won't lead
to any major changes at your company, unless you're specifically
researching for a brand refresh. Otherwise, steer clear of "knowledge
for the sake of knowledge" questions, and instead map your questions to
real decisions your team needs to make.¬†

‚Äç

Choosing the right research question will also help you [choose the
right research
method](https://www.userinterviews.com/blog/how-do-i-choose-the-right-ux-research-method).
For example:

‚Äç

-   A research question that begins with "how much" or "how many" will
    require quantitative methods.
-   A research question beginning with "how," "what," or "why" is more
    likely to require qualitative methods.¬†

‚Äç

It's important to use research questions---not assumptions, solutions,
or methods---as the starting point for your research project. Why?
Because starting with a question ensures that research is being used to
investigate real problems and find the best solutions, rather than as a
way to validate pre-existing assumptions or biases.¬†

‚Äç

### Types of research questions

[Different types of effective research
questions](https://nmbu.instructure.com/courses/2280/pages/creating-research-questions#:~:text=Both%20are%20aspects%20of%20the,between%20two%20or%20more%20variables.)
include:

-   **Descriptive research questions** seek to describe things,
    variables, behaviors, or phenomena. They ask, "what does X look
    like?" or "what is X?" For example: "What percentage of Canadian
    college students use public transportation to get to campus?"**‚Äç**
-   **Causal research questions** evaluate the relationship between two
    or more variables or phenomena. They ask, "what effect does X have
    on Y?" or "how does X influence Y?" For example: "What is the effect
    of in-app purchases on overall revenue?"**‚Äç**
-   **Comparative research questions** evaluate the difference between
    two or more groups in relation to one or more variables. They ask,
    "how does X compare or contrast with Y?" For example: "What is the
    difference in screen time between male and female Americans under
    the age of 18?"

‚Äç

Each of these types of research questions can be valuable, but only if
the question is defined correctly (specifically, practically,
actionably), matched to the [research
method](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types),
and
[synthesized](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
in a way that is useful for stakeholders.¬†

‚Äç

### Research question vs. hypothesis

Although related, "research questions" and "hypotheses" are not
interchangeable terms.¬†

‚Äç

While a research question is a focused inquiry that provides the
foundation for your research, a hypothesis is an assumption in a
testable form. In other words, **a hypothesis is the predicted answer to
the research question**.¬†

‚Äç

For example:

-   **Research question:** "What is the effect of in-app purchases on
    overall revenue?"
-   **Hypothesis:** "If we offer in-app purchases, then we'll increase
    revenue by X%."

‚Äç

Typically, the question comes first, then the hypothesis---except,
sometimes, in cases where you already have a large body of research on
which to base your hypothesis. This might happen post-product launch,
when you're deeply familiar with your product and customers, you might
be able to form an educated hypothesis about customers' response to a
new feature.¬†

‚Äç

### Research questions vs. interview questions

Likewise, it's important to distinguish between user research questions
and user interview questions. As Erika Hall, Co-Founder of Mule Design,
explains in her article, ['Research Questions Are Not Interview
Questions'](https://medium.com/mule-design/research-questions-are-not-interview-questions-7f90602eb533):

‚Äç

"The most significant source of confusion in design research is the
difference between research questions and interview questions. This
confusion costs time and money and leads to a lot of managers saying
that they tried doing research that one time and nothing useful
emerged."

‚Äç

Here's the difference between user research questions and user interview
questions:

-   **User research questions** are the core questions that set your
    learning objectives for individual research projects. These are
    outlined in your research plan at the outset of your study, and they
    inform every other aspect of your study, including the method you
    use, the audience you recruit, and the actions you take based on
    your learnings.**‚Äç**
-   **User interview questions** are the questions you ask participants
    in 1-1 interviews as part of a research project. Although they're
    informed by the core research question, interview questions tend to
    be broader and more open-ended to avoid leading participants and
    allow them to speak about whatever is top-of-mind for the subject of
    the study. For tips and examples of good user interview questions,
    head to the [User Interviews
    Chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews).¬†

‚Äç

#### Mapping interview questions to your research question

If user interviews are one of your chosen research methods, then the
types of questions you ask during an interview will be different from
(but related to) the core research question that is driving your study.
As UX researcher Ad√©la Svoboda explains in [UX
Collective](https://uxdesign.cc/the-one-thing-to-make-your-ux-research-good-32b7d7210c5c):

‚Äç

"It's not a good practice to use research questions as interview
questions for your participants (asking like this might lead to getting
biased answers---when participants know your goals, they tend to tell
you what they think you want to hear)."

‚Äç

For example:¬†

-   For the research question: "How do single 25-35 year olds choose
    where to go out on a Friday night?"
-   Ask: "Walk me through your last Friday night outing, beginning with
    when you started planning the outing."

‚Äç

The latter is likely to elicit a more valuable response, giving you
insight into their decision making process and mental models.¬†

‚Äç

Here's an example of research questions mapped to interview questions,
from [a real study on the experiences of low-priority patients during
waiting time at the emergency
room](https://www.researchgate.net/publication/221832826_Experience_of_being_a_low_priority_patient_during_waiting_time_at_an_emergency_department):

![Research questions vs. interview questions: \"What was the experience
of the low priority care patients like during their waiting period in
the emergency department?\" vs \"Can you describe your experience of the
care during your waiting time? Begin with what happened when you arrived
at the ward.\" ; \"What were the patient\'s problems that received the
low priority status in the waiting queue?\" vs \"Tell me about the
personnel that admitted you into the ward; describe your experience of
waiting for treatment; what was your total experience of the emergency
department; summarize in a few words your experience of waiting.\"
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62c4684613f28311b3df0ec9_oRuaSzIrRO8g9D9R8svo6A9qS5McKHdYh4TenUvjV2yFRc-_9x2KA9ONaAUoKILH_lyB5Ec9khdJOCpX7vhbHmhdaoKhvncCoueD0m3qeHPMpvASnU7y3Q9WToOj1ipfedgmQ9fWVFpsva_JxA.png)

As you can see in the chart, the researchers didn't ask participants
their research questions directly, but instead asked carefully-designed
interview questions to limit bias and collect aggregated information
without putting words in the participants' mouths.¬†

‚Äç

P.S. --- If you landed on this page looking for UX research job
interview questions, this is a guide to mastering the practice of user
research, so you won't find those here. [Read this article about
preparing for the UXR job interview
instead](https://www.userinterviews.com/blog/common-ux-research-job-interview-questions-how-to-answer-them).¬†

‚Äç

## Examples of good user research questions

As we mentioned earlier, good user research questions are specific,
actionable, and practical. Here are some sample research questions and
ideas to show you what that looks like in practice.¬†

‚Äç

**Qualitative research questions:¬†**

-   How well do our support pages answer customers' questions about
    adding a new credit card to their account?
-   How do families with newborn babies choose which brand of diapers to
    purchase?¬†
-   Why are so many people abandoning their shopping cart?¬†
-   What are the primary motivating factors behind the decision to
    purchase first-aid kits?
-   What tools do freelance writers use to keep track of their
    schedules?¬†
-   Which apps do women and non-binary folks who are looking to date
    other women and non-binary folks use to meet potential partners?¬†¬†

‚Äç

**Quantitative research questions:**

-   How frequently do adult European skiers replace their ski boots?¬†
-   What percentage of our customers prefer the mobile app to the
    website browser?
-   How much do families with teenage children spend on movie tickets in
    the United States?
-   How often do working Millennials check their email per day?¬†
-   To what extent does alcohol use affect college students' academic
    performance?
-   What proportion of British men and women ages 25-35 use calorie
    tracking apps?¬†

‚Äç

### Examples of good user interview questions

To break down the difference between research questions and interview
questions, we'll use one of the qualitative research question examples
above and map them to corresponding interview questions.

‚Äç

**Research Question:** What are the primary motivating factors behind
the decision to purchase first-aid kits?

‚Äç

**Interview questions:**

-   Walk me through the last time you purchased a first-aid kit.¬†
-   Which brands did you consider when buying a first-aid kit?
-   Tell me about a time when you needed a first-aid kit and didn't have
    one on hand.¬†
-   How often do you use your first-aid kit?
-   What do you appreciate most about your current first-aid kit?¬†
-   Is there anything missing from your first-aid kit that you wish was
    included?

‚Äç

Here's another, real-world example of how a research question could
break down into an interview question, from [Amy Chess, UX Researcher at
Amazon](https://www.userinterviews.com/blog/ux-research-questions-amy-chess-amazon):

‚Äç

"One of our research questions \[was\], which is the default tab? Now,
we didn\'t ask that question directly to our users, because of course,
when you ask a question like that, you\'re forcing your user to abandon
themselves as the user. You\'re asking them to leave their shoes and
enter the designer\'s shoes. And that doesn\'t really help us as
researchers... So in that case, your interview question becomes, what do
you expect to find when you click on that button?

‚Äç

In that way, you begin to enter the participant's world and see what are
their expectations, what are their needs, what do they expect based on
what they\'ve already seen in the flow. And those expectations can then
form the basis for what the default becomes. So that\'s one really good
distinction between what the research question would be and then what
the actual interview question would be and how they are different."

‚Äç

For more examples of user interview questions, check out [this big list
of 100+ user testing
questions](https://www.userinterviews.com/blog/user-testing-questions)
categorized by method, [this template of a user interview
script](https://docs.google.com/spreadsheets/d/1UrEV3o6vFqEvDFkfo3wekEAGQHbO2jaE5K02ii5Yc-c/edit#gid=0)
and moderator guide, or [this list of sample UX research interview
questions](https://projects.iq.harvard.edu/files/harvarduxgroup/files/ux-research-guide-sample-questions-for-user-interviews.pdf)
by Sarah Doody.¬†

### Start talking to users today

[Sign up for free](https://www.userinterviews.com/recruit)

## How to write an effective research question

At this point, you should have a good understanding of what a research
question is (and is not) and what a good one looks like. And that's
great---it means you're ready to start crafting an effective research
question for your own study.

‚Äç

Here are the 4 basic steps to follow:¬†

‚Äç

### 1. Identify your research goals.

Effective research starts and ends with decisions.¬†

‚Äç

Before you develop your research questions, you need to understand the
pain points and "known unknowns" on your team, high-level company goals,
and both immediate and long-term priorities. These challenges, goals,
and priorities can then be rewritten as research questions that support
the actual decisions your team needs to make.¬†¬†

‚Äç

This approach, which we like to call [Decision-Driven
Research](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research),
helps you avoid "research for the sake of research" and focuses your
work to be as impactful as possible.¬†

‚Äç

[Amy Chess, UX Researcher at
Amazon](https://www.userinterviews.com/blog/ux-research-questions-amy-chess-amazon),
uses a simple exercise for mapping research questions to decisions:¬†

‚Äç

"I\'ve kept an Excel spreadsheet where we list out the research
questions, and then we have a column for the decision that question
would help inform. It could be an item on the roadmap. It could be a
specific requirement. It could be some... piece of customer feedback
that came in and we needed a deeper dive. But I think that\'s really the
solution to having it be too 'out there in the world' and not having it
be tethered to anything specific is just to make sure that there\'s a
nice relationship between the research question and the decision that
you\'re trying to address with it."

‚Äç

By starting with the decisions your team needs to make, you can
reverse-engineer your research questions to address the gaps in the
information your team needs to make those decisions.¬†

‚Äç

Here's an example from
[NN/g](https://www.nngroup.com/articles/tracking-questions-assumptions-facts-agile/),
showing how research questions can be drawn from specific goals or plans
from the product backlog:

‚Äç

![Example 1: Feature from backlog - provide offline functionality;
research question - will our users want to use our application offline?;
next steps - do additional research before building functionality that
users don\'t need. Example 2: feature from backlog - build a user
profile; research question - how much personal information will users
provide?; next steps - determine how much information to collect and
guage how much users trust our product.
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62c46898ba0671c862207fcc_IaoYsCvbPijaifFwH260NEKt5xwInoT9vhocZAWsdW_1aanSVQgpV_BpfPfkRQAGzei4rOf8KfaHJgYdX4nekGd9Q2lndisEAI4nSZjwqf7c8ie1Jt_nLtg2zCy_nhLKeijCW6VpfcY25NWxcbk.png)

‚Äç

### 2. Scope existing evidence.

With any given research project, it's rare that you'll be stepping out
into a complete unknown. Typically, you'll already have access to
existing insights, experiences, and [other
research](https://www.userinterviews.com/ux-research-field-guide-chapter/literature-reviews)
that can influence your approach.¬†

‚Äç

So once you understand which decisions your team needs to make, ask
yourself:

-   What do you already know about your goal or decision?¬†
-   What do you NOT know about your goal or decision?¬†

‚Äç

Review existing customer feedback, analytics dashboards, Google, and
other databases for information related to your decision. And of course,
[interview
stakeholders](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)
about what they know or have explored in the past.¬†

‚Äç

Sometimes, you might find that your question has already been
answered---and you'll save yourself from duplicate work. Other times,
you'll find information that helps you hone, pivot, or revise your
question, setting the stage for more impactful research.¬†

‚Äç

### 3. Create your research question(s).

Create a list of potential research questions for your project.
Remember, research questions should be specific so that they can be
answered definitively, practical for testing within the scope of one
project, and lead to actionable outcomes.¬†

‚Äç

Think carefully about:

-   The decision your team needs to make
-   The information you still need in order to make your decision
-   Where you are in the design cycle
-   The time and resources you have available¬†
-   How your research will be used (and by whom)

‚Äç

You might need to take vague, high-concept requests from stakeholders
and refine them into concrete, answerable questions. [Max Korolev, UX
Researcher at
Acronis](https://acronis.design/frameworks-for-product-and-ux-research-planning-15e6405f4b7d),
calls this process the 'Operationalization' of research requests:

‚Äç

"Sometimes stakeholders ask to evaluate the abstract concept or metric.
For example: 'Is the new site better than the old one?' or 'Does the
design of these posters reflect our brand?'. It is difficult to work
with such requests because it is not clear what it means to be 'better
than the old' and what it means to 'reflect the brand'. Before planning
a study, these concepts need to be operationalized, connected to the
specific user behavior we want to achieve.

‚Äç

What do you mean, 'the site has become better'? What scenarios are
important to us? What metrics are important to us? What changes should
occur in the physical world as a result of launching a new
website/product? Depending on the answer, the methods of verification
will be different."

‚Äç

In other words, try to ground abstract questions ("is this design
'good'?") with specific metrics, user behaviors, or outcomes ("how
quickly can users find their account settings from the homepage?").¬†

‚Äç

‚Äç

#### Research questions should NOT be:

-   Easily answered with a Google search
-   Already answered by previous research
-   Asked only to validate biases

‚Äç

### 4. Narrow your focus, then complete your research plan.¬†

Many studies can explore multiple questions at once, but no study can
effectively answer¬† every question you have. Limit yourself to 3--4 core
research questions per study to prevent the project from becoming too
unwieldy. If you have more than 3--4 questions, you'll need to break
your research into multiple phases or projects.¬†

‚Äç

Once you've nailed down your research questions, then it's time to pick
the best method to answer those questions and [create your UX research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan).¬†

‚Äç

## Mixed methods research questions¬†

Many researchers choose to use both [quantitative and qualitative
methods](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
together---qualitative research adds nuance and context, while
quantitative research provides concrete numerical data and lends
confidence to qualitative findings.

‚Äç

As J. David Creswell and John W. Creswell explain in [Research Design:
Qualitative, Quantitative, and Mixed Methods
Approaches](https://www.sagepub.com/sites/default/files/upm-binaries/27397_Pages138_141.pdf),
mixed methods research doesn't necessarily require a different approach
to developing research questions, but you may choose to design your
question with a mixed methods approach in mind:

‚Äç

"In discussions about methods, researchers typically do not see specific
questions or hypotheses especially tailored to mixed methods research.
However, discussion has begun concerning the use of mixed methods
questions in studies and also how to design them. A strong mixed methods
study should start with a mixed methods research question, to shape the
methods and the overall design of a study. Because a mixed methods study
relies on neither quantitative or qualitative research alone, some
combination of the two provides the best information for the research
questions and hypotheses."

‚Äç

In other words, a combination of quant and qual research tends to reap
the best results---so if you find yourself asking "why," then you might
best answer that question by pairing it with "how much" and "how many."

‚Äç

## In a nutshell

Ask better questions, get better answers. A specific, practical, and
actionable user research question helps you articulate exactly what you
want to want to learn from your study and acts as the guiding light for
the rest of your project---from the methods you use to [the audience you
recruit](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
to the insights you uncover.¬†

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/user-research-process-fundamentals)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/planning-user-research)

Next:

Planning UX Research

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Planning UX
Research](/ux-research-field-guide-module/planning-user-research)

![a person looking at floating browser windows that have profiles and
graphs in
them](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f25e51c301d7f64fcffe_UI_CHAPTER_02_ARTWORK.jpg)

02\.

# Planning UX Research

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

It doesn't matter whether you're doing a quick qualitative usability
test, ethnographic field studies, or focus groups---you need a plan for
user research.

This module is all about defining your research goals and creating a
clear and actionable plan to achieve them. We'll walk you through how to
design a research study step-by-step, from running effective stakeholder
interviews to writing a stellar UX research plan (templates included!).

You'll learn all about:

-   **Creating a user research plan.** Qualitative or quantitative,
    generative or evaluative, moderated or unmoderated, beginner or
    pro---this flexible how-to guide can be adapted to any type of user
    research project.
-   **Writing great user research questions** that are specific,
    practical, and actionable. Plenty of examples and best practices
    included.**‚Äç**
-   **Conducting internal stakeholder interviews** to learn from key
    players, align around goals, earn buy-in, and set your research
    study up for success.

[Start
reading](/ux-research-field-guide-chapter/create-user-research-plan)[Start
reading](/ux-research-field-guide-module/recruiting)

In this module:

[How to Create a User Research
Plan](/ux-research-field-guide-chapter/create-user-research-plan)

A goal without a plan is just a wish---here's how to create a UXR plan
to meet your research goals.

[Ethical and Inclusive User
Research](/ux-research-field-guide-chapter/ethical-inclusive-research)

Coming Soon

Coming Soon

Coming Soon

When you're working with humans, ethics and inclusivity are
non-negotiable.

[Stakeholder
Interviews](/ux-research-field-guide-chapter/internal-stakeholder-interviews)

How to interview the people who give a sh\*t about your research.

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### How to Create a User Research Plan

A goal without a plan is just a wish---here's how to create a UXR plan
to meet your research goals.

##### Ethical and Inclusive User Research

Coming Soon

Coming Soon

Coming Soon

When you're working with humans, ethics and inclusivity are
non-negotiable.

##### Stakeholder Interviews

How to interview the people who give a sh\*t about your research.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/recruiting)

03\.

### Recruiting for UX Research

[](/ux-research-field-guide-module/user-research-methods)

04\.

### UX Research Methodologies

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Planning UX
Research](/ux-research-field-guide-module/planning-user-research)

\>

[How to Create a User Research
Plan](/ux-research-field-guide-chapter/create-user-research-plan)

# How to Create a User Research Plan

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

As you read through the Field Guide, you may start to notice a pattern:
Just about every how-to section starts with some version of "identify
your research questions and goals."

‚Äç

That's because defining your objectives (and then having a clear and
actionable plan to achieve them) is a necessary step in the user
research process, no matter which method you choose.

### ‚Äç In this chapter

-   What is a user research plan?
-   Why you need a research plan for qualitative research
-   UX research plan template
-   How to plan a UX research study
-   Research design considerations and best practices

## What is a user research plan?

A user research plan is a document (or less commonly, a slide deck or
internal wiki page) that outlines the goals, objectives, and logistical
considerations of a research project for your stakeholders and team.

Good UX research plans provide everyone involved with a concise overview
of the who, what, when, why, and how of any given research project.¬†

They are used at the kickoff of a research initiative to strengthen
stakeholder buy-in and create alignment around the goals of the research
at hand.¬†

UX research plans also serve as points of reference throughout the
research process, ensuring that your inquiry remains focused on
answering the key research questions defined at the outset. For this
reason, they are also useful tools for effectively reporting on the
results of your research in a way that speaks directly to your
stakeholders' needs, as defined at the beginning of a project.¬†¬†

A good research plan is a prerequisite for doing good user research.

### What's the difference between a research plan and research design?

Depending on who you ask, a research plan is either one part of research
design, or the other way around. Or they're the same thing. Or they're
not...

If you wanted to get really particular about it, you could argue that a
research design refers to the methodology and approach, while a research
plan also includes logistical considerations like timelines, budgets,
and so on.¬†

But in practice, the two terms are frequently used interchangeably by UX
researchers... and TBH, we think that's fine.

Similarly, the distinction between 'designing research' and 'planning
research' (or heck, 'designing a research plan') is largely semantic.
Both these verbs can be defined as 'to create a strategy for conducting
research.'

In this Field Guide, we'll be using the terms as follows:

###### Research plans are the outputs of UX research design, which is the process of planning research.

Simple enough, right?

## Why you need a research plan for qualitative research

It's only been a few paragraphs since we last said it, but this bears
repeating:

###### A good research plan is a prerequisite for doing good user research.

In other words, if you want to conduct UX research, you need to have a
plan. Here's why:

‚Äç

#### A research plan creates alignment and earns buy-in

Putting together a research plan is often a collaborative effort that
involves understanding what stakeholders wish to accomplish, and what
questions they need answered in order to make smarter decisions.

A good UX research plan---one that addresses their needs, ties research
to business objectives, and gives a succinct overview of the methods and
logistics involved---is a fantastic way to earn stakeholder buy-in and
set realistic expectations about the research process and outcomes.

#### A research plan will help you stay focused on your goals

If the goal of your UX research is "to get to know your customers
better," that's totally fine.¬†

But in order to know that your research is working, you'll need to get
more specific about what it is you want to know about them (our bet is
that it's probably something to do with your product, and not---for
example---which set of grandparents they secretly prefer).¬†

You'll also need to decide which customers you'll talk to and how often,
which methods you'll use, how you'll record and share their answers, and
so on.¬†

Creating a research plan will help you make sure your efforts line up
with the overall goal of your research, and that you're able to
demonstrate the value of your work when all is said and done.

‚Äç

#### A research plan helps you avoid common research pitfalls

No-show participants, too many participants that don't fit your
criteria, too few participants full stop, technological difficulties,
overbooked schedules, mountains of poorly organized data, trouble
distributing incentives distribution, research reports that don't get
read...

Frankly, there's a lot that can go wrong with user research. And every
speed bump and set back costs time, money, and patience---for you, for
participants, and for stakeholders.

There's really no good reason to skip research planning.

-   In a hurry? That only increases the likelihood that the process will
    break down or an important detail will get overlooked without
    preparation.¬†
-   You're a UX research team of one? All the more reason to create
    alignment and earn yourself buy-in.¬†
-   Your study is super quick and easy and doesn't need a plan? It still
    needs a plan, but it can be a brief one.¬†
-   Not sure how to¬† create a research plan? Well, that's what this
    chapter is about so you can toss that excuse out, too!

## UX research plan template

Here's an example of a user research plan---it's adapted from the same
[template](https://docs.google.com/document/d/e/2PACX-1vT7MAwQSR4pjvaqUnuCOGLuz3Eg3e3zBqVq8s7CYmx5gcVsDe6BxsyUBBsLIjCEKLIWnJcs3WPtBiGf/pub)
we use internally at User Interviews. We'll go through how to fill out
this document and create a UX research plan step-by-step in the next
section.

‚Äç

At a minimum, your research plan should include:

‚Äç

#### What: Your research question(s) and goals

You'll define these in steps 1 and 2 (below).¬†

Research goals state what you're trying to learn or accomplish with your
research.

Your research questions should reflect the goals of your study and
should be:

-   Specific enough that you'll know when you've reached an answer
-   Practical in that you could answer them within the scope of a study
-   Actionable, meaning you could act on your findings once you've
    completed your research study

‚Äç

#### Why: Business goals

Speak your stakeholders' language.¬†

Effectively tying research efforts to bottom-line goals will go a long
way toward earning stakeholder buy-in. Use the transcripts from your
[stakeholder
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)
(step 3) to get a sense for how key decision-makers talk about their
objectives and measures of success.

‚Äç

#### How: Methodology

Explain the approach you're taking to answer your research question
(defined in step 4). Include brief descriptions of the methods you'll
use, the tools you'll need, how long things will take, and anything else
you think stakeholders will want to know about the 'how.'

Just remember, these folks are (probably) not as research-savvy as you
are. Use plain language.

‚Äç

#### Who: Participants

Describe who you're going to recruit (step 6). What are their defining
characteristics (i.e. how are you screening for good-fit participants)?

Include information about the strategies you'll use to [recruit
participants](https://www.userinterviews.com/ux-research-field-guide-module/recruiting).
Are you using a [research recruiting
platform](https://www.userinterviews.com)? Social media? Emails to
customers?

Also be sure to explain how you plan to compensate people for their
time.

‚Äç

#### When and where: Research schedule and logistics

Don't forget the boring logistics!¬†

Be clear about the tools you'll need, the roles different members of
your team will play, and your research schedule (step 5 again).

‚Äç

#### Next steps¬†

Finally, set some expectations about anticipated outcomes,
[deliverables](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting),
and next steps.¬†

For example, if you're in the discovery phase of product development,
make it clear that the insights from this research will inform product
vision---but that further research will be needed to validate designs
and direction.

‚Äç

## How to plan a UX research study

This is a step-by-step guide to planning user research. It explains the
process by which a research plan comes together into a shareable
document (like the one above) that enables team alignment,
accountability, and efficiency throughout your study.

‚Äç

### 1. Identify your research goals

If you're reading this Field Guide cover-to-cover, you'll likely notice
a pattern: Most how-to sections start with defining your research goals
or design challenge.

**Research goals** state what it is you are trying to learn from your
research.¬†

**Design challenges** clearly define a known problem, the solution to
which you are hoping to identify through user research.

Clarifying your research goals is especially important in the early
stages of a research project, when the scope of your inquiry may be
quite broad. Once you have something specific to test, whether that's a
prototype developed post-discovery or a live feature, your research
focus can then be framed as design challenges. [Rebecca Smith and Kendra
Leith of MIT D-Lab
advise](https://d-lab-dev.mit.edu/sites/default/files/inline-files/D-Lab%20Scale-Ups%20User%20Research%20Framework%201.2_0.pdf)
that:

###### A good design challenge will be framed in human terms (rather than technology, product, or service functionality), broad enough to allow you to discover areas of unexpected value, and narrow enough to make the topic manageable\.... Be aware of how you choose to frame your problem, as this framing will limit the set of solutions that you consider.¬†

Terminology aside (in practice, the difference between research goals
and design challenges is often blurry), having clearly stated goals and
motivations for doing research is a critical step that provides focus
and creates shared understanding between your team and key stakeholders.

To identify your research goals, ask yourself the following questions:¬†

-   **What do I want to know?** This is the big one---in the next step
    you'll break this question down further into specific, actionable,
    and practical research questions. For now, it can help to think in
    broad strokes: What motivates users? How do they behave? How do they
    use your product? What are the pain points in their current
    workflow?¬†¬†
-   **What don't I know?** You probably can't fully answer this question
    (it's hard to know what you don't know!) but it's important to
    identify knowledge gaps early.
-   **How will I know when I've learned it?** What must be true in order
    for this research to be considered "done"?
-   **What company goals will this work support?** As a user researcher,
    you should have a solid baseline understanding of your company's
    business model and top-level goals---do your best to tie this
    research to the bottom line. You'll have a chance to dig further
    into this question during stakeholder interviews.
-   **Where am I in the product development process?** Are you trying to
    generate new ideas in the discovery phase? Are you looking to test
    and validate your designs? Are you trying to learn about the current
    customer experience through ongoing research?
-   **What decision will this research enable?** We'll cover this in
    more depth in the section on our Decision Driven Research Framework
    in the How to Choose a User Research Method chapter. TL;DR, know
    what you want people to be able to do with the answers to your
    research question.
-   **What are the anticipated outcomes of this research?** What kind of
    insights do you expect to glean? What deliverables are you planning
    to have in hand at the end of this process?¬†

### 2. Develop your research question(s)

A good research question is specific, practical, and actionable.

It should be:

-   **Specific** enough that you will know when you have found an
    answer.¬†
-   **Practical** in that you could reasonably find answers to it in the
    scope of a research project (that scope could be large or small
    depending on your question).
-   **Actionable**, in that, if you answer the question, your team will
    be able to make changes based on what you learn.

A good research question acts as a beacon---it's what drives your
research forward, lets you know when research is "done," and it's what
gets everyone involved on the same page.¬†

What's more, starting with a question is the best way to ensure you're
using your research to investigate rather than to validate.
Investigating means you're digging deeper into a problem, or searching
for an answer, whereas validating means you're working to say the
solution you've created is the right one.¬†

While research can validate your solution (indeed, that's what
evaluative research is all about), doing user research to prove you're
right is not a good use of anyone's time or energy.¬†

Going into research with a questioning mindset leaves you more open to
new solutions and ideas that may arise in the course of your research.
It also leaves room for the solution you originally envisioned to be the
wrong one, which is ok. The goal of research is to learn, grow, and
[make better
decisions](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research).¬†

**Some example of good research questions:**

-   Are our customers able to successfully navigate to the support page
    on our site?
-   What are the primary motivating factors behind the decision to
    purchase pet insurance?
-   Do people understand our blog categories and what content might
    belong in them?
-   What tools do college students use to keep track of their schedules?
-   Which apps do women and non-binary folks who are looking to date
    other women and non-binary folks use to meet potential partners?¬†¬†¬†

Each of these questions could be answered through targeted research, and
each would require different kinds of research and scopes of work.¬†

‚Äç

### 3. Gather available data and existing insights

This next step is all about figuring out what you already know (or could
learn without doing user research). There are three ways to take stock
of existing information:

-   Stakeholder interviews (this will also help you flesh out your
    goals)
-   Secondary research (i.e. literature reviews)
-   Analytics and customer feedback

#### Stakeholder interviews

As you might remember from the chapter on [stakeholder
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews),
these interviews are semi-structured, in-depth interviews that are
conducted at the outset of a research project to create consensus and
align around research goals.

Potential UX research stakeholders include people who:

-   Have organizational influence
-   Make decisions about time, money, and resources
-   Are involved in the UX and product design process
-   Have information relevant to your project
-   Will be expected to act on research insights

Unless you work at an agency and your key stakeholders are wildly
different for every project (different people, different companies,
different customers, different business goals), the stakeholder
interviews you conduct at this stage should be specific to your current
project.

Ideally, you'll have already conducted some stakeholder interviews with
the key players and decision makers at your company, which means you
have a general understanding of what they do, what they care about, how
they measure success, and what they can tell you about the product and
customers.¬†

That means you'll be able to re-interview the people most affected by
this particular project about their concerns, how the results will
impact their role, and what existing knowledge they can bring to the
table.

If that isn't the case, dedicate extra time to this step---and do it
early, to make sure your research goals and questions are rooted in
business needs.¬†

The essential question to ask yourself at this stage is:¬†

###### What do I need to learn in order to move forward with this research project?

‚Äç

##### **üìñ Read more about** [**Stakeholder Interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)

‚Äç

#### Secondary research (literature reviews)

We'll let you in on a little secret: You don't have to do everything
yourself.

Why waste limited resources on rediscovering information that other
people have found and published?¬†

Secondary research involves collecting and synthesizing existing data
and insights on a topic.

A literature review is a type of secondary research in which researchers
review published information (articles, websites, videos, research
journals) related to a topic area in order to identify patterns and
trends.¬†

[MIT D-Labs
recommends](https://d-lab-dev.mit.edu/sites/default/files/inline-files/D-Lab%20Scale-Ups%20User%20Research%20Framework%201.2_0.pdf)
you'll need approximately 20 to 80 hours for this step, but it really
depends on the project and your existing knowledge of the topic. In any
event, be prepared to do lots of reading!¬†

It can be helpful to create spreadsheets or notes documents that allow
you to compare insights across sources. After going through all of your
sources, write up a summary of key insights that might inform the
direction of your inquiries.

‚Äç

#### Analytics and customer feedback

Just as literature reviews can save you from redundant research about a
topic, consulting your company's product analytics and [customer
feedback
data](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)
can save you from spending time researching things your customers have
already told you through their words and actions.

[Analytics](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics)
can be a treasure trove of quantitative data. Coordinate with your
product and analytics teams to dig into things like key user flows,
in-app behaviors, and business metrics.¬†

Likewise, bug reports and support tickets can help you understand how
the user experience has been impacted by current or historical
frustrations.

And don't forget your sales, customer success, and marketing
teams---they are often the keepers of a wealth of qualitative insights
about what customers and prospective customers think and say about your
product.

‚Äç

### 4. Choose the right research method(s)¬†

Your methodology will be informed by your research question. If you jump
directly to methodology, you may end up stunting your study before it's
even started. Some questions are best answered by customer interviews,
while others can be answered through tree tests, task analysis, or maybe
even field studies. Many studies will include multiple methods as well.

#### Research frameworks

Need a refresher on what kinds of research you can do? We cover that in
the upcoming [UX Research
Methodologies](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods)
module, but feel free to skip ahead and circle back.

But there are a lot of different methods out there, and even experienced
researchers can be overwhelmed by choice without a good framework. A
user research framework is a systematic way of categorizing research
methodologies and approaches to guide decisions about which method to
use, when.¬†

You can map methods according to:

-   The stages of product development ("use X methods during discovery")
-   Decisions to be made ("use X methods to enable big-picture
    decisions")
-   Your research question ("use X methods if you're asking "what?"")
-   Multiple axes like quant vs. qual, attitudinal vs. behavioral, and
    context of use

##### üìñ **Read more about** [**UX Research Methodologies**](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods)

‚Äç

### 5. Design your study

In the methodology section of your research plan, you'll also need to
include the details of your study, like a moderator guide for
interviews, or the wireframe you're testing for a usability study.

Anticipate and get ahead of questions like:

-   Will it be moderated/unmoderated?
-   What tools will you need?
-   What will be tested?
-   What artifacts will come out of the study?
-   How long will the sessions be?

Work out a research schedule.¬†

This will depend on your methodology and how many participants you
include---you may be able to do all your customer interviews in one day,
or you may be conducting a diary study that will take a few weeks to
complete.¬†

Set up a timeline and dates as soon as you can. Even if you don't
schedule sessions immediately, setting a timeline keeps you accountable.
And be realistic about how many sessions you and your team can conduct
in a day.

Finally, consider the logistics. What is the budget for your research?
Will you give the participants an incentive? Do you need to reserve a
space to conduct your research? Do you need to pay for additional
software?¬†

### 6. Have a recruiting strategy

Whether you're an experienced researcher or are just getting started,
recruiting the right research participants can be a real challenge.¬†

We've dedicated an entire module ([coming up
next!](https://www.userinterviews.com/ux-research-field-guide-module/recruiting))
to the topic of user research recruiting, and we highly recommend that
you read it for a fuller understanding of recruiting strategies and best
practices..

Here are the highlights, which you'll need to think about when putting
together your research plan:

‚Äç

#### Your research question will tell you who to recruit

The specific, practical, and actionable research question you defined in
step 2 should contain clues to who your participants should be.

Say your question is: "What tools do college students use to keep track
of their schedules?"

You know you need to talk to people who are:

-   Currently enrolled in a college or university
-   Interested in keeping track of their schedules

That's it, really, unless you're developing a solution exclusively for
students in the Massachusetts public university system, in which case
"attends UMass, any campus" may or may not be useful criteria.

‚Äç

#### The research method you choose will determine your sampling strategy

Your methodology will determine how many participants you need to
recruit to participate in your study. Quantitative studies require a lot
of people to achieve statistical significance. An interview-based study
or a usability test, on the other hand, may only require you to recruit
5 to 10 participants.¬†

[Suggested sample
sizes](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)
for different types of UX research:

-   Interviews -- 3 to 10 participants¬†
-   A/B tests -- 5 to 8 users
-   Focus groups -- 5 to 10 participants per group
-   Diary studies -- 10 to 15 participants
-   Card sorting -- at least 15 users per group
-   Quantitative studies -- at least 20 participants
-   Surveys -- at least 100 participants¬†

#### You need a screener survey

A screener is a brief (\<10 questions, ideally) survey that prospective
participants take to determine whether or not they qualify for your
study.

It's a sieve that filters out the participants who can help answer your
research questions from all the folks who can't.

A few rules of thumb for [creating effective screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys):

-   Filter by behavior \> demographics
-   Ask the big, disqualifying questions early¬†
-   Don't ask leading questions that hint at the "correct" answers
-   Provide an "other" option to multiple choice questions
-   Include open-ended questions to screen for articulation

‚Äç

#### You also need a plan for distributing incentives

Regardless of your methods, participants, or budget, you should
compensate participants for their time in one way or another. [Research
incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
(which, by the way, don't have to be monetary) should be distributed as
soon as the research session ends.

Whether you're offering gift cards, account credits, or swag, the most
important thing is that you choose incentives that are valuable and
relevant to the people you're looking to recruit---and that you have a
way to distribute them in a timely manner.

Here are our recommendations for calculating the right incentives a
nutshell:

-   In-person studies demand higher incentives than remote studies.
-   Higher income earners expect higher incentives than lower income
    earners.
-   The longer the time commitment, the higher the incentive.

‚Äç

##### üìñ **Read more about** [**Recruiting for UX Research**](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)‚Äç

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

### 7. Be ready to share your research findings

This is one of the most important parts of your plan, because it
outlines what happens once you've finished your research.¬†

The way you analyze and present your research can have a huge influence
on the kind of [impact your research is able to make at your
company](https://www.userinterviews.com/blog/how-to-track-the-impact-of-ux-research).
Getting these things right is almost as important as conducting the
research in the first place.

#### Plan your research analysis ahead of time

Consider how you will analyze and report on your research findings. Good
[research
analysis](https://www.userinterviews.com/ux-research-field-guide-chapter/research-analysis)
begins at the planning stage, before research actually begins. Think
about the kind of data you're collecting (Is it qualitative or
quantitative? Will it be in the form of videos or survey responses? How
much data will there be?) and develop a plan for recording, coding, and
analyzing it as you go.

#### Strategize your deliverables

Think about the kinds of artifacts your study will produce, and how
you'll present them to stakeholders.¬†

Will you share findings as you go or wrap it all up in a final report?
Is it better to deliver results in a meeting or asynchronously? Is there
another study you want to complete after this one? How will people
access your research after you complete it?¬†

You can't know for certain what the outputs of your research will be,
but you can plan to:

-   [Share research
    results](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)
    in the format(s) that will be most relevant to your stakeholders.
-   Tell a compelling story by including things like quotes and videos
    in your deliverables.¬†
-   Store your insights in a repository so they're easy to access and
    refer back to.

‚Äç

üìñ **Read more about** [**UX Research Reports and
Deliverables**](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)

‚Äç

## Research design considerations and best practices

Your research plan ultimately leads to research findings, which go on to
inform decisions that ultimately---after much testing and
iteration---end up in the hands of real people.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/internal-stakeholder-interviews)

Next:

Stakeholder Interviews

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Planning UX
Research](/ux-research-field-guide-module/planning-user-research)

\>

[Stakeholder
Interviews](/ux-research-field-guide-chapter/internal-stakeholder-interviews)

# Stakeholder Interviews

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

'Internal stakeholder interviews' is a super fun term for 'talking to
the people you need to talk to in order to do successful research.'

They are one-on-one interviews with the key players on any given
project. Interviewing stakeholders is an absolute must-do step in the
research process, and the insights you gain from these conversations
will inform everything from the research plan you write to the methods
you use to the way you report your findings.

‚Äç

### In this chapter

-   Who are stakeholders?
-   What are internal stakeholder interviews?
-   The benefits of interviewing stakeholders
-   How to conduct internal stakeholder interviews
-   Examples of stakeholder interview questions
-   Tips and takeaways

‚Äç

## Who are stakeholders?

Stakeholders are people who have a stake in the success and outcomes of
your research. What you do matters to them, and what they think of your
work certainly matters to you.¬†

There are external stakeholders (these include your customers and users)
and internal stakeholders (these may be executives, product designers,
sales reps, or---if you work for an agency---clients).¬†

In order to do your job well, you need to know what they know and what
information stakeholders still need to make better decisions and achieve
their objectives.

In this Field Guide, when we say 'stakeholders,' we're talking about
internal stakeholders. When we talk about users and customers, we'll use
those terms rather than 'external stakeholders'---but it's important to
remember that those folks are your stakeholders, too.

‚Äç

## What are internal stakeholder interviews?

Stakeholder research is research that you do with (internal)
stakeholders, rather than with users or customers. In other words, in
stakeholder research, your stakeholders are the participants.

Many of the methods described in later chapters, such as surveys, can be
adapted to stakeholder research. But the most common method for
researching stakeholders---and the most important one, if you're looking
to really understand your stakeholders' goals, motivations, and research
needs---is stakeholder interviews.

**Stakeholder interviews** are semi-structured, in-depth interviews that
are conducted at the outset of a research project to create consensus
and align around research goals.

‚Äç

### When to conduct internal stakeholder interviews

Stakeholder interviews are an important tool in the early stages of
product development, when you're trying to define your objectives and
create a research plan.¬†

But that's not the only time they can be used. Especially when dealing
with high-profile projects or research on a longer timeline, it can be a
good idea to check in with your stakeholders at least once during each
phase of the product cycle.¬†

These check-ins can help keep everybody on the same page, make sure your
research is on the right track, generate new ideas, and gather any
additional information the project may need.

‚Äç

## The benefits of interviewing stakeholders

Successful UX design is dependent upon stakeholder involvement. There's
almost never a reason not to conduct this sort of interview---even when
you work closely and regularly with the big decision makers, you'll
still need to sit down with them to understand their goals for any given
project.

If your project has stakeholders who aren\'t on your immediate product
development team, you'll need to conduct stakeholder interviews with
them as well. They're simply the best way to gather valuable information
about your project parameters.

Stakeholder interviews help you:

‚Äç

### Define goals

Stakeholders largely get to define the success of your project.¬†

But what exactly do your stakeholders want? What do they need? What does
success look like to them? Are those answers different?¬†

Project briefs and requests for research often include ambiguity that
can lead to misunderstandings. And it's not uncommon for stakeholders to
have project requirements in mind that they don\'t vocalize or put into
initial scope documents, either because they incorrectly assume these
things are obvious, or because they haven't consciously thought of them
(yet).¬†

As with [user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
stakeholder interviews help tease out all such unmentioned goals, suss
out details, and illuminate nuances that might otherwise get lost in the
shuffle.

‚Äç

### Understand limitations, user needs, and assumptions

What is the vision? What is the need? What are the parameters? What will
get in the way of how other people might sell or market the product?
What's worked well in the past? What has not?

Talking to stakeholders will give you the initial lay of the land and
can help you determine if user research is even necessary to answer the
question at hand. Chances are good that they've already done some
data-digging of their own and they may even be able to point you toward
a knowledge base that can save time and money all around.¬†

On the flip side, stakeholder interviews can also reveal the limitations
of stakeholder knowledge. What do they not know about the users' needs?
What are some assumptions they're making about what users might want?

Part of a researcher's job is to identify user goals that internal
stakeholders may not be focused on or even aware of.

‚Äç

### Earn trust and buy-in

Future problem-solving becomes easier when there's trust and
communication built-in from the get-go.¬†

Even if your stakeholders are bought into the idea of user
research---indeed, they may well be the people driving the demand for
more research internally---they might still be skeptical about you (if
you're new on the scene), the benefits of certain methods, the time and
costs involved, or the relevance of any given project to their own
needs.

Stakeholder interviews are an opportunity for you to establish or
sustain relationships with key players, demonstrate an interest in their
goals, clarify thinking, and help everyone feel like they've had input
in the project.

‚Äç

###### **Pro tip from** [**Roberta, our VP of User Research**](https://www.userinterviews.com/about#leadership)**:** Just like customer research, stakeholder research comes in a few different flavors and you'll want to choose the best method based on what you\'re hoping to learn. ‚Äç ‚Ä¢ Individual or 1:1 interviews are great when you want more time to dig into understanding the needs and motivations of a specific individual ‚Äç ‚Ä¢ If you're in a time crunch and need to move a project along more quickly, sometimes a focus group type discussion or brainstorm can be a great way to get perspectives from a number of stakeholders at once.

‚Äç

### Are there any drawbacks to stakeholder interviews?

Stakeholder interviews do come with their own challenges. As far as
drawbacks go, they're minor---and none outweigh the value to be gained.
Still, it's worth taking the following into consideration when planning
stakeholder interviews:

#### They take time

The entire process takes time---potentially a lot of time. You can
usually manage the challenge simply by structuring your project\'s
schedule such that you only do X amount of interviews over Y amount of
time. Or there may be projects where it makes sense to partially curtail
the interview process in order to finish in a timely manner, or combine
interviews.¬†

#### Some stakeholders don't want to participate

Some stakeholders love to be consulted. Others, not so much. You will
have to gauge their interest in participation so that you don\'t ask
more of stakeholders than they're willing to give. Making sure that your
interviews are well-organized and professionally conducted will help
inspire confidence in you.

#### They create expectations

Once people are involved in the research process, they tend to develop
certain expectations. They want to see results, outcomes, and answers to
their questions. Some stakeholders may even want to dig into the data or
watch clips from research sessions. Have a plan for [communicating
research
findings](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)
throughout the process, and make sure that artifacts and reports live
somewhere stakeholders can find.

## How to conduct internal stakeholder interviews

‚Äç

### 1. Clarify your own research goals

As with any research, the very first thing you need to do is to [figure
out your
goals](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)---what
do you hope to learn from your stakeholders?

The essential question at this stage, which we've borrowed from [Michael
Margolis at Google
Ventures](https://library.gv.com/questions-to-ask-before-starting-user-research-4607c2633f6f),
is:

###### "What would need to be true for this to be successful?"

For stakeholder research, that question could be rewritten as:

###### What do you need to learn in order to move forward with this research project?

For instance, you may be trying to answer:

-   Does everyone agree about project objectives, or do they have
    conflicting goals and ideas?
-   How do they perceive their own role in the success of the project?
-   What work has already been done, and what needs to be started from
    scratch?
-   Can you clarify who each stakeholder believes is the end user?
-   What does long-term success look like to each stakeholder, in the
    context of this project?
-   Why are we building this product?
-   What user need led to this?
-   What do we know about our user\'s preferences around this product,
    and likewise, what are we not yet sure about?
-   Are there competitive examples of what we\'re building that we
    should take a look at?

These questions can form the basis of a loose interview moderator guide.

‚Äç

### 2. Identify stakeholders

Anyone whose job will be impacted by your research is a stakeholder,
regardless of seniority or job title.¬†

When making a list of stakeholders for this project, be prepared for the
possibility that you could have hidden stakeholders---people whose input
and approval you need, but whose relevance isn\'t obvious. These could
be people like customer support specialists who will end up shouldering
a lot of the burden of bad product design, or they could be silent
partners who might weigh in heavily at the tail end of a project.¬†

The more enmeshed you are in an organization, the easier it will be to
identify your stakeholders for any given project. Rely on your team's
management or folks with greater institutional knowledge to help you
find the right people to involve.¬†

Potential UX research stakeholders include people who:

-   Have organizational influence
-   Make decisions about time, money, and resources
-   Are involved in the UX and product design process
-   Have information relevant to your project
-   Will be expected to act on research insights

If there are so many stakeholders that you cannot realistically
interview everyone, choose representative team members or leaders whose
points of view are rooted in knowledge of your customers, business
goals, and internal operations.¬†

It can also be useful to group people by role, knowledge level, or
involvement in the project. You can then create different moderator
guides for each group, rather than trying to dig into the same set of
questions with both marketers and engineers, for instance.

### 3. Define your timeline, budget, and interview schedule

Once you know the scope of your interview process, you can finalize how
much time you'll spend on interviews.¬†

Do you want to spend a few days on this work? Or do you have the luxury
of time?¬†

If you can, condense your interview schedule over a short period of
time. You'll build momentum, avoid context switching, and free your time
up to work on the other aspects of your project with as much information
at hand as possible.

In most cases, interviews can be conducted by phone or video. If travel
is required, make sure to work this into your timeline and
budget.¬†Here\'s an [example of a stakeholder interview
schedule](https://docs.google.com/spreadsheets/d/1TxsfRzg0G-Jd0gA5x2QwOQDoXfwljSbomMmA8K8PGIM/edit?usp=sharing)
that you can copy and adapt.

### 4. Create a moderator guide

Revisit the research questions you identified in the first step. What
interview questions might you ask to get the information you need to
satisfy the goals of your stakeholder research?

[Prepare a moderator
guide](https://docs.google.com/document/d/e/2PACX-1vQB_Q5SMRfIneojzHmcp99tdecaPgDzoyxdXPNAuuCZr1t-ORQr3fc-Q4Ih8yqiL3X_C4AoIhIXmkLp/pub)
with a list of questions to ask stakeholders (see below for a list of
examples). We use the term 'guide' rather than 'interview script'
because you want to avoid over-structuring your interviews.¬†

Keep it natural. Ask open-ended questions that get to the heart of the
problem you're trying to solve.¬†

#### Sample stakeholder interview discussion guide:

1.  In your view, what is the objective of this project?
2.  Why is this project important?¬†
3.  How does answering this research question fit into the broader
    context of the business?
4.  What does success look like for this project?
5.  What concerns do you have about this project?
6.  What challenges do you foresee this project possibly running into?
7.  What is your role in this project? What would you like it to be?
8.  How will this project impact your day-to-day and your overall job?
9.  Above all, what problem are we trying to solve for users?
10. How will you use our insights to guide product development?
11. What questions do you have for me?

Pick a few key questions to start with and let the conversation flow.
Don't plan to read off a script, but do keep your moderator guide on
hand so you can come back to your key interview goals if things go off
track.

You will also likely have more specific follow-up questions, depending
on your interviewee\'s role. For example, while talking to someone in
marketing, you might talk about the company\'s branding and how the
product you're developing should support that identity. Meanwhile
someone from engineering would be able to tell you about the existing
systems that your product must integrate with or replace.

Be sure to leave time to respond to the questions, comments, and
concerns of your interviewee.

### A template stakeholder interview discussion guide

[Get the
template](https://docs.google.com/document/d/e/2PACX-1vQB_Q5SMRfIneojzHmcp99tdecaPgDzoyxdXPNAuuCZr1t-ORQr3fc-Q4Ih8yqiL3X_C4AoIhIXmkLp/pub)

### 5. Prepare for the interview

Before the interview, send the interviewee a list of types of questions
you intend to ask. This will let them get their thoughts in order ahead
of time, which can save both of you time, and may help you go deeper
during the interview itself.¬†

Also, some projects can be sensitive---if someone is already feeling
defensive, getting the questions in ahead of time could help them not to
feel ambushed.

[18F](https://18f.gsa.gov/2016/06/20/build-empathy-with-stakeholder-interviews-part-1-preparation/),
a digital consulting agency for the US¬†government, also recommends
asking stakeholders to share materials that are essential to their job,
or that might provide you with extra context for their work ahead of the
interview:

###### What helps them get things done right now? Consider looking into books, blogs, mailing lists, meetup groups, etc. that are related to what they do. Even a quick glance over these materials helps ensure that you'll use your time together wisely.

### 6. Flex your interviewing skills

Stakeholder interviews, by nature, tend to be more come-as-you-are and
casual than interviews with external research participants. But that's
not an excuse to get sloppy with your interviewing skills.¬†

#### Break the ice

Most interviewees already have a sense of what's happening, but some may
not. For example, an interviewee\'s supervisor may have told them to
talk to you, but not explained why.¬†

Even if you think the interviewee already knows who you are and why
you're there, state your purpose and let them know what to expect from
the interview process.¬†

\"One of the first things I tend to do during interviews is to explain
my process and agenda for the next hour. Most people haven't been in a
stakeholder interview before so it's natural that they are unsure of
what to expect. I usually begin \[by explaining that\] our goal is that
we want to understand the reason behind the project. In order for the
project to be successful, we need to tap into all their experience and
knowledge. We need to make sure that we have a cohesive vision of what
it is that we're supposed to create.\" --- [Anton Sten, UX
Lead](https://www.antonsten.com/stakeholder/)

If you plan to record the interview (and we recommend that you do), be
sure to ask the interviewee for their approval before hitting the
'record' button.

‚Äç

#### Pay attention

It\'s not unusual for interviewees to casually drop some interesting and
important information when they are literally on their way out the door.
Be observant, listen closely, and watch those non-verbal cues too!¬†

¬†

#### Be flexible and responsive

Some people don't want to talk. It's your job as an interviewer to
gently draw them out. Some people love to talk, and you'll have to
manage them by managing time and ¬†diplomatically steering things back to
topic.¬†

‚Äç

#### Dig deeper

Many of the most important insights are ones you won't have anticipated
when planning your questions. Listen carefully and follow up with
clarifying questions. Andrew Maier of 18F
[advises](https://18f.gsa.gov/2016/06/20/build-empathy-with-stakeholder-interviews-part-1-preparation/):

\"People tend to shy away from asking clarifying questions because of
how others might perceive them: no one wants to look stupid. Yet the
goal here is to document your stakeholders' understanding---not your
own---which means you should absolutely ask clarifying questions, even
if you think you know the answer.\"

#### Wrap it up

Make sure to leave time at the end of the interview to answer questions
and thank stakeholders for their time.¬†

### 7. Transcribe your interviews

Use a transcription tool or service to get your interview recordings
transcribed for analysis and reference. If you took notes during the
interview, transcribe them as soon after the interview as possible,
while the conversation is still fresh in your mind.¬†

And as Andrew Maier
[explains](https://18f.gsa.gov/2016/07/22/building-empathy-with-stakeholder-interviews-part-2-conversation/):

\"Transcribed interviews are also really useful for sharing back with
stakeholders. Everyone loves to read things that they said --- they
might regret it, or they might be proud of it, but they definitely want
to read it. Further, sharing transcripts back with stakeholders builds
trust by showing that you've actually listened to them, that you respect
their ability to speak for themselves, and... \[w\]hat's more,
stakeholders usually add information after the fact!\"¬†

‚Äç

### 8. Analyze, synthesize, and share your findings

Some interviewees are quite compelling, either because they have extra
strong opinions or because they're especially charming or otherwise
deeply engaging. You might be tempted to make decisions on this one
person's feedback. But be sure to review all of your data before your
decision-making is swayed. The loudest person isn't always the one who
best represents the needs of the whole.

As with user research, the records of your interviews are data, and
they're not of much use until they've been analyzed. You'll need to
conduct some [qualitative research
analysis](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
on your interviews---both from each individual interview and from all
the interviews collectively---to figure out what you've learned.

And just like user research, the benefits of stakeholder interviews can
only really be felt once the insights are documented, shared, and
socialized within the wider team, so it\'s important to [track the
impact of your
work](https://www.userinterviews.com/blog/how-to-track-the-impact-of-ux-research).

After each interview, [write up a
summary](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)
(it can be brief). Your objective is for anyone on your project
team---even those who never spoke to any of the interviewees---to have
full access to the insights you gleaned from talking to stakeholders. If
there's sensitive information that shouldn't be shared with everyone, be
prudent. The key thing is to identify patterns in feedback from
participant to participant.

‚Äç

## Examples of stakeholder interview questions

The right questions to ask during internal stakeholder interviews will
naturally vary depending on the goals of your research, the data already
available to you, and who you're interviewing.

Here is a list of questions you might ask, depending on what is you're
trying to learn:

##### Project vision:

-   What would success look like for this project?
-   What are the potential pitfalls of this project?

##### Business goals:

-   What are the short- and long-term business goals?
-   What should this project accomplish for the business?
-   What are the business implications if this project failed?

##### Product:

-   What actions do we want users to take?
-   If users could wish for any change to the product, what would that
    be?
-   What are the biggest product challenges today?

##### Marketing/positioning

-   What similar tools do people use?
-   What are those tools' relative strengths/weaknesses?
-   How would you describe the core value prop of our product?
-   What user problem do we solve?
-   What are the main marketing messages?¬†
-   Do users understand these marketing messages?

##### Users

-   Who are the primary users?
-   What is their defining attribute?
-   What defines a successful experience for the user?¬†
-   Are the users also buyers?
-   Where do users get stuck?

##### Customers:

-   Who are the target customers?
-   What customer problem do we solve?
-   What does the buyer journey look like?
-   What defines success for the customer?¬†
-   How do you engage with prospects?
-   What is a surprising thing you learned by working with these
    customers?

##### Context of use/workflow:

-   What frustrations/ pain points do you experience with their current
    process?
-   What data do you currently collect?¬†
-   What tools do you use as part of your job?
-   How will the results of this research impact their workflow?

‚Äç

##### Wrap-up

-   What should I have asked about?
-   Is there anyone else you think I should interview for this project?
-   Do you know how you like to receive research results and
    deliverables, and how often?

## Tips and takeaways

By now, you should understand how (and why) to conduct successful
internal stakeholder interviews. As with all research skills, your
stakeholder research skills will improve with practice.

We'll leave you with a few final tips and takeaways to help you make the
most of your time with key project stakeholders:

#### Planning:¬†

-   **Be clear about the goals of your stakeholder research**.
    Well-defined objectives and goals will help you conduct more focused
    interviews, make analyzing the results a lot easier, and will allow
    you to effectively communicate the insights you gain from your
    stakeholders' time.¬†
-   **Plan at least 45 minutes for each interview**---this is typically
    a manageable chunk of time for busy stakeholders, but still leaves
    time for the conversation to flow, to dig into interesting topics as
    they arise, and to answer questions from interviewees.
-   If a stakeholder simply cannot meet with you in-person or remotely
    (perhaps due to differences in time zones or other scheduling
    conflicts), it is possible to **conduct asynchronous interviews over
    email**. There are serious drawbacks to this method---you can't read
    non-verbal cues, conversation doesn't flow as freely---but if this
    is a key stakeholder, email interviews are better than no
    interviews. Just make sure you've given extra thought to your
    written script, and that you ask clarifying follow-up questions,
    like you would in a synchronous interview.

#### During the interview:

-   **Don't be dismissive** of stakeholder concerns or skepticisms about
    the research process. Take time to acknowledge their concerns and
    answer their questions. These conversations are a great opportunity
    to establish trust and start educating internal stakeholders about
    user research.¬†
-   **Try not to read off a list of questions.** Keep your list of
    must-asks short (2-3 questions) and memorize them. This should feel
    like a conversation, not an interrogation.
-   **Show genuine interest and curiosity** in stakeholders---their
    jobs, frustrations, observations. Remain engaged with their
    responses---stakeholders will lose focus quickly if they feel like
    you've checked out.

#### Analyzing and sharing interview data:

-   **Transcribe and analyze** the results of each stakeholder interview
    after each session, and share these summaries with your research
    team as you go.¬†
-   Once you have analyzed and synthesized the data from all the
    interviews, consider **sharing insights out with the broader team**
    in chunks vs. as a single document---this will allow you to really
    focus on a particular insight and any recommendations or next steps
    that came out of this process.
-   **Compare what stakeholders said** with your initial assumptions.
    What surprised you? Which assumptions were confirmed? Share these
    learnings with the team.

#### After the interviews:

-   **Stakeholder interviews are not a set-it-and-forget-it kind of
    thing.** You'll have project milestones, and each milestone should
    include another phase of stakeholder communication. These stages may
    be less intense than the initial round---you could even gather
    stakeholders together in one place, at one time, periodically. Or,
    if your company defaults to async, share updates and solicit
    feedback in a dedicated Slack channel. However you manage it, be
    sure to keep communication going throughout the build process.
-   **Stakeholders can change.** Companies reorganize, people take on
    new and unrelated projects, budgets are rearranged. And priorities
    change, especially over the course of longer projects. Stay up to
    date on who your stakeholders are. Frequent communication with
    stakeholders will ensure that you don't miss important shifts that
    could affect your project or broader research strategy.

And there you have it---everything you need to know about conducting
stakeholder interviews for UX research. Now you're ready to start
talking to some users\...

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/create-user-research-plan)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/recruiting)

Next:

Recruiting for UX Research

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Recruiting for UX Research](/ux-research-field-guide-module/recruiting)

![a person looking through binoculars surrounded by profile cards of
other
people](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f27f6e6378ba14228f88_UI_CHAPTER_03_ARTWORK.jpg)

03\.

# Recruiting for UX Research

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Recruiting participants for user research is no fun. It's a process full
of time-consuming logistics and potential pitfalls that most researchers
would love to push off their plate.

Well, know a thing or two about research recruiting around here
(including how to make it less of a chore). And we\'re excited to share
that knowledge with you!

In this module, we're spilling everything we know about UX research
recruitment. You'll learn how to:

-   **Recruit participants for research studies.** Whether you're
    looking to refine your recruiting strategy or DIY the whole thing,
    this step-by-step guide will help you recruit like a pro.
-   **Write effective screener surveys** that will help you find and
    filter the right participants who can answer your research
    questions.
-   **Choose the right incentive type and amount**, depending on your
    methodology, participant profile, and research goals.

[Start
reading](/ux-research-field-guide-chapter/find-good-research-participants)[Start
reading](/ux-research-field-guide-module/user-research-methods)

In this module:

[How to Recruit Participants for User Research
Studies](/ux-research-field-guide-chapter/find-good-research-participants)

A foolproof framework for finding the right participants.

[Screener Surveys](/ux-research-field-guide-chapter/screener-surveys)

These little surveys are your first line of defense against unqualified,
uncommunicative participants.

[User Research
Incentives](/ux-research-field-guide-chapter/ux-research-incentives)

Encourage participation, recruit a broader pool of participants, and
thank people for their time with the right incentives.

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### How to Recruit Participants for User Research Studies

A foolproof framework for finding the right participants.

##### Screener Surveys

These little surveys are your first line of defense against unqualified,
uncommunicative participants.

##### User Research Incentives

Encourage participation, recruit a broader pool of participants, and
thank people for their time with the right incentives.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/user-research-methods)

04\.

### UX Research Methodologies

[](/ux-research-field-guide-module/discovery-methods)

05\.

### Discovery Research Methods

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Recruiting for UX Research](/ux-research-field-guide-module/recruiting)

\>

[How to Recruit Participants for User Research
Studies](/ux-research-field-guide-chapter/find-good-research-participants)

# How to Recruit Participants for User Research Studies

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Not to toot our own horn, but here at User Interviews, we know a thing
or two about user research recruiting. It's kind of [our
thing](https://www.userinterviews.com/recruit).¬†

This step-by-step guide to user research recruiting will teach you how
to find participants for UX research, full stop. It is meant to be
agnostic---meaning you'll be able to apply this knowledge regardless of
experience, budget, type of research, user testing tools you plan to
use, and the kinds of participants you hope to recruit.

That being said, [User Interviews is a research recruiting
tool](https://www.userinterviews.com/). We exist to solve the pain point
of user research recruiting---especially qualitative research
recruiting, in which researchers are looking for participants who meet
highly specific criteria relevant to their research question.¬†

As such, we'll be name-dropping ourselves a few times in this
chapter---but only when we think it makes sense for you to know about
how our product can help during the recruitment process.

##### **üëã Read the User Interviews** [**origin story**](https://www.userinterviews.com/blog/from-failure-to-a-venture-backed-startup-through-meta-user-research)

‚Äç

### In this chapter:

-   Why is user research recruiting so hard?
-   Who are the right participants for different types of research?
-   How many participants do you need?
-   A foolproof framework for user research recruiting
-   UX research recruiting tools¬†
-   More channels for recruiting participants
-   Tips to avoid participant burnout

## Why is user research recruiting so hard?

User research recruiting is a pain. For many researchers, it's the pain
that takes up time and energy they'd rather be spending talking to
users.

Whether you're an experienced researcher or new to the game, recruiting
research participants for a study remains a challenge. Why?¬†

-   There are so many (too many!) channels and methods you can use to
    find participants, but different channels will work better for
    different projects.
-   Many user testing tools offer [participant
    panels](https://www.userinterviews.com/blog/build-manage-research-participant-panel)
    to recruit from---but you can only test on their platform.
-   Repeatedly using the same channels and methods will result in
    diminishing returns (i.e. burning out participants).
-   It's difficult to find eligible participants who meet the criteria
    for niche studies.
-   It's a lengthy and complex process, and some projects don't have the
    luxury of time.
-   Offering the right incentives and distributing them is
    time-consuming.
-   It's hard to manage participants during long-term or recurring
    studies, such as customer research projects.

These challenges are very real and very frustrating---but none of them
are insurmountable. Over the course of this chapter, we'll explain how
to overcome these challenges and make the research recruiting process (a
lot) less painful.

First, let's talk about your participants. Who are they? Or, rather, who
should they be?

## Who are the right participants for different types of research?

As you'll see in the research recruiting framework below, the first step
to a successful recruit is clarifying the goals of your research and
which methods you intend to use.¬†Ask yourself:

‚Äç

###### What do you want to learn? How do you plan to learn that?

The next step is to define your ideal research participant profile. What
criteria do participants need to have? Who, exactly, is going to have
the answers to your questions?

We'll dig into ways to define participant criteria in more detail later
in this chapter. But first, let's go over a couple of the broader
considerations that will influence your recruitment strategy.

Namely, let's talk about the differences between recruiting for
qualitative and quantitative research, as well as the differences
between recruiting external participants and recruiting among your own
customers.

### Recruiting for qualitative vs. quantitative research

Should you seek out your ideal user or cast a wide net? Do you need your
participants to be articulate, expressive, and have experience relative
to your product? Do you need a lot of people to achieve accurate
results?

#### Sampling for quantitative research

Quantitative research recruiting is a numbers game. For data analysis to
be meaningful and statistically significant, you need a lot of data.
Which means you need to do a lot of research with a lot of people.

When deciding [who to recruit for quantitative
research](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods),
you first have to define the population (the entire group you want to
study). A population can be extremely broad ("doctors," "women between
the ages of 18-35") or slightly more specific ("doctors in California,"
"unmarried Australian women between the ages of 18-35").¬†

From there, you will choose a sampling method that allows you to create
a sample---a randomly selected subset of the population who will
participate in your study.

#### Qualitative research recruiting

In qualitative research, which involves far fewer participants, you need
to be a bit of a Goldilocks. You're looking for the \*perfect\*
participants---people who meet specific demographic, geographic,
psychographic, and behavioral criteria relevant to your study.¬†

[Recruiting participants for qualitative
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
involves non-random sampling, screening, and a lot of communication.

### Recruiting your own customers for research studies

Your research goals will determine whether it makes sense to use your
existing customers, recruit a representative audience, or use a mix of
both.¬†

More often than not, if you're updating an existing product with new
power features, your existing users will be your best audience. If
you're building a brand new feature or product, non-users can provide a
fresh perspective.¬†

#### It makes sense to recruit your own customers when:

-   You're updating an existing product.
-   Your research requires extensive experience with your product.
-   You want to test for usability among experts rather than novices
    (for example, to test advanced features for power users).

If you choose to work with your existing customers, a lot of the work of
finding a representative audience is done for you. That's a big plus!¬†

It may be possible to access recruits by emailing existing customers,
posting a request for participants on your website or social media, or
having account managers, sales people, or customer service reps make
direct requests---just be mindful not to inundate your valued customers
with too many requests for input, and don't forget to make it clear
what's in it for them.

In some cases you may not need to offer financial incentives to your own
customers. Instead, consider emphasizing how much their feedback will
improve the product that they're already using or offering early access
to the new feature.

### Talk to your users in 75% less time

[Try Research Hub free](https://www.userinterviews.com/research-hub)

#### It makes sense to recruit external participants (non-customers/users) when:

-   You're developing a brand new product.
-   You need to test for usability among novices (who are more likely to
    stumble on usability issues that an experienced user of your product
    might not).
-   You want to test potential new customer groups.
-   You want to understand your competitors' customers.

Non-users are an excellent resource if you want to understand the people
who might benefit from your product if your product isn't on the market
yet. They also tend to be useful for identifying usability issues that
people familiar with the product may have already overcome.

Talking to your competitors' customers may help you understand how to
adapt your product to cater to a gap in the market or gain a competitive
edge based on your respective strengths and weaknesses.

### Recruit from our panel of 700,000+ vetted participants

[Sign up for free](https://www.userinterviews.com/recruit)

#### Why not both?

Customer research and user research aren't mutually exclusive. Depending
on the goals of your research, it is often useful to talk to both groups
for a broader range of insights. Just be sure to differentiate between
groups and adapt your methods accordingly.

## A foolproof framework for user research recruiting

### 1. Define your research goals and methodology

Defining your purpose and clarifying your objectives is a prerequisite
to any user research project. By the time you get to the recruitment
phase, you should already have clearly stated goals and reasons for
doing this research.¬†¬†

Planning your recruitment strategy is part of [UX research
design](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)---it
should happen before recruiting and research kicks off, and the 'whos,'
'whens,' 'hows,' and 'whys' should be outlined in a concise user
research plan ([like this
one](https://docs.google.com/document/d/e/2PACX-1vT7MAwQSR4pjvaqUnuCOGLuz3Eg3e3zBqVq8s7CYmx5gcVsDe6BxsyUBBsLIjCEKLIWnJcs3WPtBiGf/pub)).

Capisce?

‚Äç

### 2. Decide who to recruit for your research¬†

Generally speaking, you need to know what you're looking for in order to
find it. When it comes to finding the right user research participants,
this means taking the time to figure out what your research question is
and who, exactly, can best help you answer it.¬†

While this step may seem like a no-brainer, it's often overlooked.
Taking time to do it right can make a huge difference in the quality of
your research.

Targeting should typically be defined by using a mixture of the
following criteria:

-   Psychographics: Activities, hobbies, interests, and opinions
-   Behaviors: What they do (e.g. 'regularly commutes by car')
-   Demographics: Age, gender, education, income, marital status, etc.
-   Geographics: Country, city, region, or radius around an area

The first way to improve the quality and suitability of participants
when recruiting for a study is to clearly define your intended
participants.

If you're doing research for a company or a product, the target audience
is usually representative of your eventual---or existing---customers.

To determine who to recruit, ask yourself:

#### What is the goal of your research?¬†

What you want to learn from your study will determine who you should
study. Consider what insight would be most useful, then work backward to
figure out who can best provide that insight.

‚Äç

#### Are you in the discovery, testing and validating, or post-launch phase of product development?

Research can be useful at [every stage of the product development
cycle](https://www.userinterviews.com/ux-research-field-guide-chapter/what-is-user-research).
In the early stages, think broad---you'll want a variety of opinions and
perspectives during discovery. Further along in the process, a more
precise target audience will provide the richer insight you need to
optimize your product for current users.

‚Äç

#### What is your research question?

[According to Erika
Hall](https://medium.com/mule-design/research-questions-are-not-interview-questions-7f90602eb533),
a good research question is "specific, actionable, and practical."

‚Äç

In other words, an effective research question is one that can be
answered with a reasonable amount of certainty, using the tools at hand.

‚Äç

For example, you could not reasonably find an answer to the question:
"What does my cat think about all day?" I can't ask my cat what it
thinks about, so any answer to this question would just be a guess. I
could, however, answer the question: "What does my cat do while I'm
working?" I could monitor behavior over a period of time and eventually
wind up with a definitive answer.

Here are some examples of specific, actionable, and practical research
questions:

-   "Does our pricing page accurately address our customer's questions
    about our pricing?"
-   "What tools do 20-somethings use to manage their finances?"
-   "How are enterprise users currently addressing the problem this new
    feature is intended to solve?"

Questions like these are specific enough that you will know when you
have found an answer, practical in the sense that you could reasonably
find answers in the scope of a research project, and actionable in that
you can act on the answer that you find.

‚Äç

#### Who can answer that question?

A specific, actionable, and practical research question will also help
you identify the kinds of participants you need to answer that question.
For example, to answer the question "What tools do 20-somethings use to
learn how to manage their finances?" you would need to talk to people in
their twenties who are interested in actively managing their money.¬†

Think through the specific traits a potential participant would need to
have.¬†

Sometimes, when you're getting started with research, it's easy to get
hung up on requirements that don't really matter to your study.¬† We
always encourage researchers to narrow their list to the minimum
requirements needed.¬†

Let's use the pricing page question as an example. To answer "Does our
pricing page accurately address our customer's questions about our
pricing?," we may start off with the following list of criteria:

-   Active customers
-   Ages 25-50
-   Has a college degree¬†
-   Signed up over 6 months ago

Investigating each of our requirements further can help us to narrow
them down a little and focus on why each requirement is there.

We would want to talk to current customers because they can help us best
understand the questions our target audience will ask about our pricing.
We also want to talk to people who signed up over 6 months ago because
(in this hypothetical example) that was the last time we changed our
pricing page. People who signed up within the past 6 months may have
already seen this version of the pricing page and may already have had
their questions answered.¬†

As far as eliminating requirements goes, there's nothing about age that
would prevent someone from being helpful with feedback on our pricing
page, so we can cut that requirement. Ditto education level, unless your
pricing page uses some seriously highfalutin language (which, fyi, it
shouldn't).

So our new requirements are:¬†

-   Active customers
-   Signed up over 6 months ago

This process can help you narrow down your ideal participants and cut
out requirements that may slow down your recruit for no reason. It's
also a good way to gut-check your research question. If you find
yourself with requirements that aren't reflected in your question, this
process can help you think about why those requirements are there and if
you need to alter your research question.

Some more examples of target groups are:

-   40- to 60-year-old men who live in small New England towns and drive
    to work
-   Georgia parents who use childcare at home
-   Tennis players in England who are active on Instagram
-   Unemployed recent high-school graduates who live in big US cities

#### Who can't answer your research question?

It's equally important to define who you're not looking for.¬†

For example, if you want to know which day of the week people in San
Francisco drink the most wine, your recruitment efforts would be wasted
on participants who are under the age of 21 (in theory).¬†

It's important to define these targets and non-targets at the outset,
because it helps you create a solid screening process.¬†

### 3. Determine how many participants you need¬†

The right number of participants will depend on the [type of research
you're
doing](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
and the specific methods you plan to use.

The UX experts at [Nielsen Norman Group famously
advised](https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/)
that for usability studies, you only need 5 good participants---and
people have been parroting that advice ever since.

And for most usability studies, 5 is an ideal number---beyond that
you'll get diminishing returns. (Unless of course you recruited the
wrong people in the first place. So\... don't do that.)

But what about user interviews? Diary studies? Quantitative studies?¬†

As a rule of thumb, the right number of participants for quantitative
research = however many people you need to achieve the level of
statistical significance your study requires.¬†

For academic researchers, that could mean finding 1,000 to 2,000
participants to achieve maximum reliability. But for most quantitative
usability studies, 20 users is often plenty---although [the ideal
number](https://www.uxmatters.com/mt/archives/2016/01/how-to-determine-the-right-number-of-participants-for-usability-studies.php)
still depends on the type of study you're conducting.

For qualitative research, it really is a matter of quality over
quantity. To give an extreme example:

###### [Before Sara Blakely launched Spanx](https://www.npr.org/transcripts/493312213), she only needed insight from one person---a sales associate at Neiman Marcus---to understand that there was a market fit for her new pantyhose design.¬†That one person told her that several customers had been making a homemade version of the product she wanted to create because there was nothing else on the market at the time that met their needs. Running with that one piece of insight, Blakely was able to create a prototype, and guess who her first customer was? Neiman Marcus.

In general, though, we recommend talking to more than one person before
making any major decisions.¬†

Here are some suggested sample sizes for different types of UX research:

-   Interviews -- 3 to 10 participants¬†
-   A/B tests -- 5 to 8 users
-   Focus groups -- 5 to 10 participants per group
-   Diary studies -- 10 to 15 participants
-   Card sorting -- at least 15 users per group
-   Quantitative studies -- at least 20 participants
-   Surveys -- at least 100 participants¬†

Nielsen Norman Group has found that the [average no-show
rate](https://www.nngroup.com/articles/recruiting-test-participants-for-usability-studies/)
for a usability study is 11%. That means that for every 10 participants
you recruit, 1 of them is likely to be a no-show. You can reduce the
risk of no-shows with good communication and the right incentives, but
it's always a good idea to recruit a few extra participants that you can
call on, just in case.

If you're using [User
Interviews](https://www.userinterviews.com/recruit), we'll do this for
you so you never find yourself without backup if someone doesn't show up
for their session.¬†

### 4. Create an incentive plan

We cover incentives in more depth [later in this
module](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives).
But the ¬†gist is that you should compensate participants for their time,
and do it in a timely manner.

Setting an appropriate incentive increases the likelihood of a great
recruit. It shows that you respect participants' time and that you value
their expertise.

Monetary incentives, including gift cards, are the most popular form of
incentive, but incentives can also take the form of charitable
donations, account credits, or swag. (Seriously, don't underestimate the
power of good swag: There's a whole community of people dedicated to
buying, selling, and trading Mailchimp monkeys, after all.)¬†

The most important thing about your incentives is that they are valuable
to your participants and that they get people excited about
participating in your research.¬†

Here are our [incentive
recommendations](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
in a nutshell:

-   In-person studies demand higher incentives than remote studies.
-   Higher income earners expect higher incentives than lower income
    earners.
-   The longer the time commitment, the higher the incentive.

We've also found that moderated research---which requires more
coordination and communication between researchers and
participants---generally warrants a higher incentive than unmoderated
research.¬†

For a detailed breakdown of how much to pay your research study
participants for in-person and phone interviews, consult [this handy
cheat
sheet](https://docs.google.com/document/d/e/2PACX-1vQYgHN7gqHflkZAIRwr_C4KQNoU8aeqeaRgcXJn4IgehUFmeb0pu3X2ZdP6ReoRksmBmMUQeZQu-gOG/pub).
And check out the [UX¬†Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
for personalized, data-backed incentive recommendations.

Once you determine what and how much your incentives will be, you should
also have a plan for distributing them soon or immediately after each
session.

üìñ **Read more about** [**User Research
Incentives**](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)

‚Äç

### 5. Find participants

Finding participants is a consistent and frequently cited pain point
among just about everyone who does user research. Companies with big
research teams have entire research ops divisions to help them manage
the logistics of recruiting and managing participants for all those
projects. Smaller research teams either go it alone with a recruitment
tool or use research agencies to handle recruiting for them.¬†

The good news is there are lots of tools out there to help you recruit
participants for your research. You can use low-cost user research
recruiting tools like User Interviews to recruit vetted participants, go
it alone on Craigslist or social media, or turn to a research recruiting
agency for a totally hands-off (but expensive) process.¬†

We'll go over the different channels and tools for recruiting research
participants in more detail at the end of this chapter.¬†

‚Äç

In a nutshell, your options are:

-   **User research recruiting platforms** (like ours). These tools
    offer a large pool of participants and let you filter by target
    criteria to fill niche studies, regardless of where they'll be
    conducted.
-   **Your customers.** If you're doing research about an existing
    product or service, recruiting from your own customer base is always
    a good place to start. Depending on the goals of your project, you
    could look at things like user analytics, customer support tickets,
    NPS scores, etc. to identify customers that are a good fit for your
    study.
-   **User research recruiting agencies**. There are good ones and bad
    ones, and typically cost a pretty penny. But if you're looking to
    outsource the whole, unpleasant process and can afford to do so, an
    agency can help take recruiting off your plate in a big way.
-   **Social media.** Posting a Google Form on LinkedIn, Facebook,
    Twitter, or even Slack groups can be a good way to find research
    participants---just make sure you have a robust screener prepared to
    weed through unqualified candidates, since you'll likely get a lot
    of them.¬†
-   **Your website.** Intercept surveys, popup modals, and banners can
    be effective ways to reach site visitors. Just make sure you're not
    interrupting an important workflow or task---otherwise you'll end up
    recruiting a lot of annoyed participants.

‚Äç

### 6. Screen participants¬†

This next step puts the work you did in step 2---defining a research
question and key participant traits---into action to separate the good
participants from, well, the not-so-good.

The best way to do this is with [a screener
survey](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys),
which is a (typically brief) survey participants take before they
qualify for your study. You can think of a screener survey as a sieve
that captures the people who hit all your 'must have' criteria and
filters out the ones who don't quite fit the bill.

Again, these criteria are usually a mix of:

-   Psychographics: Activities, hobbies, interests, and opinions
-   Behaviors: What they do (e.g. "regularly commutes by car").
-   Demographics: Age, gender, education, income, marital status, etc.
-   Geographics: Country, city, region, or radius around an area

This is a deceptively straightforward concept---many (many!) researchers
struggle to create the perfect screener survey. And getting this part of
the process wrong can have far-reaching implications for the entire
research project.

Because screener surveys are so important, we've dedicated an entire
chapter to the topic, which you can read here. User Interviews customers
also have access to our knowledgeable [Project
Coordinators](https://www.userinterviews.com/blog/cs-support-operations-team-guide),
who can help you craft a standout screener survey.

Short on time/patience? Here are our recommendations in a nutshell:

‚Äç

#### Filter by behaviors \> demographics

Demographics are the low hanging fruit of screener surveys, and it often
makes sense to include a few demographics questions either at the
beginning or at the end of your survey. But don't let age, gender, and
location questions be the end-all be-all.

You'll want to start by identifying which demographics, if any, really
define your audience conclusively.¬†

###### **Remember:** your screener survey and the research that follows should help you tap into what people really want and need from your product---and demographics alone won't get you there.

#### Eliminate unqualified people early

Don't make prospective participants complete your entire screener before
finding out they don't qualify. Start with the questions that are most
likely to weed out large groups of unqualified participants. The easiest
way to do this is to write out your questions, rank them in order of
importance, and look for any interdependencies.¬†

For example, before diving into questions about how people use apps on
their smartphones, find out if they use a smartphone at all. Then, move
on to the questions that tap into specific behaviors, interests, and
preferences.¬†¬†

#### Avoid tipping your hand

A screener survey is meant to help you find the candidates who are a
perfect fit for your study. Giving away the plot too early---by, say,
telling participants what your study is about---can devalue the
screening process and make your research less effective.

To avoid tipping your hand at this stage:

-   Don't reveal the purpose of your research study.
-   Don't reveal the name of your company or product.
-   Don't ask leading questions.

#### Look for expressive people

Don't you just love conversations where you have to drag answers out of
the other person?

Of course you don't. People who make terrible dinner party guests also
tend to be less-than-optimal candidates for qualitative research.¬†

Screen for high-quality participants by asking "articulation questions."
These are open-ended questions designed to test a user's capacity to
communicate. If a person can express their ideas with depth of thought,
they're likely to be a helpful participant.¬†

Including open-ended questions also helps weed out "professional
participants" who are just looking to make a quick buck by qualifying
for any and every study.

#### Provide an "other" option

If you create multiple choice responses, don't assume that you've
presented the user with every possible option. As Gandalf once said,
"even the very wise\[st survey designers\] cannot see all ends."¬†

Include a 'none of the above,' 'I don't know,' or 'other' option to
account for any outliers.¬†

Otherwise you could end up with someone in your survey who doesn't
belong there because they were forced to choose an answer that didn't
apply to them. Likewise, you might screen good participants out because
they didn't quite fit the answers you provided.

#### Remember to keep it brief

Lastly, it's important to keep screener surveys short and sweet. We've
seen some screener surveys get so long that participants mistake them
for a (paid) research survey! If you're looking for a rough guideline on
length, try to keep your screener to fewer than 10 questions.¬†

‚Äç

### 6. Schedule participants for a mutually convenient time

Don't you just love emailing back and forth to "find a time that works
best for everyone?" Yeah, neither do we. That's why we built scheduling
right into [the User Interviews
interface](https://www.userinterviews.com/), so you can just choose the
times you're available and your participants can select from
the¬†available time slots.¬†

If you're not using User Interviews to schedule your sessions, you may
need a dedicated scheduling tool to help you coordinate your
sessions---especially when coordinating multiple interviews‚Å†.¬†

Tools like Calendly, Doodle, and YouCanBookMe help take the hassle out
of scheduling sessions by allowing your participants to select an
available time slot on your calendar, similar to our scheduling
function.

Make sure to include a calendar invite when each booking is confirmed.
If they accept the invite, the participant may get notifications on
their phone in addition to your emails and other outreach---all of which
help them remember to show up!¬†¬†¬†¬†

Be respectful of your own time, too. Limit the number of sessions you
conduct each day, and give yourself at least 15 minutes between sessions
in case you have a particularly talkative participant. If you can, aim
for a 30 minute buffer---this will give you time to polish your notes
from the previous session while they're fresh in your mind, and will
give you time to prepare for the next one.

### 7. Communicate with participants to reduce no-shows

After a participant signs up for a user research session, send them a
confirmation email right away. To help your participants remember the
interview and get to the right place at the right time, be sure to
include 3 key pieces of information:¬†

-   Time and date---if doing remote research, make sure you give the
    time and date in your participant's time zone.
-   Location---include a map and directions if the test is in person, or
    a link to a video call and instructions for joining.
-   Research topic---don't give too much information away, but do remind
    users what the research will be about.

It never hurts to be enthusiastic, thank the interviewee, and
re-emphasize the impact of the interview.¬†

And while you don't want to bombard your participants with a constant
stream of messages, do plan to follow up multiple times for interviews
scheduled a week or more in advance.

A typical outreach cadence may be:

-   On the day of sign-up---this will be your first opportunity to give
    them all the details so they can plan effectively.¬†
-   A week in advance---if you scheduled more than a week in advance,
    follow up 7 days before the interview.¬†
-   The day before---follow up the day before the interview with all
    relevant details to make sure your participant can plan accurately.¬†
-   The day of the test---send a final follow-up a few hours before the
    interview. Again, include all details, especially directions and
    access information, to make sure your user can reach you without
    trouble. You may want to provide a phone number or way to contact
    the researcher in case your participant needs real-time assistance.¬†

By the way, you can automate all of this outreach in User Interviews,
whether you're contacting your own users via [Research
Hub](https://www.userinterviews.com/research-hub) or sourcing new
participants through [Recruit](https://www.userinterviews.com/recruit).¬†

For longer research like [diary
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies),
periodic reminders may be needed to keep motivation high. You might also
consider spreading your incentives distribution out over time to promote
and reward continued engagement.

‚Äç

### 8. After the session, thank participants for their time

The incentive plan that you put together in step 4 should include a
strategy for distributing incentives to participants as soon as possible
once the session wraps up.

We recommend researchers use popular digital payment platforms like
PayPal for cash-based incentives. If you use User Interviews for
recruiting participants for a study, we can instantly process incentive
payments through gift cards. We will also automatically issue 1099s for
your tax records. Or you can handle incentives independently---it's up
to you.¬†

Just remember, while compensation is important, incentives aren't enough
to guarantee high-quality and happy participants---people need to have
clear instructions, and they need to know you're truly grateful for
their time.¬†

## User research recruiting tools

Look, User Interviews is a user research recruiting and management
platform. We're a little biased when it comes to [UXR recruiting
tools](https://www.userinterviews.com/blog/ux-research-tools-map-2021)...
but that's only because we're the best.

All jokes aside, User Interviews is one of just a few tools fully
dedicated to solving this part of the user research process. It's why we
exist---and we're good at what we do.

Our platform is [a one-stop shop for recruiting
participants](https://www.userinterviews.com/)---whether you want to
draw from your current user list or recruit from our audience of over
700,000 ready, willing, and vetted research participants from seven
countries. You can also target over 140 different industries, job
titles, demographics, and custom screener criteria. If you incentivize
your participants with Amazon gift cards, we'll manage the incentives
for you.

User Interviews also includes screener surveys, scheduling for
interviews, and participation tracking for your existing users. Don't
feel like handling incentives? If you choose to have them distributed as
digital gift cards, we'll manage the distribution for you.¬†

The median turnaround time to match you with your first participant is 3
hours, though it can vary based on the project.¬†

If you're looking for a solution to manage your own participant
population, we can do that too! Our Research Hub Free Forever plan
stores up to 100 of your own participants and lets you keep track of
when they last participated and even how much you've paid them in
incentives.

#### Other popular research recruiting tools (the honorable mentions):

-   [TestingTime](https://www.testingtime.com/en/)---Zurich-based
    TestingTime is a good solution if you're looking to recruit
    participants from Europe. They also offer a UX research service for
    companies looking to outsource the entire user research process.
-   [Askable](https://www.askable.com/)---based in Australia, Askable is
    a solid option if you're looking to recruit participants from
    Australia and New Zealand. They also offer a remote testing suite
    with video,¬† text chat, screen sharing, and session recording.
-   [Respondent](https://www.respondent.io/marketplace)---a popular
    option for researchers who want to recruit business professionals,
    Respondent is especially useful for B2B research (although they do
    offer B2C recruiting as well).
-   [UserZoom](https://www.userzoom.com/participant-recruitment/)---if
    you've been in user research for a few years, there's a good chance
    at least one of your favorite products has since been acquired by
    UserZoom. They offer a suite of user research and usability testing
    tools, as well as a large pool of participants. This can be an
    efficient option if¬† you're planning on doing research through the
    UserZoom platform.

## More channels for recruiting participants¬†

If you decide to DIY your research recruiting, you have several options,
depending on who it is you're trying to recruit.

‚Äç

### Researching your own users

‚Äç

#### Live intercepts

Messages can be delivered in real time within your website or app based
on the user's actions or engagement, their background account
information, and/or other criteria. You can recruit at the flick of a
switch, but you'll need to contend with third-party integrations and
potential complexity in managing the tool.¬†

‚Äç

#### Organic social media

If you've built an active and engaged social following from your own
customer base, you can recruit people directly through these profiles.
It's free and straightforward, but some platforms (e.g., Facebook &
Instagram) are making it hard for brands to get by on organic reach
alone---so you might struggle to capture enough eyeballs. You can
navigate this by boosting posts to an audience of your own page
followers (this requires budget allocation).

‚Äç

#### Customer service

Your support staff are in touch with customers every day, and these are
the customers who have something to say. This makes them great
candidates for qualitative user research---if you can align with the
support team.

‚Äç

#### Your email list

If you're doing research with your own customers, turning your email
list into a participant recruitment tool is relatively simple and can be
very effective. These are people who are already invested in your
product, and may have great insights to share. Work with your marketing
or sales team so your research efforts don't overlap with existing
outreach.¬†

###### **Pro tip:** Use a research CRM to manage your own participant panel. You can build your own research panel using any of these channels, and import your database into [Research Hub](https://www.userinterviews.com/research-hub). There, you can manage the whole research process from within one platform: profile building, scheduling, tracking responses, incentive payments, and more.

‚Äç

### Researching with non-customers

‚Äç

#### UX research agencies

If you want a completely hands-off recruitment process, you can enlist
the help of a specialized [research recruitment
agency](https://www.userinterviews.com/blog/user-research-recruiting-agency-vs-in-house).
Specialist market research companies or participant recruitment agencies
are often very good at what they do, but their help comes at a high
price (around \$107 per participant, on average). That can be a hefty
price tag for small businesses to handle, especially since you typically
need at least 5 participants to complete a research study.¬†

‚Äç

#### Manual outreach

This is a highly targeted and customizable approach, but it's
time-intensive to crawl through LinkedIn profiles, send out speculative
messages, and follow up on conversations. Frankly, few people have time
for this and it doesn't scale well

‚Äç

#### Paid social media

[Performance marketing
techniques](https://www.userinterviews.com/blog/research-recruiting-on-facebook-and-other-strategies)
can be directly applied to the research recruitment process, and if you
have a savvy and helpful marketing team, you can recruit participants
through paid Facebook, Instagram, LinkedIn, or other social
advertising.¬†

Defining your audience is especially important here, because your ad
targeting strategy will determine whether you get relevant respondents
for your screening survey.¬†

‚Äç

#### LinkedIn and Facebook groups

Organic reach for posts is limited nowadays. But groups and community
pages are still a hive of activity, packed with people who are actively
talking about shared interests, ideas, professions, hobbies, and more.¬†

The challenge is that many of these groups are closed or invite-only, so
you may need the admin's approval to recruit there. If you're able to
get approval, some of your best participants could come from these
hyper-specific groups.¬†

‚Äç

#### Slack

Slack isn't just a great tool for communication with your
colleagues---you can also use it to connect with research participants!
Many specialized communities have Slack workspaces where people get
together and talk about their industry. These communities can be a good
place to connect with participants for a hard-to-recruit study.¬†

Just make sure you are asking for research participation in the right
channel, communicate the details of your study clearly, and abide by any
community rules that exist.¬†

¬†You can use [Slofile](https://slofile.com), an online database of Slack
communities, to find ones that align with your target audience.¬†

‚Äç

#### Reddit

Another social media network you may not think of for participant
recruitment is Reddit. Like Slack, it primarily consists of specialized
subgroups (subreddits) that center around a theme, idea, hobby,
location, etc. Because of this, Reddit can be a good place to find
people who fit niche recruitment criteria.¬†

When posting your research project on Reddit, remember to provide a
clear description of your research project, why you need help from the
people in this subreddit, and engage with any comments or questions
people might have.¬†

You can also use research-specific Reddit communities to find
participants for your research. These communities are devoted to
participating in research or finding ways to make a little extra pocket
money. They're not as targeted as posting in a subreddit specifically
for your target participant, but can still yield good results.¬†¬†

-   r/SampleSize
-   r/BeerMoney
-   r/Assistance

‚Äç

#### Craigslist

Finally, recruiting participants through classified ads like Craigslist
can be a cheap way to recruit participants. Craigslist limits the amount
of ads you can post, so if you have a few studies to recruit for we
recommend sticking with the free posts.¬†

The quality of participants you get from this channel can be hit or
miss, but it can be worth working into your recruitment checklist and
letting your screener survey sort out the good participants from the
bad.

## Tips to avoid participant burnout

If you keep hitting the same audiences time and time again for different
research studies, you will experience the law of diminishing returns.
Repeat participants will eventually get fatigued, and your research will
be based on interviewing the same people with the same views.

There are 2 possible ways to avoid this problem:

-   Use a huge database of potential participant targets.
-   Use a mixture of different recruitment strategies and channels.

Of course, it might be unavoidable to hit the same audience repeatedly
when you're testing product development among your most engaged current
customers.¬†

So, how can you keep things fresh?

-   Try the [RITE
    method](https://uxmag.com/articles/the-rite-way-to-prototype) (Rapid
    Iterative Testing and Evaluation) for product research. This means
    you only speak to tiny groups of one or two people, before iterating
    on designs and speaking to the next group. This approach will burn
    through fewer of your users.
-   Keep studies short and sweet. Get the insights you need without
    overburdening users.¬†
-   Mix up your methods to keep the structure and process of your
    research studies fresh.
-   Sustain long-term advocacy by thanking participants and showing them
    the direct results of their participation (e.g., a new feature
    addition).¬†

## A quick recap

The quality of your participants directly impacts the outcome of your
research project, which is why it's so important to get off to a good
start by specifying targets, building a bulletproof screening process,
and offering incentives that match the expectations of your target
audience.

We know we packed a lot of information into this chapter, so let's take
a moment to recap.¬†

In this chapter we went over how to:

-   **Decide who to recruit for your research.** You learned how to
    establish an effective research question and create recruitment
    requirements to help you identify who can help you best answer that
    question.
-   **Find user research participants.** You discovered different ways
    to use social media, classifieds, user research tools, and even your
    own email list to find participants.
-   **Screen your user research participants.** You learned about the
    importance of writing screening questions that focus on the right
    criteria, filter out unqualified people from your study, don't lead
    participants, and ensure you're recruiting the right people for your
    research.
-   **Incentivize research participants.** You got the low-down on the
    different types of research incentives, how the right incentives can
    attract quality participants, and the importance of distributing
    these in a timely manner at the end of a session.
-   **Schedule research sessions.** We're all beholden to our
    calendars---you found out how to create shared calendar invites so
    everyone has the information they need to show up and succeed.
-   **Check in with participants to reduce no-shows.** You now know to
    check in with your participants before a session to reduce no-shows.
    (Because hey, everyone forgets sometimes.)
-   **Avoid participant burnout.** Finally, repeatedly recruiting from
    the same small pool of users is a great way to burn participants out
    on the whole idea of user research. You learned a few ways to avoid
    participant fatigue and keep things fresh.

And there you have it---everything you need to know to recruit great
participants for your UX research study!

### Talk to users today.

[Get a demo](https://userinterviews.na.chilipiper.com/book/sdr-rr)

‚Äç

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/screener-surveys)

Next:

Screener Surveys

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Recruiting for UX Research](/ux-research-field-guide-module/recruiting)

\>

[Screener Surveys](/ux-research-field-guide-chapter/screener-surveys)

# Screener Surveys

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

In the last chapter, [How to Recruit Participants for User Research
Studies](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants),
we introduced you to the topic of screener surveys. Well, we actually
introduced that topic way back in chapter about [the UXR
process](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-process-fundamentals),
and again when we walked you through [how to create a user research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan).¬†

Why do we keep harping on about screeners?

Because they're important! Screener surveys are what stand in the way of
you and hoards of unscrupulous, unqualified, uncommunicative
participants. (That's a bit dramatic, but you get the point.

Screener surveys are essential tools for qualitative research. And while
they sound simple, they're actually very easy to get wrong. Which is why
we've dedicated a whole chapter to them!

### In this chapter

-   What is a screener survey and why do you need one?
-   How to create an effective screener survey
-   Examples of common screener questions and formats
-   When double-screening makes sense
-   Avoiding no-shows

## What is a screener survey and why do you need one?

Screener surveys, or just 'screeners,' are surveys people take before
participating in a research study. They're made up of a few questions,
designed to weed out the folks who aren't your intended audience and
capture the ones who are.¬†

You can think of a screener survey as a sieve that captures the people
who hit all your 'must have' criteria and filters out the ones who don't
quite fit the bill.

‚Äç

## How to create an effective screener survey

If you want the right participants, you've got to design smart screening
questions.

That's not always as straightforward as you might think. You have to ask
questions in a somewhat roundabout way to avoid leading people to
certain responses, but also in a clear way to make sure you're
universally understood.

The devil is in the details, but luckily there are some pro strategies
that anyone can learn and put to use right away.¬†

The guiding principles explained in this chapter will help get you
there.

###### **Tip:** If you haven't already got your ideal participant profile nailed down, review the previous chapter on [finding the right participants](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants) for your study before reading further.

‚Äç

### 1. Know your goals¬†

We covered this bit in previous chapters, and the advice here is the
same as the last.¬†

Clearly defined goals and objectives are must-have requirements for any
user research project. These goals---aka your reason for doing
research---should be hammered out well before you start writing your
screener surveys. (If they're not, head on back to the chapter on
[planning
research](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
to get some clarity. Go on, we'll wait\...)¬†

‚Äç

### 2. Define specific target audience criteria

This is the part where you consider your research question, imagine the
ideal participant who can give you the answers you need, and identify
the targeting criteria (the things that must be true about them) needed
to qualify for your study.

Your targeting criteria will typically be defined by using a mixture of:

-   Psychographics: Activities, hobbies, interests, and opinions
-   Behaviors: What they do (e.g. 'regularly commutes by car')
-   Demographics: Age, gender, education, income, marital status, etc.
-   Geographics: Country, city, region, or radius around an area

So... how do you decide what criteria to target by?¬†

‚Äç

#### To figure out who to recruit for UX research, ask yourself:

-   **What is the goal of your research?** Consider what insight would
    be most useful, then work backward to figure out who can best
    provide that insight.
-   **Are you in the discovery, testing and validating, or post-launch
    phase of product development?** In general, your audience should be
    broad in the early stages and get more targeted as development
    progresses.
-   **What is your research question?** [A good research
    question](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
    like "What tools do 20-somethings use to manage their finances?" has
    much of the targeting criteria already baked in.
-   **Who can answer that question?** Think through the specific traits
    a potential participant would need to have. In the example above,
    you'd want to talk to people in their twenties who are interested in
    actively managing their money.
-   **Who can't answer that question?** Don't ask retirees how their
    grandchildren manage their finances. Likewise, if a 25-year old says
    'nah, I'm not really interested in having a budget,' they are the
    wrong person for your study.

We covered all of those points in finer detail [in the last
chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants).
If you're still struggling to pin down who to recruit, we recommend
revisiting those recommendations before moving onto the next steps.

### 3. Screen for behaviors and psychographics over demographics

Take a closer look at your targeting criteria. Do they include
demographic criteria like age, gender, race, income, etc? Do they need
to?

Demographics are the low-hanging fruit of screener surveys, but these
characteristics have their limitations.

For instance, where people live is important if you're doing an
in-person study, or if your app will only serve certain locations. But
if you don't have a clear reason to target based on geography... don't.
The same thing applies to demographics. In many cases, a person's gender
or how much they earn per year won't determine how they interact with a
product.¬†

Our assumptions about these characteristics are prone to bias, which can
invalidate your study and do real harm to the people your research will
ultimately impact.

Also, it's just bad form to waste valuable screener questions on
criteria that aren\'t absolutely essential.

Screening for psychographics and behaviors lets you group people based
on how they live, what they value, and how they relate to your product
or category. That's the juicy stuff!

###### **Rule of thumb:** Worry less about how people are categorized on a census and more about how they think, feel, and behave.

#### When asking demographic questions makes sense

Let's say you want to test for accessibility with a mix of gender
identities, age ranges, and educational backgrounds. In this case,
adding demographic criteria will allow you to target a diverse audience.

Not every question on your screener has to result in an automatic in or
out, but can be used to filter for a variety of participants as a final
step. Accept anyone who could be a fit based on any given question.¬†

###### **Tip:** Some recruiting services ([User Interviews included](https://www.userinterviews.com/)) will automatically provide basic demographic, geographic, and technographic information for you, so you don't need to include it in your screener survey. Win for you and your participants!

### Recruit from our panel of 700k+ participants or bring your own

[Sign up for free](https://www.userinterviews.com)

### 4. Write precise, carefully worded questions

Once you know the characteristics of your target participants and you've
broken that down into specific criteria for how you'll identify the
people who qualify, it's time to write the questions that will help you
filter out the good'uns.

The language you use in your screener is important. When writing
screener questions:

-   Avoid double negatives.
-   Keep the questions short and sweet.
-   Leave out industry jargon (unless knowledge of it is a requirement
    for participation).
-   Be specific.

The more clearly worded and specific your questions are, the less likely
participants will be to get confused and answer inaccurately. Leave no
room for misinterpretation!

Similarly, make sure the multiple choice options you provide are
carefully worded. Being clear in your responses is just as important as
being clear with your questions.

Have you ever taken a survey where, on a certain question, you found
yourself forced to choose between more than one answer that applied to
you?

To avoid putting your audience in that position, make sure your answers
have clear borders without any overlap. For example, when asking for
numerical values (age, size, frequency etc.), make sure your values are
mutually exclusive:

-   Correct: 0-3, 4-7, 8-12
-   Incorrect: 0-3, 3-7, 7-12

For less definitive answers or for answers that can't be made mutually
exclusive, ask participants to select the answer that is most true or
give them the option to select all that apply, rather than a single
answer.

### 5. Put your screener questions in the right order

Don't make prospective participants complete your entire screener before
finding out they don't qualify. Eliminate unqualified people early.

Think of the process as a funnel. You're refining your participants, and
refining them further. Or, think of it like weeding a grown-over garden.
The biggest, tallest, most obvious weeds come out first, simply because
they're the easiest to grab. Start with the questions that are most
likely to weed people out.¬†

The easiest way to do this is to write out your questions, rank them in
order of importance, and look for any interdependencies.¬†

For example, if you're doing an in-person study, ask about location
right away. Location here is a must and must-have criteria go first.

Before diving into questions about how people use apps on their
smartphones, find out if they use a smartphone at all. Then, move on to
the questions that tap into specific behaviors, interests, and
preferences.¬†¬†

If you're not working with a recruiting service that gathers
demographics for you, ask any demographic questions that you need to
ensure a diverse recruit pool.

### 6. Avoid leading or loaded questions

You know how some folks add a "right?" at the end of every sentence, so
that you have no choice but to nod or shrug in agreement? Right?¬†

That's an example of 'leading.' Leading questions will influence people
to answer in a certain way.¬†

It's a handy conversational device if, say,¬† you're a dogged prosecutor
in a courtroom TV series and the judge will allow it (for the drama,
obviously). But leading questions have no place in user research---and
definitely not in your screener survey. This is not the place to try to
validate your assumptions. You'll end up with skewed results or the
wrong kind of participants.

Here's an example:

-   **Leading:** Would you like it if there was a feature that did
    \[X\]?
-   **Not leading:** Are there any features that don't currently exist
    in the product that would help you do \[X\]? If so, what are they?

A good way to identify whether a question might be leading is if it
includes a hint or excludes possible answers.

Another way to avoid leading questions is to provide a series of
unrelated options as answers.¬†

For example, if you want to screen users who have a high level of
concern around internet privacy issues, rather than diving right into
questions about internet privacy by asking:

-   **Leading:** Are you concerned about internet privacy?

... you can create a question like this **(not leading)**: Which of the
following topics is most concerning to you regarding internet use in
your life?

-   How much time my kids spend online. - Reject‚Äç
-   Data privacy issues. - Accept‚Äç
-   False information appearing in search results. - Reject‚Äç
-   I don't have any concerns about the internet. - Reject¬†‚Äç
-   I don't know. / None of the above. - Reject

Likewise, avoid yes/no or true/false questions, which tend to be
leading. Users might answer in the way they believe will entitle them to
participate in the study. Whenever possible, replace these questions
with multiple choice options or provide a scale for degree of agreement
with a given question.¬†

**Exception:** In cases where a black and white answer is required---for
example, when asking if a person is willing or able to participate under
the conditions of your study---a binary question will be your best bet.

'Loaded questions' are similar to leading questions (and the two are
often conflated), in they push the participant to answer a certain way.
Loaded questions do this by making assumptions, which are implicit in
the question itself.

Here's an example:

-   **Loaded:** On a scale of 0-100, how much do you despise pistachio
    ice cream with every fiber of your being?
-   **Not loaded:** On a scale from 1-10 where 1 is 'gross,' 5 is
    'neutral,' and¬† 10 is 'delicious', please rank how you regard
    pistachio ice cream.¬†

A good way to identify whether a question might be loaded is if it
includes strong language or excludes possible answers.

-   **Loaded:** What is your favorite thing about the new, improved app?
-   **Not loaded:** How does your experience with this version of the
    app compare to your experience with the previous version?

### 7. Provide a catchall alternative option

If you create multiple choice responses, don't assume that you've
presented the user with every possible option. Even the best survey
designers have their limitations. As Gandalf once said, "even the very
wise\[st survey designers\] cannot see all ends."¬†üßô

Include a 'none of the above,' 'I don't know,' or 'other' option to
account for any outliers.¬†

Otherwise, you could end up with someone in your study who doesn't
belong there because they were forced to choose an answer that didn't
apply to them. Likewise, you might screen good participants out because
they didn't quite fit the answers you provided.

### 8. Include an open-ended question to screen for articulation

Spare yourself the pain of having to drag answers out of a reticent
participant by screening uncommunicative people out of your study.

Screener surveys help you to get more value for your time and money on a
per-participant basis. Sometimes that means excluding certain people who
otherwise perfectly fit your ideal audience profile.

Screen for expressive participants by asking 'articulation questions.'
These are open-ended questions designed to test a user's capacity to
communicate. If a person can express their ideas with depth of thought,
they're likely to be a helpful participant.¬†

Including open-ended questions also helps weed out "professional
participants" who are just looking to make a quick buck by qualifying
for any and every study.

### 9. Don't reveal too much

A screener survey is meant to help you find the candidates who are a
perfect fit for your study.¬†

Giving away too much information about the purpose of your study---by,
say, revealing the name of your company to non-users or telling
participants who you're looking to interview (which is a real mistake
that we've seen)---can devalue the screening process and make your
research less effective.

And this advice doesn't just apply to your screener. The title and
description you give your study, the way you talk about it when you're
recruiting participants, and the things you reveal in the lead-up to the
session itself---it all matters.¬†

For instance, let's say you are doing research on (yet another) photo
editor app for influencers and people who actively post photos on social
media. You might tell participants it's a study related to social media
habits. That way they have some context (which can help them decide to
click into the screener), but they don't know what type of social media
habits (editing photos) you're looking for.

This will make it harder for professional testers to guess what you
want, making it more likely you'll get authentic responses.

#### To avoid tipping your hand, don't:

-   Reveal the purpose of your research study.
-   Reveal the name of your company or product.
-   Ask leading questions.

###### **Pro tip:** If you're struggling to write descriptive titles and copy that don't give away too much information, see if there's a friendly wordsmith on your marketing team who can lend a hand.

‚Äç

### 10. Manage the expectations of survey takers

Make sure your participants are clear about what they're doing, and at
what stage of the process they're at.¬†

The screener survey is a sort of dress rehearsal, and it will help the
participant to know they're not yet in the final round. Be sure the
candidate knows what they're in for if they do make it.¬†

‚Äç

If there are any possible deal-breakers (like [NDA
agreements](https://www.userinterviews.com/blog/ndas-and-informed-consent-for-user-research),
for example) let them know up front.¬†

And of course, be clear that they won't be paid until they make it
through to complete the actual survey.

### 11. Remember to keep it brief

Finally, keep your screener surveys short and sweet. We've seen some
screener surveys get so long that participants mistake them for a (paid)
research survey! If you're looking for a rough guideline on length, try
to keep your screener to fewer than 10 questions.¬†

## Examples of common screener questions and formats

Remember, the point of a screener survey is to help you find the right
participants for your research. This list of screener questions is meant
to be used for inspiration, and to help you get a gut check on your own
screener. It's not a library of general use questions to copy and paste
from in all circumstances.¬†

With that caveat out of the way, here are some sample screening
questions to ask, depending on the type of criteria you're filtering
for.

### Sample screening questions for different types of criteria

##### Industry or occupation¬†

Ask employment questions when you want to screen for people with a
certain level of familiarity with a particular industry, or exclude
those who work for competitors.

**Example question:** What industry do you work in?¬†¬†

**Answers:** A list of industries (retail, IT, healthcare, education,
etc.)

**Format:** Single select¬†

**Example question:** Which category best describes your job function?

**Answers:** A list of job functions (marketing, accounting,
engineering, product design)

**Format:** Single select¬†

##### Familiarity with a product or service

If you need to test with novices, experienced users, or some combination
of each, ask about familiarity with a given product.

**Example question:** Please rank your experience with {name of
product}.

**Answer:** A range from expert to novice

**Format:** Scale rating or single select

**Example question:** Which of these tools do you use for work? (Select
all that apply)

**Answer:** A list of software products

**Format:** Multiple select

##### Frequency of performing specific tasks

Asking about frequency of use or action is useful when you're screening
for users who regularly do a specific task, or who used to behave in a
certain way and then stopped.

Consider defining terms like often (every day) and rarely (once a year)
so there's no guesswork.

**Example question:** Please tell us how often you {name the task}.

**Answer:** A range of time from often to rarely.

**Format:** Scale rating or single select

**Example question:** When was the last time you {name the task}.

**Answer:** A range of time from today to never.

**Format:** Scale rating or single select

##### Comfort with sharing personal information

Just because someone meets your screening criteria doesn't mean they're
actually going to be willing to participate, especially if your study
touches on sensitive topics like health, income, lifestyle, marital
status, etc. Ask participants directly if they're willing and able to
answer personal questions.

**Example question:** This study will require you to share openly about
{examples}. Do you agree to share honestly about these subjects?

**Answer:** Agree or disagree

**Format:** Single select.

‚Äç

### A note on extra requirements for medical researchers

If you're conducting medical research, the recruitment process and
screening process are considered separate activities. Recruitment---in
which you reach out to research candidates and tell them about the
planned study---is a pre-screening activity that can be done without
informed consent. But even your pre-screening process may have to be
submitted to your Institutional Review Board (IRB) before you can
proceed.

Before you gather protected health information or obtain medical records
to determine study eligibility, you'll need patients to sign a consent
form to proceed with screening activities. Your screening script for
interacting with possible participants and gathering information also
has to be submitted for IRB review.

For more information about IRBs, refer to the [FDA
website](https://www.fda.gov/about-fda/center-drug-evaluation-and-research-cder/institutional-review-boards-irbs-and-protection-human-subjects-clinical-trials).
For your institution's specific rules regarding screening and research
procedures, refer to its specific IRB.

‚Äç

## When double-screening makes sense

If you want, your screening procedures can include a phone call to
potential candidates who seem most promising. Double-screening like this
typically isn't necessary, but it can be a good way to be absolutely
sure that you're getting the right people to talk to during your study.

We've seen researchers use double-screening when the study they're doing
is high-profile (visible to important stakeholders in their
organizations) or when they have a highly specific research need.¬†

## Avoiding no-shows

‚Äã‚ÄãPeople who promise to show up for your study and don't will cost you
time, and likely a moment of discomfort with colleagues and bosses who
are forced to sit around waiting. Save yourself some trouble and work to
prepare your participants and yourself to avoid the dreaded no-show.

-   Get your users contact information including email and cell phone.
-   Send reminder emails from an individual (not a generic group email).
-   Give participants your number or the number of the testing office so
    they can get in touch if they'll be late.
-   Send great instructions for how to get where they're going.
-   Most of all, stress the importance of their participation so that
    they're incentivized to show up because they're able to perceive
    their own value in the project.

Also consider being prepared by recruiting a few extra folks who you can
call in at the last minute, if need be.

‚Äç

## In summary

Long story short, envision your [ideal
participant](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)---know
who they are, know who they aren't---and build a screener survey that
allows you to filter out the right people to answer your research
question.¬†

The specifics of how to get there are outlined above. Just remember to
keep an open mind as to who these study participants might be, and don't
limit yourself with prejudgements mired in demographics.

We'll leave you with a few rules of thumb:

### Screener survey best practices

-   Eliminate people early---get the big, must-have criteria out of the
    way first.
-   Don't reveal what the study is about or who you're trying to
    recruit.
-   Don't screen for demographics unless strictly necessary.
-   Ask open-ended questions about behaviors, feelings, habits, and past
    actions..
-   Don't ask leading questions that hint at what the 'correct' answer
    might be.
-   Avoid 'yes' or 'no' questions.
-   Provide an 'other' option on multiple choice questions.
-   Keep it brief---10 (or fewer) screener questions is typically
    plenty.

Oh, and did we mention that you can build and fully customize screener
surveys with User Interviews? [Launch a research
project](https://www.userinterviews.com/) and easily build your
screener---we\'ll give you 3 free participants to get started.

‚Äç

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/find-good-research-participants)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/ux-research-incentives)

Next:

User Research Incentives

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Recruiting for UX Research](/ux-research-field-guide-module/recruiting)

\>

[User Research
Incentives](/ux-research-field-guide-chapter/ux-research-incentives)

# User Research Incentives

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

### In this chapter

-   What is a research incentive?
-   Types of incentives and when to offer them
-   Why participant compensation matters
-   How to create a UX research incentives plan
-   Saying thank you¬†

## What is a research incentive?

An incentive is a reward that you offer participants in exchange for
taking part in your research. Incentives encourage participation, can
help you recruit a broader pool of participants, and thank people for
their time.

Incentives can be anything---from company swag to cold, hard cash. While
cash and cash-like rewards are the most common type of incentive, what
you offer should be based on who you're looking to recruit.¬†

## Why participant compensation matters

When it comes right down to it, incentives are a tool for attracting
quality applicants, getting a large volume of applications, and
encouraging people to show up for your study.¬†

What's more, as 18F, a digital consultancy for the US government
[explains](https://methods.18f.gov/fundamentals/incentives/):

Incentives often result in a more diverse, representative set of
participants. Without incentives, you often end up recruiting people
with a strong intrinsic interest in your website. These people may not
have the same needs and experiences as a less interested pool of users.
With incentives, you can encourage less interested, more representative
people to participate.¬†

But it's well worth mentioning that people ought to be compensated
simply because their time and their input are valuable. You probably
wouldn't bother inviting them to participate in your research
otherwise.¬†

And your time is valuable too! That's why it's so important to structure
your incentives appropriately so that your participants don\'t end up
leaving you and your team hanging at the last minute.

‚Äç

### Are there drawbacks to paying participants?

Some people worry that offering incentives to participate in user
research can compromise the results of a study. The argument goes that
doing so will:

-   Introduce bias and oversampling of certain groups.
-   Attract professional participants who lie about their eligibility to
    qualify.
-   Exclude people who aren't interested in the type of incentive you're
    offering.
-   Create a conflict of interest.

Laura Klein, user experience expert and author of Build Better Products
and UX for Lean Startups (and [Awkward
Silences](https://www.userinterviews.com/blog/laura-klein-on-building-products-that-dont-cause-emotional-trauma)
guest!),
[writes](https://guides.co/g/how-to-recruit-participants-for-user-research-ux-tests/8660):

A lot of people ask whether offering some sort of incentive for people
to participate in a study will bias the results. The answer is, \"not if
done correctly.\"¬†

And luckily, that's what this chapter is about---how to create a great
incentives plan!

###### **Note:** Certain participants simply cannot accept compensation for their time---government officials, for example. If you're recruiting participants who you know can't accept an incentive, don't offer one (just make sure you take extra care to thank them for their time).

## How to create a UX research incentives plan

Now that you know your options, let's go over how to create a plan for
user research incentives---including how to calculate the right amount
to pay, how to communicate about incentives, and how to distribute them
(which you should be prepared to do soon or immediately after each
session).

Firstly, know your audience\...

‚Äç

### 1. Be clear about who you're trying to recruit (and why)

Before you can hammer out the specifics of your incentives plan, you
need to establish:

-   Clearly defined research goals and study objectives
-   Must-have participant criteria
-   Screener questions to filter out the right participants

We covered the first two items in-depth in the chapter on [How to
Recruit Participants for User Research
Studies](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants),
and we went deeper on [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
in the last chapter. If you haven't already, we recommend pausing to
read those before finalizing any incentive plans.

As a refresher, to figure out who to recruit for a study, you should
think about your research question, imagine the ideal participant who
can give you the answers you need, and identify the criteria that must
be true about them in order to qualify for your study.

‚Äç

#### To figure out who to recruit for UX research, ask yourself:

-   What phase of product development are you in?¬†
-   What is the goal of your research?¬†
-   What is your research question?¬†
-   Who can answer that question?¬†
-   Who can't answer that question?

The answers to these questions will help you create a profile of the
type of participant you're looking for---aka the folks you're trying to
attract and motivate with an incentive.

‚Äç

### 2. Choose the right type of incentive

To get really useful results you need to capture the right audience. So
how should you incentivize people to participate in your study?

Monetary incentives, including gift cards, are the most popular form of
incentive, but incentives can also be:

-   Account credits or discounts
-   Charitable donations
-   Swag
-   Early access to a feature

The most important thing about your incentives is that they are valuable
to your participants and that they get people excited about
participating in your research.¬†

‚Äç

#### Types of incentives and when to offer them

‚Äç

##### Cash-based incentives

Cash-based incentives are an understandably popular incentive format
from the participant side. Cash is straightforward---it's easy to pay
out, appeals to customers and non-customers, and gives participants the
flexibility to spend it however they want.

There are drawbacks to cash incentives, however. For one thing, some
participants are not able to accept cash---with government employees,
for example, cash might be considered a bribe. Other participants---such
as very high-income earners, current customers, or B2B prospects---might
not be as motivated by cash as they would be by account credits, swag,
or other types of incentives.

Cash-based incentives can also come with tax implications, depending on
how much you're paying and where both parties are located.

We recommend researchers use digital payment platforms like PayPal for
cash-based incentives (rather than, you know, sending participants a
stack of \$20s). If you use [User Interviews for recruiting
participants](https://www.userinterviews.com/) for a study, you can
choose to have us instantly process incentive payments through gift
cards---we'll also automatically issue 1099s for your tax records.¬†

**Use cash-based incentives when you:**

-   Want a simple rewards payout
-   Are looking to attract a diverse audience, including non-users
-   Are recruiting for B2C studies
-   Need a lot of participants for a quick study

**Consider different methods if you:**

-   Are recruiting internationally and don't have a plan for converting
    currencies
-   Are looking to appeal to high-income earners or current customers
-   Are recruiting for B2B research
-   Want to include people like¬† government employees who cannot accept
    cash
-   Don't want to deal with the tax implications

##### Gift cards

Gift cards are cash equivalents, redeemable at particular retailers and
websites. They're another popular incentive format.¬†

They appeal to both customers and non-customers, may be permissible in
cases where people can't accept cash, and---while they don't offer
participants the same flexibility on where to spend them---still give
participants a degree of control over how to redeem their reward. And
sometimes gift cards can be more appealing to high income earners than
straight up cash.

But there are drawbacks here as well. If you're recruiting from an
international audience, bear in mind that the value of gift cards often
doesn't translate from country to country--- participants in San
Francisco are unlikely to appreciate a ‚Ç¨50 gift card to Dutch
supermarket chain Albert Heijn, just as users in the Netherlands would
find your generous offer of a \$300 Applebee's gift card rather
worthless.¬†

In fact, many gift cards simply won't appeal to some people at all,
which is why we recommend offering participants the ability to choose
their own gift card from a list of popular retailers. Incentives are
always more valuable when they're relevant to the recipient.

Another thing to consider is that many of the same bribery and ethical
rules about not accepting cash incentives will apply to gift cards as
well. And as cash-equivalents, gift cards can have the same tax
implications as cash.

**Use gift cards incentives when you:**

-   Have a way to provide multiple gift card options
-   Are looking to attract a diverse audience, including non-users¬†
-   Want to broaden your study appeal to high-income participants
-   Are recruiting for B2C studies
-   Need a lot of participants for a quick study

**Consider different methods if you:**

-   Are recruiting internationally
-   Are recruiting for B2B research, especially with current customers
-   Want to include people who cannot accept cash equivalents
-   Don't want to deal with the tax implications

##### Account credits or product discounts

Product discounts or account credits can often trump cash-based
incentives when it comes to recruiting current customers.

If you're recruiting consumers, this can be as straightforward as a
coupon code for future purchases, or a reduced subscription price for
services.¬†

With B2B research, you'll want to consider whether the people you're
hoping to talk to are your users (people who actually use your product
day to day) or the people in charge of making purchasing decisions or
both.

If your users aren't the same people involved in purchasing decisions
for their team, they may be less motivated by account credits (they
won't personally see the reward---their company will). In this case,
other types of incentives may be more motivating. But account credits
can be a great way to appeal to B2B customers higher up the ladder.¬†

One benefit of using discounts and credits to incentivize participation
in research is that it costs nothing upfront and there's much less
administrative overhead---you don't have to worry about distributing
cash or gift cards to individuals. It can also be a great way to
encourage ongoing customer engagement with research.

But of course, this strategy is much less appealing to
non-customers---and unhappy customers, too, for that matter.

**Offer account credits or product discounts when you:**

-   Want to cut down on upfront costs and tedious administrative work¬†
-   Are looking to recruit (satisfied) customers
-   Want to speak to people with direct purchasing power¬†
-   Have a plan for keeping track of credits

**Consider different methods if you:**

-   Want to recruit non-customers and B2B users without purchasing power
-   Are looking for a diversity of feedback, including from unhappy
    customers
-   Don't have the authority or stakeholder approval to offer discounted
    rates

##### Swag

Don't underestimate the power of good swag. There is, after all, a whole
community of people dedicated to buying, selling, and trading Mailchimp
monkeys. (Related side note: Do any other New England kids remember
Dunkin Donuts' [Coolatta
bears](https://goodstuff1976.com/coolatta-bears)? Oh, to be a child in
2000\...).

Swag---branded products that you give away for free---can be a great way
to motivate die-hard fans and current customers. And if you already have
swag on hand (hint: ask your marketing team), there's minimal (new) cost
to this strategy. Plus, it's free advertising for your company.

However, like account credits and discounts, swag won't appeal to
everyone. Non-customers are less likely to be motivated by branded
products, and no matter how cool your T-shirts are, they won't pay the
bills.

**Offer account credits or product discounts when you:**

-   Have swag to offer!
-   Are looking for a no (new) cost incentive strategy
-   Want to appeal to customers and fans
-   Are recruiting people who can't accept cash or cash equivalents

**Consider different methods if you:**

-   Want to recruit a diverse group of participants that includes
    non-customers
-   Believe your audience is motivated by cash or cash-equivalents
-   Need longer time commitments from participants (in-depth interviews,
    diary studies)

##### Other incentive types

If none of the common incentive types outlined above feel like the right
fit for your ideal participant profile, it may be time to get creative.¬†

Here are a few alternative incentive formats to consider:

-   **Charitable donations**---If your audience can't accept cash or
    cash equivalents, donations can be a meaningful way to reward their
    time. Consider offering participants a choice between several
    charities to make this option even more relevant. Of course, this
    strategy only works if your audience is motivated by social impact.
-   **Exclusive perks**---You might consider offering participants
    exclusive or early access to things like beta versions of an app, a
    sneak preview of upcoming releases, customer workshops, etc. This
    strategy is similar to swag and product discounts, in that it will
    primarily appeal to engaged customers and users.
-   **Large, lottery style rewards**---Rather than offering many smaller
    incentives, you might consider entering participants into a lottery
    style drawing for a few larger rewards. (i.e., instead of paying 50
    participants \$75 each, you could offer participants a chance to
    earn one of three \$1250 payouts).¬†

### 3. Calculate the correct incentive amount

Incentives are best when they're tailored to the task you're requesting
your participants to complete, the time commitment involved, and how
(in)convenient it is for users to participate.¬†

Some studies require more effort, time, and thought than others. For
example, if you're conducting a quick, unmoderated usability test, a
lower incentive is probably enough to compensate your participants. On
the other hand, if you're conducting a weeks-long diary study that
requires multiple interviews and diary entries, prepare to spend more on
your incentives.¬†

As a rule, moderated user research studies warrant a higher incentive
than unmoderated studies. That's because unmoderated research can often
be completed on the participant's own time, while moderated research
takes place at a specific time and requires more coordination and
communication between the researcher and participants.¬†

Essentially, the longer it takes participants to complete a study, the
higher their compensation should be. Ditto goes for effort---if
participants have to commute to an in-person study, download new
software, or make significant adjustments to their schedules, that
effort should be reflected in the incentive amount.

We also recommend participants be paid different amounts based on their
expertise. For example, if you need to talk to people about their
grocery shopping preferences, you don't need to recruit participants
with any kind of specialized experience. You just need general consumers
who buy groceries.¬†

But if you need to do research on the usability of a new EEG technology,
you need to talk to neuroscientists with specialized training. Because
you're drawing on this very niche skill, you'll have to pay more in
incentives to make it worth your participant's time.¬†

#### So wait... how much should user research participants get paid?

In our experience---and based on the number crunching we did to create
our [UX Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)---we've
found that the most successful researchers are the ones who pay the best
incentive they can reasonably afford.¬†

But if you're looking for a quick-and-dirty answer:

‚Äç

###### For most studies you should **aim for \$60 - \$100/hr.**

That's a threshold, after which you may need to adjust your incentive
amount based on things like how tricky it is to recruit your specific
participants, how meaningful cash or cash-like incentives are to them,
the nature of your study, and so on.¬†

For more detailed guidelines, see the quick reference guide below or use
the [UX Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
to get personalized recommendations based on your study's unique
criteria.

‚Äç

#### User research incentives recommendations

Use this [quick reference
guide](https://docs.google.com/document/d/e/2PACX-1vQYgHN7gqHflkZAIRwr_C4KQNoU8aeqeaRgcXJn4IgehUFmeb0pu3X2ZdP6ReoRksmBmMUQeZQu-gOG/pub)
to plan your incentives depending on the type, length, and audience for
your study. But remember: Our recommendations aren't hard-and-fast
rules. They're meant to be starting points for a larger conversation
about what incentive you should offer to get the best results from your
research.¬†

##### Moderated studies with general consumers

For studies that require specific behaviors or demographics but do not
require expertise in specific industries:

![incentive recommendations for moderated studies with general consumers
Remote: \$80/hrIn-person:
\$100/hr](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a99f235eb4bfb896a7dd30_general-consumers_opt.png)

‚Äç

##### Moderated studies with professionals

For studies that require experts in specific fields or with specific job
titles.¬†

![incentive recommendations for moderated studies with professionals--
Remote (baseline): \$100In-person (baseline): \$125Remote, high earners
(\$150k+): \$130In-person, high earners (\$150k+): \$165Remote,
mid-level earners (\$75-150k): \$100In-person, mid-level earners
(\$75-150k): \$125Remote, low earners (\<\$75k): \$75In-person, low
earners (\<\$75k):
\$90](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a99f7f2903236416df57e0_professionals_opt.png)

‚Äç

##### For unmoderated studies:

![research incentive table unmoderated studies - Consumers (baseline):
\$50Professionals (baseline):
\$75](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a99faf22edd999a1afb733_unmod_opt.png)

To really dig into the weeds of this topic, check out our report, [The
Ultimate Guide to User Research
Incentives](https://www.userinterviews.com/blog/the-ultimate-guide-to-user-research-incentives),
compiled from data from over 25,000 completed research sessions. ‚Äç

### 3. Decide how you're going to distribute incentives¬†

Incentives should be distributed as soon as possible after each session.
In fact, part of the appeal of digital gift cards and cash-based
incentives is that it's possible to send them to participants within
seconds of wrapping up a session.

For longer projects like diary studies, compensation can be broken up
and distributed at different times throughout the study to keep
participant motivation high over a longer period of time.

Details of how and when you'll distribute incentives should be clearly
communicated in the study description and in emails to participants
before and after the session.

To make sure the promised payout goes off without a hitch, you'll need a
plan for distributing incentives in a timely manner. This means
collecting the information you'll need ahead of time---email, address
(if sending swag), etc---and keeping track of who has received what (and
how much).

Or, if you're using [User Interviews](https://www.userinterviews.com/)
and you choose to distribute incentives as gift cards, you can opt to
have us handle distribution for you. Easy peasy.

### Recruit with User Interviews and leave the gift cards to us

[Sign up for free](https://www.userinterviews.com/recruit)

## Saying thank you

Paying your participants appropriately is important, but a little
kindness and hospitality can go a long way too.

Treat each participant like an important guest, rather than an anonymous
test subject. Always emphasize the value of their contributions, and
thank them sincerely before and after the study.¬†

And do sweat the details. Make sure participants are aware of what's
required of them before the study, including any deal breakers such as
an NDA. Be clear and professional in all of your communications, ask for
consent before recording audio or video, and let people know they can
take a break or leave if necessary.

Part of being an effective researcher is showing participants their
input has value. Payment is one way of doing that, but don't discount
the impact of a good old fashioned 'thank you' as well.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/screener-surveys)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/user-research-methods)

Next:

UX Research Methodologies

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Methodologies](/ux-research-field-guide-module/user-research-methods)

![two people conversing surrounded by floating graphs and an abstract
landscape](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f29d6e63781b71228f9c_UI_CHAPTER_04_ARTWORK.jpg)

04\.

# UX Research Methodologies

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

There are so many different types of user research---and so many
methodologies and approaches in each category---that it's easy to get
overwhelmed by choice, even for experienced UX researchers!

This module is all about the different user research methodologies and
when to use them. We'll cover:

-   **The types of UX research methods**. You'll learn about the
    differences between different kinds of user research
    methods---quantitative and qualitative, generative and evaluative,
    attitudinal and behavioral, moderated and unmoderated.
-   **Qualitative vs. quantitative research** in more depth, including
    the differences in research design, sampling, data analysis, and how
    to combine them in mixed methods studies.
-   **How to choose a user research method** based on where you are in
    the product development cycle, your research goals, the kinds of
    data you need, and other factors.
-   **User research frameworks**, including our Decision Driven Research
    framework for mapping your methods to the kinds of decisions you
    want to enable.¬†

[Start
reading](/ux-research-field-guide-chapter/user-research-types)[Start
reading](/ux-research-field-guide-module/discovery-methods)

In this module:

[Types of User Research
Methods](/ux-research-field-guide-chapter/user-research-types)

Know your options with this overview of different types of UX research
methodologies.

[Qualitative vs. Quantitative
Research](/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)

How much, how many, and why? A guide to quant v. qual.

[How to Choose a User Research
Method](/ux-research-field-guide-chapter/how-to-choose-a-research-method)

Just say \"no\" to research decision paralysis. Learn how to choose the
right UXR method for any study.

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### Types of User Research Methods

Know your options with this overview of different types of UX research
methodologies.

##### Qualitative vs. Quantitative Research

How much, how many, and why? A guide to quant v. qual.

##### How to Choose a User Research Method

Just say \"no\" to research decision paralysis. Learn how to choose the
right UXR method for any study.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/discovery-methods)

05\.

### Discovery Research Methods

[](/ux-research-field-guide-module/evaluative-methods)

06\.

### Evaluative Research Methods

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Methodologies](/ux-research-field-guide-module/user-research-methods)

\>

[Types of User Research
Methods](/ux-research-field-guide-chapter/user-research-types)

# Types of User Research Methods

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

In the previous chapters, we've covered the [fundamentals of UX
research](https://www.userinterviews.com/ux-research-field-guide-module/user-research-fundamentals),
gone over how to [create a user research
plan](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research),
and went over a foolproof [framework for user research
recruiting](https://www.userinterviews.com/ux-research-field-guide-module/recruiting).

At this point, you're probably brimming with all the essential knowledge
and feeling ready to actually, y'know, do some user research.

But before we get into the individual methods (which we will, in depth),
it's worth taking time to review the different types of UX research
methods at your disposal. Because there are a lot of different types of
user research.¬†

Many methods are best suited to a particular scenario. Some only work
well when combined with other, specifically complementary methods. And
almost all deliver more valuable results when they are part of a
comprehensive hybrid research strategy.¬†

That's why, before you dive into the trenches, it's helpful to take a
step back and look at some of the broader categories that define
different types of user research.¬†

This chapter provides the 30,000-foot view that gives you the overall
lay of the land complete with the terms and topics that will help you
decide which research method is best for your project.¬†

¬†

Let's get to it.

### In this chapter:

-   Qualitative vs. quantitative methods
-   Generative vs. evaluative methods
-   Attitudinal vs. behavioral methods
-   Remote vs. in-person user research¬†
-   Moderated vs. unmoderated methods
-   Which user research method should you use?

## Qualitative vs. quantitative user research methods

The primary differences between qualitative and quantitative UX research
have to do with how the data is collected and the nature of the data
itself.¬†

**Qualitative UX research** typically involves collecting data through
direct observation of a small group of people in order to assess
behavior and answer the question: "Why?" Common qualitative research
methods include interviews, focus groups, field studies, usability
tests, and co-design sessions.

**Quantitative UX research**, on the other hand, usually involves
collecting data from a much larger group of people in order to quantify
a problem by answering the questions, "How much?" and "How many?" Common
quantitative research methods include usability studies, surveys, click
tests, card sorts, and A/B tests.

Which type of method you choose depends on the kind of question you're
asking. The qualitative and quantitative data produced by each type of
research has unique strengths and weaknesses.¬†

**Quantitative data** provides very clear and unambiguous information
about variables like how much, how many, and how often. The numerical
nature of the data makes it easier to analyze, but it can also lack
context. For example, while quantitative research can tell you fairly
quickly and easily how often a set of users performs a particular task,
that information is only valuable if you also have the context to judge
whether that rate of task performance is good or bad.¬†

**Qualitative data** is more challenging to analyze and interpret. It is
presented in the form of unstructured or semi-structured observational
findings like comments, preferences, and motivations. While this kind of
data usually contains the context, it doesn't offer a black-and-white
output, relying instead on researcher interpretation. It does, however,
help identify root causes of behaviors, which then makes it easier to
develop appropriate solutions.¬†

The two types of data may seem worlds apart, but they are actually
highly complementary. When in doubt, mix methods for a more holistic
view of the problem you're trying to solve.

¬†As for whether it's a good idea to skip the qualitative bit and lean
into the statistics, well, [Jakob Nielsen of Nielsen Norman
Group](https://www.nngroup.com/articles/risks-of-quantitative-studies/)
had a few things to say about that:

"Quantitative studies must be done exactly right in every detail or the
numbers will be deceptive. There are so many pitfalls that you\'re
likely to land in one of them and get into trouble. If you rely on
numbers without insights, you don\'t have backup when things go wrong.
You\'ll stumble down the wrong path, because that\'s where the numbers
will lead. Qualitative studies are less brittle and thus less likely to
break under the strain of a few methodological weaknesses. Even if your
study isn\'t perfect in every last detail, you\'ll still get mostly good
results from a qualitative method that relies on understanding users and
their observed behavior."

### Types of qualitative research¬†

The various qualitative research methods can be further categorized into
5 main research types:¬†

1.  Ethnographic---observation of study participants in their natural
    environment to gain a better understanding of context, cultural
    insights, and participant's day-to-day lives.
2.  Narrative---in-depth research (typically interviews) with a small
    number of people to uncover narrative themes that illustrate how
    various factors can affect events and relationships.
3.  Phenomenological---a variety of tactics (interviews, observation,
    documentation, etc.) used to describe and interpret a specific
    phenomenon or event, including participant perceptions and
    motivations.
4.  Grounded theory---long-term, in-depth research to discover the
    social and psychological processes behind an event or situation,
    including its causes.
5.  Case studies---a detailed accounting, either explanatory or
    exploratory, of an individual, organization, or event that reflects
    how things happen in the real world.

‚Äç

**Note:** That's a good, concise overview of the differences between
qualitative and quantitative research. If you're looking for a deeper
dive into the whole quant/qual thing, never fear---we've written [a
whole chapter on the
subject.](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)

‚Äç

## Generative vs. evaluative user research methods

The primary differences between generative and evaluative UX research
have to do with when the data is collected and why. Generative methods
help you identify opportunities and ideas, while evaluative or
evaluation research methods help you figure out if your existing
solution is on the right track.¬†

**Generative research** (sometimes called foundational, exploratory, or
(as in this Field Guide) [**discovery
research**](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods))
helps researchers gain a deep and highly detailed understanding of the
audience, the market, and even internal project goals. It does a lot
more than simply describe a user persona---it gets into the nitty-gritty
of the real-world person who may eventually become a user. Generative
research uses direct observation, deep inquiry, and careful analysis to
develop a fully rounded, 360-degree understanding of the human beings in
question---who they are, what their experiences are like (in relation to
a product and to life in general), what they care about, what they
believe in, how they think about the world, what drives their behavior
and decisions.

The goal of discovery research is to unearth opportunities to innovate
new solutions that will meet a specific and real need in the market.
Without this, it's all too easy to head off and develop a product no one
wants.¬†

**Evaluative research** is used to evaluate people's responses to a
product or solution. It comes into play a little later in the product
development process, but not that much later. Evaluative methods can
deliver valuable insights as soon as you have an initial concept (even
just a rough sketch or representative prototype), and should be used
throughout the design and development process as a kind of reality
check. Continuously putting design iterations in front of the relevant
audience for feedback helps ensure that the final product delivers the
experience people want while providing the solution they need.

Used together, generative and evaluative methods are like two sides of
the same coin. One side helps you identify and define the problem you
need to solve, while the other side makes sure you're building the right
solution to meet the need.

### Discovery (generative) methods

[Generative research
methods](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)
include things like [stakeholder
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)
to uncover internal goals, [field
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/field-studies)
to provide real-life context, and in-depth [user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews).

Each of these methods uses a combination of first-hand observation, deep
inquiry, and data analysis to ensure you're building the right product
at the right time for the right audience. Generative research methods
often allow researchers to observe every aspect of a study participant's
engagement---verbal responses, actions, behavior, body language, and so
forth. Researchers can gain a deeper understanding of the preferences
and mental models by asking follow-up questions to uncover the "why"
behind certain choices and behaviors. Any data---qualitative or
quantitative---is [analyzed to reveal relevant
patterns](https://www.userinterviews.com/ux-research-field-guide-chapter/research-analysis)
in the responses.¬†

‚Äç

##### üìñ **Read more about** [**Discovery Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)

‚Äç

### Evaluative methods

There are a wide range of evaluative research methods, many of which are
most valuable at specific stages of development. Their purpose is to
validate whether or not your in-progress design is effectively solving
the problem you identified during your generative research.

[Evaluative
methods](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods)
employ many different approaches---from [tree
testing](https://www.userinterviews.com/ux-research-field-guide-chapter/tree-testing)
to [qualitative usability
testing](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing),
accessibility testing, [A/B
testing](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing),
and more---to determine what is and isn't working in a design.¬†¬†

‚Äç

##### üìñ **Read more about** [**Evaluative Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods)

‚Äç

### Continuous research methods

Research doesn't end once you've launched. In fact, it's incredibly
important to engage in ongoing listening and dialog with users using
methods like NPS and other [feedback
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys),
[product
analytics](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics),
as well as [customer
support](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)
and feedback channels. Keeping the lines open is a critical part of
sustaining your product's value to users over the long term.¬†

Not only do [continuous research
methods](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods)
give you your first look at how people experience your product in real
life, they also help you adapt and evolve as things change. (And things
will change---maintaining an ongoing conversation and really listening
will help ensure that you don't get left behind.)

##### üìñ **Read more about** [**Continuous Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods)

‚Äç

## Attitudinal vs. behavioral user research methods

We know it's shocking, but people often say one thing and do another.
The disparity is usually unintentional, which is one of the reasons it's
so important to use UX research methods that collect both behavioral and
attitudinal data.¬†

**Attitudinal research methods** rely on self-reported data. This means
that they reflect people's stated beliefs, perceptions, and
expectations. This category includes things like interviews, surveys,
[focus
groups](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups),
and card sorts---all of which ask study participants to tell researchers
what they think.

The insights from attitudinal research methods are valuable, but they
also need to be taken with a grain of salt. People sometimes fall short
of telling you what they really think or are unable to fully articulate
their perceptions. And even when they think they are telling you the
whole truth and nothing but the truth, it can turn out that their
expectations don't match up with reality. (This is because human beings
are notoriously bad at accurately predicting their own behavior.)

Despite these cautions, attitudinal research methods can still be
helpful as a way of uncovering a participant's mental model, which can
then be used to shape a design to better meet user expectations.

**Behavioral research methods** are based on direct observation as a
study participant interacts with a prototype or finished product.
Researchers often prefer these methods since they are able to deliver
more reliable insights based on real-world scenarios. Research methods
that study a user's actual actions include things like eye tracking, A/B
tests, tree tests, [first-click
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing),
and also user analytics.

There are also a number of research methods---user interviews and [task
analysis](https://www.userinterviews.com/ux-research-field-guide-chapter/task-analysis),
for example---that can produce either attitudinal or behavioral data. In
any situation, best practices include collecting a variety of both
attitudinal and behavioral data.¬†

### Start talking to users today

[Sign up for free](https://www.userinterviews.com/recruit)

## Remote vs. in-person user research¬†

The biggest and most obvious difference between in-person and remote
research is that with remote research, the participant and the
researcher are in different locations.¬†

Here is a quick run down of some of the advantages most often associated
with each approach:

**In-person research:**

-   Is easier to moderate because participants tend to be more attentive
    and can ask questions if they get stuck.
-   Offer a more complete view of participant responses because
    researchers can combine verbal response and task-related actions
    with non-verbal cues.
-   Provides more opportunities to ask follow-up questions or make
    additional in-the-moment inquiries about participant choices or
    thought processes.
-   Gives researchers more control over the environment, including types
    of devices and software being used, internet connection, data
    security, noise, interruptions, and so forth.
-   Creates better group dynamics, which can contribute to idea
    generation and useful dialog depending on the type of research being
    performed.

**Remote research:**

-   Allows for much greater scheduling flexibility since there is no
    travel required.
-   Is less expensive because there are no space-related costs and both
    recruitment and compensation costs are often lower than for
    in-person studies.
-   Makes it easier to recruit a larger, more diverse group of
    participants.
-   Comes with fewer recruitment constraints such as availability or
    geographic location.
-   Can provide a more accurate reflection of real-life usage because
    participants can use their own equipment.

Remote research isn't suited for all research methods. For example,
[ethnographic field
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography)
are particularly hard to replicate remotely.¬†

But in many cases, the benefits of in-person research can be replicated
in remote scenarios, giving researchers the best of both worlds:
ultimate flexibility and cost-effectiveness without sacrificing the
quality of responses.¬†

## Moderated vs. unmoderated user research methods

The difference between moderated and unmoderated research methods is the
role of the researcher.¬†

**Unmoderated or automated research** involves unobserved tests that a
participant can complete at their own pace. The participant interacts
with the product via an online platform or software that prompts them to
answer specific questions or perform specific tasks.¬†

The nature of this kind of test makes it easier, less expensive, and
faster to run than research facilitated by a professional moderator. The
data from unmoderated research studies tends to be quantitative rather
than qualitative, although some unmoderated tests include the option for
participants to provide a recorded self-narration of their actions
during the test.¬†

Examples of research methods that are often unmoderated include surveys,
first-click tests, A/B tests, and user analytics.

**In moderated research**, a facilitator observes---either in person or
remotely---as participants take part in the study. This real-time
moderation allows researchers to adapt their script and process in
response to participant actions and engagement, and also to ask
follow-up questions that probe more deeply into why participants make
certain choices.¬†

Because of the human element of introducing a facilitator, moderated
tests can be more time consuming and more expensive. They can also
require additional expertise and preparation since there is a specific
skill set required to moderate a study effectively. And because the
output usually includes a good deal of qualitative data, analyzing the
results can also take a little more time.

Examples of research methods that are usually moderated include
interviews, ethnographic field studies, focus groups, and task analysis.

## Which user research method should you use?

The answer to this question is, of course, "it depends."

The right user research method for any given study depends on a
combination of factors, including which stage of product development
you're in, the nature of your research question, the types (and number)
of participants you're looking to recruit, your budget, and whether or
not there's a pandemic making in-person research particularly
challenging!

There are several good frameworks out there to help you choose the right
method, and we cover them in-depth in the upcoming chapter on [how to
choose a user research
method](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-choose-a-research-method).

‚Äç

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)

Next:

Qualitative vs. Quantitative Research

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Methodologies](/ux-research-field-guide-module/user-research-methods)

\>

[Qualitative vs. Quantitative
Research](/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)

# Qualitative vs. Quantitative Research

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Knowing when to use which type of research is an essential instinct for
UX researchers to hone. In the [last
chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types),
we gave an overview of the different types of user research methods. In
this chapter, we're going to take a closer look at qualitative and
quantitative research, in particular.

Why? Because combining qualitative and quantitative UX research methods
is the most effective way to create a comprehensive portrait of your
customers' wants and needs.¬†

Properly acquired and analyzed, the high-volume of data in quantitative
research helps you uncover what is happening---trends, issues, and
opportunities---and prove hypotheses.¬†

Qualitative research, on the other hand, adds a layer of humanity to
user data, delivering details that add depth and a deeper understanding
of not only what's happening, but why it's happening.¬†

The trick to choosing the right user research method is knowing what
kind of data you need to answer your research question. In this chapter,
we'll go over the differences between qualitative and quantitative UX
research methods, the pros and cons of each one, and how they complement
each other in a mixed methods approach.¬†

‚Äç

### In this chapter:

-   The differences between qualitative and quantitative research
-   When to do qualitative vs. quantitative user research
-   Research methodologies for both qualitative and quantitative
    research
-   Recruiting participants for qualitative vs quantitative studies
-   Qualitative vs quantitative data analysis

## The differences between qualitative and quantitative research¬†

The primary difference between qualitative and quantitative UX research
lies in the nature of the data---which impacts how it is collected and
then analyzed.

![a simple user research decision tree for qualitative vs quantitative
methods](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a9a7f6d54f7348b34210f1_qual-or-quant.png)

A simple decision tree for quant v. qual

In qualitative research, researchers gain insight through direct
observation of a small group of people, often engaging in follow-up
questions that dig deeper into the "why" behind certain attitudes and
behaviors. Qualitative research can also be adapted on the fly as
researchers adjust study protocols based on participant engagement and
response.¬†

Common qualitative research methods include
[interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
[focus
groups](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups),
[field
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/field-studies),
[qualitative usability
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing),
and co-design sessions.

Quantitative research, on the other hand, usually involves collecting
large quantities of numerical data from a much larger group of people,
often indirectly through surveys or analytics tools. Insights are
derived using mathematical analysis of the data to quantify a problem by
answering the questions, "How much?" and "How many?" Because statistical
significance is a key goal of qualitative research, testing protocols
are rigid and not subject to change over the course of a study.¬†

Common quantitative research methods include [user
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing),
surveys, [click
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing),
card sorts, and [A/B
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing).

### Let's take a closer look.

‚Äç

##### **Qualitative vs quantitative UX research methods**

![a table comparing quantitative and qualitative research
methods](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a7c61cea2cff4f2143d4a9_qual-vs-quant_optimized.png)

Qualitative vs quantitative UX research methods

‚Äç

Whatever kind of product you're working on, and wherever you are in the
product development cycle, it's important to know which kind of UX
research will get you the answers you need.¬†

‚Äç

## When to do qualitative user research

We love qualitative UX research at User Interviews. Qualitative methods
can provide valuable insight when you are trying to:

-   Come up with new ideas.
-   Gain deeper insight into customer needs.
-   Identify design problems.
-   Formulate hypotheses.

The use cases for qualitative research stretch across the product
development and design cycle---when you're brainstorming, in discovery,
validating a concept, testing the usability and desirability of a
finished product, preparing a go-to-market strategy, iterating post
launch, doing a redesign... every step of the way.

Qualitative research brings the human element to bear on whatever
question you're exploring. It lets you hear what people think in their
own words. It helps you compile detailed information that is both
valuable in itself and also a great jumping off point for additional
research directed at solving specific challenges.¬†

‚Äç

## When to do quantitative user research

Stakeholders love hard data. Compiling data to drive a strategic
research agenda with management is far from the only reason to engage in
quantitative UX research, but it is often the catalyst for major
research efforts.¬†

Quantitative research can help you to:

-   Establish critical benchmarks.
-   Identify problem areas.
-   Begin to define specific problems.
-   Elevate one solution over another.
-   Prioritize projects.

It can also lay the foundation for (and help you make the case for)
doing the qualitative research you need to find solutions to problems.¬†

Quantitative UX research is most commonly applied when you already have
a working product and are trying to evaluate its usability. It can also
be very effective at uncovering the answers to broad, high-level
questions through statistical analysis to either validate or disprove
your hypothesis.¬†

‚Äç

## Qualitative research methodologies

Qualitative research methods---which may be behavioral or attitudinal,
moderated or unmoderated, remote or in-person---can be further
categorized into five different types.¬†

Some kinds of qualitative research (like grounded theory) are
infrequently utilized in a UX research context. They're more commonly
used by researchers in the fields of sociology, anthropology, and other
social sciences from which they originated. But that's not to say you
couldn't use grounded theory for UX research, if a problem called for
it.¬†

### Five types of qualitative research

‚Äç

#### 1. Ethnographic research

In [ethnographic research
methods](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography),
researchers observe user behavior in participants' natural environment.
This approach is a powerful way to understand context, observe
real-world product use, and gain deep cultural insights about
participants' day-to-day lives.¬†

#### 2. Narrative research

Humans are wired for story, which is why narrative research often packs
an outsized punch. In this approach, researchers run in-depth interviews
with a very small number of participants in order to create a cohesive
narrative that reveals themes and patterns.

#### 3. Phenomenology

Phenomenology uses a combination of interviews, observation,
documentation, video recordings, etc. to help researchers understand the
what, how, and why behind a particular phenomenon or event. This method
helps describe and interpret lived experiences, which in turn helps
uncover participants' perceptions and motivations.

#### 4. Grounded Theory

While phenomenology aims to describe an event, grounded theory aims to
explain why an event happens, by uncovering the social and psychological
processes behind it. This is typically done through a combination of
user interviews with 20 to 60 participants and in-depth document
research.

#### 5. Case Study

The purpose of the case study is to relate, in detail, a real example of
a specific type of experience. The nature of a case study can be either
explanatory or exploratory, but the aim in either case is to gain access
to deep understanding of how things happen in the real world.¬†

‚Äç

## Quantitative research methodologies

As with qualitative research, quantitative methods can be broken down
into categories---which type of quantitative approach is most
appropriate depends on the nature of the issue you are researching, the
type of information you are after, and the study protocols involved.¬†

The following decision tree illustrates the process:

![example of a quantitative research decision
tree](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a7c6cfcbad4f1bbd8866f5_flow-chart.png)

[Source](https://libguides.sdstate.edu/c.php?g=364511&p=2462279)

### Four types of quantitative research¬†

‚Äç

#### 1. Descriptive¬†

Descriptive research uses a wide variety of methods to identify the
characteristics and frequency of a study topic while also looking at
associated trends and categories. It relies on observation and
measurement to deliver insights into the what, where, when and how
something happens.

#### 2. Correlational

Correlational research looks at how two or more variables that are
similar and interdependent relate to each other. This type of research
uses mathematical analysis to show how each variable affects the other.
Results are often presented using diagrams or statistics.¬†¬†

#### 3. Quasi-experimental (aka causal-comparative)

This type of research looks at the cause-and-effect relationship between
two variables---one dependent and one independent---that are not related
to each other.

#### 4. Experimental

Used to verify an argument, experimental research takes a theoretical
approach that focuses on a theory and then helps researchers identify
whether a given statement is right or wrong.¬†

‚Äç

## Recruiting participants for qualitative vs quantitative studies

Quality research---whether it's qualitative or quantitative---requires
quality participants.¬† But [the challenges of recruiting are
different](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
depending on which research methods you're using.

‚Äç

In quantitative research, you start with a large 'population'---the
entire group you want to study---and then you create a 'sample,' which
is a subset of the specific individuals who will participate in the
study. This process is often called 'sampling.'¬† For this to work, you
need two things: 1) a large sample size, and 2) a solid sampling design
that guarantees a random sample, which is critical to ensure truly
accurate results.¬†

‚Äç

In qualitative research (especially for B2B or other highly targeted
studies) the key is finding the perfect participants---people who fit
your customer profile exactly in terms of not only demographics and
geographics, but also psychographics, behavior, and specific criteria
relevant to the study parameters. Recruiting participants for
qualitative studies involves non-random sampling and appropriate
screening to deliver the best results.

‚Äç

[User Interviews can help](https://www.userinterviews.com/) with both
types of recruiting, but we're especially great at helping researchers
fill qualitative studies that require vetted, good-fit participants who
meet the specific criteria of your study.

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

## Qualitative vs quantitative data analysis

Once you've collected your data, what next?¬†

Regardless of whether your data is qualitative or quantitative, it isn't
much use to anyone until it's been analyzed and synthesized. The methods
you use to analyze your data will depend on the methods you used to
gather it---and unsurprisingly, there's quite a lot of difference
between quantitative and qualitative research analysis.

We'll be covering user [research data
analysis](https://www.userinterviews.com/ux-research-field-guide-chapter/research-analysis)
in more detail in a later chapter. But here's what you need to know in a
nutshell.

‚Äç

### Analyzing qualitative data

Qualitative data to yield a wealth of information, but not all of it is
relevant to your research goals. Qualitative analysis involves sifting
through the raw data to find patterns, themes, and stories that tell you
something meaningful about the product, the user, or both.

#### Qualitative findings are:

-   Estimates, impressions, and interpretations
-   Informed by the knowledge and experience of the researcher
-   Unstructured or semi-structured in nature

#### They are used to determine:

-   General strengths and weaknesses of a design or process
-   Average scores across multiple participants
-   Themes and trends
-   Correlation or causation between two or more variables

#### They are analyzed using:

-   The application of metadata to help organize unstructured data
-   Qualitative content analysis, which tracks instances, positioning,
    and intended meaning of specific words and phrases
-   Thematic analysis, which identifies themes and patterns
-   Discourse analysis, which looks at the nature of communication
    within a specific social context

### Analyzing quantitative data

Quantitative analysis is comparatively (deceptively) straightforward. It
involves a lot of number crunching---but what you are doing at heart is
trying to understand how people use a certain product, what problems
they may be experiencing, and where improvements could be made by
looking for patterns in the data.

‚Äç

#### Quantitative findings are:

-   Statistically meaningful¬†
-   Replicable
-   Measurable data points expressed in numerical form
-   Structured data that is easy to organize and search using a
    relational database

#### They are used to determine:

-   How many
-   How much
-   How frequently

#### They are analyzed using:

-   Mathematical and statistical analysis

‚Äç

##### üìñ **Read more about** [**UX Research Analysis and Synthesis**](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)

## Comparing advantages and disadvantages

We know there's a lot of information in this chapter, so before we wrap
up with a brief discussion of mixed methods, let\'s take a moment to
summarize what we've learned about each type of research with a list of
pros and cons.

‚Äç

### Advantages of qualitative research

-   Gives you first-hand insight into what people are really thinking
    and feeling
-   Reveals nuances and subtleties that quantitative data conceals
-   Uncovers the cause-and-effect connections that shape experience and
    drive behaviors
-   Works with a smaller sample size
-   Allows for a flexible and nuanced approach¬†
-   Provides study participants with a more expansive way to express
    their feelings and share their experience
-   Delivers emotionally driven, narrative-style evidence that can be
    very persuasive
-   Reveals why something is happening¬†
-   Helps identify solutions to UX problems¬†
-   Inspires future studies

### Disadvantages of qualitative research

-   Incremental expense---can have a higher upfront cost than
    quantitative research since most teams already run some sort of
    analytics by default
-   Time required---can take a long time to coordinate and run (though
    getting help with recruiting, one of the most time-consuming parts
    of the process, can streamline things substantially)
-   Risk of researcher bias, which can influence conclusions consciously
    or subconsciously
-   Non-traditional validation---the subjective, open-ended nature and
    small participant pools do not align with conventional standards for
    reliability and validity such as statistically representative data
-   Non-replicable---neither the study nor the results can be replicated
    since you cannot control for variables like the context, conditions,
    researcher knowledge, researcher approach, etc.
-   Narrow context---you cannot extrapolate results to make confident
    generalizations about a broader audience.
-   Challenging analysis---accurate interpretation requires expert
    knowledge of both the subject matter and qualitative research
    methodology.¬†

### Advantages of quantitative research

-   Provides some level of statistical significance
-   Reduces random noise
-   Allows for fast results
-   Lends itself to rapid analysis¬†
-   Delivers comparatively more objective results\*
-   Supports helpful data visualizations
-   Simplifies connecting the dots between UX improvements and team
    objectives
-   Enables test replication

###### **\*Caveat:** The aim of quantitative research is to provide unbiased and objective results. But, despite best intentions, there are always variables that can influence a study. Quantitative methods do offer a greater opportunity to find statistical significance, but only when the data is collected, analyzed, and presented correctly. For example, if a survey design is biased---even unintentionally---the data will also be biased. Excellence in quantitative research requires a high level of expertise and knowledge about each step in the process.¬†¬†

### Disadvantages of quantitative research

-   Limited insight---quantitative research can reveal the what, but it
    can't tell you the why. It can tell you that there is an issue, but
    it can't necessarily identify the specific problem, and it doesn't
    provide a solution.
-   Risk of confirmation bias---researchers may overlook certain
    generative insights due to an over focus on evaluative testing.
-   Limited context---participants' response options are narrowly
    defined. They do not have the opportunity to explain their choices
    or ask for clarification about questions.¬†
-   Reliance on researcher assumptions---the context-bound nature of
    responses means that researchers need to make their own assumptions
    about how participants interpreted questions and why they chose
    certain responses.
-   Large sample size requirement---statistical significance requires a
    large pool of participants.
-   High analytical skills required---an inadequate knowledge of how to
    apply statistical analysis can influence data interpretation and
    negatively affect the accuracy of results.

‚Äç

## For best results, mix methods

Oftentimes, the best way to answer your research question with both
certainty and nuance is to take a mixed methods approach.¬†

**Mixed methods user research** is exactly what it sounds like---the
practice of using both kinds of research methods in a single study. Side
note: If you're blending multiple qualitative methods (and you often
will) or multiple quantitative methods---but not the two
together---that's referred to as hybrid research. Similar, but
different.

Many UX researchers opt for a mixed method approach. That's because
quantitative and qualitative methods are actually highly complementary.
Quantitative research helps you identify specific problems by measuring
the 'what' and the 'how', and provides hard data that can be quickly
analyzed and understood. Meanwhile, qualitative data helps you uncover
the 'why' behind an issue or opportunity. Each type of data helps fill
in the gaps left by the other, giving you a holistic picture of exactly
what's happening, why it's happening, and how you should address it.

Mixing methods also helps you avoid making false assumptions that can
cause you to travel down the wrong path, wasting time and resources on
developing a solution that users don't really need.¬†

For example, if quantitative research shows that a particular step in
your conversion journey takes twice as long as any other part of the
process, you might assume that that step is simply more time-consuming.
However, if you then run a qualitative test to observe how people do
that step and collect direct feedback about the experience, you may
learn that the instructions are confusing and users are getting hung up
on trying to interpret them.¬†

The key to successful UX research is knowing which methods will give you
the answers you need, and how they can be combined with other methods to
give you the most complete and accurate picture possible.¬†

Which is an excellent segway into the next chapter, [How to Choose a
User Research
Method](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-choose-a-research-method),
which is all about the frameworks user researchers use to decide on the
specific methodologies their research question requires.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/user-research-types)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/how-to-choose-a-research-method)

Next:

How to Choose a User Research Method

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research
Methodologies](/ux-research-field-guide-module/user-research-methods)

\>

[How to Choose a User Research
Method](/ux-research-field-guide-chapter/how-to-choose-a-research-method)

# How to Choose a User Research Method

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

[Getting started with user
research](https://www.userinterviews.com/ux-research-field-guide-module/ux-research-basics)
can be intimidating. Even for experienced UX researchers, the variety of
possible approaches to any given research project can feel
daunting---with so many methods, which one should you choose? What is
the best way to answer your research question? Is it the most efficient
way that will keep your project within scope, under budget, and on
time?¬†

In the previous two chapters, we gave an overview of the [different
types of user research
methods](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types),
and dove deeper into the important differences between [qualitative and
quantitative
research](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods).
You may already have an idea, based on what you read and the
pre-existing UXR knowledge you're bringing to the table, which methods
you want to use for your current project.

In this chapter, we're going to help you solidify those choices, and
introduce you to a few different frameworks for choosing the right user
research method for any project that comes your way, or any research
question that might crop up.

These frameworks---which can be adapted to your own research practice
and the realities of your organization, customers, and unique
constraints---will help you answer the question "which UX research
method should I use?" efficiently and effectively every time.

### In this chapter:

-   Start with clearly stated research questions and goals
-   Pick the right method for your research question
-   User research frameworks
-   The right methods for each stage of product development¬†
-   Mapping UX research methods to decisions
-   A 3-dimensional framework for UXR¬†
-   Additional considerations

Without further ado, here's how to choose the right methods for your UX
research study.

## Start with clearly stated research questions and goals

As ever, you'll want to start with well-defined goals and clear research
questions.¬†

If you're not already clear about the goals of your research, stop here.
Do not pass go. Do not collect \$200 in [gift card
incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives).

Circle back to the chapter on [creating a user research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
for help identifying your research goals, which should be statements
about what you're trying to learn from your research.

**To define your research goals, ask yourself:**

-   What do I want to know?
-   What don't I know?
-   How will I know when I've learned it?
-   What company goals will this work support?
-   Where am I in the product development process?
-   What decision will this research enable?¬†
-   What are the anticipated outcomes of this research?

You'll want to further refine the answers to these questions through
[stakeholder research](#)---your key stakeholders can clarify business
goals and the kinds of decisions your research needs to enable to be
successful.¬†

Good research questions are [specific, actionable, and
practical](https://medium.com/mule-design/research-questions-are-not-interview-questions-7f90602eb533).
They also contain clues about who you need to recruit and which methods
you'll need to use.¬†

**Some example of good research questions:**

-   Are our customers able to successfully navigate to the support page
    on our site?
-   What are the primary motivating factors behind the decision to
    purchase pet insurance?
-   What tools do college students use to keep track of their schedules?

‚Äç

##### üìñ **Read more about** [**Planning UX Research**](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)

‚Äç

## Pick the right method for your research question

In the likely event that you aren't binge reading the UX Research Field
Guide in a single sitting, it's probably helpful to take a moment to
revisit the different types of user research, along with the different
questions they can help you answer.¬†

User research methods can be divided along several different axes. They
can be:

‚Äç

#### Quantitative or qualitative

**Qualitative UX research** involves collecting data through direct
observation of a small group of people in order to assess behavior and
provide context. Qualitative methods produce unstructured or
semi-structured observational findings like comments, preferences, and
motivations.

Qualitative research helps you answer the questions:¬†

-   "Why?"¬†
-   "How?"
-   "How can we fix this?"

**Quantitative UX research**, on the other hand, involves collecting
data from a much larger group of people in order to quantify a problem
and uncover patterns through statistical analysis.¬†

Quantitative research helps you answer the questions:¬†

-   "How much?"
-   "How many?"¬†
-   "How often?"

‚Äç

#### Generative or evaluative

**Generative (discovery) UX research** (also foundational, or
exploratory research) uses direct observation, deep inquiry, and careful
analysis to generate ideas (go figure) and discover opportunities for
innovation that will meet a specific and real need in the market.
Generative research is often (but not always) qualitative.¬†

Discovery methods help you answer questions like:

-   Who are our users?
-   What are their problems?
-   How do they think?
-   Is there a real need for this solution?
-   What should we build?

**Evaluative UX research** is used to evaluate people's responses to a
product or solution. It is used throughout the product development cycle
to test and validate the appeal, intuitiveness, and functionality of
ideas, prototypes, and finished products.

Evaluative methods help you answer questions like:

-   Which design do users prefer?
-   Is this interface intuitive?
-   Does this feature work as intended?
-   Are we building the right thing, correctly?
-   What could be better?

#### Attitudinal or behavioral

**‚Äã‚ÄãAttitudinal UX research** methods (like surveys and [focus
groups](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups),
for example) rely on self-reported data about people's beliefs,
perceptions, and expectations. Take what participants say with a grain
of salt, especially if they're referring to future behaviors---even the
most self-aware user can't predict the future.

Attitudinal research can help you answer questions like:

-   What do people think about this feature?
-   What do people say they want?
-   How do people describe their current problem?
-   What are their mental models?

**Behavioral UX research** methods (like [A/B
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing)
and [first click
tests](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing))
are based on direct observations about how a study participant interacts
with a prototype or finished product.¬†

Behavioral research can help you answer questions like:

-   How do users interact with this new feature?
-   How long does it take users to complete a workflow?
-   Which CTA has a higher conversion rate?
-   Can people navigate the UI?

## User research frameworks

A user research framework is a systematic way of categorizing research
methodologies and approaches to guide decisions about which method to
use, when. Whether you're a solo UX researcher or are working within a
larger team, a reliable framework will provide consistency and can
dramatically speed up research planning and decision-making.

They can be intricate, like this behemoth from UX researcher [Lena
Borodina](https://uxplanet.org/which-ux-research-method-to-use-2ca910a9b68e):

![large ux research methods selection
framework](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a9ab4e3e8856d5d1f49d2f_Screen%20Shot%202021-12-03%20at%2012.29.36%20AM.png)

[Source](https://overflow.io/s/E42BS4/?node=8fdcdf0f)

Or they can be simpler, like Tomer Sharon\'s [Lean User Research
framework:](https://medium.com/mytake/validating-product-ideas-lean-user-research-by-tomer-sharon-e3c805601035)

‚Äç

![61a9ad31eefde3336b90c00b_lean%20uxr%201](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a9ad31eefde3336b90c00b_lean%20uxr%201.png)

[Source](https://medium.com/mytake/validating-product-ideas-lean-user-research-by-tomer-sharon-e3c805601035)

The best framework is the one that works for you. In order for it to be
used effectively, a framework needs to be relevant to your team, your
business goals, and your internal resources. If you don't have the
budget or people power for long ethnographic field studies, don't
include those types of studies in your framework. (Remember, frameworks
can evolve.)

All of the frameworks in this chapter can and should be adapted to your
own practice as necessary. We'll cover how to map UX research methods
to:

-   Where you are in the product development cycle
-   The decisions you want to enable
-   The nature of the data collected

Let's hop to it!

## The right methods for each stage of product development¬†

In the very first chapter, What Is User Research?, you learned about how
(and why) to conduct user research at [different stages of the product
development
cycle](https://www.userinterviews.com/ux-research-field-guide-chapter/what-is-user-research).

As you progress through the discovery, design, testing, implementation,
and post-launch phases, the problems you need to solve will change.
You'll ask different questions, which will require different research
methods to answer.

![ux activities in the product and service design
cycle](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a8ea0463291e28ab9555bf_wELrjfNxq1SOEYktbBMPL-LTlxmvXTE7ZnD_B21WaTTaO-AKFD7V-BsQTVvFk1HhLJsWfcSHIWX5jVuz2UvE33irinTLLUhbu-uqKzujAYDvt5X_EGuUfvO5vviTTUFU6TKlnPvt.png)

[NN/g\'s UX Research¬†Cheat
Sheet](https://www.nngroup.com/articles/ux-research-cheat-sheet/)

‚Äç

### Discovery stage (pre-prototype)

Most projects begin with some
[discovery](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods),
in which you're trying to pinpoint the problem and get a clearer picture
of who you're solving it for.¬†

The goals at this stage are to explore new directions, develop a
detailed understanding of (potential) user needs and their context, and
uncover opportunities. Both qualitative and quantitative approaches are
used during this phase.

Conducting UX research during discovery helps you **empathize** and
**strategize.**

‚Äç

#### Key discovery methods

[**Stakeholder
Interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)---Understanding
what your stakeholders ultimately value and need to know is a necessary
component of effective user research. Part of a user researcher's role
is to align and articulate both business and user goals, and find where
they intersect.¬†

[**Ethnography**](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography)---Ethnography
is all about observing people and their habits in context (their natural
habitats, if you want to get zoological about it). Field studies and
online ethnographic studies can help you understand how people behave in
groups and how they might interact with your product outside of a lab
environment. What people do is so often different from what they report,
and ethnographic studies can be a great way of getting around this
issue.

[**Diary
studies**](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies)---When
you need to understand long-term user behavioral patterns, diary studies
are a great option. They provide insights into habits, changes over
time, motivations, and long-term customer journeys. And they can be a
solid alternative to ethnographic field studies when you're on a limited
budget.¬†¬†

[**Focus
groups**](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups)---Focus
groups are not exactly the, ahem, darling of UX research circles these
days. But they have their uses, especially when it comes to market
research. Focus groups allow you to observe a lot of people relatively
quickly. When you are very early in developing and marketing your
product, this type of research can be useful in getting a broad view
into the audience you seek to serve.¬†

[**Generative user
interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)---In-depth
user interviews typically involve talking to participants one-on-one,
asking them a set of non-leading questions, with an emphasis on past
behaviors and perceptions. User interviews are valuable throughout the
product development cycle, but are especially important in the early
stages---the things you learn might confirm your hypotheses or lead to
wildly different conclusions that reshape the direction of your inquiry.

‚Äç

##### üìñ **Read more about** [**Discovery Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)

‚Äç

### Concept validation and testing stage (prototype and build)

At this point, you have a good sense of your market, your users, and
their needs.¬†You've come up with an idea for a solution, are actively
building (or have built) a prototype, and are ready for feedback.¬†¬†

‚Äç

This stage of product development is about [evaluating your solutions
and validating your
decisions](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods)
through both qualitative (formative) and quantitative means. The goals
of testing are to validate conceptual fit, evaluate the usability of the
design, and inform changes.

‚Äç

Eventually, you will reach a \"go/no-go\" decision point, when you
transition into a period in which you are continually improving the
design direction that you have chosen to reduce the risk of execution.

‚Äç

Conducting UX research during this phase helps you **optimize** and
**execute.**

#### Key validation and testing methods

[**Qualitative usability
testing**](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing)---This
method involves having participants think aloud as they interact with a
prototype or product, allowing researchers to evaluate implicit and
explicit cues and find patterns quickly.¬†

[**Task
analysis**](https://www.userinterviews.com/ux-research-field-guide-chapter/task-analysis)---Task
analysis helps you better understand your user's goals, and how they go
about achieving them. This can be coupled with a variety of other
methods, and is an important aspect of evaluating the overall user
experience for most apps.

[**A/B testing and multivariate
testing**](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing)---Whether
you use A/B test, A/B/C test, single variant test, or multivariate test,
the goal is to collect quantitative data on which version of your
product best achieves the goal of the test---generally a hybrid of a
business and user goal, for instance conversion rate on an ecommerce
site.

[**First click
testing**](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing)---This
is just what it sounds like. First click testing---in which you record
the first click someone makes to accomplish their goal and analyze the
results---is a popular way to assess the user's ability to efficiently
and effectively complete a task.

**Card sorting and** [**tree
testing**](https://www.userinterviews.com/ux-research-field-guide-chapter/tree-testing)**---**Card
sorting and tree testing are methods for testing your information
architecture (IA), i.e. how you categorize and label content. Card
sorts, which involve users grouping topics into categories, can provide
great insight into your user's mental models and how you should organize
your content. Tree tests---in which users are tasked with finding
information in a sitemap---are often used as a followup method to
evaluate how intuitive your site navigation is.

**Accessibility testing**---The validation and testing stage should not
be the first time accessibility crosses your mind; ---accessible design
begins with thoughtful planning and research design.¬† By the time you
get to this stage of product development, you should be using
accessibility testing to stress test prototypes or products that have
already been designed with accessibility in mind. In addition to running
your product through accessibility checking tools, consider conducting
qualitative usability studies with participants with disabilities.

‚Äç

##### üìñ **Read more about** [**Evaluative Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods)

‚Äç

### On-going listening (post-launch)¬†

You've launched a product... congratulations!¬†

‚Äç

Now, keep researching it!

‚Äç

No, seriously---user research doesn't (or shouldn't) stop once you've
launched a product or feature. "Set it and forget it" is not a smart
product strategy. [Ongoing listening
methods](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods)
help keep your product useful, impactful, and relevant over the
long-haul.

‚Äç

The goals of post-launch research are to understand how well your
product is performing, assess how well it continues to address customer
needs, and identify opportunities for improvement. Methods are typically
quantitative (summative) in nature, and allow you to measure product
performance against itself or its competition.

‚Äç

Conducting UX research after launch helps you **assess** and
**iterate.**

‚Äç

#### Key ongoing listening methods

[**Feedback
surveys**](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys)**---**There's
a variety of survey types and tools that can help you meet your goals,
from user intercept (in-app) surveys, to NPS surveys, to longer surveys
that dig into specific aspects of the user experience. Like other
methods at this stage, ongoing listening surveys typically require some
cross-functional collaboration to do effectively. Talk to your product
team to find out where and when an in-app survey would be most
effective, partner with marketing to launch and monitor an NPS survey,
and coordinate with customer development to segment and send email
surveys to existing customers.

[**Analytics**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics)---Analytics
can be a treasure trove of great quantitative data if you know how to
analyze them and connect insight to action. Keeping a close track on key
user flows, in-app behaviors, and business metrics will help you see
changes over time.¬†

[**Bug reports and support
tickets**](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)---Bugs
come up and need to be fixed. That's just the reality. Make sure you
have good bug reporting and systems to address them rapidly. Your dev
team is probably on top of this, but you can use this data to understand
where current or historical frustrations may have impacted the user
experience in ways you wouldn't have known otherwise. Similarly, FAQ and
support desk reporting can help you understand where users are getting
stuck. Taking proactive steps to clear up these moments in the product
itself will improve the user experience and make your support team oh so
happy.

##### üìñ **Read more about** [**Continuous Research Methods**](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods)

‚Äç

## Mapping UX research methods to decisions

Research is systematic inquiry. If it is not systematic, you're not
researching---you're just being a busybody. To quote [Roberta
Dombrowski,](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research)
VP of User Research at User Interviews:

‚Äç

\"Research is the act of acquiring knowledge---we could literally
conduct research on any topic under the sun. That endless potential
scope is why it\'s so important that, as practitioners, the research we
are leading and conducting is focused and aimed at enabling decisions
for our organizations.\"

‚Äç

At User Interviews, we keep our research focused by using our own
[Decision Driven Research
Framework](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research),
which is centered on the belief that the purpose of research is to
enable decisions for your company, product, or service.¬†

‚Äç

### A framework for Decision Driven Research

In this framework, the idea is to map your research methods to the types
of decisions you want to enable. There are 4 types of decisions:

-   **Vision decisions** establish a potential company, product, or
    service direction. To enable vision decisions, you should choose
    methods that give you clarity on participants' big-picture beliefs,
    philosophies, and experiences.
-   **Strategy decisions** determine how you will achieve your vision.
    To enable strategic decisions, you should choose methods that give
    you detailed insights into participants' big-picture beliefs,
    philosophies, and experiences.
-   **Definition decisions** determine whether or not you pursue a
    specific design direction. To enable these decisions, you should
    choose methods that allow you to get early feedback on potential
    design directions and to better understand how a participant may
    interact with a potential product or service.
-   **Evaluation decisions** concern iterations to existing products or
    services. To enable evaluation decisions, you should choose methods
    that allow you to continuously identify problems, bugs, or confusion
    that customers may encounter during use.

Below is a list of the most common methods we use when conducting
research at User Interviews. For each method, we've created internal
documentation about what the method is, the type of decisions it helps
inform, and the output.

![a table mapping research methods to decision
types](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a9af18ec82b34c27bfbad3_Mapping-research-methods_opt.png)

‚Äç

There are 5 stages to doing Decision Driven Research, the first three of
which are all about creating a clear and focused plan for research.
Here's the process in full:

1.  **Identify the decision trigger**. This is the first and most
    important phase, in which you identify that there\'s a decision that
    your team has to make, or a question you need to answer.¬†
2.  **Scope evidence**. Once you know what decision needs to be made
    (i.e. once you've defined your research goals), take time to review
    whether there is any existing data or evidence that can inform the
    decision or even answer your research questions.
3.  **Define your approach.** If there\'s no existing data or you decide
    you need more information in order to proceed, then it's time to
    figure out which approach or research method will get you the
    answers you need to confidently inform a decision.¬†
4.  **Explore.** Now that you have a research plan, it's time to go out,
    explore, and gather data. In other words, research!
5.  **Reflect and decide.** Finally, [analyze and
    synthesize](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis),
    reflect on what you learned, and make informed decisions about what
    to do next.¬†

‚Äç

##### **üí° Read more about the** [**Decision Driven Research Framework**](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research)

‚Äç

## A 3-dimensional framework for UXR¬†

Many teams limit their research opportunities by consistently using the
same familiar methods over and over again. And while it's unlikely you'd
ever need to use all the different UX research methods out there on a
single project (what a nightmare), you should be prepared to mix up your
playbook when the research question calls for it.

[Nielsen Norman
Group](https://www.nngroup.com/articles/which-ux-research-methods/)
developed a helpful chart that illustrates where 20 popular methods fall
along the following axes:

‚Äç

**Attitudinal vs. behavioral**---Attitudinal refers to what people say,
while behavioral refers to what they do. Often there's a pretty wide gap
between the two. The most popular research methods blend elements of
these two to capture both what people say and what they do.¬†

**Qualitative vs. quantitative**---As we've been discussing, qualitative
research data comes from observing behaviors and/or attitudes directly
while quantitative research data is acquired indirectly via an
instrument like a survey or web analytics tool.¬†

**Context of use**---The final axis of NN/g's three-dimensional
framework looks at how study participants use the product in question
(if indeed they do). Context of use can be defined as:

-   Natural or near-natural use of the product¬†
-   Scripted use of the product¬†
-   Not using the product during the study
-   A hybrid of the above

Using this chart, you can start to hone in on which methods will satisfy
your research goals:¬†

‚Äç

![landscape of user research methods chart from
nng](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a8eaefddf7076cc6cd1454_nng.png)

[Source](https://www.nngroup.com/articles/which-ux-research-methods/)

The folks at NN/g are [careful to
note](https://www.nngroup.com/articles/which-ux-research-methods/) that
theirs, like all frameworks, is not set in stone. Few of the methods are
fixed in a single place.

Most of the methods in the chart can move along one or more dimensions,
and some do so even in the same study, usually to satisfy multiple
goals. For example, field studies can focus on what people say
(ethnographic interviews) or what they do (extended observations);
desirability studies and card sorting have both qualitative and
quantitative versions; and eye tracking can be scripted or unscripted.

## Additional considerations

User research rarely (if, indeed, ever) happens without constraints. You
may be short on time, money, or people power. And that will impact which
methods are available to you.

### Some methods are expensive and time consuming

Say you want to learn about how participants interact with your product
in a real-world context. Field studies would be an obvious choice---you
could observe people in the field, using your product IRL. Great!¬†

But field studies can take months.¬†

¬†¬†

If you don't have the luxury of time, [diary
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies)
would be a solid option for learning about product use in-context. The
best UX research method in this case is the one you can reasonably fit
into your timeline and budget.

‚Äç

### Some methods require more people power

Unmoderated research involves unobserved tests that a participant can
complete at their own pace using tools that prompt them to answer
specific questions or perform specific tasks. The nature of this kind of
test makes it easier, less expensive, and faster to run than research
facilitated by a professional moderator.¬†

Moderated research requires a moderator (go figure). Researchers observe
as participants complete a study, which allows researchers to respond to
participant actions on the fly and to ask follow-up questions that probe
more deeply into why participants make certain choices.¬†

Because of the human element of introducing a facilitator, moderated
tests can be more time consuming and more expensive. They can also
require additional expertise and preparation since there is a specific
skill set required to moderate a study effectively. And because the
output usually includes a good deal of qualitative data, analyzing the
results can also take a little more time.

You shouldn\'t skip moderated research (which includes methods like
interviews and qualitative usability testing). You really [only need
about 5
participants](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants),
anyway. But if you're trying to collect data at scale, whether that's
qualitative or quantitative, remember that there's only so much time in
a day. Be realistic about how many facilitated research sessions your
team can handle within a project's timeline.

‚Äç

### Some methods need specialized tools

We don't have a usability testing lab at User Interviews. Nor do we have
a closet full of eye tracking devices or other biometric technology. In
fact, we don't have a lot of the things some user research teams rely on
as part of their practice.¬†

And that works for us! We're a [fully remote
company](https://www.userinterviews.com/about), and we conduct remote UX
research. We don't need to monitor people's heart rates or do research
in clinically controlled environments to answer our research questions.

We also don't pay for all-in-one research platforms. That's less about
cost, and more about the fact that we'd rather assemble our own toolkit
with products that let us bring our own participants ([recruited with
User Interviews](https://www.userinterviews.com/), naturally).¬†

But that's just us. The [tools you need for user
research](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-tools)
might be different. Or not---many user research methods don't require
special software.¬†

If your research question can be answered by simple means---do that.
Research that's hard to do doesn't get done.

‚Äç

## So, which user research method should I choose?

Well, that was kind of the whole point of this chapter. But if you're
still feeling stuck, we created a methods quiz that might help!¬†

‚Äç

##### **‚ùì**[**Take the UX Research Method Quiz**](https://www.userinterviews.com/blog/how-do-i-choose-the-right-ux-research-method)

‚Äç

Editor's note, December 2021: We're in the process of updating the
resources associated with each method recommendation in the UX Research
Method Quiz.¬†

Keep reading to learn more about each user research method in depth.
First up: [Discovery research
methods](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)!

### Recruit from our panel of 700,000+ vetted participants

[Sign up for free](https://www.userinterviews.com/recruit) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/discovery-methods)

Next:

Discovery Research Methods

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

![two people in separate browser windows conversing via charts and
speech
bubbles](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f2b95e0d1b98a703a7c2_UI_CHAPTER_05_ARTWORK.jpg)

05\.

# Discovery Research Methods

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Discovery research (also called generative, foundational, or exploratory
research) is all about pinpointing the problem and getting a clearer
picture of who you're solving it for.¬†

‚Äç

UX researchers use generative research methods that rely on direct
observation, deep inquiry, and careful analysis---to understand their
users, what they care about, how they think, and what motivates their
behavior.

‚Äç

The data collected through this research helps generate ideas and
discover opportunities to innovate and improve solutions that meet a
real and specific need in the market.¬†

‚Äç

In this module, you'll learn all about conducting

-   **Literature reviews,** in which researchers collect, analyze, and
    synthesize published data to integrate \'known knowns\' into future
    projects.
-   **Generative user interviews.** In-depth, 1-on-1 interviews involve
    talking to participants and asking them a set of non-leading
    questions about behaviors, beliefs, and habits.
-   **Ethnography** and **field studies.** Ethnographic research
    involves observing participants in natural (non-lab) settings.
-   **Diary studies**, which offer insights into user habits, changes
    over time, motivations, and long-term customer journeys.¬†
-   **Focus groups**. In the early stages of research, this method can
    be a useful way to get a broad-strokes view of your target
    audience.¬†
-   **Card sorting**, a technique for finding patterns in how people
    understand and categorize information.¬†

[Start
reading](/ux-research-field-guide-chapter/literature-reviews)[Start
reading](/ux-research-field-guide-module/evaluative-methods)

In this module:

[Literature
Reviews](/ux-research-field-guide-chapter/literature-reviews)

New

New

New

Everything a UX researcher needs to know about how to conduct literature
reviews: definition, types, benefits, and examples.

[User Interviews](/ux-research-field-guide-chapter/user-interviews)

It may come as a shock, but\... we\'re big fans of this method.

[Ethnography](/ux-research-field-guide-chapter/ethnography)

A guide to observing users in context. Get your notebooks ready, folks!

[Diary Studies](/ux-research-field-guide-chapter/diary-studies)

This may be the only time you'll get permission to read someone's
diary\... use the opportunity wisely!

[Focus Groups](/ux-research-field-guide-chapter/focus-groups)

An instructional guide to the most divisive method in user research.

[Card Sorting](/ux-research-field-guide-chapter/card-sorting)

Card sorting---it\'s not just for magicians and gamblers. Learn how to
use card sorts to uncover mental models and build better IA.

[Co-Design](/ux-research-field-guide-chapter/co-design)

Coming Soon

Coming Soon

Coming Soon

You don't have to do this alone. Co-design---or participatory
design---is research done better together.

[](#)

**Coming Soon** To this module:

##### Literature Reviews

New

New

New

Everything a UX researcher needs to know about how to conduct literature
reviews: definition, types, benefits, and examples.

##### User Interviews

It may come as a shock, but\... we\'re big fans of this method.

##### Ethnography

A guide to observing users in context. Get your notebooks ready, folks!

##### Diary Studies

This may be the only time you'll get permission to read someone's
diary\... use the opportunity wisely!

##### Focus Groups

An instructional guide to the most divisive method in user research.

##### Card Sorting

Card sorting---it\'s not just for magicians and gamblers. Learn how to
use card sorts to uncover mental models and build better IA.

##### Co-Design

Coming Soon

Coming Soon

Coming Soon

You don't have to do this alone. Co-design---or participatory
design---is research done better together.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/evaluative-methods)

06\.

### Evaluative Research Methods

[](/ux-research-field-guide-module/continuous-research-methods)

07\.

### Continuous Research Methods

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

\>

[Literature
Reviews](/ux-research-field-guide-chapter/literature-reviews)

# Literature Reviews

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

If you thought you left literature reviews behind in academia, think
again.¬†

‚Äç

Although UX researchers tend to focus heavily on primary research
methods, secondary methods like literature reviews can reveal
fundamental insights that ground our decision-making in established
theory and real-life context.¬†

‚Äç

Like user insights leader Xenia Avezov says in ["Secondary research is
chronically underused in UX
research"](https://medium.com/@xenia.avezov/leverage-secondary-research-in-your-user-research-practice-part-i-b1cd06dffc81):

‚Äç

"Research that is not grounded in the systemic, environmental, and
psychological nature of human problems is often incomplete. Secondary
research empowers us to incorporate these perspectives and reframe
problems in a holistic way."

‚Äç

More pragmatically: Why waste your limited resources on rediscovering
info that other researchers have already found? Literature reviews allow
you to reduce, reuse, and recycle insights, minimizing your research
footprint and maximizing your impact-to-effort ratio.¬†

‚Äç

## In this chapter:

-   Literature review definition, structure, and types
-   Benefits of literature reviews for UX research
-   Examples of literature reviews
-   When to use literature reviews for UX research
-   How to write an effective literature review
-   Literature reviews for mixed methods research

‚Äç

## What is a research literature review?¬†

A **literature review** (also called a '**lit review**' or '**desk
research**') is a type of [secondary
research](https://www.nngroup.com/articles/secondary-research-in-ux/) in
which researchers collect, analyze, and synthesize published
data---including articles, websites, videos, research journals, and
existing [research
repositories](https://www.userinterviews.com/blog/librarians-on-uxr-insights-repositories-nada-alnakeeb-joanna-perez)---on
a topic, in order to identify patterns and trends.¬†

‚Äç

Unlike primary research, which you conduct to answer the research
question at hand, secondary research was conducted by other researchers.
(The exception to this would be if you were using research that you
previously conducted (after all, you were a different person back then).
Most of the secondary research you'll find was likely conducted for
purposes unrelated to your project or product, but a thorough and
focused literature review can help you consolidate relevant data and
boost your confidence in your own research questions.¬†

‚Äç

Literature reviews are commonly associated with university
theses---sometimes taking months or years to complete in an academic
setting---and some researchers leave this method behind when they move
onto a business environment. But lit reviews deserve a place in any UX
research toolkit, whether you're working on a post-doctorate or a food
delivery app.¬†

‚Äç

‚è∞ To maximize the value gained for the time spent, UX researchers will
probably want to limit the scope of their literature reviews to **5
hours or less**, but it really depends on the topic and the resources
available.

‚Äç

![Literature reviews help with visionary or strategic decisions; their
output is a written report; they take roughly 5 hours or
less](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62ea8804096bbafb2a22be44_QwyU2-QmBAvqwN1UxHEAVzekybk8IXi_i1XJdoAVw_N8-joxutbBNyN90fmBEsiVdIFTYmMR5FnWkmupQRulthXRcS6MQVcna26SbhU820Qc1jpmCd4hTWnKP7yIhSOhoQdZjrGDQBS1fDgQveU6Xmc.png)

Outputs, time required, and decisions made with literature reviews

‚Äç

#### **What kind of decisions do literature reviews help with?**¬†

Literature reviews are typically used to inform visionary or strategic
decisions related to a product or service.¬†

‚Äç

For example, you might conduct a literature review to answer [user
research
questions](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-questions)
like:

-   What is our competitive advantage with our newest product line?
-   How are our target customers managing their challenges without our
    product or service?

‚Äç

#### **What should you include in a literature review?**¬†

Literature reviews require lots of reading, so researchers often use
spreadsheets or documents to keep track of their sources and make note
of key insights.¬†

‚Äç

The output of a literature review is a written report that is structured
to include:

-   An overview of the project, including the research questions and
    goals
-   A summary of each of the sources included
-   An evaluation or critique of each source, comparing and contrasting
    key insights
-   A discussion of biases or weaknesses
-   Suggestions for future research or decision-making

‚Äç

### What are the different types of literature reviews (and how do you know which one to use)?

There are several types of literature reviews, and each one requires a
different amount of time, effort, and resources:¬†

-   **Systematic literature reviews** are the most rigorous form of
    literature review, aiming to summarize as much of the relevant
    research as possible with little to no bias. They can take anywhere
    from 8 months to 2 years, requiring 2 or more researchers to
    complete. (You may sometimes hear systematic reviews confused with
    meta-analyses. You'd only conduct a meta-analysis in the context of
    a systematic review, but they're not exactly synonymous. [Here's a
    quick overview of the
    difference](https://guides.lib.odu.edu/c.php?g=966167&p=7021863).)
-   **Rapid literature reviews** aim to provide robust and reliable
    information, while omitting or streamlining certain components of
    the review to save time. They typically take 2 to 6 months to
    complete with 2 researchers reviewing materials.¬†
-   **Scoping literature reviews** assess the scope and nature of
    existing research prior to a more rigorous review or study. They can
    take anywhere from 2 to 8 weeks with 1 or 2 researchers working on
    the review. Scoping reviews are often used to map the available
    evidence as preparation for a more extensive review.¬†
-   **Traditional (narrative) literature reviews** are a focused and
    objective analysis of the existing evidence, usually narrower in
    scope than a systematic review. Often, narrative reviews include
    commentary from the researcher, expressing their opinion about the
    topic. This kind of lit review can take 1 to 4 weeks to complete and
    usually only require a single researcher.¬†

‚Äç

![62ea88045f1a0b1b00c4d0c7_iFf_PFtoM_fhkzRj6GLlaY35858EuwtiwU45MgNxPaG2M8zjZUT6geFdavauU1j2cjA_uGLPTc_DzbMqA-\_FZzBCGV1ogxAWyxxYEkIu-yWy9NJ-\_FeGSbTAgsgSI8Y_YrLdZCz2N4HGQh9m5JOxSHc](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62ea88045f1a0b1b00c4d0c7_iFf_PFtoM_fhkzRj6GLlaY35858EuwtiwU45MgNxPaG2M8zjZUT6geFdavauU1j2cjA_uGLPTc_DzbMqA-_FZzBCGV1ogxAWyxxYEkIu-yWy9NJ-_FeGSbTAgsgSI8Y_YrLdZCz2N4HGQh9m5JOxSHc.png)

Types of literature reviews

‚Äç

üí° In the context of UX research---where time and resources are often
limited---you'll typically conduct **scoping** or **traditional**
literature reviews.¬†

‚Äç

## What's the purpose of a literature review, anyway?¬†

Literature reviews are extensive audits of the existing research on a
particular topic---but why are literature reviews important?

‚Äç

As Samantha Silver says in her article for [Key Lime
Interactive](https://info.keylimeinteractive.com/the-value-of-old-school-literature-reviews-for-modern-ux-research):

‚Äç

"Many folks want to roll their eyes at the idea of having to do a 'large
book report,' but this discredits the powerful research methodology that
is the literature review. Spending 6 years in academia prior to my time
in UX research, I have been able to see a tremendous amount of value
(and critical need) for the application of literature reviews in modern
UX research."

‚Äç

The key benefits of lit reviews for UX research include:

-   Minimizing research costs
-   Saving time compared to a form study
-   Quickly getting you up to speed on a particular topic
-   Helping you avoid "rookie mistakes" in follow-up research
-   Showcasing context or highlights gaps in knowledge
-   Justifying or revealing the need for more involved research
-   Improving the overall credibility of future research findings

‚Äç

In other words, literature reviews help you avoid "reinventing the
wheel" when conducting research with limited time and resources,
allowing you to strategically refine, narrow, and kick-start future
projects by building off of what's already known.¬†

‚Äç

üôá Some researchers also value lit reviews as a show of respect for the
researchers who came before them. Unless you're truly blazing a new,
never-before-explored path, any research you conduct will be informed
(and ultimately improved) by drawing on the hard work of others in the
field.

‚Äç

## Examples of literature reviews: What does an effective lit review look like?

Quality standards for lit reviews might vary depending on the type and
context of the review, but in general, a good lit review will be:

-   Well-structured (we'll teach you how to structure a lit review later
    in the chapter)
-   Well-written (use clear and concise language)
-   Unbiased (as much as possible, by calling out areas of controversy)
-   Conducted with reliable and relevant sources

‚Äç

Here are some examples of good literature reviews, both from User
Interviews's internal research team and external researchers.¬†

‚Äç

### User Interviews's Monthly Insights Review

Here at User Interviews, the [User
Research](https://www.userinterviews.com/ux-research-field-guide-chapter/what-is-user-research)
team does a monthly review of our research repository in EnjoyHQ and
puts together a report to identify key trends and insights.¬†

‚Äç

It includes insights like where the majority of our user feedback comes
from:

‚Äç

![may 2022 user feedback report: a graph showing that the majority of
our user feedback comes from Zendesk, the rest from Slack and
email](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62ea88048ac8e48119a3262e_FjMwkx-ksvrhk7fnZ1xhrgqI-3FYfoLLYCwX-U1vF5SMRr-tkf0xIeDV9waZrifBIGWo1xaKPbemzbtcOWEqQJm99SqvkqHv3qIP__IBTNO0k3Mah49OU_gMFX0bPIcTPcZzur3R1zbiwA7miPb6BWU.png)

‚Äç

... the customer segments who provide us with the most feedback:

‚Äç

![may user feedback report showing which customer segments provided us
with the most
feedback](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62ea8805ec692bbf80bac442_gc5FR1pBhgzKQBJHsPdGUhe5TR6cgZMj1HGLSo5-N-OPm9F6Apxqo43a-W_bfEe8u7oQ1eWO5ZWt9BwnSpzSomXT0KMsGhRinFvbzYtmS2HxPS8Op2-2lWbV0pGt_2YU8tEuJ0zLtYMmFKhtR9YarPE.png)

‚Äç

... as well as an overview of themes and patterns in user feedback from
the past month:

‚Äç

![graph showing the themes and patterns in customer
feedback](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62ea880490718c33a4900710_ye9r7oY86cMKyTZGI0clFmOQU1dLj1VHibDaAtGNW_XxsNIHRsZPmRxMlet9_Y-tYcFLVCDUEmhIMR7xMNYqKj4E-oLfmdur5fblnBTA19iE_yrj5d99TwfJJ2n9j8_bTJ8ZpTEENAmd25_qbS2OZn0.png)

‚Äç

The insights from this monthly review are based on our yearly goals and
used to inform team decisions.¬†

‚Äç

### More literature review examples:

-   [**Mail Surveys and Response Rates: A Literature
    Review**](https://www.jstor.org/stable/3151093?searchText=literature%20review&searchUri=%2Faction%2FdoBasicSearch%3FQuery%3Dliterature%2Breview%26so%3Drel&ab_segments=0%2FSYC-6490%2Ftest_segment_3&refreqid=fastly-default%3A219620c29a8d2d30ea0f2016c28cc348)**:**
    This literature review, published in The Journal of Marketing
    Research, looked at empirical studies concerned with [increasing
    response
    rates](https://www.userinterviews.com/blog/improve-your-research-participant-response-rate-with-better-invites)
    to mail surveys. It found that many techniques used for improving
    response rates have little supporting evidence, and that the only
    techniques with evidence for being consistently effective are
    follow-up letters and monetary incentives.¬†
-   [**Psychosocial Work Environment and Mental Health---A Meta-Analytic
    Review**](https://www.jstor.org/stable/40967597?searchText=literature%20review&searchUri=%2Faction%2FdoBasicSearch%3FQuery%3Dliterature%2Breview%26so%3Drel&ab_segments=0%2FSYC-6490%2Ftest_segment_3&refreqid=fastly-default%3A219620c29a8d2d30ea0f2016c28cc348)**:**
    This systematic literature review, published in The Scandinavian
    Journal of Work, Environment & Health, looked at papers concerning
    the relationship between work stressors and mental health. It found
    that high psychological demands, little freedom for decision-making,
    low social support, high job insecurity, and an imbalance between
    effort and reward are all risk factors for common mental disorders.¬†
-   [**Assistive Technology as a Self-Management Tool for Prompting
    Students with Intellectual Disabilities to Initiate and Complete
    Daily Tasks: A Literature
    Review**](https://www.jstor.org/stable/23879621?searchText=literature%20review&searchUri=%2Faction%2FdoBasicSearch%3FQuery%3Dliterature%2Breview%26so%3Drel&ab_segments=0%2FSYC-6490%2Ftest_segment_3&refreqid=fastly-default%3A219620c29a8d2d30ea0f2016c28cc348)**:**
    This review, published in Education and Training in Developmental
    Disabilities, looked at papers concerning technology to help those
    with intellectual disabilities to initiate and complete tasks on
    their own. It found that assistive technology is an effective
    self-management tool for people with intellectual disabilities.¬†

‚Äç

## Should you conduct lit reviews before or after a primary research study?

Mostly before---but you might choose to do both, if you're doing
research regularly.¬†

‚Äç

Literature reviews can be performed any time you want to quickly get up
to speed on a particular topic, and many researchers use lit reviews as
a first step in developing their overall [UX research
strategy](https://www.userinterviews.com/blog/the-ultimate-guide-to-ux-research-strategy).
As more research is added to the literature over time, you might want to
conduct follow-up lit reviews to stay up to date.¬†

‚Äç

Sometimes, they're included as part of a larger research paper, such as
[ethnographies](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography).
They're ideal for those times when you:¬†

-   Aren't sure which questions you need to ask
-   Don't know if your questions warrant a full study¬†
-   Want to gain a better understanding of the 'known knowns' and 'known
    unknowns' before you dig deeper

‚Äç

Here's a helpful graphic demonstrating where lit reviews fit into the
[user research
process](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-process-fundamentals),
created by [UX Researcher Emile
Natasha](https://medium.com/@eugeniaemile/reasons-why-i-need-literature-review-to-do-ux-research-6191e117626c):

‚Äç

![workflow of ux research process, showing that lit reviews fall under
the planning stage and inform your
hypothesis](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62ea880401188b496e39136f_-UVYq48OrknvAxkXd76_IdRaSIO3PPgOi4Fj18kM_FcwbGjAYgdG4HDngkTRr78okhEpA4P_rY_QFB4sWI9zCg5mgngbgFyi5GBt8vscniBQZRTaQISb7IAegv7oi99fcG3fZ7aC6CAxvYH2CVlNWS0.png)

Lit Reviews in the UX¬†Research Process, by [Emile
Natasha](https://medium.com/@eugeniaemile/reasons-why-i-need-literature-review-to-do-ux-research-6191e117626c)

‚Äç

Regardless of the circumstances, a lit review will illuminate gaps in
existing knowledge about a topic. Expect a lit review to inspire more
questions than answers, and to bring your needs for future research into
focus.¬†

‚Äç

## How to conduct (and write) a good literature review¬†

### 1. Choose the topic and research question.¬†

If you've been reading this Field Guide from the beginning, you're
already familiar with the process of [planning for UX
research](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research).¬†

‚Äç

Just like every other research method (and really, most big decisions in
life---like buying a car, getting your master's degree, or taking a
vacation), literature reviews benefit from having [a focused and
intentional
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan).¬†

‚Äç

Before you start your lit review, identify:

-   **The topic you're going to focus on** (e.g. Managerial habits in
    enterprise companies)
-   **The** [**research
    questions**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-questions)
    **you're hoping to answer** (e.g. How do managers in enterprise
    companies currently approach their roles and responsibilities? What
    are their primary goals and challenges? Which managerial techniques
    are most effective? What tools do they use to do their jobs?)

‚Äç

Try to keep your topic and research question broad enough to allow for a
thorough,
[discovery](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)-based
review of the available resources, but narrow enough that you aren't
overwhelmed by the size and scope of the literature.¬†

‚Äç

### 2. Determine the type and scope of the review.

As we mentioned earlier, UX researchers will typically focus on
**scoping** or **traditional** literature reviews---but you might
consider other types of lit reviews depending on your research questions
and goals.¬†

‚Äç

No matter what type of review you choose, it's important to clearly
delineate the scope before you begin researching: What is the maximum or
minimum number of sources that your review should include? What is the
maximum or minimum amount of time you should spend on collecting and
analyzing those sources?

‚Äç

Defining your scope ahead of time will help you avoid going down a
rabbit hole and wasting time and effort that would be better spent
elsewhere.¬†

‚Äç

#### How long should a literature review be?¬†

As long as it needs to be, and no longer. The exact length will depend
on your topic, audience, and goals---but in the context of UX research,
you probably won't need to write more than a few pages, if that.¬†

‚Äç

### 3. Find internal and external sources.¬†

Once you've set a topic and scope, it's time to search the literature.¬†

‚Äç

Your sources will vary depending on what you're researching, but you may
want to look at:

-   **Internal sources** like customer feedback and [user
    interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
    research repositories, Slack channels, or other company databases.¬†
-   **External sources** like books, social media, customer reviews on
    third-party websites, Google Scholar, JSTOR, Proquest, etc.
-   **Topic-specific sources.** For example, because most of User
    Interviews's work is in the UX space, our VP of User Research,
    [Roberta
    Dombrowski](https://www.userinterviews.com/yearbook-profiles/roberta-dombrowski),
    often refers to blogs like [Nielsen Norman
    Group](http://www.nngroup.com), [dscout's People
    Nerds](https://dscout.com/people-nerds), [Mind the
    Product](https://www.mindtheproduct.com/), or [UX
    Booth](https://www.uxbooth.com/).¬†

‚Äç

Use a spreadsheet to keep track of your sources and make note of
important sections and terms that you want to come back to during the
analysis stage.¬†

‚Äç

Be sure to record:

-   The author, date, and type of study
-   The research questions
-   The methods used (including mixed methods, [qualitative, or
    quantitative](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods))
-   The results and conclusions made by the authors
-   Any weaknesses or areas of controversy

‚Äç

Julie Dobre, UX Researcher and Strategist at ICF, recommends keeping
track of sources you choose not to use as well, in [her article for
UXBooth](https://www.uxbooth.com/articles/quick-lit-reviews-reduce-ux-research-time-and-supercharge-your-design/):¬†

‚Äç

"If a source lacks valuable information, copy the URL to the bottom of
your table and provide a short sentence to summarize the article for
yourself and why you did not extract information from it. Provide a code
like 'No Info' so you can sort them out. This will allow you to capture
the full breadth of your research effort. It may also prove useful if,
as your research develops, you realize that you may have overlooked
something valuable and you want to reread a source, or if a source has
very basic information that you later realize may be valuable to junior
team members. It is also a useful way to keep yourself on task."

‚Äç

üí° **Pro tip:** When you find a high-quality source, look through its
cited references for additional relevant sources.¬†¬†

‚Äç

### 4. Record and analyze the data from all sources.

Once you've collected a healthy body of literature on your chosen topic,
you can begin exploring the relationships between each source and
identifying key insights and conclusions.

‚Äç

Look for:

-   **Trends and patterns** in the
    [methods](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
    used, conclusions drawn, recency of sources, or other key components
    of each study.
-   **Themes** in the types of questions or ideas that crop up
    throughout the literature.
-   **Debates, conflicts, or disagreements** between sources.¬†
-   **Gaps, weaknesses, or surprises** that need to be addressed.¬†

‚Äç

For more helpful information and tips about analysis, head to the
[Analysis and Synthesis
module](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
of this Field Guide.¬†¬†

‚Äç

### 5. Write a summary of your findings.

With your sources collected, cited, and scoured for insights, you're
ready to write up your report. The process for writing literature
reviews is similar to that of [writing
reports](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)
for any kind of study.¬†

‚Äç

#### **Here's how to write a literature review:**

The typical literature review outline includes an introduction, a
summary of the sources and insights, a discussion of weaknesses, and
recommendations for next steps.¬†

-   **Introduce the topic and provide context:** Why did you conduct
    this review? What were you hoping to learn? What is and isn't
    included in the review?
-   **Summarize the sources and present common themes:** These themes
    and insights can be organized chronologically, thematically,
    methodologically, or theoretically---however you think makes the
    most sense for your topic and the insights you found.
-   **Identify important gaps or biases:** What are the main limitations
    with the research you reviewed? What questions do you still have?
-   **Outline new questions or areas for future research:** Now that
    you've completed your literature review, what's next? How does the
    information you found influence future decisions?

‚Äç

Looking for a refresher on writing research reports and deliverables?
Check out the [Field Guide Chapter: How to Write Effective Reports and
Presentations](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations).¬†

‚Äç

## Literature reviews for mixed methods and hybrid research

As we mentioned earlier, it's not advisable to use lit reviews as a
substitute for primary research. Although lit reviews are typically
quicker and cheaper than primary research studies, the insights (and the
quality of those insights) are limited to whatever can be found in your
sources.¬†

‚Äç

Instead, we recommend using lit reviews to help you narrow down your
questions for primary research. By understanding which questions have
already been answered and what's still uncertain, you can focus your
resources on [more impactful
research](https://www.userinterviews.com/blog/how-to-track-the-impact-of-ux-research).¬†

‚Äç

## In a nutshell

Literature reviews are not just for academic research---they're useful
and valid for research in a business context, too.¬†

‚Äç

The research community is releasing interesting, relevant, and sometimes
groundbreaking information on a daily basis. You can maximize the impact
of your work by paying attention to and building off the work of your
peers.¬†

‚Äç

So before you dive into a month-long [diary
study](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies),
[A/B
test](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing),
or [continuous feedback
survey](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys),
start with a literature review. You just might discover something that
surprises you.¬†

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/user-interviews)

Next:

User Interviews

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

\>

[User Interviews](/ux-research-field-guide-chapter/user-interviews)

# User Interviews

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

User interviews are one of the most flexible and adaptable
methods---they are powerful tools for uncovering new opportunities and
generating ideas during the discovery phase, complement both qualitative
and quantitative evaluative methods, and can be used in conjunction with
ongoing listening continuous methods to keep up with changing customer
needs and opinions over time.¬†

¬†

In case it wasn't obvious from our name, we're big fans of this method.

### In this chapter:

-   What are user interviews?
-   When to choose interviews
-   Planning and conducting user interviews
-   Writing an effective interview guide
-   Recruiting participants for user interviews
-   Moderating user interviews
-   Recording insights and taking great notes
-   Analyzing user interview data
-   Tools and logistics
-   Combining interviews with other methods¬†

## What are user interviews?

User interviews (also called in-depth interviews) are 30- to 60-minute
conversations with a single participant, in which a researcher asks
questions about a topic of interest to gain a deeper understanding of
participants' their attitudes, beliefs, desires and experiences.

Because interviews are live (either online or in-person), moderators are
able to pick up on and respond to verbal and non-verbal cues, ask
followup questions, and probe into topics more deeply. The candid,
interactive nature of interviews often leads to serendipitous nuggets of
insight that is hard to achieve by other methods.

This UX research method is a relatively quick and easy way to collect
qualitative user data, and interviews pair well with just about any
other research method---use them to follow up with usability testers,
understand decisions made during card sorting studies, or flesh out
feedback from ongoing listening surveys.

User interviews:

-   Are moderated (live)
-   Can be structured or semi-structured
-   Generate rich, qualitative user data
-   Can produce both attitudinal and behavioral insights

### Types of user interviews

‚Äç

#### Generative interviews

**Generative interviews** are the most common type of user
interview---they are the best way to answer the question "what don't I
know?".

Like other generative or discovery methods, generative interviews are
used early in the design and development process when you're looking for
opportunities and ideas.¬†

But these are not simply brainstorming sessions---interviews are
structured conversations used to gather the information you need to
answer clear, specific, and actionable research questions (even if, at
this stage, your research questions are fairly broad).

Note that this chapter is primarily focused on generative interviews.

#### Contextual interviews

**Contextual interviews** (or **contextual inquiry**) are a special type
of semi-structured interview that gives researchers insight into the
context of use. These interviews take place in a user's environment (in
context), which can make them feel more natural than interviews
conducted in a lab or a staged virtual setting.

During contextual interviews, researchers ask participants questions
while they complete tasks. This could involve shadowing a participant in
their physical workplace, or moderating a usability testing session and
asking questions as users interact with a site.

#### Continuous interviews

**Continuous interviews** are interviews you do on a regular basis by
setting aside a chunk of time each week to connect with users. The goal
of continuous interviewing is to keep you in touch with the people that
matter most---[your
customers](https://www.userinterviews.com/blog/the-ultimate-guide-to-doing-kickass-customer-interviews).¬†

Continuous interviews are especially important for people who may not
have regular research contact with users. They can also be used to keep
teams in touch with users in between research projects. [Teresa
Torres](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk),
who teaches a course on continuous interviewing, explains:

The value of continuous interviewing is really just being reminded on a
regular basis that our customers will always know their world better
than we possibly could.

One thing to keep in mind is that the feedback you get from continuous
interviewing may be a bit more scattered than feedback from other, more
focused research.

‚Äç

Our [Continuous User Interview Launch
Kit](https://www.userinterviews.com/launch-kit/continuous-user-interview)
includes an analysis template that will help keep track of the notes you
take during sessions and scan through them quickly to find emerging
themes. These themes can help influence more focused research, or serve
to add color to your existing roadmap.

### What decisions do user interviews enable?

User interviews are used to inform vision decisions, allowing you to get
clarity on a participant\'s big-picture beliefs and philosophies in
order to determine a potential company, product, or service direction.

They can also be used to inform strategic decisions, allowing you to
understand participants\' current behaviors, expectations, or
frustrations to determine a plan for a product or service.

### What are the outputs?

Interviews generate a large amount of qualitative data, including
detailed notes, transcripts, and videos. All of this data then needs to
be synthesized into artifacts such as: personas, scenarios, thinking
styles, or journey maps.

Because interviews capture the voice of the participant, they often
provide powerful first-hand testimonials that support research-backed
recommendations for improvement or change.

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

## When to choose interviews

User interviews, as we mentioned, can be used throughout the product
development cycle---from ideation to testing to post-launch listening.¬†

**Interviews are used:¬†**

-   During initial discovery (before you have a product to test) to
    uncover broad patterns and themes relating to people's¬† experiences,
    problems, behavior, and opinions.
-   To test concepts and early ideas for possible solutions, before
    heavy design work gets underway.
-   As a followup to usability tests or other evaluative methods, when
    it's important for you to have users articulate their decisions or
    experiences.
-   After a product has launched, as a means of understanding evolving
    customer needs and expectations.

### Why are user interviews so important?

We've mentioned contextual and continuous interviews, and have also
explained how interviews can be used alongside methods during the
testing and validation phase.¬†

But the truth is user interviews really shine during discovery, when you
still don't really know exactly the problem you're trying to solve or
how. You might have a general idea about what a problem is, in which
case generative interviews can help you refine your understanding. Or,
you may simply want to develop a product in a given space, and you need
to generate ideas about what problems exist before you can imagine their
solutions.¬†

Generative interviews are a fantastic method for uncovering
opportunities for innovation and illuminating solutions to problems. And
what's more, this method allows you to build up a nice bed of rich
information about your user base from which you can pull ideas---both
for brand new project builds or improvements to existing products.

### Limitations and potential pitfalls of user interviews

Interviews, like every user research method, have their limitations and
drawbacks. None of the potential pitfalls are big enough to outweigh the
benefits, and most can be offset with mindful research design and
planning.

Some things to be aware of:

-   Interview data is largely self-reported. Although researchers can
    record observations about nonverbal responses and make inferences,
    the bulk of interview data comes straight from the participants'
    mouths. And participants, like all humans, are flawed and prone to
    misremember facts and experiences.¬†
-   Participants may leave out important information because they take
    it for granted that the interviewer already knows or is not
    interested in the minor details.¬†
-   Not every participant will share the same amount of information or
    be as forthcoming about their thoughts, feelings, and personal
    experiences. Some people are just more private or shy than others.
-   Interviewing takes practice and skill. From writing effective,
    non-leading interview questions to moderating (but not leading) a
    conversation to qualitative analysis---a lot rests on the abilities
    and preparedness of the researcher

User interviews can help you answer just about any qualitative research
question you can think of. Qualitative means it\'s answered with words,
not numbers. So while user interviews can\'t tell you how many people
bought your competitor's product, they can help you understand why
people made that purchasing decision.¬†

Typically, user interviews are just one piece of your research puzzle.
For most projects, you'll want to supplement interview data with
quantitative methods like product analytics, usability tests, or
surveys.

## How to plan and conduct user interviews

We covered how to set research goals and come up with effective research
questions in depth in the [Planning UX Research
module](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)---definitely
give the chapters in that module a read if you're struggling to clarify
your goals or uncover stakeholder needs.¬†Very briefly...

### Define your research goals

**Talk to your stakeholders.** Conduct stakeholder interviews to find
out what it is they want to learn, what decisions they need to make, and
what they hope to achieve. You won't be able to satisfy every
stakeholder wish in one research project---look for the core, concrete
goals that can practically be answered through UX research.

**Ask yourself** **(and your stakeholders) the following questions**:

1.  What do I want to know?¬†
2.  How will I know when I've learned it?¬†
3.  What company goals will this work support?¬†
4.  What decisions will this research enable?¬†

From there, you should be able to answer the key question: What do I
want to learn through user research?

User interviews, like all the research methods discussed in this Field
Guide, should start with a research question that is **specific** enough
to know when you\'ve found the answer, **actionable** in that you can do
something about it, or **practical** in that you can reasonably answer
it within the scope of a research project.¬†

For example, you can\'t reasonably answer \"Why don\'t people buy my
product?\" There could be many different reasons people aren\'t buying
your product, and covering them all in one study wouldn\'t be practical
or give you actionable results.

‚Äç

A better question may be, \"Does my pricing page accurately answer my
users questions?\", or \"Why do people in my target market choose X
competitor over my product?\".¬†

Both of these questions could be answered with user interviews, and your
team would have a clear path to action once the study was complete.

**Get a copy of our** [**UX research plan
template**](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)**.**

## How to write an interview guide

Next, prepare a set of questions to ask participants. Having a list of
questions helps keep the conversation flowing and serves as a good
framework for notetaking and organizing data during and after the
interview.

Some of these interview questions should spring directly from your core
research question.¬†

For example, if you want to learn how people research travel
destinations, you could plan to say "Tell me about your last vacation"
followed by the question "What prompted you to choose X as a
destination?"

But remember: This is an interview, not an interrogation---a good
moderator guide should also incorporate get-to-know-you questions, and
leave room for spontaneous, open-ended responses and followup
questions.¬†

### Tips for writing user interview questions

-   **Ask questions that focus on past behavior vs. hypothetical
    scenarios.** "What would you do if..." can be a useful question, but
    in many cases, it's not as useful as "How did you handle it
    when...". It's a golden rule in job interviews, too: past behavior
    is the best indication of future behavior. So begin in real life
    scenarios where the subject has prior experience.
-   **Ask open-ended questions.** Give your participants the opportunity
    to elaborate on their answers and take the conversation in new and
    interesting directions. Questions like "What is your opinion on
    Neoclassical architecture?" are much more likely to produce
    unexpected insights than closed questions such as "Do you agree that
    people built far too many dang columns between the late 18th-mid
    20th century?" (That is also a leading question, which makes it
    doubly bad.)¬†
-   **Mitigate your own biases and presumptions.** Generative interviews
    can be glorious in how they meander and illuminate areas you might
    not have even considered. Still, generative interviews can suffer
    from interviewer assumptions or bias. To keep yourself accountable
    for your own presumptions and preconceived ideas, try to keep
    questions open-ended and aligned around words like how, why, and
    what. This will guide your interviewee toward their own answers,
    rather than leading or prompting them toward the areas where you
    want or expect them to go.
-   **Be willing to have your assumptions challenged.** It helps to come
    in with some idea of what you think is true, but generative
    interviews are only useful if you allow ideas to be generated. So
    don't be overly attached to the rightness or wrongness of your
    preconceptions.¬†
-   **Create a list of possible followup questions.** Anticipate
    different responses to your key questions, and make a list of
    possible followup questions that will help you dig deeper and steer
    the conversation down interesting avenues. It can also be useful to
    think about how you'd keep the conversation flowing if a participant
    didn't have an answer to your question at all.
-   **Be prepared for different conversation styles and personalities.**
    Some participants will talk your ear off---others might need to be
    asked several followup questions to elicit the same amount of
    information. Identify your most important interview questions (the
    must haves) to keep talkative participants focused. To account for
    the reticent types, make sure you've prepared more questions than
    you think you'll have time to ask.
-   **Avoid leading questions.** Leading questions prime the participant
    to answer in a certain way by suggesting a 'correct' response. A
    (glaringly, obviously) leading question would be something like "Why
    do you love sugary food so much?" Less obviously, "What is your
    biggest dietary challenge?" could also be considered leading
    question as it assumes a negative relationship with food, which may
    not be true for all participants.

### Moderator guide vs. script

We purposely this set of questions a 'discussion guide' or 'moderator
guide', rather than a 'script'.

That's because although its good to prepare a loose questionnaire to
guide the interview, you should feel free to deviate from it when it
makes sense. You don't want the interview to feel stilted---you want it
to flow, and you want your interviewee comfortable. If the interview is
taking a useful turn, follow it where it wants to go.¬†

For discovery interviews, where the scope of your inquiry might be quite
broad, consider a list of topics in lieu of a questionnaire.¬†

If you identify a handful (3-6) of larger topics you'd like to cover,
and identify a handful of subtopic, you've got yourself a nice loose
guideline for an interview that won't be overly confining.¬†

For example, say your area of interest is snacks (because who isn't
interested in snacks?). You might come up with larger topics like
cookies, popcorn, charcuterie, and healthy snacks. And beneath each main
topic, you might have a few subtopics. In the end, your list of topics
might look like\...

-   Cookies: gooey, crunchy, layered
-   Popcorn: instant, savory, sweet
-   Antipasto: meats, cheeses, olives, nuts
-   Fruits: fresh fruit, dried fruit, pureed fruit

And you can use this list of presumptions as a guideline for
understanding how, why, and what your interviewee looks for in a snack
without locking yourself into a prescribed list of questions.

### Examples of good user interview questions

We put together a list of sample interview questions in [this handy
sheet](https://docs.google.com/document/d/1LSuiFwi30MVl7msbAnB8kZoAf25Zr6jW3Zt4-ug9McI/edit?usp=sharing).
Here are a few examples of different types of interview questions you
can ask:

**Getting-to-know-you questions**

-   Tell me about your role at work
-   What did you do last weekend?

**Digging in questions**

-   When was the last time you did \[activity\]?¬†
-   Tell me about how you currently solve \[problem\].

**Product/market fit questions**

-   Have you used any other tools in the past to solve \[problem\]?
-   What\'s your team\'s current budget for \[activity\]?

**Usability testing questions**

-   Please describe your experience with \[tool\].
-   If you were looking for \[information\] where would you expect to
    find it?

[**Customer
interview**](https://www.userinterviews.com/blog/the-ultimate-guide-to-doing-kickass-customer-interviews)
**questions**

-   Tell me about how you and/or your team uses our product.
-   What do you wish our product could do that it can\'t today?

### Sample user interview guide

Below is an example interview script that follows [Teresa Torres's
Continuous Discovery Habits
framework](https://www.amazon.com/Continuous-Discovery-Habits-Discover-Products/dp/1736633309).
This [sample discussion
guide](https://docs.google.com/document/d/1BbcE7nn5tINAAeIPAYu5aMw-qoc4AOYLanHwZ0-_RHs/edit?usp=sharing)
is based on a fictional study with people who sell their handmade art on
Etsy.

‚Äç

## How to recruit participants for interviews

Researching with humans does, unfortunately, involve some (sometimes
tedious) administrative work---like creating an interview schedule,
collecting signatures, and plenty of emails--- to make sure everything
runs smoothly.¬†

Thankfully, there are ways to streamline the process, which we've shared
below. But first, it's time to:

### Decide who to interview

Take another look at your research question and ask yourself: Who is
likely to have the answers I'm looking for? Do the same with your most
important interview questions.

Write down the qualities you think that person---this knowledgeable
answer-giver you're picturing---is likely to have. This list is the
beginning of your participant profile, which you will use to write your
[**screener
survey**](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys).

We say beginning, because it's likely that your list is too long, the
profile too narrow. Really scrutinize each of the qualities you wrote
down---does a participant have to be vegetarian or Black or married or
live in Southern California in order to provide valuable insights to
your question?¬†

Unless it's truly necessary for a participant to fall within a certain
demographic, you can probably strike that criteria from your list. When
we filter by demographics, we're often making assumptions about
relationships between people's backgrounds and their behaviors---and
doing so risks biasing your research and missing out on diverse
perspectives.

We wrote an entire module about [finding and recruiting the right
participants](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants),
creating [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys),
and [UX research
incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)---which
is why we aren't diving deep into the details here.¬†

Read the chapters on [UX Research
Recruiting](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
for a step-by-step guide to user research recruitment, plus in-depth
advice on filtering participants and calculating rewards.

### How many people do you need to interview?

There is something of an art to deciding how many people to interview.
In general, the more people you talk to, the more information you will
get---but only up to a point. The amount of fresh insights you'll glean
on a topic diminishes with each subsequent interview. Eventually (often
sooner than you think), the responses will start to get repetitive.¬†

That's why it's good to start small. **For most interview studies, you
only need 5 participants.**

So start by recruiting 5 people, since you are almost certain to need
that many. You can always recruit more folks later based on your needs:¬†

-   Consider how much information you need; the more complex the
    situation you are investigating, and the less you know about it to
    begin with, the more people you will need to talk to. Depending on
    complexity, you might plan to recruit 6 to 10 participants.
-   Consider important subgroups in your pool of potential interviewees
    (for example, if you need to talk to members of multiple age
    groups). In that case, you might want to recruit 3-5 people from
    each subgroup, so multiply accordingly.
-   If you have not conducted open-ended interviews before, or have not
    done any recently, add two or three extra interviews to your list
    for practice---if everything goes well, you'll even have some extra
    data.¬†

Remember that when you're doing discovery research, it's good to keep an
open mind and have a flexible research plan. You can plan and budget for
any number of participants, but that doesn't mean you have to recruit
them all at once. Generative interviews can sometimes generate ideas
about who you should interview next. So if one interview leads you down
an unexpected (but relevant path), follow it.¬†

Recruiting participants for interviews can be fast (really)---which
means you can respond to new lines of inquiry as they crop up.¬†

### Sign up and start recruiting today---your first 3 participants are free!

[Start talking to users](https://www.userinterviews.com/recruit)

### Create an interviewing schedule

User interviews can be as long or as short as you need them to be, but
we typically find that 30-45 minutes is the right amount of time for
each session. That gives you enough time to spend a few minutes at the
beginning warming up and getting comfortable, and to wrap up. It\'s also
short enough that interviews don't feel like an unmanageable time
commitment from you or the participant.

Of course, if you feel like doing a 15-minute, 20-minute, or even
hour-long user interview, that\'s perfectly ok too!¬†

### Obtain consent

Don't collect data without permission. Before the day of the interview
and at the beginning of the session, clearly explain why you're
conducting the interview, how the data will be used, and how it will be
stored. Get every participants' informed consent in writing---these
forms, and your verbal explanation, should be in plain,
easy-to-understand language.

And remember: Your interviews may involve collecting sensitive or
personal information, in which case you will have to take steps to
either safeguard or destroy all such information.¬†

### Communicate with participants

To help your participants remember the interview date and get to the
right place at the right time, send them an email with the following key
pieces of information:

-   Time and date---if doing remote research, make sure you give the
    time and date in your participant's time zone.
-   Location---include a map and directions if the test is in person, or
    a link to a video call and instructions for joining.
-   Research topic---don't give too much information away, but do remind
    users what the research will be about.

Plan to follow up multiple times for interviews scheduled a week or more
in advance. And when conducting remote interviews, never assume that a
participant has or knows how to use a platform---give them clear
instructions on how to join the call in the emails leading up to the
interview.

**Read more about scheduling and communicating with participants in**
[**this Field Guide
chapter**](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)**.¬†**

##### Tips for conducting [remote user interviews](https://www.userinterviews.com/blog/tools-for-remote-user-interviews):

###### ‚Ä¢ Send participants instructions on how to join ahead of time, especially if they'll need to download software to participate. ‚Äç ‚Ä¢ If you don't get confirmation from a participant, send them a reminder and include that software/dial in information again. This will save you time and heartache! Product plug: you can easily do this through bulk messaging in User Interviews.¬† ‚Äç ‚Ä¢ If you're showing a prototype or doing a usability test, test the test first. Ask a colleague to run through it with you or, at the very least, trial it yourself. ‚Äç ‚Ä¢ Be kind and patient, especially with folks who may be stressed during this time and/or unfamiliar with the tools you're using to conduct your interviews. ‚Äç ‚Ä¢ Maintain eye contact. Get a notetaker and/or record and transcribe the interview so you can focus on your participant, not your keyboard.¬†

‚Äç

## How to moderate a user interview

It's here: Interview day! Kicking off a user interview study is always a
bit nerve-wracking---but a little practice and preparation go a long
way. Whether this is your first user interview or your 100th, we promise
you'll get into the groove.

### Testing, testing, 1-2-3

To make sure everything goes off without a hitch, always test your tech.
Do a test run of the software you'll be using, make sure it\'s
up-to-date, triple-check your internet connection, and charge your
devices.

We recommend clearing your workspace as much as possible to help you
focus on the interviewee. Tidy up your desk, close some of those browser
tabs, and make sure any materials you'll be asking participants to
interact with or respond to---files, images, websites, a physical
prototype, etc---are organized and close at hand.

Once you have everything in order, it's time to conduct your interview!

### Be friendly, personable, professional.¬†

Begin by introducing yourself. Briefly explain the reason for the
interview and how long you expect it to take---your interviewee may
already know all of this from your prior communications, but always
recap on the day itself.¬†

Make the participant feel comfortable. Create a rapport, assure them
that there are no right or wrong answers, and get them warmed up with
some get-to-know-you small talk. Remember, this is about establishing
trust, not becoming BFFs---focus on making sure they feel safe and
seen.¬†

Talk slowly. Pause. Ask them if they have any questions of their own
before you begin.

### Start with the easy, general questions¬†

Start with questions that are easy to answer and contain no judgements
or assumptions. Work toward more specific questions gradually, and save
deeper probing about personal details and behaviors for later in the
interview, once the participant has started to open up and feel at ease.

For instance, if you are interviewing [public school teachers who have
to purchase classroom
supplies](https://www.nytimes.com/2018/05/16/us/teachers-school-supplies.html)
with their own money, you might work toward the specifics by asking
them:

1.  Tell me about \[town/city in which they teach.
2.  Can you describe your school for me?
3.  What does your classroom look like?
4.  Can you tell me about the decorations in your classroom? Where did
    those come from?
5.  What about supplies like pencils, markets, craft paper?
6.  For the items that you purchased, with your own funds, what made you
    decide to buy those items in particular?

### Ask clarifying followup questions

[Play
dumb.](https://www.userinterviews.com/blog/7-tips-for-better-user-interviews)
Don't be shy about asking questions that seem obvious, or that you think
you know the answer to. For instance, if someone says "I really hate
wine" you might ask them "what do you mean by that?" They might then go
on to say "I mean I don't like that it gives me headaches. I actually
used to love drinking red wine with dinner, but it's not worth the
agonizing hangovers."¬†

In another example, if someone from Boston is talking about their habits
and says "I go to Harvard often," ask them to clarify if they mean
Harvard Square, the metro stop, or the university---or something else
entirely.¬†

You can also ask people to perform tasks by sharing their screen, or by
describing the action: "Can you show/describe to me how you \[X\]?"¬†

User Researcher [Nikki
Anderson](https://uxdesign.cc/how-to-write-a-generative-interview-guide-270faa46dbbc)
shared that she frames interview questions using the Taxonomy of
Cognitive Domain, which explains how certain verbs can trigger
particular thought processes:

### Get comfortable with awkward silences

Don't rush the participant. Once they finish speaking, let their
response hang in the air for several seconds longer than feels
comfortable (try counting to 5 in your head before replying).
Eventually, many participants will fill that silence themselves by
expanding on their response. If they don't, you know you've given them
enough time to answer thoroughly and can move on.¬†

### Keep things on track

Some people have a lot to say. Digressions or apparently excessive
storytelling can be great opportunities to learn things you didn\'t
think to ask about, and allowing some digression is good for rapport,
but be prepared to diplomatically pivot back on topic when necessary. Do
not let an interview go into overtime, since your interviewee has places
to be---as do you. You can always schedule a follow-up if need be.

### Wrap it up

As you approach the end of a session, preface your final questions with
a statement like"I just have one more question before we wrap up," or
"To wind things down, I have just one or two more questions." This will
make the end more gentle, especially if you have someone really pouring
their heart out.

Make sure to reserve time at the end of the interview to sincerely thank
your participants for their time, vulnerability, and contribution to
your project. Before you close the book, ask participants if they have
any questions or anything else to add ("Is there anything I didn't ask
about that you think I should have?").

[UX Researcher St√©phanie Walter
says](https://stephaniewalter.design/blog/a-cheatsheet-for-user-interview-and-follow-ups-questions/)
of this final question:

"Most of the people will say no. So I wait. Then they think a little bit
and actually have things to add. So here again, don't underestimate the
power of silence, don't turn the recorder off. A lot of people will give
you interesting feedback once the interview is "finished".

## How to record insights and take great notes

We recommend bringing someone else on your team along to [take notes
during the interview
session](https://www.userinterviews.com/blog/why-you-really-need-a-notetaker-for-moderated-research-sessions)
so you can focus on the conversation and stay attuned to nonverbal cues
and opportunities for insightful follow up questions. This is especially
true if you're conducting interviews in-person, but even recorded remote
interviews can benefit from having a skilled notetaker in the copilot
seat.

And even if you're relying on recordings, it's always a good idea to
take time after a session to write down thoughts and impressions and add
those notes to the transcripts.¬†

Note taking can be descriptive---describing something you saw or
heard--- or evaluative---making a judgement or inference based on
something you saw or heard. If you can, include timestamps with your
notes for context.

You can take notes with pen and paper, in a whiteboard tool like Miro,
with a dedicated research tool, spreadsheets---whatever works.¬†

In our [User Interview Launch
Kit](https://www.userinterviews.com/launch-kit/user-interview), we've
included a Google Sheets note-taking template that makes it easy to take
quick and organized notes during an interview session. It also makes it
easy to pull out specific answers and tidbits from each interview.¬†

‚Äç

**üöÄ Get the** [**User Interview Launch
Kit.**](https://www.userinterviews.com/launch-kit/user-interview)

And whenever possible, record your interviews. Not only will
[transcription
tools](https://www.userinterviews.com/blog/user-research-recordings-analysis)
make your life a whole lot easier in the next step, but you'll be able
to pull out impactful audio or video snippets to share with
stakeholders. Just be sure that you notify the participant before
recording begins and obtain their consent.

### The User Interview Launch Kit includes everything you need to launch a study.

[Get the Launch
Kit](https://www.userinterviews.com/launch-kit/user-interview)

## How to analyze user interview data

Transcriptions and audio/video recordings are powerful tools for
capturing and sharing verbatim records of the sessions, but it's up to
you, as the researcher, to make sense of those records.

You can save yourself a lot of work at the end of a project by forming
good note taking habits and transcribing and tagging data as you go.

For every interview:

-   Transcribe audio and video recordings
-   Convert shorthand notes into full, clear sentences
-   Organize and contextualize any notes that were jotted down¬†
-   Use **qualitative coding** to tag and categorize your data

Some study designs even call for giving interviewees a chance to review
the transcripts, notes, and initial analysis, in case they have any
corrections or retractions. Place all your records, including copies of
the recordings or field notes and any amendments offered by the
interviewee, together for easy later retrieval.

### Synthesize and organize insights

It is easy to get lost in the sheer amount of information that
qualitative methods like user interviews can generate. Keep your
analysis focused by answering your research questions first and
foremost. Don't ask the data questions if you don't have a plan or use
for the answers. (But that doesn't mean you can't revisit the data later
and analyze it with a different research question in mind! Properly
tagged and stored, interview data is a rich edition to your research
repository.)

For most interview analysis and synthesis, **Google Sheets** (or your
preferred spreadsheet tool) is all you need. We also recommend using a
tool like **Miro**, **MURAL**, or **Figjam** to organize your notes and
make sense of emerging themes in the data.

Roberta Dombrowski, our VP of User Research, typically conducts
interview analysis in two stages: first looking at each session in
isolation, and then looking for patterns across interviews.¬†

### Share snippets and insights¬†

User interviews produce audio and video recordings that are full of
rich, first-person accounts of the user experience. Include audio/video
clips in your findings to bring a human voice/face to the data. If
you're sharing interview snippets as you go, be sure your stakeholders
understand that the clips don't necessarily reflect trends across
participants (since you haven't done the final analysis).¬†

Mind maps, word clouds, and storyboards are other effective ways to
share interview data with stakeholders who don't have the time or
patience to mine through spreadsheets or large data sets.

##### **How we synthesize user interview data at User Interviews**

###### Here\'s how Roberta, VP of User Research at User Interviews [analyzes and shares interviews](https://www.userinterviews.com/blog/ux-research-presentations-reports-templates-examples):

###### ‚Ä¢ After each user interview, Roberta create a snapshot of the interview in Miro.¬† ‚Äç ‚Ä¢ She shares the snapshot and key takeaways in a project Slack channel to give stakeholders visibility as the study progresses. ‚Äç ‚Ä¢ After all the interviews have wrapped up, Roberta does a "final synthesis" using the takeaways she put together along the way.¬† ‚Äç ‚Ä¢ This synthesis can be shared with stakeholders (and the wider company) as a slide deck, a written summary, or both.¬†

## UX interview tools and logistics

One of the reasons user interviews are such a popular method is that
they are economical. You don't need a lot of time, budget, or special
tools to conduct successful interviews.¬†

To conduct user interviews, whether in-person or remotely, you'll need:

#### Research recruiting tools

[**User Interviews**](https://www.userinterviews.com/recruit) has a pool
of [over 700,000 vetted
participants](https://www.userinterviews.com/recruit?source=navbarRecruitResearcher)
and customizable filters to help you find exactly the people you're
looking for. You typically only need 5 participants to start with---and
when you sign up, your [first three
participants](https://www.userinterviews.com/recruit) are on us.¬†

#### Video conferencing tools or a quiet venue

Next, you'll need a way to talk to people. For in-person interviews,
this means a venue that allows for quiet, private conversation. This
could be your office, their office, a lab, a rented workspace, etc. Be
sure to factor travel expenses and refreshments into the cost of your
budget for in-person interviews.

Remote user interviews are simpler---you and your participant will just
need a video conferencing link and a computer or smartphone. Tools like
**Zoom**, **Microsoft Teams**, and **Google Meet** have become so
ubiquitous that most (though not all!) users will feel comfortable using
these platforms for a call. Even still, try to choose software that will
be familiar to people and always provide clear, step-by-step
instructions ahead of time.¬†

#### Tools for recording sessions and data

If you're using a tool like Zoom to conduct your interview, recording
the session is simple---and you can easily download a transcript of the
conversation, which you can then use for analysis.¬†

To record in-person interviews, you may be able to get by with a
smartphone, or you might need special audio/video equipment. Always
test-drive your setup ahead of time to make sure the sound is clear and
(if applicable) the video offers an unobstructed view of the
participant.¬†

During the interview, you'll need a tool for taking notes.¬† A good
old-fashioned notepad and pen can work but remember you'll need to
transcribe your notes later for analysis. We recommend that you:

-   Have a team member sit in and record observations and participant
    responses in a word document or spreadsheet (like the one in the
    [User Interview Launch
    Kit](https://www.userinterviews.com/launch-kit/user-interview))
-   And/or a tool like [**Grain**](https://grain.co),
    [**Otter.ai**](https://otter.ai), or [**Perfect
    Recall**](https://www.perfectrecall.app) that create transcriptions,
    enable contextual notetaking, and let you highlight important
    snippets¬†

#### Qualitative research analysis tools

Finally, you'll need a way to analyze your data. If you're just getting
started with user research, you won't need anything fancier than a
spreadsheet (like the one in the [User Interview Launch
Kit](https://www.userinterviews.com/launch-kit/user-interview)) and
maybe a whiteboard tool like
[**Miro**](https://www.userinterviews.com/blog/collaborative-ux-research-miro)
for organizing and synthesizing data.¬†

If you're planning to conduct a lot of in-depth interviews, you may want
to invest in a research repository tool that offers built-in analysis
such as
[**Aurelius**](https://www.aureliuslab.com/user-research-synthesis-and-analysis),
[**Dovetail**](https://dovetailapp.com/features/user-research-data-analysis/)
, or [**Optimal
Workshop**](https://www.optimalworkshop.com/reframer/)**.**

**üîß Read more:** [**Your Remote User Interview
Toolkit**](https://www.userinterviews.com/blog/tools-for-remote-user-interviews)

## Hybrid research: Combining interviews with other methods¬†

Interviews are [like the
capybaras](https://www.boredpanda.com/capybara-unusual-animal-friendship/)
of user research methods---they play nice with almost everything.

They can be combined with other methods, such as observational field
studies or focus groups. An initial series of interviews can lay the
groundwork for a field study, or an observational field study can
develop insights that are later used in planning an interview series.
Participant-observer studies often include interviews.

The same recruitment methods, tools, and logistical planning---and
sometimes even the same interviewees---can be used in both the
generative and evaluative phases of a project. In the generative stage,
you might pick their brains regarding the pain points of using a certain
product, and later ask them to use the product to determine whether
those problems have been resolved.

## Our favorite user research method

User Interviews (the company) owes a lot to user interviews (the
method). Our founders conducted generative user interviews as part of
the discovery process that led them to found the company. You can read
all about how we went from being a failed startup to raising a \$10M
Series A with (meta) user research in [our origin
story](https://www.userinterviews.com/blog/from-failure-to-a-venture-backed-startup-through-meta-user-research).

‚Äç

But don\'t take our word for it. Get out there, conduct some interviews,
and see for yourself how powerful user insights can be!

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/literature-reviews)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/ethnography)

Next:

Ethnography

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

\>

[Ethnography](/ux-research-field-guide-chapter/ethnography)

# Ethnography

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Margaret Mead, the world-renowned anthropologist, famously said: \"What
people say, what people do, and what people say they do are entirely
different things.\"

‚Äç

We have alarming blind spots when it comes to describing and explaining
our own behavior. In trying to recall what we did or believe we did, our
recollections will often not align with, say, a video of the incident we
tried to describe. And the motivations that drive our behavior aren't
always clear to us, either.¬†

‚Äç

This is largely why ethnography was born. By bringing researchers into
the 'field'---or the real-life environment of the subject---ethnographic
research serves to fill these blind spots to better understand people's
needs.¬†

‚Äç

Although ethnography has its roots in anthropology, ethnographic methods
have been adapted for use in user research and product development,
which is what we'll focus on in this chapter.¬†

### ‚ÄçIn this chapter:

-   What is ethnography?
-   Types and examples of ethnography
-   When to use ethnography in product development
-   How to conduct ethnographic user research
-   Ethnographic tools and logistics
-   Benefits of ethnography in UX research and design

## What is ethnography?

Ethnography is a type of field study in which researchers observe people
in their natural environments in order to gain a more holistic,
contextual understanding of their needs. Unlike [**other types of field
studies**](https://www.userinterviews.com/ux-research-academy-lesson/field-studies),
ethnography requires the researcher to immerse themselves in the
environment they're studying.¬†

‚Äç

In ethnographic field studies, the researcher might become friendly with
their subjects, and work alongside them socially throughout the study.
This is especially useful when the researcher's natural or known
environment is very different from the one they've set out to study.

### Types of ethnography

(Explored in more depth below)

-   Field studies
-   Ethnographic interviews (contextual inquiry)
-   Rapid or mini ethnography
-   [Digital
    ethnography](https://www.userinterviews.com/blog/digital-ethnography-megan-mclean-spotify)

### Ethnography in UX research

In the context of UX design, ethnography is sometimes referred to as
**digital anthropology**, **field research**, or **contextual
inquiry**.¬†

‚Äç

Ethnographic UX research reveals user insights by allowing you to
observe users in the context of their real-life technical and social
environments.

## Benefits of ethnography in UX research and design

The benefits of ethnography in UX research and design include:¬†

-   **Natural, real world settings to observe natural, real world
    behaviors.** An ethnographic approach to research in UX design and
    technology looks at how people relate to tech in their natural
    settings. Through ethnographics, designers are able to learn about
    the daily lives of their potential users and their natural
    tendencies and behavior patterns as they unfold.
-   ‚Äç**Repeated exposure to examples.** In a survey or interview or even
    a focus group, you get to tap user insights on a single occasion (or
    maybe a handful of occasions, but they're isolated and curated).
    Ethnography is ongoing. Research happens continuously throughout the
    length of a study.
-   **Provides context.** Ethnography allows researchers to observe the
    situations and circumstances in which a product will be used. Some
    circumstances are obviously important---for example, how quickly are
    users able to retrieve and open their umbrella when it starts to
    rain?---but there are subtle moments that can provide further
    insights as well. At what point do users reach for their
    umbrella---after the first thunder, or earlier? At what point
    between mist and downpour do people make the hood-to-umbrella
    changeover? And so on.¬†
-   **Really get to know your end user.** Imagine an engineer from
    sparsely-populated Havre, Montana trying to develop a product for
    the light rail system in congested Baltimore, Maryland. Without
    ethnographic research, that engineer likely wouldn't know where to
    begin. By observing the target audience firsthand and developing
    insights based on real behavior, the engineer can build a product
    that's better suited to the needs of future users.¬†
-   **Understand pain points, gaps, and opportunities.** Ethnographic
    studies tap into the social aspect of product design by revealing
    the challenges people deal with as they interact with their
    environments or existing tools. Researchers observe behavioral cues
    to discover where technology might help (or where it could be
    interfering), and it ultimately informs better, more effective
    product design.¬†

P.S.---Need help reaching participants for your next ethnographic study?
We\'ve got you. [**Get 3 free participants for your first study with
User
Interviews**](https://www.userinterviews.com/lp/rorpaccount?promo_code=3FREE).)

### Start talking to users today

[Sign up for free](https://www.userinterviews.com/recruit)

### Examples of ethnographic studies

#### Parking study

A real-life example is [**an ethnographic study on
parking**](http://www.izix.com/pubs/Isaacs-Parking-EPIC2011.pdf) from
Ellen Isaacs and her team at the Palo Alto Research Center. They studied
things like how people searched for parking, how intuitive parking signs
were, and how easy signage was to read as they drove past. They used
their findings to understand what might make parking better and inform
the design of new parking systems.

‚Äç

#### Photocopier study

[**This fun video**](https://www.youtube.com/watch?v=nV0jY5VgymI&t=203s)
shows two world renowned computer scientists trying to understand a
basic copy machine... and failing to do so, which gives insight into how
and where copiers can be made more intuitive.

##### **UXR Case Study: How IDEO Collected Emotional Data Through Ethnography**‚Äç

###### Storytelling is the foundation of human relationships. But often, people are guarded and will hold back their perspectives in a research setting. This phenomenon is known as the [**Hawthorne Effect**](http://www.economist.com/node/12510632): people are likely to change their behavior if they know they are being observed. ‚Äç One way that [IDEO](https://www.ideo.com/), a global design and innovation company, counteracts this challenge---and gets people to open up---is by diverging from traditional Q&A-style interviews. Often, these are situations that necessitate a change in communication dynamics. In these situations, IDEO takes a remixed approach to interception-based recruiting. ‚Äç In 2014, the company partnered with Mercy Corps to provide support to Typhoon Haiyan survivors in the Philippines. The communities most at-risk were low-income, rural, and without banks. The company's goal was to understand how people could rebuild their livelihoods---how to obtain funds to restart businesses that communities had lost. ‚Äç In addition to conducting interviews, IDEO built an interactive board game: ‚Äç "We watched closely to observe people's body language, and asked what the player thought and felt about the results," explains the IDEO team. "By designing a visually compelling way to more deeply engage with the people we're designing for, we had greater access to stories of how rural people felt about banks and the financial products available to them. We learned that because many had unsteady cash flows, they were afraid to take loans they may not be able to pay back." ‚Äç By the end of the game, IDEO identified which aspects of a financial product sparked excitement or fear, to understand their emotional relationship with the product. The stories helped IDEO.org create a financial product that served the needs of the region.

## When to use ethnography in product development¬†

The short answer: Early on.¬†

‚Äç

Although ethnography could be applied to learn how to make a product
better, it's more commonly used to decide what product to build in the
first place. In the earliest stages of a product's development,
researchers use ethnography to explore concepts for new products, find
business opportunities, and discover what sorts of tech products people
might want.

## How to conduct ethnographic user research

There are two main phases of conducting an ethnographic field study: the
preliminary planning period and the part that involves working with
participants.

### Designing ethnographic research studies

While potentially open-ended, a field study---like any research
study---still requires early planning to get the logistics right.¬†

‚Äç

Before you start, you'll need to decide:

-   How long will your study be?
-   Where will it take place?
-   Who should be involved in the study?
-   How will you record your data?
-   Which observational methods will you use?¬†
-   What questions do you hope to answer?

Once you're in the field, you\'ll want this information nailed down to
ensure everything goes smoothly.

‚Äç

For example, some study locations might require planning or permissions
ahead of time. If you're dealing with the public transportation system
of a certain city, you will certainly conduct your research in that
city. But if you want to learn about schools or construction sites, you
need to pick a specific school or construction site. In either case,
preparation also includes forming the professional contacts and
alliances you will need to function in your chosen setting.

‚Äç

Additionally, you may need to involve people other than just the
participants---such as partner organizations, additional researchers,
[**internal
stakeholders**](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews),
or parents or teachers in studies involving children. Make sure to loop
these people in as early as possible to avoid any snags after you get
started.¬†

### Methods for ethnographic research

There are multiple research methods that all fall under the category of
field research. These fall into three broad categories---**direct
observation**, **active participation**, and **interviews**---but the
same study may include methods from multiple categories.

‚Äç

#### Direct observation

Direct observation means simply watching somebody (or a group of
somebodies) to see how they behave and why. Ideally, your subject
doesn't care that you're watching and acts exactly as if you were not
there. Under some circumstances, you may be able to hide yourself.¬†

‚Äç

For example, researchers sometimes observe shoppers in malls or gift
shops without anyone knowing they're being watched. However, there are
both ethical and practical limits to incognito observation. In most
cases, you will have to explain your presence to participants and hope
they act naturally.

‚Äç

Data recording may take the form of free-form notes, the use of
structured protocols and data sheets, or audiovisual recording
(supplemented by the researcher\'s notes).

‚Äç

Direct observation can stand on its own, but is also a great way to
gather the information you need to structure later phases of the study.

‚Äç

#### Active participation

Active participation observation means that the researcher joins the
group of people being studied. Data recording is usually by field notes
or diary entries written after the researcher has ceased observations
for the day.¬†

‚Äç

The classic (and largely outdated) example of this method is the
anthropologist who goes to live with a remote population for years on
end. But an equally valid example would be a market researcher who makes
a habit of inviting herself to cook-outs in order to identify design
flaws in popular grill models.¬†

‚Äç

The ethnographic method combines informal [qualitative
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
with direct observation, except that the researcher has given up on
trying to be the proverbial fly on the wall. Instead, the hope is that
the research subjects will act normally because they perceive the
researcher as one of their own.

### Ethnographic research questions¬†

Ethnography, by nature, can be more open-ended than other types of
research. So you don\'t necessarily need a specific set of research
questions. Rather, ethnographic researchers often begin with defined
topics of study. Field studies exist on a continuum from strictly
observational, where the researcher is as unobtrusive as possible, to
designs involving interviews and product testing. Decide where on that
continuum you need to be to explore your topic properly.

‚Äç

Check out the [**Planning for UX Research
chapter**](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)
to view tips and templates for outlining your research plan, as well as
the [**User Interviews
chapter**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
for tips on choosing the right questions to meet your research goals.¬†

### Recruiting and sampling¬†for ethnographic research

[**Recruiting the right
participants**](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
is one of the most important---and challenging---steps for any type of
study, and ethnographic studies are no exception.

‚Äç

Similar to recruiting for other types of qualitative research,
recruitment for ethnographic user research involves:

1.  **Defining your research goals and methodology** (usually covered in
    your [**user research
    plan**](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)).¬†
2.  **Determining the best types of participants** to recruit. Consider
    defining your target audience by criteria like psychographics,
    behaviors, demographics, and geographics.¬†
3.  **Determining how many participants you need**. For qualitative
    studies, 5--12 is usually enough to create a valid data set.¬†
4.  **Creating an incentive plan.** Check out our [**Incentive
    Calculator**](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
    for personalized, data-backed recommendations.¬†
5.  **Finding participants.** User Interviews can help! Check out
    [**Recruit**](https://www.userinterviews.com/recruit) to source from
    our 700,000+ pool of participants or [**Research
    Hub**](https://www.userinterviews.com/research-hub) to manage your
    own panel.¬†
6.  **Screening participants.** Head to the [**Screener
    Surveys**](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
    chapter to learn the what, why, and how of this step.¬†

‚Äç

[**Some
suggest**](https://indeemo.com/blog/remote-ethnographic-user-research)
recruiting in waves to give yourself time to iterate on the data you
collect as the study progresses.¬†

‚Äç

Whatever your approach, collecting informed consent from participants is
essential. [**Here are tools, tips, and templates for collecting
NDAs**](https://www.userinterviews.com/blog/ndas-and-informed-consent-for-user-research)
and other informed consent documents from participants.¬†

### In the field

Ethically, participant-researchers must identify themselves as such; the
word for incognito participant observation is \"espionage.\" Whether or
not people who know they are research subjects will ever act entirely
normally is difficult to say, but ideally their behavior is close enough
to normal to yield valid data.

‚Äç

Whenever you finish in the field, pay attention to the process of
leaving. Unless you are simply taking notes on crowd behavior in public,
don\'t just vanish. Let your participants say goodbye to you. As with
introductions, farewells may take five minutes or several weeks,
depending on your situation. Take the relationships you have made during
your research seriously.

### Other considerations in ethnographic research design

As always, be mindful of different types of bias that can seep into your
research:¬†

-   **Observational bias** describes a phenomenon where people behave
    differently when they know they're being studied. It's almost
    impossible to prevent, and a researcher has to know this and account
    for it. The best and really only way to account for this is to
    balance results from other types of research when those being
    studied aren't aware that they're being studied, or when other data
    comes in from more neutral sources.
-   **Observer bias** is the same phenomenon, but from your end---when
    you believe or declare that you've observed something simply because
    you expected it or wanted to observe it. This, too, may be
    impossible to prevent entirely, but an awareness of the situation is
    the first step to curtailing it.

## Analyzing ethnographic data¬†

Once you've gathered your observations and anecdotal data, it's time to
organize that data and draw conclusions from it.
[**Analysis**](https://www.userinterviews.com/ux-research-field-guide-chapter/research-analysis)
is the process of transforming raw data into actionable insights

‚Äç

Data can be interpreted in any number of ways, so it's up to you to
decide how to analyze it and use it to tell a compelling story about
what your study did (or didn't) achieve. Analysis, done correctly, will
generate the building blocks you'll need to synthesize your results,
create your deliverables, and share your findings with stakeholders.¬†

‚Äç

Because ethnographic data is by nature qualitative, there aren't many
hard-and-fast rules for approaching this type of analysis. However, some
[**common qualitative data analysis
methods**](https://www.experiencedynamics.com/blog/2017/06/power-rapid-ethnography)
include:

-   **Affinity diagrams,** which allow you to organize and identify
    meaningful relationships between data points.¬†
-   [**Task
    flows**](https://www.userinterviews.com/ux-research-field-guide-chapter/task-analysis)
    that allow you to organize the flow of participant behavior,
    including where they start and what tools and information they need
    to complete the task.¬†
-   [**Journey
    maps**](https://www.userinterviews.com/ux-research-field-guide-chapter/customer-journey-maps),
    which are visual representations of the user's experience, including
    all key touch points, pain points, and actions in sequential order.¬†

Whichever method you choose, be sure to revisit the questions you
outlined in your research plan and analyze your data with these in mind.
Other important questions to ask during the analysis might include:

-   Which patterns or themes can you discern in participant behavior?
-   How did participants' behavior change over time?¬†
-   What influenced participants' behavior and decisions?
-   When did participants surprise you?¬†

After analyzing your data, you might find you want to dig deeper. In
that case, you may choose to return to your participants for additional
interviews.

## Sharing ethnographic UX research¬†

Now that you've discovered meaningful themes and insights from your
data, you need to synthesize and share your findings in a format that
will resonate with stakeholders.¬†

‚Äç

Videos, quotes, voice recordings, stories, and other concrete artifacts
are helpful resources to include in your reports. Stakeholders who
weren't embedded in the field study won't have the same context that you
have, so these types of deliverables will help them get a better sense
of the population and research environment.

### How to write an ethnography¬†

In anthropology or sociology, the findings from ethnographic research
are typically presented as an '**ethnography**'---basically, a paper or
report.¬†

Traditionally, [**an ethnography comprises the following
components**](https://medium.com/media-ethnography/how-to-write-an-ethnography-798e1bd83465):

-   **Thesis:** This section provides a summary of the key takeaways
    from your study. Stakeholders should be able to read this section
    for an 'at-a-glance' understanding of your findings and
    conclusions.¬†
-   **Literature review:** This section analyzes previous research on
    the same topic. By exploring existing research, you gain essential
    background knowledge that illuminates both the importance of your
    own research and places your study within the context of the broader
    research community.¬†
-   **Data collection:** This section explains the type of data you
    collected, your methods for collecting it, and the reasoning behind
    your overall research design.¬†
-   **Data analysis:** This section explains how and why you interpreted
    the data and uses it to support the core messages and conclusions
    you outlined in your thesis.¬†
-   **Reflexivity:** This section discusses your personal investment in
    the study, any limitations you ran into during the research process,
    and any points of potential bias or misinterpretation of the data.¬†

In the context of UX research, your ethnography may not need to follow
exactly the same format. [**Check out this Field Guide
chapter**](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)
for more inspiration on writing effective research reports and
deliverables.¬†

## Ethnographic user research tools and logistics

### Digital ethnography tools and logistics

The logistics of digital (or 'mobile') ethnography is largely similar to
that of any other kind of remote research method; smartphones,
computers, webcams, and other digital tools will likely come in handy.
However, there are a few [ethnography-specific apps and
tools](https://www.userinterviews.com/blog/digital-ethnography-tools-remote-ux-research)
that you should be aware of.

‚Äç

**Data collection tools:**

-   [**Indeemo**](https://indeemo.com/mobile-ethnography) is a mobile
    ethnography platform that enables remote, non-invasive research of
    human behaviors and user experiences. It allows you to assign,
    capture, and analyze these experiences in the moment, within the
    context of everyday life---without having to go 'in the field' in
    the traditional sense. Because it enables remote ethnography, it's
    particularly effective for studies involving diverse,
    geographically-dispersed populations. Indeemo's dashboard is
    filterable by participants, tasks, keywords, tags, and other
    attributes, so you can quickly and easily review your work so far.¬†
-   [**Maxqda**](https://www.maxqda.com/blogpost/maxqda-supports-ethnographic-research)
    is a world-leading software for qualitative and mixed methods data
    analysis. By digitizing your field notes from ethnographic
    studies---typing notes, scanning PDFs, or transcribing recorded
    audio, for example---you can upload them to the Maxqda platform for
    easier, more efficient data analysis. It allows you to code and
    organize large amounts of data for flexible analysis, with built-in
    collaborative functions for teams. Plus, Maxqda also has a
    smartphone/tablet app, so you can import your notes, videos, and
    interviews directly from the field.¬†
-   [**QualSights**](https://www.qualsights.com/) is an 'immersive
    insights platform' allowing you to remotely observe, interview, and
    interact with participants. As one of the more robust mobile
    ethnography platforms on the market, it provides a wide range of
    capabilities, including flexible data capture using any form of
    media, a blend of quant and qual data, a powerful suite of AI tools
    for analysis, a visual presentation builder to support synthesis and
    reports, and more.¬†
-   [**Contextmapp**](https://www.insightplatforms.com/link/contextmapp/)
    is a mobile research and ethnography solution for customer journey
    mapping, mobile diaries, and co-creation projects. With the ability
    to design studies, invite participants, collect feedback, and
    analyze your data in one platform, it's a great option for managing
    the end-to-end creation of customer journey maps. Its analysis
    dashboard allows you to browse and filter by participant,
    assignment, or task, and it's easily shared with stakeholders.¬†

**Analysis tools:**

-   [**ATLAS.ti**](https://atlasti.com/) provides intuitive research
    tools for sophisticated data analysis. Supporting a wide variety of
    media types---including textual, graphical, audio, and
    video---ATLAS.ti enables powerful qualitative analysis, insights
    visualization, mind mapping, and more. Because of its flexibility
    and capacity for managing huge amounts of data, it's great for large
    projects and collaborative work.¬†
-   [**QSR NVivo**](https://www.qsrinternational.com/) was designed
    specifically for qualitative and mixed methods data analysis, and
    it's one of the most widely-cited qualitative analysis platforms out
    there. Advanced data management, query, and visualization tools
    allow you to ask complex questions of your data, discover nuanced
    insights, and draw clear, evidence-based conclusions. It also
    provides automated transcription to free your team from menial work,
    as well as collaboration tools to share data and insights across
    teams.¬†
-   If your data is exclusively text-based (written or verbal
    transcriptions),
    [**Tropes**](https://www.semantic-knowledge.com/tropes.htm) is a
    free platform providing high-performance text analysis, qualitative
    analysis, and text mining tools. It enables summarization, semantic
    classification, qualitative analysis, knowledge discovery, and
    more.¬†

### Field studies tools and logistics

The logistical side of field research revolves mostly around travel and
documentation. Consider the following before you go:

-   **Practical matters:** You and your team may need lodging,
    transportation, food, equipment, repairs or replacements, There may
    also be safety considerations, licensing or permissions, and other
    practical matters to take care of before you go.¬†
-   **Equipment:** Technology, chargers, extra batteries, paper and pen,
    NDA/permission agreements, and anything else you need to be
    comfortable in your environment (lunch, water, sunscreen, etc).¬†
-   **Team:** Whether you go alone, with a buddy, or with an entire team
    depends on your research design. ‚ÄçIf you do bring colleagues, it
    might make sense to leave the larger team nearby and switch out
    observers from time to time throughout the study to remain
    unobtrusive and avoid observer bias.
-   **Attire:** Being observed already makes people behave strangely, so
    be culturally sensitive, and dress to belong. Also, check the
    weather and dress accordingly.¬†

As always, an important tool of the trade is always **courtesy** and
**professionalism**. Conducting research on people can be a socially
awkward thing, and you must behave in a respectful and trustworthy
manner at all times or no one will cooperate with you.

‚Äç

Part of respect and trustworthiness is **reciprocity**; don't forget to
bring your incentive for participants. Incentives can range from
monetary rewards and product giveaways to simple 'thank yous' or free
food. Whatever you offer, include it in your budgeting and other
planning.

## Ethnography vs. field studies vs. contextual inquiry

‚Äç**Field studies** are the most well-known type of ethnographic research
method, and the terms are often conflated.¬†

‚Äç

Commonly, user researchers wonder: What's the difference between
[**field studies vs. ethnographic studies vs. contextual
inquiry**](https://www.nngroup.com/videos/field-studies-ethnographic-studies-contextual-inquiry/)?
To put it simply: not much (or at least, it's not a big deal if you use
the terms interchangeably).¬†

‚Äç

The primary distinction between field studies and other types of
research is the location: Field studies are conducted in the
'field'---you go to wherever your participants are---while other types
of studies are not.

‚Äç

True ethnographic research would take place over the course of days,
weeks or months while living in participants' natural environment, while
contextual inquiry involves asking questions within this context (as
opposed to pure, removed observation). But for the purposes of UX
research, these differences are subtle and largely unimportant.¬†

‚Äç

### ‚ÄçWhat are ethnographic field studies?

[As defined by NN/g](https://www.nngroup.com/articles/field-studies/),
**field studies** are qualitative research activities that take place in
the user's context rather than in your office or lab.¬†

‚Äç

Some of the questions field studies can address include:

-   **How do your potential users talk about a given issue?** When your
    users belong to a culture or subculture different from yours, they
    likely use jargon and terminology that differs from yours as well.
    Listening in the field is a great way to learn their language.
-   **What is the cultural context of the need you want to address?**
    Products are designed to solve problems---but if your target users
    have a life context very different from yours, you are likely to
    misunderstand (and be unable to solve) their problems. Field studies
    are an excellent way to better understand your customers' problems,
    so you can offer them meaningful solutions.¬†
-   **How do the circumstances your users face vary?** By visiting
    multiple study sites, or one study site multiple times, you can gain
    insight into what commonalities your potential users have, how they
    differ from each other, and how adaptable your product (and your
    marketing) will have to be to support these differences.¬†
-   **What variables are relevant to your research?** If you don\'t ask
    the right questions, you won\'t get the right answer. For example,
    if men and women use your product differently, then you\'ll have to
    [control for gender in your study
    designs](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants).
    If the ambient air temperature changes what users need from your
    product, then you\'ll have to test it at multiple temperatures. If
    the age or educational status of your users matters, then you\'d
    better not recruit all of your study participants from an
    anthropology professor\'s classroom.

### When to choose field studies for UX research

Field studies provide the most complete, unbiased picture of what
potential users actually do. Unfortunately, field studies are expensive
and can be time-consuming, due to the need for travel and the greater
number of hours required by researchers. For these reasons, most
research teams use them only when no other method will do.

‚Äç

Choosing a field study for UX research might be a good idea when:

-   **You need to understand the big picture.** If your product is
    designed to function in a particular context, testing in a lab might
    not give you accurate results. You can also use field studies to
    explore a need that you hope your as-yet-uncreated product will
    fill.¬†
-   **You're starting from the beginning.** What do you do when you
    don\'t know enough about your potential customers to ask good
    questions about them? A study that asks inapplicable questions is
    worse than useless, being not only uninformative but also
    misleading. In this case, a field study is a good way to get the
    information you need to begin more focused research.
-   **Your research can't fit in the lab.** Even if you can lab-test
    your product, doing so might not be practical. For example, if your
    device is designed to function as a component of the navigational
    system of an oil tanker, going to an oil tanker for final testing
    makes sense. You probably have an R&D budget for field studies if
    you\'re in the oil tanker business, too.

### How to conduct ethnographic field studies

Field studies come with a much higher level of unpredictability and less
control than studies conducted in a lab or a controlled environment.
[According to Singleton and Straits
(2005)](https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=1071&context=tqr),
the process for conducting a field study is as follows:

1.  **Define the focus of the study**, including any problems you're
    hoping to solve and questions you'd like to answer.¬†
2.  **Choose your location.** You'll want to find a place where your
    target audience is likely to be found, but are also easily
    observed.¬†
3.  **Gain access.** Depending on the location you choose, you may need
    to gain special permissions or an onsite representative to accompany
    you.¬†
4.  **Present yourself appropriately.** Whether you're doing covert
    research or presenting yourself as a researcher, you need to choose
    the right attire, role, and space to fit into the setting without
    disrupting participants' natural behavior.¬†
5.  **Record data.** Recording your observations in the field can be
    complicated, so you need to choose the right format: video,
    hand-written notes, audio recordings, etc.¬†

## Other ethnographic methods

### Contextual inquiry (ethnographic interviews)

**Contextual inquiry**, also known as '**observation**' or
'**ethnographic interviews**', involves watching and listening to users
in their natural environment. Often, what participants say they do and
what they actually do is different, so observing them will give you a
better understanding of their daily activities.¬†

‚Äç

#### How to conduct a contextual inquiry

[**According to
NN/g**](https://www.nngroup.com/articles/contextual-inquiry/), the
process for conducting contextual inquiry interviews involves four
parts:

1.  **The primer:** Building rapport, managing expectations, discussing
    consent and confidentiality, and easing into the conversation with
    your participant.¬†
2.  **The transition:** Explaining to the participant how the rest of
    the interview will work, what they can expect, and how they can
    expect to interact with you moving forward.¬†
3.  **The contextual interview:** Observing the participant as they
    perform the task, stopping to ask questions or gain clarification as
    needed.¬†
4.  **The wrapup:** Asking any final questions, summarizing your
    takeaways, and giving the participant one last chance to provide
    clarification or feedback.¬†

#### Types of ethnographic interviews

Below is a guide that may serve as a useful template for choosing your
approach to ethnographic interviews:¬†

-   **Informal interviews** are simply conversations, though the
    researcher may have certain areas of inquiry in mind.
-   **A semi-structured interview is formal**, and has a designated area
    of focus. The researcher seeds the discussion with the same series
    of questions or prompts for every interviewee.
-   **Structured, open-ended interviews** allow the researcher to follow
    a set script, and the questions are carefully planned so as to not
    suggest answers. For example: "You want electronics that are easy to
    use, right?\" Leading questions are avoided, as always in good
    qualitative research.

### Digital ethnography

**Digital ethnography**, also called '**mobile ethnography**' or
'**virtual ethnography**,' is a form of ethnographic research that
occurs, well, digitally. Rather than traveling to join your participants
in their environments, you design tasks for them to record in their
natural environments using videos, pictures, audio, or other digital
artifacts.¬†

#### Methods for digital ethnography

You can practice digital ethnography in a variety of ways, including:

-   **Netnographic methods**, which involve collecting data from free,
    previously-existing content. This includes joining Reddit groups,
    reading reviews on competitors' websites, monitoring conversations
    on social media, and watching relevant YouTube videos. Because this
    content is posted organically, you can immerse yourself in your
    target audience's community to learn more about their thoughts and
    experiences.¬†
-   **Asynchronous interviews.** One-to-one interviews aren't always
    possible---if, for example, you and your participants live in
    different time zones. Asynchronous interviews allow both you and
    your participants the flexibility to interact at the times that work
    best for each of you. They can be conducted using text-based
    technology like email or video technology like Zoom.¬†
-   **Watching videos or screen-share recordings.** Videos are a great
    way to observe users' behavior in context without invading their
    space. You might choose to design tasks for participants to perform
    on camera, or ask them to go about a particular activity as they
    normally would. In the context of app and product design,
    screen-share recordings allow you to observe users' interactions
    with the product without having to stand over their shoulders.
-   **Digital diaries** are conducted similarly to a typical diary study
    via apps, smartphones, or other digital technology. They enable
    researchers to monitor diary entries in real-time and adjust or ask
    additional questions as needed, while providing participants with a
    more convenient way to submit their responses.¬†

Any of the digital ethnography tools listed above are great options for
conducting your research.¬†

‚Äç

#### Examples of digital ethnography

-   [**What Motivates Consumers to Participate in
    Boycotts**](https://www.researchgate.net/publication/223316121_What_Motivates_Consumers_to_Participate_in_Boycotts_Lessons_from_the_Ongoing_Canadian_Seafood_Boycott):
    This study, published in the Journal of Business Research, used
    netnographic methods---looking at comments left on an online
    petition---to analyze the motivations behind consumers' decisions to
    boycott seafood.¬†
-   [**Developing Successful New Banking
    Products**](https://www.cmnty.com/blog/atb-financial-money-secure-customer-insights/):
    This study, conducted by the banking app Brightside, involved
    creating a digital research community where consumers could talk
    about their banking habits. Brightside used the insights gleaned
    from this ethnographic study to develop new solutions.¬†
-   [**Using Eye Tracking to Optimize Product
    Packaging**](https://www.tobiipro.com/applications/marketing-user-research/shopper-research/):
    In this study, Unilever used eye tracking technology to follow
    shoppers through their shopping journeys and understand how they
    interacted with packaging in-store. By literally looking through
    their shoppers' eyes, they were able to better understand what
    captures their attention to improve packaging design.¬†

### Rapid ethnography¬†

**Rapid ethnography**, also known as '**mini ethnography**' or
'**focused ethnography**,' is essentially ethnography on fast-forward.
Researchers use typical ethnographic methods, but in a much shorter
timeframe with more focused inquiry---and because of the fast-paced
nature of the UX field, this is pretty much always going to be the case
in ethnographic UX research.¬†

‚Äç

#### Methods for rapid ethnography

Rapid ethnography doesn't differ too much from traditional ethnography,
using methods like:

-   Field notes
-   Direct observation
-   Focus groups
-   Diary studies
-   Informal interviews

##### **UXR¬†Case Study: Ethnographic Thinking to Understand Unknowns**

###### Thinking like an ethnographer means having users act out and paint for you the contexts in which they experience the world. When designing a new health insurance service for farm employers, we used ethnographic thinking to study employers' pain points and priorities in managing their employees' health. We observed how farm employers explored healthcare, their spending habits, and the role of health insurance in their lives and those of their employees. Although farm employers didn\'t explicitly discuss or describe scenarios of race, apartheid, or land rights during their interviews, it was the big elephant in the room that shaped how we came to interpret their transcripts and, ultimately, the recommendations that we delivered to the client. In this context, the users---the farm employers---were predominantly white males presiding over black farm employees in South Africa, just 25 years after apartheid. Ethnographic thinking helped us capture the racial, historical, and socioeconomic divisions underlying the healthcare market we were seeking to serve. From these contexts we designed a list of employee health insurance benefits that would position the client to act as a champion in reducing health inequalities and impacting social change. Rachel Ceasar, PhD Global Health Tech Researcher [**Culture of Health+Tech Consulting**](https://www.cultureofhealthtech.com/)

## Hybrid research: Combining ethnography with other methods

Ethnography often pairs well with [**diary
studies**](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies).
In a diary study, users record their own entries in a log or diary over
a determined period of time. Ethnography can be quite labor-intensive,
and traditional ethnographic note taking might not be possible, or might
tax resources and budgets. Employing a diary study is a great
alternative to enable deeper, longer-lasting research or to continue
when researchers can't be there to observe.

‚Äç

Check out our [**Diary Study Launch
Kit**](https://www.userinterviews.com/launch-kit/diary-study) for tips
and templates for getting started.

‚Äç

In general, field studies are only the initial stage of a larger
research effort. The fieldwork explores the context and helps set the
research parameters for the rest of the project. Some aspects of a field
study can grade into laboratory-type research as you are essentially
creating a temporary lab on site. Explore these [**discovery research
methods**](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)
to continue your research design.¬†

## A final note

‚ÄçRemember that ethnographic research doesn't need to be complicated,
doesn't have to take an excessive amount of time, and doesn't have to
involve specialist researchers.¬†

‚Äç

In fact, while a good field study should always yield a report that can
be read and understood by people uninvolved in the study, part of the
point of field research is to get out there and talk with the people who
will use your product. Get to know and understand them. If you can
develop an intuitive (and accurate!) feel for your customers, you will
be much better at creating and selling products that feel intuitive to
them.

‚Äç

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/user-interviews)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/diary-studies)

Next:

Diary Studies

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

\>

[Diary Studies](/ux-research-field-guide-chapter/diary-studies)

# Diary Studies

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Dear diary...

‚Äç

Today I learned that diary studies are a relatively hands-off and
economical way to gather loads of useful longitudinal qualitative data
(and sometimes quantitative data, too).¬†¬†Sounds neat, huh?¬†

‚Äç

In this chapter, we'll dig into diary-based studies and how this method
can be used to uncover insights over a period of time.

### In this chapter:

-   What is a diary study?
-   When to choose this method
-   How to conduct a diary study
-   Tools and software
-   Hybrid research: Combining methods
-   The pros and cons of diary studies

## What is a diary study?

A **diary study** (sometimes called a camera study) is a UX research
method in which participants keep a log of their thoughts, experiences,
and activities over a defined period of time, usually a few days to
several weeks.

‚Äç

Diary studies provide a self-reported and longitudinal record of users'
behaviors and attitudes that researchers later parse and analyze to
better understand habits and patterns.¬†

‚Äç

Study participants may be asked to log data as events occur or might be
prompted at predefined intervals (for example, via an email or text
message at a particular time of day).

‚Äç

This method is a relatively hands-off and cost-effective way to learn
about the how and why of the user experience in context. Because of
this, [diary studies have been
called](https://www.nngroup.com/articles/diary-studies/) "the poor man's
field study," but we think that characterization sells the method a bit
short.¬†

‚Äç

Diary studies are an economical compromise between a highly structured
lab-based study and an open-ended observational field-based ethnographic
study---and for UX researchers working on digital products, a diary
study is often a perfectly good alternative to on-site field studies.

## When to choose diary studies

Diary studies can help you learn more about how users act in real-world
situations.

‚Äç

This method has a place in many different types of research, but is
especially useful in UX research because of the fine-grained, contextual
information diary studies can offer product and design teams. It's one
of the few ways to really get a peek into how users interact with your
product in a real-world setting over a period of days or weeks.

‚Äç

Diary studies are useful for understanding long-term behaviors or
processes like:

-   **User habits.** What does a typical work day look like for your
    users? Where and when in a user's day do they reach for your
    product? What behaviors are spontaneous vs. planned?
-   **Attitudes and feelings.** How do users feel as they complete a
    task or use your product? Why do they make certain decisions?¬†¬†¬†
-   **User journeys.** How do users' feelings and perceptions about your
    brand change over time? What unexpected points of friction or
    delight do users experience?¬†
-   **Context of use.** When, why, and how does life interrupt use of
    your product? What do users do immediately before or after using
    your product?

### When in the product development cycle to use diary studies

This method is especially useful when you're in the early discovery
phases of your product or project. You can use diary studies to learn
more about the process users currently use to solve a problem, look at
products you want to create or replace, or better understand the precise
layers of the pain points you seek to solve.

‚Äç

Diary studies are also useful for testing early-stage products or
prototypes in order to identify any necessary changes, before altering
the course of a build becomes too onerous.

‚Äç

And they can also be useful at the very end of the development cycle. At
these later stages, you can dig into the user experience to see if your
products are being handled in the anticipated ways in order to fine-tune
details.

##### Intuit + diary studies

###### Since the company's founding days, Intuit has stressed the importance of studying customers in their everyday environments. Intuit oversees a line of business and consumer-oriented financial tools that more than 37 million customers use each year to track expenses, manage payroll, and pay taxes. Diary studies keep the company close to customer behavior. Teams that participate in these studies are cross-functional, consisting of research, engineering, product, and design leaders. These observational research studies uncover points of feedback that may otherwise remain undetected, and findings are shared throughout the company. \"By observing someone in their natural habitat we can determine how often they get interrupted when they are trying to do taxes, payroll, or perform some other task. Many people are probably not even mindful of how many interruptions they get or how many things distract them as they work on finances.\" ‚Äç-Intuit CFO, Neil Williams, via [Business Insider](https://www.businessinsider.com.au/intuits-cfo-wants-to-follow-you-home-and-watch-you-work-2015-12)

## How to conduct a diary study

Actually conducting a diary study has five main phases: planning,
recruiting and onboarding, monitoring, debriefing, and analysis. It's
important to put roughly equal energy and effort into all five phases to
get useful and usable results.

To make life easy for you, we created a [Diary Study Launch
Kit](https://www.userinterviews.com/launch-kit/diary-study) with:

-   Tips for writing a good screener survey, to help you identify the
    right participants
-   A guide to creating and launching your diary study‚Äç
-   Form template to help you collect diary entries from participants
-   A feedback analysis spreadsheet that automatically organizes diary
    entries

**üöÄ Get the** [**Diary Study Launch
Kit**](https://www.userinterviews.com/launch-kit/diary-study)**.**

### Download our free templates for collecting and analyzing diary study data.

[Get the Diary Study Launch
Kit](https://www.userinterviews.com/launch-kit/diary-study)

## Planning a diary study

If you're reading this Field Guide in order, you're probably sick of
hearing it, but here we go:

‚Äç

Step one of any user research study is identifying your goals and
defining a specific, actionable, and practical research question.¬† Step
two is figuring out [which
method](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
is the right one for your goals.

‚Äç

We assume that if you've read this far, you're probably pretty confident
that a diary study is the right method for your current research goals.
So we won't belabor the point, but just in case...

‚Äç

If you don't already have clear goals and an effective research question
in hand, circle back to the chapter on [How to Create a User Research
Plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
to hammer those out. Then, be sure to revisit the chapter on [choosing a
user research
method](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-choose-a-research-method)
to confirm that a diary study is really the most appropriate method for
your goals.

‚Äç

Once you've done that, you can start planning your diary study in
earnest. This is the fun-challenging part!

‚Äç

There are many different ways to conduct a diary study---which one you
choose depends on who your participants are, the kind of information
you're hoping to learn, and the resources at your disposal. Here are
some of the choices you'll need to consider along the way.

### Study topic scope

The focus on your study will be determined by your goals, and may be
broad ("what does a typical day for third-grade teachers involve?") or
narrow ("how do third-grade teachers use this specific math workbook?").

‚Äç

[Nielsen Norman Group](https://www.nngroup.com/articles/diary-studies)
breaks diary topic scopes into 4 categories:

-   Product or website (e.g. understand all the interactions with an
    app)
-   Behavior (e.g. general information about smartphone usage)
-   General activity (e.g. how people shop for groceries)
-   A specific activity (e.g. how people use a particular app to buy
    groceries)¬†¬†

### Study format: online vs offline

The most basic diary format is a **notebook and a pen or pencil**, a
low-cost and straight-forward option. Unfortunately, not all
participants have legible handwriting, and handwritten diaries must
later be digitized, adding another step to the processes of analysis and
archiving. If you want participants to include images with their diary,
consider including a **disposable camera** as part of their kit, or
(more likely in 2022), instruction for uploading digital photos.

‚Äç

Smartphones are now so ubiquitous that using **an app** for the diary
may be more comfortable for many users, though typing a lot of text into
a phone might be uncomfortable for some. Electronic diaries can also
take on other forms beyond the written word: entries can be logged by
voice, video, or photos.¬†

‚Äç

There are several well-rated diary apps already available in app stores
(we cover a handful below in the tools and logistics section), or you
can create your own. Bear in mind that using an app means you will have
to train participants how to use it.¬†

‚Äç

**Laptops or desktop computers** tend to be less ideal, since they are
not as portable, convenient, or discreet. But if the scope of your diary
study is narrowly focused on, say, a participant's interaction with B2B
software as part of their work day, you might also give them the option
to log their entries that way.

‚Äç

You can also combine methods like creating a daily or regular-use
questionnaire via mobile that can be paired with typed or handwritten
notes. Just be sure not to over complicate things, either for yourself
or your participants.

### Diary structure¬†

Another consideration is whether you want your participants' diaries to
be free-form or structured?

‚Äç

A **free-form or open diary** is similar to the personal diaries or
journals some people already keep. You'll still want to give your
subjects some initial guidance, by and large a free-form diary is quite
loose, and the subjects determine how and when to record feedback (when
they're already using a product) or to record their experience as they
accomplish certain tasks or go about their day.

‚Äç

Free-form diaries require less training and encourage the user to
speculate and to offer information you didn't ask for and might not
think to ask for. The risk is that the participant might not include the
information you need---or might include way too much information.¬†

‚Äç

A **structured or closed diary**, meanwhile, is more like a survey, with
closed-ended questions on pre-set forms. Because their format is
consistent across participants, structured diaries are much more
straightforward to analyze.

‚Äç

Mixed approaches of various kinds are also an option. How much structure
you use depends on where your study falls on a continuum between the
need for open-ended communication on the one hand, and precise answers
to specific questions on the other.

‚Äç

A structured diary might include:

-   An introduction page with **clear instructions** about how and how
    often participants should log their data. If you're asking
    participants to include photos or videos, be sure to provide clear
    instructions on how to do so.
-   **One page for every day of the study** (or every day participants
    are expected to fill in the diary, if not daily) with
    questions/prompts and space to answer
-   A final page with a list of **concluding questions** that
    participants will fill out at the very end of a study.¬†

##### Sample diary study questions

For a structured or hybrid diary study, you might ask questions like:

-   Describe your morning.¬†
-   What is the most important thing you have to do today?
-   What were you doing immediately before \[task\]?
-   What was the hardest part about doing \[task\]?
-   Which parts of \[task\] were you unsure about/lacked confidence in?
-   How did you feel while doing \[task\]?
-   Why did you feel that way?
-   How could that experience have been better?

### Logging techniques

The next thing to think about is the logging protocol. Whether you're
asking participants to complete a free-form or structured diary, you'll
want to provide them guidance around when to fill out their diary. There
are three categories of diary protocols:

-   **Interval-contingent protocol** in which diaries have to be filled
    out at regular, predetermined intervals (e.g. every 6 hours, once
    per day, one entry per week, etc). To avoid missing data,
    participants may need occasional reminders to maintain a consistent
    logging habit.
-   **Signal-contingent** **protocol**, in which you prompt the
    participant to make an entry with a notification alert, call, text
    message, or other signal. This method is effective, but intrusive.¬†
-   **Event-contingent** **protocol**, which requires the participant to
    fill in their diary whenever a specific something happens---after
    using your product, after making an online purchase, when it begins
    to rain, when their baby needs their diaper changed, etc.¬†

Event-contingent protocol is also known as **in-situ logging**, and is a
straightforward method for collecting data, but does require
participants to fill in their diary immediately after (or even during) a
relevant activity, which can end up being disruptive.¬†

‚Äç

A modified version of this method is called the **snippet technique**,
in which participants record brief notes at the time of the event so as
not to forget key points, and then follow up and expand on their
snippets with more information at the end of the day.

‚Äç

Whatever logging method you choose will depend almost entirely on your
research questions.

### Study duration

Diary studies can take place over a few days, or they can go on for
months. The optimal length depends wholly on the nature of your study.
But do keep in mind¬† that the longer your diary study is, the more
likely it is that participants will drop out or become unresponsive
later in the study. Make your study as short as possible while still
being long enough to answer your research question fully. If you don't
really need that extra week of entries, cut it!

Regardless of study length, be sure to check in on participants
regularly to keep them engaged and answer any questions that might crop
up.

### Additional considerations

Your diary study may involve collecting **sensitive or personal
information** about your participant and you will have to take steps to
either safeguard or destroy all such information. Your recruitment and
onboarding processes should include obtaining **informed consent**. That
means getting express permission from participants after¬† advising them
that you're collecting information, why collecting this information is
important, how you plan to use¬† and store the data they share, and what
you're doing to minimize risk.¬†

‚Äç

It's also a good idea to conduct a **pilot study** to make sure your
diary study design is sound. Recruit a couple teammates to help you
practice onboarding and debriefing participants, test drive your¬†
materials to make sure the logging instructions are clear, and
troubleshoot any tools or processes that participants will be expected
to use.¬†

## Recruiting and onboarding diary study participants¬†

There are two parts to diary study recruitment. The first---finding and
screening participants ---is similar to recruiting for other qualitative
research methods.

The second---briefing and onboarding participants---is a more involved
process than you may be used to if you typically stick to, say, user
interviews.

### Finding and screening participants

For starters, you'll need to have a good idea about who, exactly, can
help you answer your research question. If you haven't already, we
highly (highly!) recommend reading the chapter [How to Recruit
Participants for User Research
Studies](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)
to learn more about defining your participant profile and screening
criteria.

We also encourage you to read the chapter on [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
carefully---you'll need a good screener to find participants who are not
only qualified to answer your questions, but who are willing and
communicative enough to stick with the demands of a long-term research
study.

[Tony
Turner](https://www.userinterviews.com/blog/the-magic-of-diary-studies-with-tony-turner-of-progressive),
UX Researcher at Meta, emphasizes the importance of screening for
articulation in diary study recruitment:

‚Äç

"The key thing is to \[have\] screeners that get at how interactive the
participant is in terms of answering questions and things like that. So
having questions in the screener that give them an opportunity to be
verbose (or not) and learning about them that way."

Your study might call for as few as 3 or as many as 30
participants---the number will, naturally, depend on the scope and
budget of your project.¬†

For a typical diary study, aim to recruit **10 to 15 participants**.
It's also not a bad idea to recruit a couple more folks as a buffer
against potential dropouts.

### Incentivizing participants

It's always important to compensate your study participants fairly. How
and how much you offer should be informed by the participant's level of
expertise, the amount of time and effort required, and (of course) your
own budget.

We wrote [a whole chapter on UX research
incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)---including
the different formats these can take---and even made a handy [User
Research Incentive
Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
to help you figure out the right amount for your study.

#### Special considerations for diary study incentives

-   Remember that you're asking a lot of participants. Although the
    logging itself may be simple, keeping a diary requires dedication
    and time. This should be reflected in a **higher incentive rate**.
-   As part of your periodic check-ins, **remind participants** about
    what they stand to receive for completing the study.¬†
-   If you're offering cash or gift card incentives, you might want to
    consider distributing your incentives **in installments** to keep
    participants motivated throughout the study.¬†
-   If the study involves testing a device or software, you could also
    offer participants the possibility to **keep the product** as a
    final reward for completing the study.¬†

### Start talking to users today

[Sign up for free](https://www.userinterviews.com/recruit)

### Onboarding participants

After recruiting participants, you'll need to train them. Diary studies
require a lot of (unmoderated) effort from participants, and your
onboarding process should include a pre-study brief with thorough
instructions about what, exactly, you want them to do.

‚Äç

Schedule a face-to-face meeting with each participant (this can be
in-person or virtual) to discuss the details of the study. Make sure
they're clear on the timeline, logging schedule, and expectations around
entry content and quality. Give them a walkthrough of the tools and
technology they will be using, and leave plenty of time for questions.

‚Äç

But don't rely on their memory alone---include clear written
instructions and a reminder about expectations in the diary itself, so
participants always have the most important information on hand.

‚Äç

[Nielsen Norman Group
recommends](https://www.nngroup.com/articles/diary-studies/) providing
participants with a simple framework:

Be as specific as possible about what information you need participants
to log, without stifling natural variability and differences that you
cannot plan for. (Discovering the unexpected is after all one of the
primary reasons to do user research.) Create clear and detailed
instructions for logging. Give users example log entries to help them
understand the level of detail you need from them. (But make sure you
don't bias participants toward those types of entries that you happened
to provide as examples.)

## During the logging period¬†¬†

Once the study begins, you may need to remind them to make their diary
entries, and they might have questions for you about the process. Plan
to check in on your participants regularly to support consistent logging
and to address issues as they come up.

‚Äç

Exactly how closely you monitor participants throughout the study
depends on your study design and perhaps also on the needs of individual
participants. The longer a study is the harder it will be for
participants to stick with it. (A few weeks is a good maximum length for
most diary studies for this reason.)

‚Äç

During your check ins, be sure to recognize the efforts of participants
that are engaged and creating quality entries per your instructions (a
friendly "keep up the good work" goes a long way). For participants who
are less engaged or seem to be struggling, take time to answer their
questions and offer encouragement.

## Debriefing participants with post-study interviews

After you collect all the completed diaries, you should plan to meet
with each participant to discuss their diary entries in detail.

‚Äç

To prepare for your debrief, review each participant\'s diary
entries---you might also want to begin the analysis process ahead of
time by tagging and coding the data. Then, conduct one-on-one followup
interviews with each participant. Ask them to expand on their entries or
clarify where needed, and incorporate the information into your study
results for analysis in the next step.

‚Äç

The post-study interview is also a chance to personally thank each
person for their efforts and gather feedback about the participant
experience.¬†

## Analyzing and sharing diary study data

Analysis transforms your raw data (the diaries, debriefing interview
transcripts, and whatever other information you have gathered) into
insights you can use.¬†

If diaries were hand-written or voice-recorded, step one of analysis
will be transcribing the diaries into a format that can be analyzed
using spreadsheets or specialized software.¬†

‚Äç

Next, you will want to revisit your research questions. Diary studies
create a lot (a lot) of qualitative data and it's easy to get lost among
all the interesting nuggets of information you're likely to encounter as
you dig in. Be clear about your research questions and the goals of your
study, and focus your initial analysis on answering those first.¬†

‚Äç

Questions to ask during diary study analysis include:

-   How do target behaviors evolve and change over time?
-   What influences certain behaviors or decisions?
-   What similarities and differences do you observe between
    participants' processes?

The feedback you get from diary studies can be difficult to organize.
Our [Diary Study Launch
Kit](https://www.userinterviews.com/launch-kit/diary-study) includes an
analysis spreadsheet template that automatically organizes diary entries
so you can spend more time on analyzing and synthesizing the data and
less time sifting through it.¬†¬†

In general, we find Google Sheets to be a pretty good way to organize
research feedback. It's a free, widely accessible tool that your whole
team can use, even remotely. And while it doesn't have all the power of
a dedicated research repository or diary study tool, it's a good way for
getting started.

‚Äç

If you used a highly structured diary format, you may also have
quantitative data to analyze with statistical analysis software or some
deft spreadsheet formulas, which can then be layered in with qualitative
insights.

###### üí° **Pro tip:** As a rule, it's a good idea to figure out what type of analysis will best serve a study before you begin, since analysis methods must be matched to both your research questions and your study design. Knowing how you plan to analyze incoming data also makes it possible to tag data as it rolls in, saving your team time at the end of a study.

### How to share diary study results

After analyzing the data, you can construct a [**customer journey
map**](https://www.userinterviews.com/ux-research-field-guide-chapter/customer-journey-maps)
that shows the user experience, pain points, and opportunities plotted
over time. You can read more about how to create a customer journey map
in this Field Guide chapter. We also put together a (giant) [list of
journey map templates and
examples](https://www.userinterviews.com/blog/best-customer-journey-map-templates-examples)
for you to borrow from.

‚Äç

Include your journey map in your [final research
report](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting)---this
can be a written report, slide deck, and/or a live presentation.
Consider including quotes from the diaries or post-study interviews in
your report, along with any images, videos, or voice recordings you may
have collected.¬†

‚Äç

If you're looking for some inspiration, check out this [collection of
research report templates and
examples](https://www.userinterviews.com/blog/ux-research-presentations-reports-templates-examples).
You can also borrow and adapt our own simple [UX research
summary](https://docs.google.com/document/d/1X1ASvX6nPMX8au8iQxACRo3T6JGGjv12k1FvZtORhos/edit)
and
[presentation](https://docs.google.com/presentation/d/1N8qpXAMiwi-yYEneIZFCBy1_kqQ7KWE1dwSUPRsq948/edit?usp=sharing)
templates---the same ones used by the User Interviews team.

###### üí° **Pro tip:** You don't have to wait until you have a polished customer journey map or final report to share diary study results with stakeholders. If you're using a structured format and reviewing diary entries as you go, you might consider analyzing and synthesizing the data at set intervals.¬†

###### For example, if your diary study is focused on the user experience of a fitness app, you might share early insights about participants' progress or commitment levels at the 3-day, 1-week, and 2-week marks.

## Diary study tools and software

There are a number of off-the-shelf diary study tools out there,
although these aren't always practical for small teams, or for teams
just getting started with diary studies.¬†

If you're assembling your own toolkit, you'll need to provide each
participant with the following:

-   **Diaries** (either digital or physical)
-   **The product** to be tested (if applicable)¬†
-   **A place to upload** images, videos, or voice recordings (if
    applicable)\*

\*This could be Google Drive, Dropbox, or simply an email address or
phone number for texting media.

‚Äç

You will also need solutions for:

-   [Recruiting, screening, and communicating with
    participants](https://www.userinterviews.com/) (hey, that's us!)
-   Meeting with participants---[a video conferencing tool like
    Zoom](https://www.userinterviews.com/blog/zoom-user-interviews-integration-making-your-workflow-way-easier)
    or a researcher-specific solution like
    [Lookback](https://www.lookback.com/)
-   [Transcribing](https://www.userinterviews.com/blog/user-research-recordings-analysis)
    handwritten entries and audio/video recordings
-   Organizing and analyzing data---feel free to adapt [our analysis
    spreadsheet](https://www.userinterviews.com/launch-kit/diary-study),
    or see below for more robust options
-   Storing and sharing data and insights post-analysis

If you are collecting and retaining sensitive personal information (such
as where participants go during the day, how they use social media, or
any medical or banking information) you will also need some way to keep
that information secure until it is no longer needed and can be
destroyed.

#### Specialized diary study tools

-   [**Dscout**](https://dscout.com/diary) is a popular end-to-end tool
    made for designing, conducting, and analyzing remote diary studies.
    Reviewers cite their helpful researcher support team as a major pro,
    although they also note that some features and functionalities like
    scheduling are limited (but improving).
-   [**Indeemo**](https://indeemo.com/) is a robust platform for
    gathering user feedback of all kinds. It includes a mobile diary
    study app that lets participants record audio and video, allows
    researchers to schedule prompts and assign tasks, and comes with
    automated transcription and coding tools.
-   [**Lifedata**](https://www.lifedatacorp.com/) is an experience
    sampling tool that includes an "eDiary" mobile app with flexible
    scheduling options, support for complex study designs, and anonymous
    data collection. This tool is tailored to healthcare researchers
    conducting clinical trials, so most UX researchers may find its
    feature set a bit niche for their needs.
-   [**Teamscope**](https://www.teamscopeapp.com/features/mobile-forms),
    another tool tailored to medical researchers, offers mobile forms
    for diary studies. Features include scheduled prompts, custom
    reporting and data filtering, strong data security safeguards, and
    offline data collection.

#### Qualitative research analysis tools

-   [**Aurelius**](https://www.aureliuslab.com/user-research-synthesis-and-analysis)
    is a powerful research repository, analysis, and reporting tool
    designed for qualitative researchers. Features include note taking,
    transcription, tagging, keyword search, sentiment analysis, and
    automated analysis.
-   [**Dovetail**](https://dovetailapp.com/features/user-research-data-analysis/)
    offers a sophisticated transcription tool with bulk editing, tag
    management, highlight reels, sentiment analysis, and more. They also
    offer a research repository tool for storing and sharing insights.
-   [**Optimal Workshop**](https://www.optimalworkshop.com/reframer/)'s
    suite of tools includes Reframer, a qualitative research analysis
    tool for organizing notes, tagging data, and analyzing patterns

## Hybrid research: Combining diary studies with other methods¬†

Diary studies can be combined with other methods in order to expand the
reach of the study while keeping costs manageable. As we've discussed,
diary studies are a means of observing natural use of a product. So, it
can be handy to combine diary studies with some more quantitative
methods that might fill in and support this same discovery stage of
research.

**Surveys** are commonly paired with diary studies. For example, you may
use a widely-distributed survey to collect the information you'll use to
develop the diary study. (Example: A survey might tell you how many
times a day people drop their phones on the floor, and in a diary study,
you get to learn more about the circumstances under which they drop
their phones.)

Or, you could use the results of a diary study to develop further
research questions that you then explore in a survey. (Example: A diary
study might show that people are super diligent about flossing their
teeth in the few weeks after a cleaning, and less so over time. You
could follow this up with a survey to ask what might motivate them to
continue flossing consistently.)

Other complementary methods include:

-   [**Interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)---a
    brief diary study can be used to prompt self-reflection ahead of
    in-depth interviews.
-   [**User
    analytics**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics)---in
    addition to self-reported behaviors, you might also track in-product
    behaviors using analytics tools
-   [**Focus
    groups**](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups)---after
    one-on-one debrief interviews, you might find it valuable to gather
    study participants for a one-time focus group discussion after to
    see if any additional insights emerge¬†
-   **Co-design**---diary study participants may good candidates for a
    participatory design study, since they will have been thinking about
    a product or process extensively and are likely to have developed
    some opinions about the optimal solution

## The pros and cons of diary studies

There are many avenues researchers can take to gather contextual
understandings about users in their natural habitats, but none are
without their drawbacks. Some solutions are more costly than others
(extended [**field
studies**](https://www.userinterviews.com/ux-research-academy-lesson/field-studies),
for example), others can be somewhat unnatural (asking users to repeat
real-life behaviors in a lab environment), and others may be unreliable
(retroactively trying to understand context through a survey.)

‚Äç

Every UX research method has its challenges, but the good news is: the
challenges you might encounter with diary studies are manageable.¬†

‚Äç

#### Potential diary study pitfalls and how to mitigate them

**Keeping a diary is a lot of work**.¬†

-   **Problem:** Some participants might lose steam or forget---not
    everyone who agrees to begin the study will record diary entries
    correctly and diligently, and some will drop out before the end.
-   **Solution:** Consistent communication and incremental rewards. You
    may wish to set up alerts, or reach out to participants directly to
    be sure they're still engaged and committed. For longer studies,
    consider distributing incentives periodically to keep motivation
    high.

**Data can be challenging to analyze.**¬†

-   **Problem:** The process of [**analyzing qualitative
    data**](https://www.userinterviews.com/blog/how-to-analyze-qualitative-data-with-the-design-gym)
    is a whole different ball game from analyzing quantitative data:
    qualitative data is just more cumbersome, and is more challenging to
    automate. Diary studies can be even more challenging than other
    types of qualitative data because you'll be dealing with the
    meanderings of people's minds.
-   **Solution**: If possible, use a digital diary format. This at least
    reduces the need for transcription, which will save time later. It
    can also enable you to create sortable fields (like time of day of
    each log) and automate tagging. Making diaries digital will allow
    you to search keywords and more easily identify trends when it comes
    time for analysis.

**Self-reported data may not be totally accurate.**¬†

-   **Problem**: Human beings are unreliable narrators---we all have
    blind spots, biases, and are generally bad at predicting our own
    future behaviors. Even the most diligent, upstanding participant is
    likely to miss or misrepresent details, recall information partially
    or inaccurately, and inject their own unconscious biases into their
    observations.
-   **Solution**: Keep diary study tasks and prompts focused on past or
    current behaviors---don't ask participants to hypothesize about
    their future selves. You can also use your screening process and
    onboarding meetings to get to know your participants and identify
    biases they may bring to the study. This knowledge may help you
    interpret or report on diary study data more accurately. And of
    course, diary studies are just one piece of the puzzle---supplement
    the data you gather through this method with moderated studies,
    product analytics, and/or a high volume of quantitative data for a
    more complete understanding of the user experience.

#### The advantages of diary studies

No research method is perfect, and as we've just shared, diary studies
do come with drawbacks (although the more serious pitfalls are easily
avoided).

If you've considered your options and have decided a diary study is the
best way to answer your research question---we say, go for it! The pros
far outweigh the cons with this method.

Among other things, diary studies:

-   **Capture** **temporal dynamics.** Many common research methods fall
    short when it comes to capturing how time influences the user
    experience. One of the most compelling reasons to conduct diary
    studies is that they allow researchers to efficiently collect
    longitudinal qualitative data from multiple participants
    simultaneously---without intensive field study or moderation.
-   **Reflect real-world environments and natural context of use.**
    Diary studies help researchers understand how a product is used and
    experienced in the real world. Like observational methods such as
    field studies, diary studies can help reveal external
    factors---distractions, social situations, technical limitations,
    etc---that may influence real-world usage.
-   **Give participants time to think deeply about their experience.**
    Diary studies allow participants to take the time they need to put
    their thoughts and feelings into words, and to express themselves in
    a variety of formats. This in-depth introspection and creative
    feedback can be a fantastic complement to other methods like [first
    click
    testing](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing)
    that capture initial responses or reflexive decision making.¬†¬†

What's more, as [Kelly
Moran](https://uxdesign.cc/diary-studies-cd65a61a4f89), Staff UX
Researcher at Google, observes:

"‚Äã‚ÄãThese studies often surface topics that a team has not thought to
pursue in other, more tightly controlled research because the team does
not know it exists as a phenomenon. This can include topics and
phenomena that participants have not brought up in interviews because
they simply did not come to mind in that interview moment.

One final benefit to diary studies is the ability they give your team to
"get smart" about the population before going out to the field when used
as a first step in a multi-phase discovery project. The team can head
out already knowing about specific instances they can probe into in more
depth. A positive byproduct of getting to know the respondents before we
meet for face-to-face observation is the breaking down of some initial
barriers. Arriving with a foundation of rapport already laid down means
we can get right into meaningful observation shortly after arrival."

## ‚ÄçA final word

Diary studies are just one piece of the user research puzzle---it would
be unwise to make sweeping design decisions based only on diary study
data. But the same can be said for literally any other UX research
method.

If you're looking for an economical way to collect in-depth, contextual,
longitudinal data that captures the voice of the user, there's no better
tool to have in your belt.

[](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/ethnography)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/focus-groups)

Next:

Focus Groups

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

\>

[Focus Groups](/ux-research-field-guide-chapter/focus-groups)

# Focus Groups

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

A focus group might involve plumbers discussing the installation of
shower heads, or pet owners discussing their grievances with fur around
the house, or cancer patients sharing their insights into what it's like
to go through treatment at a certain stage.¬†

Focus groups are not interviews that happen to have multiple respondents
in the same room. Au contraire, the value of a focus group lies in the
group discussion, and the interactions that occur among the members.

This method (which, as we'll discuss, has its detractors) is best used
to explore what people believe, how they feel, and what they perceive.¬†

### In this chapter:

-   What is a focus group?
-   Why do some user researchers hate focus groups?
-   When to use focus groups for UX research
-   How to conduct a focus group
-   Analyzing focus group data
-   Sharing your findings
-   Tools for conducting focus groups
-   Hybrid research: Combining focus groups with other methods¬†

## What is a focus group?

A focus group is a moderated conversation with a group of 5 to 10
participants in which a moderator asks the group a set of questions
about a particular topic. They can be helpful tools for learning about
attitudes, beliefs, desires, and reactions to concepts or designs. Focus
groups typically last from 1 to 2 hours.

Because of their social dimension, focus groups can sometimes be more
effective at uncovering spontaneous reactions or ideas than 1:1 methods
like user interviews. However, there is a risk that participants might
influence each other or inhibit others from sharing honest thoughts or
feedback.¬†

Focus groups are traditionally used by social scientists seeking to
understand group dynamics, or by marketing researchers in order to
obtain feedback about a product or assess perceptions about a brand.

### What decisions do focus groups enable?

‚Äã‚ÄãFocus groups are used to inform vision and strategic decisions. They
provide clarity around a participant\'s big-picture beliefs and
philosophies in order to determine a potential company, product, or
service direction.

They can also be used to inform definition decisions, allowing you to
get early feedback on a potential design direction to determine if it's
worth additional investment or resourcing.

### What are the outputs?

Focus groups can generate a large amount of qualitative data, including
detailed notes, transcripts, audio, and video recordings.

All of this data is then synthesized into recommendations related to
potential product directions or opportunities.

### Benefits of focus groups as a UX research method

Focus groups are a good way to draw out ideas and information that
participants might not be willing or able to share in an interview
setting or through a survey.¬†

Being surrounded by a small group of peers makes many people more
comfortable and more willing to talk, even about sensitive or personal
topics.¬†

The interaction among group members can bring out ideas that were
previously not conscious, or simply taken for granted. The way group
members agree or disagree---either with passion or indifference---can
shed light on how important a certain consideration should or should not
be to your development team.

## Why do some user researchers hate focus groups?

"If I achieve one thing with my time here on earth, I might be content
if that one thing could be burning to the ground the practice of running
focus groups in place of actual user research." --- [Erika
Hall](https://medium.com/mule-design/focus-groups-are-worthless-7d30891e58f1),
Co-founder, Mule Design

Some user researchers really dislike focus groups. And there are plenty
of reasons to be wary of this approach---it's certainly not a method to
use in isolation. Let's go over some of the commonly cited drawbacks:

### Drawbacks and potential pitfalls¬†

‚Äç

#### 1. Focus groups tell you what people say, not what they do.

"The correlation between stated intent and actual behavior is usually
low and negative."¬† --- Gerald Zaltman, How Customers Think

Humans are notoriously bad at predicting their own behaviors,
remembering past events, and conceptualizing abstract ideas. There is a
large gap between what people say and what they do---and group dynamics
can further compound this fact of human nature. If you're trying to get
an accurate read on user behavior or customer purchasing intent, focus
groups are probably the wrong method.¬†

#### 2. Focus groups result in groupthink.

Focus groups trace their roots to the 1930s and 1940s, when they were
used by social scientists to study the effect of WWII propaganda.
Advertisers then adopted the method as a way to understand how consumers
think.

Focus groups are an effective way to study how individuals behave in a
group, and how group dynamics impact perceptions and decision-making. In
other words, focus groups are a useful tool for studying groups of
people.

What they are not good at is uncovering individual thoughts and
feelings. That's because focus groups lead to groupthink, a phenomenon
in which participants unconsciously conform to the opinion of the group
at large. Groupthink is a natural byproduct of group discussion---it's a
means of maintaining social harmony---but it means that focus groups
offer a skewed understanding of individual users' experiences.

#### 3. Dominant personalities overshadow other group members.

We've all been in a meeting or classroom where one or two dominant
voices command the room. (If you can't remember such an occasion,
chances are good that you're one of those voices!)¬†

In a group setting, extroverts and contrarians can easily monopolize the
conversation. Sometimes this means literally talking over other people,
but it isn't always combative.

‚Äç

One or two influential participants often steer a discussion through the
strength of their thoughts and opinions. All it takes is one charming
and persuasive member to declare that wine from the Emilio-Romagna
region is the best wine and suddenly the whole group loves Lambrusco.
(And they would be right to do so, but that\'s beside the point.)

Your audience is likely a fairly even mix of introverts, extroverts, and
folks in the middle of the spectrum. But in a focus group, the voices of
quieter, more reserved personalities often go unheard. Again, if you're
hoping to learn about individuals, focus groups are not the right
method.

#### 4. It takes skill and experience to successfully moderate a focus group.

The success of a focus group depends heavily on the skill of the
moderator.

Group dynamics are tricky. No matter how diligently you prepare or how
thoroughly screen participants, bringing a group of people together is
always a gamble. Personalities might clash, leading to a conflict
between a couple of highly opinionated people. Or sometimes, like a bad
dinner party, there's just no group chemistry no matter how hard your
moderator might try.

### How to mitigate common focus group problems¬†

‚Äç

#### Have participants actually use the product.

If you're conducting a focus group to understand user perceptions and
reactions to a product, give users an opportunity to interact with that
product. Feedback based on actual experience is more accurate and useful
than feedback based on hypothetical scenarios or out-of-context prompts.
Run individual usability tests before participants convene for a focus
group discussion.

#### Screen for introversion/extroversion.

Include questions in your screener survey that will help you identify
introverted and extroverted participants. Ask questions like "Does being
around other people give you energy?" and "Do you prefer to be with
other people or to be alone?"¬†

You might also conduct a screener call with participants to assess their
conversation style---do they dominate the call? How much prompting do
they need to provide detailed answers? Will their voice be drowned out
in a group?

¬†

It's impossible to predict how any group of people will interact when it
comes down to it, but you can do your best to create a balanced group
that won't feel like hostile territory for the introverts involved. You
might also consider conducting a group with only self-identified
introverts.

#### Try conducting video focus groups online.

Moving your focus groups to an online setting can mitigate the effects
of group dynamics. Seasoned user researcher [Jay Eskenazi
suggests](https://uxmag.com/articles/how-to-fix-the-5-most-common-mistakes-with-focus-groups)
using a platform that allows participants to share their responses with
moderators privately, before they see the responses of other group
members. This ensures that their responses are "uncontaminated by group
dynamics."¬†

## When to use a focus group for UX research

With so many cons and caveats, are focus groups ever worth it?¬†

They can be!

In fact, oftentimes the reason focus groups fail is because researchers
try to use them to answer the wrong questions or during the wrong stage
in product development.¬†

Focus groups are meant to uncover perceptions, not behaviors. Group
dynamics can be a great way to learn about perceptions because
conversations can reveal things that a one-on-one interview might not.

#### Use focus groups to:

-   Identify or clarify research questions during the earliest stages of
    a research project.
-   Gain insight into how people talk about a problem, product, or
    shared experience in a group setting.
-   Learn about users' opinions, attitudes, and preferences after they
    have used a prototype.

## How to conduct a focus group

‚Äç

First things first:

‚Äç

#### What are your research goals?

As we discussed above, focus groups often fail because researchers use
them to answer the wrong types of research questions.¬†

Before you spend time and money on planning, recruiting, and conducting
a focus group study, make sure it's really the right method to meet your
needs! Remember: Focus groups can help you uncover perceptions and
opinions, not behaviors.¬†

Read the chapter on [**How to Create a User Research
Plan**](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
for a step-by-step guide to coming up with effective research goals and
questions. A good research question is:¬†

-   Specific (so you'll know when you have found an answer)¬†
-   Practical (you can reasonably find answers in the scope of a
    research project)
-   Actionable (your team will be able to make decisions based on your
    learnings)

#### Where will the group meet?

If you're conducting a focus group online, your biggest logistical
considerations will be deciding on a platform, sending each participant
a link and instructions on how to join the group, and troubleshooting
any technical issues along the way.

For in-person focus groups, location plays a much larger role in the
planning process.

The decision is partially a matter of logistics---you need some place
everyone can get to, and you need a comfortable room of the right size
that is free of distracting noises. If you'd like to observe from behind
a two-way mirror, you'll want to invite participants to a lab (either
your own, or a [rented space](https://breather.com/)).¬†

Location can also impact group dynamics, and different people feel
comfortable in different kinds of places. For example, businesspeople
will find the conference room at a hotel comfortingly familiar, whereas
another group of participants might prefer a ring of folding chairs in a
space that feels like a church basement or a classroom.¬†

The question is: Under what circumstances do these people normally sit
around and talk about this subject? Try to mimic those circumstances as
closely as possible---nobody likes to feel like fish out of water.

**Always visit a location before to check:¬†**

-   Is the room easy to find? If not, find or create a map.
-   Is the building easy to find?
-   Is there affordable parking nearby?
-   Are there clean and accessible toilets onsite?
-   Does the building have an elevator?
-   Is the temperature comfortable? Is it air-conditioned or heated, as
    the case may be?
-   Is anything problematic likely to be happening in or near the venue
    during your group meeting? For example, is an unrelated convention
    likely to make the place confusing, crowded, or noisy? Is a sports
    game or college commencement nearby likely to snarl up traffic?

#### Who will moderate?

Focus groups require experienced moderators with strong [interviewing
skills](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
and the ability to bring a group back to center if things veer off
course. If a moderator is too passive, the group can get lost in its own
momentum and veer off topic. Too leading, and your results will be
skewed. Awkward, and the participants won't feel comfortable. Overly
confident, and they could be perceived as domineering and off putting.¬†

Good moderators have:

-   Some background knowledge or direct experience with the subject at
    hand
-   Energy and enthusiasm for the discussion
-   The ability to encourage quiet participants and rein in strong
    personalities
-   A good memory for names and details
-   Experience interviewing participants¬†

### Recruiting participants for a focus group

As with other research methods like user interviews, the first step of
recruitment involves identifying the participants you need.¬†

Ask yourself: Who can answer my research questions?

If you have a sense of your product's target personas, there may be an
opportunity to match your participants with those personalities.¬†

If you're in earlier stages of development, aim for a highly diverse
population within your product's target market. All sorts of people wear
sneakers, for example, so a focus group on sneakers would be very
diverse indeed: a whole spectrum of sneaker-wearers could be included. A
focus group on tie clips and cufflinks, on the other hand, might look a
bit more homogenous. If your target audience is tighter, you might need
fewer groups overall.

In either case, your focus group participants need to have something in
common in order for the discussion to provide you with actionable
insights.

‚Äç

When creating [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
to filter for good-fit participants, always second-guess your
participant criteria: Does gender matter? Income? Education level? Race?
While demographics might influence the way people experience a product,
most of the time these factors don't prevent someone from being able to
answer your research question.¬†

If you're interested in how experiences differ across populations, you
can collect demographic data without screening on it.

Pro tip: Many recruiting services, including [User
Interviews](https://www.userinterviews.com/recruit), already collect
(with ¬†consent) data on participants about things like race, ethnicity,
income, education, and location. Unless you're filtering by one of these
factors, don't need to include these questions in your screener.

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

#### How many groups do you need?

The more groups you have, the more ideas and opinions you will collect,
but this is helpful only up to a point. How many groups your study will
need depends on your budget, how many different varieties of
participants you want to include, and how many geographical areas you
want to cover.

Aim to recruit for 3 to 6 groups, depending on the requirements of your
study.

#### How many people do you need?

Group size affects the group dynamic. Too few people, and the discussion
won\'t take off. The meeting will function more like an interview with
multiple interviewees. Too many people, and not everyone will be heard.¬†

Focus groups typically involve 5 to 10 participants, although you can
conduct a focus group with as few as 3 participants. We don't recommend
going over 10, since not only will some participants be overlooked, but
also because larger focus groups tend to take more time and require more
effort from the moderator.

So, if you're conducting a study with 4 focus groups of 6 participants,
you'll need to budget for 24 participants overall.

#### Communications and consent¬†

Make it easy for participants to show up to your study. Send each
participant an email with the following key pieces of information:

-   Time and date---if doing remote research, make sure you give the
    time and date in your participant's time zone.
-   Location---include a map and directions or a link to a video call
    and instructions for joining.
-   Research topic---don't give too much information away, but do remind
    users what the research will be about.

Any research involving humans requires informed consent. Always take
care to explain to participants that you will be recording and
collecting data and how you plan to use it.¬† [Have them sign a
document](https://www.userinterviews.com/blog/ndas-and-informed-consent-for-user-research),
written in plain language, confirming their consent. Repeat this
information at the outset of the session, and verify once again that
everyone is on the same page.¬†

‚Äç

#### Incentives

Pay your participants! (Or compensate them fairly another way, if
cash-based incentives aren't the right option for your audience.)¬†

We wrote a whole [chapter on UX research
incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
and even made [this handy incentive
calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
to help you figure out the right amount to offer people as a reward for
their time and expertise.¬†

On average, you should plan to compensate each participant at a rate of
\$100 per hour for in-person focus group studies or \$80 an hour for
online studies.¬†

If you're targeting professionals by industry, that rate goes up to
\$125 for an in-person study or \$100 for an online focus group.

### Use the UX Research Incentive Calculator for personalized, data-backed incentives recommendations.

[Do the
math](https://www.userinterviews.com/lp/ux-research-incentive-calculator)

### Moderating a focus group session

As Demetrius Madrigal and Bryan McClain write in
[UXmatters](https://www.uxmatters.com/mt/archives/2011/07/dos-and-donts-for-focus-groups.php):

"A good focus-group session flirts at the edge of chaos."

A moderator\'s job is not to ask questions and get answers the way an
interviewer does. Instead, facilitating a focus group involves using
questions, group exercises, and other techniques to get the discussion
going and keep it going.¬†

The trickiest part of moderating is making sure that everyone gets to
speak and that one or two dominant voices don't end up monopolizing the
conversation. It also takes great skill to keep a discussion on track
without seeming overbearing.

Nielsen Norman Group
[explains](https://www.nngroup.com/articles/focus-groups/):

For participants, the focus-group session should feel free-flowing and
relatively unstructured, but in reality, the moderator must follow a
preplanned script of specific issues and set goals for the type of
information to be gathered. During the group session, the moderator has
the difficult job of keeping the discussion on track without inhibiting
the flow of ideas and comments.

#### Best practices for moderating a focus group

-   The conversation should be both audio and video recorded, since
    group discussions are too complex for effective note-taking. Remind
    participants at the beginning of the session that they are being
    recorded.
-   Treat your discussion guide as just that---a guide---not a script.
    If you try sticking to a script, you'll likely find yourself at odds
    with the tone and flow of the conversation. As with one-on-one
    interviews, create a loose guide to help you stay on track, but
    don't expect to follow it by the letter.
-   Begin each session with a round of introductions. You first---tell
    participants a little bit about yourself, to model the kinds of
    answers you'd like to hear. You might also consider doing a couple
    brief warm up exercises unrelated to the topic at hand. Talking in a
    group can be intimidating (for some folks more than others) so give
    people a chance to loosen up before launching into the research.
-   Don't fly solo. Focus group sessions should only have one moderator
    (otherwise things can get messy, fast). But that doesn't mean you
    have to handle everything on your own. Ask a member of your team to
    help by taking notes, keeping an eye on the time, and being a second
    pair of eyes and ears.
-   Be aware of who the dominant group members are---people with strong
    personalities who have an outsized influence on the conversation. If
    it seems like one or two participants are getting all the airtime,
    be prepared to politely but firmly redirect the discussion to
    another participant.¬†

#### How to write a focus group discussion guide¬†

Writing a focus group discussion guide is, in many ways, similar to
writing an interview guide. The difference, of course, is that you're
writing questions that will be answered by multiple people in the same
session and that will, ideally, spark conversations in which you become
an active observer.

[As with user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
think of your list of discussion questions as a guide, not a script.
Keep your list of must-asks brief---otherwise you may not get to them
all.¬†

Try to anticipate how the conversation might go. Participants might have
difficulty answering a certain question, or you may be eager to dig
deeper into a topic if the conversation allows. Create a list of
followup questions in case you need them.¬†

Although it's impossible to predict how any discussion will play out, do
your best to anticipate moments where you might need to rein things back
in. Be prepared by coming up with a game plan and a few key phrases for
dealing with different types of disruptions.

A few more rules of thumb for writing focus group questions:

-   Don't ask about hypothetical scenarios---focus on direct (past)
    experiences, perceptions, and opinions.¬†
-   Keep things open-ended. Yes/no questions can quickly kill the flow
    of a conversation.
-   Avoid leading questions that hint at the "correct" answer.

‚Äç

#### Sample focus group questions for UX research

‚Äç

**Warm up questions**

Always open with some getting-to-know-you questions. Keep things light,
and let participants get comfortable with each other.¬†

-   What did you do last weekend?
-   What do you do for work?
-   What's your favorite time of day?

**Discovery and context of use questions**

When you're conducting a focus group to gain a broad understanding of
participant motivations, needs, and opinions in order to generate ideas.

-   Tell us a story about the last time you used/did \[X\].
-   What is the hardest part about being a \[persona attribute\]?
-   Think about the last time you did/used \[X\]. How did you feel?

**Usability and interaction questions**

If you're conducting a focus group after usability testing to gather
feedback on a prototype or product, ask open-ended questions like:

-   How would you describe the onboarding experience of this app?
-   What frustrated you the most about this experience?¬†
-   Which version of the support page did you find easier to navigate
    and why?
-   Did anything distract you or get in the way of completing \[task\]?

**Opinion questions**

To understand participants' opinions about a design or experience and
evaluate how pleasing (or not) it is.

-   How would you describe this product?
-   Can you think of any similar products that you've used in the past?
    How do they compare?
-   What changes would make this product more appealing?

‚Äç

#### Focus group activities

Focus groups can involve activities as well as the standard question and
answer format. You might try working in one of these activities to add
variety to the session and generate additional artifacts.

Group activities ideas for focus groups include:

-   Drawing pictures
-   Fill-in-the-blank worksheets
-   Word associations
-   Card sorting
-   List making
-   Role-playing
-   Answering imaginative questions like "\"if our product were a
    person, what would they be like?\"

## Analyzing focus group data

Analyzing focus group discussion data can be difficult, in part because
there is so much of it. Transcripts alone can run to dozens of pages.

Generally, the [analysis
process](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
must include both the video and the transcript, in order to capture
non-verbal communication and in order to eliminate confusion over who
said what. You'll also likely find yourself referring back to the
session notes taken by your partner.

‚Äç

#### Focus group note taking tips to make analysis easier

Focus groups produce a lot of data, and session recordings can be
difficult to wade through without supplementary notes. Ask your partner
to take notes during the session so you can focus on moderating the
discussion. Have them:

-   Draw a **seating chart** to show where each participant sat during
    the exercise
-   **Record observations** about group dynamics, body language, and
    other things that might not be obvious from an audio recording or
    transcript.
-   Write down **key points and themes** that come out of each question.
-   Try to tag and **code notes** as you go---this will save your team
    time at the end and make it easier to identify patterns in the data
    as they emerge.
-   Capture interesting quotes---including who said what and when. As
    much as possible, try to **record the time** that things happened,
    to make it easier to find that moment in your recordings.

### How to analyze focus group notes and deliverables

‚Äç

#### Review your notes after each session

Immediately after each focus group session, revisit your discussion
guide and try to recall the responses, trends, and questions that arose
from each topic. Use this time to review session notes and any
participant-created materials while your memory is fresh.

Since focus group studies produce so much data from so many different
people, it is useful to write up a simple report or summary after each
session.¬†

‚Äç

#### Use qualitative coding to tabulate the data

Use qualitative data coding to tag the artifacts from each session.
Ideally, you (or your notetaker) will have done some preliminary data
coding in real-time. If not, don't wait until the end of a study---code
your notes and artifacts after each session. If you've been tagging
things as you go, revisit your notes at the end of a study to clean up
your tags.¬† Consult audio or video recordings if something is unclear.

Once all your data has been coded, you'll be able to organize, tabulate,
and analyze patterns and themes by descriptive stats like frequency and
percentage.

‚Äç

#### Analyze focus group data

Analyzing focus group data involves analyzing each session individually,
and then analyzing those reports again in a meta-analysis of key
insights and themes.

Themes or categories that you might use include:

-   Likes and dislikes
-   Emotive words
-   Mental models
-   Problems/issues
-   Ideas/opportunities

When analyzing focus group data, ask yourself:

-   What **words** did people use to talk about a product or experience?
-   Was the participant passionate, happy, angry, etc? What was the
    **intensity of feeling** behind a response?
-   What comments/words/responses occurred most often (**frequency**)?
-   How often did **individual participants** speak? Which participants,
    if any, dominated the discussion?¬†
-   What was the **context** for particular responses? What triggered
    strong feelings?

## Sharing your findings

It's easy to get bogged down in focus group data. Remember that the
value of focus groups lies in their ability to reveal big-picture,
qualitative information about people. Keep that in mind as you run your
analysis. And as always, use your initial research questions as a guide
to analyzing the data.

Similarly, don't try to include every single observation, quote, or
insight in your research report. Keep your deliverables focused on the
key insights, themes, and takeaways that relate back to your study
goals.¬†

If your focus groups involve group activities, including the outputs of
these activities can help illustrate your final report. As with
interviews, sharing video clips and key quotes can help stakeholders
connect with the data in your report. But remember that it's your job as
a researcher to help people make sense of the research---whenever you
include things like participant-made artifacts or quotations, always
contextualize the information for people who weren't in the room.

## Tools for conducting focus groups

Focus groups require recording equipment, first and foremost. You will
definitely want to review footage later. If you are conducting an
in-person focus group, this will involve a video camera (or several) and
a good mic.¬†

For remote focus groups, you'll need a video conferencing tool like
[Zoom](https://www.userinterviews.com/blog/zoom-user-interviews-integration-making-your-workflow-way-easier),
or a specialized solution like one of the ones listed below.

You will also need:

-   A solution for [recruiting, screening, and communicating with
    participants](https://www.userinterviews.com/recruit) (ahem...)
-   A tool for taking notes (Google Sheets/Docs are an accessible and
    low-cost option)
-   Software for [transcribing your
    recordings](https://www.userinterviews.com/blog/user-research-recordings-analysis)
-   And a tool for organizing and analyzing your data.

‚Äç

#### Specialized software for focus groups

-   [Collabito](https://www.collabito.com/) is specially designed for
    online focus groups. Features include live chat, built-in card
    sorting, white boarding, and an onscreen moderator guide.
-   [Recollective](https://recollective.com/)'s Video Focus Groups
    feature supports focus groups of up to 25 participants and includes
    features like mobile support, private chat, and screen sharing.
-   [incling](https://incling.com/platform/) is a qualitative research
    service that offers a proprietary platform with a Live Chat tool for
    focus groups and interviews.
-   [Forsta](https://www.forsta.com/) is a robust enterprise-grade
    platform that offers a webcam focus group feature (formerly
    FocusVision InterVu)¬† and a suite of analysis tools.
-   [CMNTY](https://www.cmnty.com/qualitative-market-research-platform)
    is a market research platform with purpose-made tools for conducting
    video focus groups, moderating forum discussions, and co-creation
    activities.

#### Tools for recording, transcribing, and taking notes

-   [Grain](https://grain.co/how-it-works),¬† [Perfect
    Recall](https://www.perfectrecall.app/), and
    [Otter.ai](https://otter.ai/) are Zoom add-ons that automatically
    create transcripts and make it easy to highlight clips to share with
    your team.
-   [Rev](https://www.rev.com/) -- Since focus group recordings involve
    so many voices, you may find that AI-generated transcripts don't
    quite cut it. Rev delivers human-generated transcription and
    captions that can be more accurate.
-   [Reduct](https://reduct.video/) -- AI-generated transcription, note
    taking, and insight management for user research.
-   [Noted](https://www.notedapp.io/) -- a Mac/iOS app that records
    audio and allows you to take timestamped notes.

#### Tools for qualitative research analysis

-   Research repository tools like
    [Dovetail](https://dovetailapp.com/features/user-research-data-analysis/),
    [Aurelius](https://www.aureliuslab.com/features/), and [Optimal
    Workshop](https://www.optimalworkshop.com/reframer/) include tools
    for transcribing, tagging, and organizing insights.¬†
-   Robust qualitative analysis tools like
    [ATLAS.ti](https://atlasti.com/), [QSR
    NVivo](https://www.qsrinternational.com/), and
    [Maxqda](https://www.maxqda.com/blogpost/maxqda-supports-ethnographic-research)
    can help you make sense of large datasets and turn them into data
    visualizations.

## Hybrid research: Combining focus groups with other methods¬†

Focus groups are rarely used alone, even if the goals of the research
are entirely qualitative.
[Interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
for example, are another qualitative research approach that can be used
to drill into some of the more micro details (the "whys") that focus
groups aren't designed to answer.¬†¬†¬†

Alternatively, a focus group study can be used to develop the parameters
of a quantitative study, such as a survey. On the flip side, you might
conduct a focus group as a follow up to a survey.

## Yes, designing a terrible focus group is easy

But that doesn't mean its inevitable! Focus groups get a bad rap.¬†

It is easy to screw this method up. (If you're determined to do so, we
actually wrote a handy guide on [How to Conduct a Terrible Focus Group
Study for UX
Research.](https://www.userinterviews.com/blog/how-to-conduct-a-terrible-focus-group-study-for-ux-research))
But most of the time, focus groups fail because researchers are using
them to answer the wrong questions.¬†

So long as they're used for the right reasons and moderated by a skilled
and experienced user researcher (like yourself!), focus groups still
deserve a place in the UX research toolkit.

[](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/diary-studies)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/card-sorting)

Next:

Card Sorting

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Discovery Research
Methods](/ux-research-field-guide-module/discovery-methods)

\>

[Focus Groups](/ux-research-field-guide-chapter/focus-groups)

# Focus Groups

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

A focus group might involve plumbers discussing the installation of
shower heads, or pet owners discussing their grievances with fur around
the house, or cancer patients sharing their insights into what it's like
to go through treatment at a certain stage.¬†

Focus groups are not interviews that happen to have multiple respondents
in the same room. Au contraire, the value of a focus group lies in the
group discussion, and the interactions that occur among the members.

This method (which, as we'll discuss, has its detractors) is best used
to explore what people believe, how they feel, and what they perceive.¬†

### In this chapter:

-   What is a focus group?
-   Why do some user researchers hate focus groups?
-   When to use focus groups for UX research
-   How to conduct a focus group
-   Analyzing focus group data
-   Sharing your findings
-   Tools for conducting focus groups
-   Hybrid research: Combining focus groups with other methods¬†

## What is a focus group?

A focus group is a moderated conversation with a group of 5 to 10
participants in which a moderator asks the group a set of questions
about a particular topic. They can be helpful tools for learning about
attitudes, beliefs, desires, and reactions to concepts or designs. Focus
groups typically last from 1 to 2 hours.

Because of their social dimension, focus groups can sometimes be more
effective at uncovering spontaneous reactions or ideas than 1:1 methods
like user interviews. However, there is a risk that participants might
influence each other or inhibit others from sharing honest thoughts or
feedback.¬†

Focus groups are traditionally used by social scientists seeking to
understand group dynamics, or by marketing researchers in order to
obtain feedback about a product or assess perceptions about a brand.

### What decisions do focus groups enable?

‚Äã‚ÄãFocus groups are used to inform vision and strategic decisions. They
provide clarity around a participant\'s big-picture beliefs and
philosophies in order to determine a potential company, product, or
service direction.

They can also be used to inform definition decisions, allowing you to
get early feedback on a potential design direction to determine if it's
worth additional investment or resourcing.

### What are the outputs?

Focus groups can generate a large amount of qualitative data, including
detailed notes, transcripts, audio, and video recordings.

All of this data is then synthesized into recommendations related to
potential product directions or opportunities.

### Benefits of focus groups as a UX research method

Focus groups are a good way to draw out ideas and information that
participants might not be willing or able to share in an interview
setting or through a survey.¬†

Being surrounded by a small group of peers makes many people more
comfortable and more willing to talk, even about sensitive or personal
topics.¬†

The interaction among group members can bring out ideas that were
previously not conscious, or simply taken for granted. The way group
members agree or disagree---either with passion or indifference---can
shed light on how important a certain consideration should or should not
be to your development team.

## Why do some user researchers hate focus groups?

"If I achieve one thing with my time here on earth, I might be content
if that one thing could be burning to the ground the practice of running
focus groups in place of actual user research." --- [Erika
Hall](https://medium.com/mule-design/focus-groups-are-worthless-7d30891e58f1),
Co-founder, Mule Design

Some user researchers really dislike focus groups. And there are plenty
of reasons to be wary of this approach---it's certainly not a method to
use in isolation. Let's go over some of the commonly cited drawbacks:

### Drawbacks and potential pitfalls¬†

‚Äç

#### 1. Focus groups tell you what people say, not what they do.

"The correlation between stated intent and actual behavior is usually
low and negative."¬† --- Gerald Zaltman, How Customers Think

Humans are notoriously bad at predicting their own behaviors,
remembering past events, and conceptualizing abstract ideas. There is a
large gap between what people say and what they do---and group dynamics
can further compound this fact of human nature. If you're trying to get
an accurate read on user behavior or customer purchasing intent, focus
groups are probably the wrong method.¬†

#### 2. Focus groups result in groupthink.

Focus groups trace their roots to the 1930s and 1940s, when they were
used by social scientists to study the effect of WWII propaganda.
Advertisers then adopted the method as a way to understand how consumers
think.

Focus groups are an effective way to study how individuals behave in a
group, and how group dynamics impact perceptions and decision-making. In
other words, focus groups are a useful tool for studying groups of
people.

What they are not good at is uncovering individual thoughts and
feelings. That's because focus groups lead to groupthink, a phenomenon
in which participants unconsciously conform to the opinion of the group
at large. Groupthink is a natural byproduct of group discussion---it's a
means of maintaining social harmony---but it means that focus groups
offer a skewed understanding of individual users' experiences.

#### 3. Dominant personalities overshadow other group members.

We've all been in a meeting or classroom where one or two dominant
voices command the room. (If you can't remember such an occasion,
chances are good that you're one of those voices!)¬†

In a group setting, extroverts and contrarians can easily monopolize the
conversation. Sometimes this means literally talking over other people,
but it isn't always combative.

‚Äç

One or two influential participants often steer a discussion through the
strength of their thoughts and opinions. All it takes is one charming
and persuasive member to declare that wine from the Emilio-Romagna
region is the best wine and suddenly the whole group loves Lambrusco.
(And they would be right to do so, but that\'s beside the point.)

Your audience is likely a fairly even mix of introverts, extroverts, and
folks in the middle of the spectrum. But in a focus group, the voices of
quieter, more reserved personalities often go unheard. Again, if you're
hoping to learn about individuals, focus groups are not the right
method.

#### 4. It takes skill and experience to successfully moderate a focus group.

The success of a focus group depends heavily on the skill of the
moderator.

Group dynamics are tricky. No matter how diligently you prepare or how
thoroughly screen participants, bringing a group of people together is
always a gamble. Personalities might clash, leading to a conflict
between a couple of highly opinionated people. Or sometimes, like a bad
dinner party, there's just no group chemistry no matter how hard your
moderator might try.

### How to mitigate common focus group problems¬†

‚Äç

#### Have participants actually use the product.

If you're conducting a focus group to understand user perceptions and
reactions to a product, give users an opportunity to interact with that
product. Feedback based on actual experience is more accurate and useful
than feedback based on hypothetical scenarios or out-of-context prompts.
Run individual usability tests before participants convene for a focus
group discussion.

#### Screen for introversion/extroversion.

Include questions in your screener survey that will help you identify
introverted and extroverted participants. Ask questions like "Does being
around other people give you energy?" and "Do you prefer to be with
other people or to be alone?"¬†

You might also conduct a screener call with participants to assess their
conversation style---do they dominate the call? How much prompting do
they need to provide detailed answers? Will their voice be drowned out
in a group?

¬†

It's impossible to predict how any group of people will interact when it
comes down to it, but you can do your best to create a balanced group
that won't feel like hostile territory for the introverts involved. You
might also consider conducting a group with only self-identified
introverts.

#### Try conducting video focus groups online.

Moving your focus groups to an online setting can mitigate the effects
of group dynamics. Seasoned user researcher [Jay Eskenazi
suggests](https://uxmag.com/articles/how-to-fix-the-5-most-common-mistakes-with-focus-groups)
using a platform that allows participants to share their responses with
moderators privately, before they see the responses of other group
members. This ensures that their responses are "uncontaminated by group
dynamics."¬†

## When to use a focus group for UX research

With so many cons and caveats, are focus groups ever worth it?¬†

They can be!

In fact, oftentimes the reason focus groups fail is because researchers
try to use them to answer the wrong questions or during the wrong stage
in product development.¬†

Focus groups are meant to uncover perceptions, not behaviors. Group
dynamics can be a great way to learn about perceptions because
conversations can reveal things that a one-on-one interview might not.

#### Use focus groups to:

-   Identify or clarify research questions during the earliest stages of
    a research project.
-   Gain insight into how people talk about a problem, product, or
    shared experience in a group setting.
-   Learn about users' opinions, attitudes, and preferences after they
    have used a prototype.

## How to conduct a focus group

‚Äç

First things first:

‚Äç

#### What are your research goals?

As we discussed above, focus groups often fail because researchers use
them to answer the wrong types of research questions.¬†

Before you spend time and money on planning, recruiting, and conducting
a focus group study, make sure it's really the right method to meet your
needs! Remember: Focus groups can help you uncover perceptions and
opinions, not behaviors.¬†

Read the chapter on [**How to Create a User Research
Plan**](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
for a step-by-step guide to coming up with effective research goals and
questions. A good research question is:¬†

-   Specific (so you'll know when you have found an answer)¬†
-   Practical (you can reasonably find answers in the scope of a
    research project)
-   Actionable (your team will be able to make decisions based on your
    learnings)

#### Where will the group meet?

If you're conducting a focus group online, your biggest logistical
considerations will be deciding on a platform, sending each participant
a link and instructions on how to join the group, and troubleshooting
any technical issues along the way.

For in-person focus groups, location plays a much larger role in the
planning process.

The decision is partially a matter of logistics---you need some place
everyone can get to, and you need a comfortable room of the right size
that is free of distracting noises. If you'd like to observe from behind
a two-way mirror, you'll want to invite participants to a lab (either
your own, or a [rented space](https://breather.com/)).¬†

Location can also impact group dynamics, and different people feel
comfortable in different kinds of places. For example, businesspeople
will find the conference room at a hotel comfortingly familiar, whereas
another group of participants might prefer a ring of folding chairs in a
space that feels like a church basement or a classroom.¬†

The question is: Under what circumstances do these people normally sit
around and talk about this subject? Try to mimic those circumstances as
closely as possible---nobody likes to feel like fish out of water.

**Always visit a location before to check:¬†**

-   Is the room easy to find? If not, find or create a map.
-   Is the building easy to find?
-   Is there affordable parking nearby?
-   Are there clean and accessible toilets onsite?
-   Does the building have an elevator?
-   Is the temperature comfortable? Is it air-conditioned or heated, as
    the case may be?
-   Is anything problematic likely to be happening in or near the venue
    during your group meeting? For example, is an unrelated convention
    likely to make the place confusing, crowded, or noisy? Is a sports
    game or college commencement nearby likely to snarl up traffic?

#### Who will moderate?

Focus groups require experienced moderators with strong [interviewing
skills](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
and the ability to bring a group back to center if things veer off
course. If a moderator is too passive, the group can get lost in its own
momentum and veer off topic. Too leading, and your results will be
skewed. Awkward, and the participants won't feel comfortable. Overly
confident, and they could be perceived as domineering and off putting.¬†

Good moderators have:

-   Some background knowledge or direct experience with the subject at
    hand
-   Energy and enthusiasm for the discussion
-   The ability to encourage quiet participants and rein in strong
    personalities
-   A good memory for names and details
-   Experience interviewing participants¬†

### Recruiting participants for a focus group

As with other research methods like user interviews, the first step of
recruitment involves identifying the participants you need.¬†

Ask yourself: Who can answer my research questions?

If you have a sense of your product's target personas, there may be an
opportunity to match your participants with those personalities.¬†

If you're in earlier stages of development, aim for a highly diverse
population within your product's target market. All sorts of people wear
sneakers, for example, so a focus group on sneakers would be very
diverse indeed: a whole spectrum of sneaker-wearers could be included. A
focus group on tie clips and cufflinks, on the other hand, might look a
bit more homogenous. If your target audience is tighter, you might need
fewer groups overall.

In either case, your focus group participants need to have something in
common in order for the discussion to provide you with actionable
insights.

‚Äç

When creating [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
to filter for good-fit participants, always second-guess your
participant criteria: Does gender matter? Income? Education level? Race?
While demographics might influence the way people experience a product,
most of the time these factors don't prevent someone from being able to
answer your research question.¬†

If you're interested in how experiences differ across populations, you
can collect demographic data without screening on it.

Pro tip: Many recruiting services, including [User
Interviews](https://www.userinterviews.com/recruit), already collect
(with ¬†consent) data on participants about things like race, ethnicity,
income, education, and location. Unless you're filtering by one of these
factors, don't need to include these questions in your screener.

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

#### How many groups do you need?

The more groups you have, the more ideas and opinions you will collect,
but this is helpful only up to a point. How many groups your study will
need depends on your budget, how many different varieties of
participants you want to include, and how many geographical areas you
want to cover.

Aim to recruit for 3 to 6 groups, depending on the requirements of your
study.

#### How many people do you need?

Group size affects the group dynamic. Too few people, and the discussion
won\'t take off. The meeting will function more like an interview with
multiple interviewees. Too many people, and not everyone will be heard.¬†

Focus groups typically involve 5 to 10 participants, although you can
conduct a focus group with as few as 3 participants. We don't recommend
going over 10, since not only will some participants be overlooked, but
also because larger focus groups tend to take more time and require more
effort from the moderator.

So, if you're conducting a study with 4 focus groups of 6 participants,
you'll need to budget for 24 participants overall.

#### Communications and consent¬†

Make it easy for participants to show up to your study. Send each
participant an email with the following key pieces of information:

-   Time and date---if doing remote research, make sure you give the
    time and date in your participant's time zone.
-   Location---include a map and directions or a link to a video call
    and instructions for joining.
-   Research topic---don't give too much information away, but do remind
    users what the research will be about.

Any research involving humans requires informed consent. Always take
care to explain to participants that you will be recording and
collecting data and how you plan to use it.¬† [Have them sign a
document](https://www.userinterviews.com/blog/ndas-and-informed-consent-for-user-research),
written in plain language, confirming their consent. Repeat this
information at the outset of the session, and verify once again that
everyone is on the same page.¬†

‚Äç

#### Incentives

Pay your participants! (Or compensate them fairly another way, if
cash-based incentives aren't the right option for your audience.)¬†

We wrote a whole [chapter on UX research
incentives](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
and even made [this handy incentive
calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
to help you figure out the right amount to offer people as a reward for
their time and expertise.¬†

On average, you should plan to compensate each participant at a rate of
\$100 per hour for in-person focus group studies or \$80 an hour for
online studies.¬†

If you're targeting professionals by industry, that rate goes up to
\$125 for an in-person study or \$100 for an online focus group.

### Use the UX Research Incentive Calculator for personalized, data-backed incentives recommendations.

[Do the
math](https://www.userinterviews.com/lp/ux-research-incentive-calculator)

### Moderating a focus group session

As Demetrius Madrigal and Bryan McClain write in
[UXmatters](https://www.uxmatters.com/mt/archives/2011/07/dos-and-donts-for-focus-groups.php):

"A good focus-group session flirts at the edge of chaos."

A moderator\'s job is not to ask questions and get answers the way an
interviewer does. Instead, facilitating a focus group involves using
questions, group exercises, and other techniques to get the discussion
going and keep it going.¬†

The trickiest part of moderating is making sure that everyone gets to
speak and that one or two dominant voices don't end up monopolizing the
conversation. It also takes great skill to keep a discussion on track
without seeming overbearing.

Nielsen Norman Group
[explains](https://www.nngroup.com/articles/focus-groups/):

For participants, the focus-group session should feel free-flowing and
relatively unstructured, but in reality, the moderator must follow a
preplanned script of specific issues and set goals for the type of
information to be gathered. During the group session, the moderator has
the difficult job of keeping the discussion on track without inhibiting
the flow of ideas and comments.

#### Best practices for moderating a focus group

-   The conversation should be both audio and video recorded, since
    group discussions are too complex for effective note-taking. Remind
    participants at the beginning of the session that they are being
    recorded.
-   Treat your discussion guide as just that---a guide---not a script.
    If you try sticking to a script, you'll likely find yourself at odds
    with the tone and flow of the conversation. As with one-on-one
    interviews, create a loose guide to help you stay on track, but
    don't expect to follow it by the letter.
-   Begin each session with a round of introductions. You first---tell
    participants a little bit about yourself, to model the kinds of
    answers you'd like to hear. You might also consider doing a couple
    brief warm up exercises unrelated to the topic at hand. Talking in a
    group can be intimidating (for some folks more than others) so give
    people a chance to loosen up before launching into the research.
-   Don't fly solo. Focus group sessions should only have one moderator
    (otherwise things can get messy, fast). But that doesn't mean you
    have to handle everything on your own. Ask a member of your team to
    help by taking notes, keeping an eye on the time, and being a second
    pair of eyes and ears.
-   Be aware of who the dominant group members are---people with strong
    personalities who have an outsized influence on the conversation. If
    it seems like one or two participants are getting all the airtime,
    be prepared to politely but firmly redirect the discussion to
    another participant.¬†

#### How to write a focus group discussion guide¬†

Writing a focus group discussion guide is, in many ways, similar to
writing an interview guide. The difference, of course, is that you're
writing questions that will be answered by multiple people in the same
session and that will, ideally, spark conversations in which you become
an active observer.

[As with user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
think of your list of discussion questions as a guide, not a script.
Keep your list of must-asks brief---otherwise you may not get to them
all.¬†

Try to anticipate how the conversation might go. Participants might have
difficulty answering a certain question, or you may be eager to dig
deeper into a topic if the conversation allows. Create a list of
followup questions in case you need them.¬†

Although it's impossible to predict how any discussion will play out, do
your best to anticipate moments where you might need to rein things back
in. Be prepared by coming up with a game plan and a few key phrases for
dealing with different types of disruptions.

A few more rules of thumb for writing focus group questions:

-   Don't ask about hypothetical scenarios---focus on direct (past)
    experiences, perceptions, and opinions.¬†
-   Keep things open-ended. Yes/no questions can quickly kill the flow
    of a conversation.
-   Avoid leading questions that hint at the "correct" answer.

‚Äç

#### Sample focus group questions for UX research

‚Äç

**Warm up questions**

Always open with some getting-to-know-you questions. Keep things light,
and let participants get comfortable with each other.¬†

-   What did you do last weekend?
-   What do you do for work?
-   What's your favorite time of day?

**Discovery and context of use questions**

When you're conducting a focus group to gain a broad understanding of
participant motivations, needs, and opinions in order to generate ideas.

-   Tell us a story about the last time you used/did \[X\].
-   What is the hardest part about being a \[persona attribute\]?
-   Think about the last time you did/used \[X\]. How did you feel?

**Usability and interaction questions**

If you're conducting a focus group after usability testing to gather
feedback on a prototype or product, ask open-ended questions like:

-   How would you describe the onboarding experience of this app?
-   What frustrated you the most about this experience?¬†
-   Which version of the support page did you find easier to navigate
    and why?
-   Did anything distract you or get in the way of completing \[task\]?

**Opinion questions**

To understand participants' opinions about a design or experience and
evaluate how pleasing (or not) it is.

-   How would you describe this product?
-   Can you think of any similar products that you've used in the past?
    How do they compare?
-   What changes would make this product more appealing?

‚Äç

#### Focus group activities

Focus groups can involve activities as well as the standard question and
answer format. You might try working in one of these activities to add
variety to the session and generate additional artifacts.

Group activities ideas for focus groups include:

-   Drawing pictures
-   Fill-in-the-blank worksheets
-   Word associations
-   Card sorting
-   List making
-   Role-playing
-   Answering imaginative questions like "\"if our product were a
    person, what would they be like?\"

## Analyzing focus group data

Analyzing focus group discussion data can be difficult, in part because
there is so much of it. Transcripts alone can run to dozens of pages.

Generally, the [analysis
process](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
must include both the video and the transcript, in order to capture
non-verbal communication and in order to eliminate confusion over who
said what. You'll also likely find yourself referring back to the
session notes taken by your partner.

‚Äç

#### Focus group note taking tips to make analysis easier

Focus groups produce a lot of data, and session recordings can be
difficult to wade through without supplementary notes. Ask your partner
to take notes during the session so you can focus on moderating the
discussion. Have them:

-   Draw a **seating chart** to show where each participant sat during
    the exercise
-   **Record observations** about group dynamics, body language, and
    other things that might not be obvious from an audio recording or
    transcript.
-   Write down **key points and themes** that come out of each question.
-   Try to tag and **code notes** as you go---this will save your team
    time at the end and make it easier to identify patterns in the data
    as they emerge.
-   Capture interesting quotes---including who said what and when. As
    much as possible, try to **record the time** that things happened,
    to make it easier to find that moment in your recordings.

### How to analyze focus group notes and deliverables

‚Äç

#### Review your notes after each session

Immediately after each focus group session, revisit your discussion
guide and try to recall the responses, trends, and questions that arose
from each topic. Use this time to review session notes and any
participant-created materials while your memory is fresh.

Since focus group studies produce so much data from so many different
people, it is useful to write up a simple report or summary after each
session.¬†

‚Äç

#### Use qualitative coding to tabulate the data

Use qualitative data coding to tag the artifacts from each session.
Ideally, you (or your notetaker) will have done some preliminary data
coding in real-time. If not, don't wait until the end of a study---code
your notes and artifacts after each session. If you've been tagging
things as you go, revisit your notes at the end of a study to clean up
your tags.¬† Consult audio or video recordings if something is unclear.

Once all your data has been coded, you'll be able to organize, tabulate,
and analyze patterns and themes by descriptive stats like frequency and
percentage.

‚Äç

#### Analyze focus group data

Analyzing focus group data involves analyzing each session individually,
and then analyzing those reports again in a meta-analysis of key
insights and themes.

Themes or categories that you might use include:

-   Likes and dislikes
-   Emotive words
-   Mental models
-   Problems/issues
-   Ideas/opportunities

When analyzing focus group data, ask yourself:

-   What **words** did people use to talk about a product or experience?
-   Was the participant passionate, happy, angry, etc? What was the
    **intensity of feeling** behind a response?
-   What comments/words/responses occurred most often (**frequency**)?
-   How often did **individual participants** speak? Which participants,
    if any, dominated the discussion?¬†
-   What was the **context** for particular responses? What triggered
    strong feelings?

## Sharing your findings

It's easy to get bogged down in focus group data. Remember that the
value of focus groups lies in their ability to reveal big-picture,
qualitative information about people. Keep that in mind as you run your
analysis. And as always, use your initial research questions as a guide
to analyzing the data.

Similarly, don't try to include every single observation, quote, or
insight in your research report. Keep your deliverables focused on the
key insights, themes, and takeaways that relate back to your study
goals.¬†

If your focus groups involve group activities, including the outputs of
these activities can help illustrate your final report. As with
interviews, sharing video clips and key quotes can help stakeholders
connect with the data in your report. But remember that it's your job as
a researcher to help people make sense of the research---whenever you
include things like participant-made artifacts or quotations, always
contextualize the information for people who weren't in the room.

## Tools for conducting focus groups

Focus groups require recording equipment, first and foremost. You will
definitely want to review footage later. If you are conducting an
in-person focus group, this will involve a video camera (or several) and
a good mic.¬†

For remote focus groups, you'll need a video conferencing tool like
[Zoom](https://www.userinterviews.com/blog/zoom-user-interviews-integration-making-your-workflow-way-easier),
or a specialized solution like one of the ones listed below.

You will also need:

-   A solution for [recruiting, screening, and communicating with
    participants](https://www.userinterviews.com/recruit) (ahem...)
-   A tool for taking notes (Google Sheets/Docs are an accessible and
    low-cost option)
-   Software for [transcribing your
    recordings](https://www.userinterviews.com/blog/user-research-recordings-analysis)
-   And a tool for organizing and analyzing your data.

‚Äç

#### Specialized software for focus groups

-   [Collabito](https://www.collabito.com/) is specially designed for
    online focus groups. Features include live chat, built-in card
    sorting, white boarding, and an onscreen moderator guide.
-   [Recollective](https://recollective.com/)'s Video Focus Groups
    feature supports focus groups of up to 25 participants and includes
    features like mobile support, private chat, and screen sharing.
-   [incling](https://incling.com/platform/) is a qualitative research
    service that offers a proprietary platform with a Live Chat tool for
    focus groups and interviews.
-   [Forsta](https://www.forsta.com/) is a robust enterprise-grade
    platform that offers a webcam focus group feature (formerly
    FocusVision InterVu)¬† and a suite of analysis tools.
-   [CMNTY](https://www.cmnty.com/qualitative-market-research-platform)
    is a market research platform with purpose-made tools for conducting
    video focus groups, moderating forum discussions, and co-creation
    activities.

#### Tools for recording, transcribing, and taking notes

-   [Grain](https://grain.co/how-it-works),¬† [Perfect
    Recall](https://www.perfectrecall.app/), and
    [Otter.ai](https://otter.ai/) are Zoom add-ons that automatically
    create transcripts and make it easy to highlight clips to share with
    your team.
-   [Rev](https://www.rev.com/) -- Since focus group recordings involve
    so many voices, you may find that AI-generated transcripts don't
    quite cut it. Rev delivers human-generated transcription and
    captions that can be more accurate.
-   [Reduct](https://reduct.video/) -- AI-generated transcription, note
    taking, and insight management for user research.
-   [Noted](https://www.notedapp.io/) -- a Mac/iOS app that records
    audio and allows you to take timestamped notes.

#### Tools for qualitative research analysis

-   Research repository tools like
    [Dovetail](https://dovetailapp.com/features/user-research-data-analysis/),
    [Aurelius](https://www.aureliuslab.com/features/), and [Optimal
    Workshop](https://www.optimalworkshop.com/reframer/) include tools
    for transcribing, tagging, and organizing insights.¬†
-   Robust qualitative analysis tools like
    [ATLAS.ti](https://atlasti.com/), [QSR
    NVivo](https://www.qsrinternational.com/), and
    [Maxqda](https://www.maxqda.com/blogpost/maxqda-supports-ethnographic-research)
    can help you make sense of large datasets and turn them into data
    visualizations.

## Hybrid research: Combining focus groups with other methods¬†

Focus groups are rarely used alone, even if the goals of the research
are entirely qualitative.
[Interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
for example, are another qualitative research approach that can be used
to drill into some of the more micro details (the "whys") that focus
groups aren't designed to answer.¬†¬†¬†

Alternatively, a focus group study can be used to develop the parameters
of a quantitative study, such as a survey. On the flip side, you might
conduct a focus group as a follow up to a survey.

## Yes, designing a terrible focus group is easy

But that doesn't mean its inevitable! Focus groups get a bad rap.¬†

It is easy to screw this method up. (If you're determined to do so, we
actually wrote a handy guide on [How to Conduct a Terrible Focus Group
Study for UX
Research.](https://www.userinterviews.com/blog/how-to-conduct-a-terrible-focus-group-study-for-ux-research))
But most of the time, focus groups fail because researchers are using
them to answer the wrong questions.¬†

So long as they're used for the right reasons and moderated by a skilled
and experienced user researcher (like yourself!), focus groups still
deserve a place in the UX research toolkit.

[](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/diary-studies)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/card-sorting)

Next:

Card Sorting

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

![a group of people sorting through graphs, charts, and browser windows
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f2d7936eb9c54df303ad_UI_CHAPTER_06_ARTWORK.jpg)

06\.

# Evaluative Research Methods

A new edition of this module is coming soon! Subscribe to get notified.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Evaluative research is all about validating your concepts, testing your
prototypes, and knowing whether or not your project is on the right
track.¬†

‚Äç

UX researchers use evaluative methods---which include both qualitative
and quantitative methods---to answer questions about conceptual fit and
the usability of a product.

‚Äç

The data collected through this type of research helps validate design
direction, informs changes, and enables product teams to execute on user
feedback.

‚Äç

In this module, you'll learn all about conducting:

-   **Qualitative usability testing**, a popular UXR method in which
    participants think aloud as they interact with a prototype or
    product.
-   **Preference testing.** This method is used to find out which
    version of a design people like better.
-   **Surveys,** a deceptively simple process for collecting data from
    respondents through a questionnaire.
-   **Tree testing,** a technique for testing your information
    architecture (IA). Tree testing often follows card sorting.
-   **First click testing,** which is just what it sounds like. First
    click studies help assess the usability of a product by whether
    users are able to efficiently complete a task.
-   **Task analysis.** This method, which is often paired with other
    methods, helps you understand user goals and the steps they take to
    achieve them.
-   **A/B testing,** for when you need to know which version of your
    product performs better in a test.

[Start
reading](/ux-research-field-guide-chapter/qualitative-usability-testing)[Start
reading](/ux-research-field-guide-module/continuous-research-methods)

In this module:

New edition arriving January 2022!

[Usability
Testing](/ux-research-field-guide-chapter/qualitative-usability-testing)

The best method for answering the question: Can people actually use this
thing?

[Preference
Testing](/ux-research-field-guide-chapter/preference-testing)

New

New

New

Subjective but useful tests for measuring user opinions about your
designs.

[Surveys](/ux-research-field-guide-chapter/surveys)

New

New

New

How to use this (deceptively simple) research method correctly.

[Tree Testing](/ux-research-field-guide-chapter/tree-testing)

Understand your information architecture by watching your users swing
from branch to branch.

[First Click
Testing](/ux-research-field-guide-chapter/first-click-testing)

First click, best click---or at least, it better be. When the first
click fails, the rest of the session tends to tank as well.

[Task Analysis](/ux-research-field-guide-chapter/task-analysis)

Break it down for me---understand how users accomplish and think about
complex tasks.

[A/B Testing](/ux-research-field-guide-chapter/a-b-testing)

Apples or oranges? Night or day? Big or small? A/B testing will help you
decide which variable is better.

[](#)

**Coming Soon** To this module:

##### Usability Testing

The best method for answering the question: Can people actually use this
thing?

##### Preference Testing

New

New

New

Subjective but useful tests for measuring user opinions about your
designs.

##### Surveys

New

New

New

How to use this (deceptively simple) research method correctly.

##### Tree Testing

Understand your information architecture by watching your users swing
from branch to branch.

##### First Click Testing

First click, best click---or at least, it better be. When the first
click fails, the rest of the session tends to tank as well.

##### Task Analysis

Break it down for me---understand how users accomplish and think about
complex tasks.

##### A/B Testing

Apples or oranges? Night or day? Big or small? A/B testing will help you
decide which variable is better.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/continuous-research-methods)

07\.

### Continuous Research Methods

[](/ux-research-field-guide-module/research-analysis-synthesis)

08\.

### UX Research Analysis and Synthesis

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[Usability
Testing](/ux-research-field-guide-chapter/qualitative-usability-testing)

# Usability Testing

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

For most researchers, usability testing is deeply ingrained in what we
do. It's the process of seeing how "usable" your product is. Sometimes
it means seeing how easy it is for website visitors to find a button or
a piece of information. Sometimes usability has meanings that are more
complex or esoteric, depending on what you're building. But testing for
usability will always involve exploring how well (or not) your target
audience is able to accomplish the things you want them to be able to
do, which (hopefully) are more or less the same things they want to
accomplish.

## How does usability testing work?

Generally, researchers will ask participants to attempt a series of
assigned tasks, and then observe and record how well they can accomplish
those tasks. Their ability to do the things you want them to do informs
your next steps---namely, whether to make changes to your design or not,
and which changes to make.

‚Äç

Usability testing can have both qualitative and quantitative elements,
which we'll get to below.

‚Äç

You don't need a special lab or facility to conduct a usability test,
though you can use one if it feels like the best choice. Lots of folks
use a conference room or even run them remotely from their home office.
We'll get more into the nitty gritty of this below as well.

‚Äç

Usability tests are most often conducted by a moderator. The moderator
comes ready with a list of pre-determined tasks they'd like the
participants to try to execute in order to put the product or
[prototype](https://www.userinterviews.com/blog/best-prototype-templates-examples)
through its paces. If the tester can\'t do the thing, or has trouble
doing the thing, it means your design needs some work.

‚Äç

Usability testing can test any aspect of your product\'s function, but
that doesn\'t mean you want to do it all in one go. Each usability test,
for clarity of results and organization of ideas, should be organized
around specific questions. This will keep your test and its results
manageable.

‚Äç

After the test is done, you'll gather and analyze data, and then make
choices about the best next-steps.

‚Äç

### When does usability testing make sense?

You\'ll want to run usability testing when you have a specific question
that a test can help to answer. There are many different types of
questions you can ask.

‚Äç

For example:

-   We want users to be able to find the information they're looking for
    through several different paths---through search, through
    navigation, through tags. Does each path work effectively?

```{=html}
<!-- -->
```
-   We want users to be able to complete a purchase---from product to
    payment---in under 4 clicks.

```{=html}
<!-- -->
```
-   Uploading is the most important action, and so we want the upload
    button to be the most obvious thing on the page.

```{=html}
<!-- -->
```
-   In the case of a game: We want users to be able to jump and crouch
    on this level.

```{=html}
<!-- -->
```
-   In the case of a service: After users are drawn to our touch-screen
    kiosk, we want them to be enticed to first tap on the "start"
    feature.

‚Äç

Before you leap into testing, you should already have a functional
versions or
[prototypes](https://www.userinterviews.com/blog/best-prototyping-tools)
of your product. This means that usability test isn't an appropriate
method for the discovery phase. However, it is appropriate for just
about every stage after discovery. It's often employed at all levels of
a product's release, just as soon as you can interact with it, until
long after its initial launch, in order to improve and optimize.

‚Äç

![quantitative vs. qualitative by matt p
lavoie](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5c1a87605058957a9852a2c6_Quant%2BQual%2BCartoon%2B%40MattPLavoie.png)

A quick illustration of Quantitative vs. Qualitative by [**Matt P.
Lavoie**](http://www.mattplavoie.com/#/resources/)

‚Äç

### Qualitative vs. quantitative usability testing

Usability testing can be qualitative, quantitative, or both. The
difference lies in the questions you need answered.

‚Äç

#### Quantitative

Quantitative data is numeric. Analysis is primarily statistical and can
be entirely objective; an average success rate for a given task will be
the same no matter who calculates the average. Research subjects (in
this case, your test participants) are a representative sample of a
larger population, so the results can be applied to the entire
population. For example, quantitative testing can tell you that X% of
users have trouble with a certain function.

‚Äç

#### Qualitative

Qualitative data is not numeric, but may be narrative or descriptive.
Analysis involves extracting usable information from the data in a way
that minimizes bias. For example, the raw data might be narrative
descriptions of a tester attempting a series of tasks. The analyzed
results would then consist of a report on which aspects of which tasks
the tester had trouble with and what kind of trouble it was. Qualitative
analysis yields results that can\'t be applied to the entire population,
but instead provides insights that help explain the quantitative
results. Qualitative data can tell you why users might have trouble, for
example.

‚Äç

#### Qualitative results in usability studies

There is rarely such a thing as a quantitative-only usability test. You
can't help but observe nuance as you watch a user interact with your
product. Observing people try to do a thing for the first time that you
already know how to do is bound to engender observations that are
amusing, frustrating, surprising, the whole gamut. This sort of
qualitative material can help you get at the why behind your
quantitative results.

‚Äç

The main challenge of qualitative data in usability studies will be to
avoid drawing conclusions that would require quantitative data and
statistical analysis. For example, if all seven of your testers sail
through all their tasks easily, it would be natural to conclude that
your product is perfect because \"everyone\" can use it, no problem. The
human mind instinctively draws conclusions about what is normal or
likely based on what you experience and what you hear about from others.
But the reason we invented statistics is that our instinctive
conclusions are sometimes very wrong.

‚Äç

## Conducting a qualitative usability test

Conducting usability testing isn\'t difficult, but there can be a lot of
moving parts, so proper planning and attention to detail are a good
idea, especially when you're new to it!

‚Äç

### Planning for the test

Not every moderator is great at thinking on the fly, or knows the
product well enough to be able to ad-lib. Planning for various
eventualities can be a roadmap for the conversation. A clearly-written
plan will also help you explain the goals of the test to your team, and
help you achieve buy-in, if you need that. There are a number of points
your plan should include, from the scope of the test to the number of
testers, and we outline them all right now.

‚Äç

#### Define the scope and purpose

What do you want to learn from this test and how many of your product's
qualities and features do you need to probe to get that information?

‚Äç

To figure out what parts of your product to prioritize for testing, you
might wish to explore\...

‚Äç

When [testing a
prototype](https://www.userinterviews.com/blog/prototype-testing-process):

-   What concerned the development team during the design and build
    process?
-   Are there features that involved compromise or conflict between
    teams or key players during the build and design?
-   Are there aspects of the design you're just not sure about?
-   Have you reinvented the wheel somewhere to try to be innovative and
    cool, but you're just not sure it'll work?

‚Äç

When testing a live product:

-   Which features get the most use from users enjoying the product?
-   Which features contribute most directly toward your product's
    mission or end goal?

‚Äç

In a redesign/rebuild:

-   Which features are new, unique, tricky?
-   What are people [**complaining about with support or
    sales**](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)
    or in the form of bugs?

‚Äç

If you're getting lost in the soup as you define test goals, return to
your product goals. That's ground zero and can continue you to guide
your research goals for usability testing and beyond.

‚Äç

#### Location and equipment

You can conduct your test in a lab, in a meeting room or office,
anywhere else that will make for a good place to observe users
interacting with your product. You can go to them, or they can come to
you, or you can observe remotely.

‚Äç

Many usability tests are done in a lab setting where observers (your
team) sits out of the way---sometimes behind police-station-style
two-way mirrors, and the moderator sits in the testing area with the
participant. The participants generally know they're being watched, but
they can't see or hear the team behind the glass.

‚Äç

Remote/online usability tests are also a great option, especially if
your business caters to niche audiences that can be spread across the
world. Remote tests can save time and lots of money. They might
sacrifice some of the intimacy the lab-setting will afford, but the ease
of remote testing more than makes up for anything that might get lost.

‚Äç

Once you decide on the best approach, any other logistical requirements
will, for the most part, become obvious.

‚Äç

The test might require nothing besides your tester, the device with your
product or prototype on it, and a couple of clipboards and pens so your
observers can take notes. Or, you might need multiple recording devices
(if raw results will need to be shared with a distributed team, say),
screen capture software, refreshments....

‚Äç

#### Scheduling

You'll choose which days and times work best for your teams and testers.
You can plan your day/s of testing ahead of time if you figure out how
long each test will take, how many tests you'd like to run per day, and
how much time to leave between testers.

‚Äç

A great starting point to figure your schedule can be: 90 minute testing
sessions, 30 minute breaks between, and as many participants as you can
fit into your day, especially if you're renting a special space.

‚Äç

90 minute sessions tend to be long enough to really allow a tester to
meander through their process without overwhelming or boring the tester,
moderator, or the observers. If you feel a shorter or longer session
might benefit the test, adjust as needed.

‚Äç

#### Staff

Your testing staff will include a moderator and several observers. There
may also be other assistants on hand, such as note-takers or camera
crew. The moderator should be someone with good people skills and enough
insight to steer the conversation where it needs to go. They should be
conscious of tactics they can use to avoid bias during the interview.
Most of all, they should be a comfortable and skilled interviewer.

‚Äç

You might hire someone for the task---a professional moderator who you
educate about your product and goals. Or, it could be someone on your
team who's good with people and also already knows the product. It might
be you! Or it might be one of your researchers. Whoever it is will set
the tone for the study.

‚Äç

The observers won't interact with the tester, so you can bring anyone in
to observe who wants to benefit from the research. Observers can also
guide the moderator during or between sessions, so key stakeholders
should be included.

‚Äç

#### Metrics

To know where to look for data, just look at your test goals. What's the
purpose of the test?

‚Äç

You will have a guide with a list of the tasks you want your tester to
accomplish, and any other relevant questions, and you'll track the
tester as they move through their tasks. For example:

‚Äç

What do you expect to happen when the users click here? What actually
happened? The metric then becomes: the user successfully completed the
task 55% of the time.

‚Äç

At the end, you might want to ask what their overall experience was
like? Fun? Frustrating? The metric becomes: 25% of users were
frustrated, 25% of users had fun, and 50% rated the experience neither
fun nor frustrating.

‚Äç

#### Scenarios

Consider whether to break your test up into sub-tests. For example, if
your product is a game, you might want to test a mobile version and a
desktop version. If your user base is diverse, you might prefer testers
from multiple demographic categories.

‚Äç

#### Testers

When crafting a plan for testers, consider questions like:

-   How many testers do you want overall?
-   How many subjects will you have time for?
-   What criteria do we need for our participants?
-   How are we going to recruit them?
-   How long will the recruitment process take?
-   [**How will we compensate each tester, and is it in the
    budget?**](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)
-   Do we need them to sign a non-disclosure agreement?
-   Other details like: Location, directions, parking

‚Äç

### Recruiting Testers

If you have access to a pool of people typical of your users---like an
established customer base, for example---you can recruit among them. You
can also recruit participants from outside of your established pool.
Either way, you can use [**User
Interviews**](https://www.userinterviews.com/) to find and organize your
participants.

‚Äç

For a qualitative-only usability test, five to ten testers overall makes
sense. More than ten, and you're not likely to reveal anything brand
new. Ten people\'s qualitative data is about as much as you can probably
handle anyway. Remember that if you're doing your own recruiting, some
people won\'t show up---usually 10-20% depending on the methods you're
using to recruit---and others might not complete the test. You\'ll want
to have a pool of a few extra, say 5-10% potential fill-ins.

‚Äç

![usability testing
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5c1acbaf31b7986538571b3a_WhatYouShouldKnowAboutUsabilityTesting01.jpg)

Usability testing is all about learning how your users use your product,
not telling them how you want them to use it.

### Moderating the Test

The moderator is in charge of the test itself, from setting the tone, to
asking questions, to providing the tester with all necessary
information---and no unnecessary information.

‚Äç

#### Types of Moderation

A good moderator will encourage each tester to share their thought
process, to think aloud as it were. There are four basic approaches for
doing so, each with its own advantages and disadvantages. Pick the one
that suits your needs best.

-   **Concurrent Think Aloud (CTA)** means asking the tester to think
    aloud as they work. The only big drawback is that you won\'t find
    out how long the task takes when the user isn\'t talking. Also, not
    everyone is equally aware of their own thought processes.

```{=html}
<!-- -->
```
-   **Retrospective Think Aloud (RTA)** means asking the tester to
    verbally repeat their thinking after the fact. You can show a video
    of the test as a prompt. The risk is that the tester might not
    remember their thought process well.

```{=html}
<!-- -->
```
-   **Concurrent Probing (CP)** means asking the tester \"why?\" as
    needed throughout the test. The repeated interruptions could alter
    the results, but CP might not take as long as CTA.

```{=html}
<!-- -->
```
-   **Retrospective Probing (RP)** means asking detailed questions after
    the fact. Again, recall could be an issue, but your questions may
    help them remember, and the task is never interrupted or delayed.

‚Äç

#### Assigning Tasks

When you give testers a task, state the goal of the task; do not provide
instructions. See if the tester can accomplish the goal. Use clear,
ordinary, non-technical language. If you\'re worried about being clear,
working from a pre-written script helps. Creating numbers for tasks can
help you organize your data later. If the tester does the task the wrong
way, that's information. Don't correct them. Your product is being
tested, not the tester. Though it can be difficult to watch the tester
struggle with the task at hand, it\'s important to let them navigate
through it on their own to gain the best data possible.

‚Äç

#### Taking Notes

The moderator can\'t take notes and moderate at the same time. You can
simplify note taking by including an observer (or observers) to take
notes as the test happens. If you don\'t have observers at your
disposal, you can record your session. If you\'re conducting your test
remotely, you can record directly from your video conferencing service.
Some services, like [**Zoom**](https://zoom.us/?utm_source=zoom.com),
also include auto-transcription services, which can be especially useful
for taking quotes from the interview later.

‚Äç

## Analyzing and Reporting Your Findings

Raw test data is usually your notes from the test, occasionally you will
also have recordings. Before analyzing the data, clean up and expand the
notes so that they would make sense to someone who wasn\'t present for
the test. Use the recordings, if you have them, to expand and enrich the
notes. You can highlight specific moments and bring a little more of the
person you were interviewing to the data. The 30 minute buffer between
your sessions is a great time to do this!

‚Äç

[**Analyzing qualitative
data**](https://www.userinterviews.com/blog/how-to-analyze-qualitative-data-with-the-design-gym)
consists mostly of going through the notes and \"translating\" them into
clear, succinct descriptions of what the tester did and why. If two
testers did essentially the same thing, the descriptions should be the
same so that patterns across testers are clear. Then go through and look
for patterns. Did one task stump everybody? Did it stump them all the
same way, or were there a variety of stumpage types? Are there certain
types of tasks that caused problems, and, if so, how and why? Record all
the patterns you notice.

‚Äç

Based on the patterns you find, you should be able to clearly define a
number of problems that the current version of your product has. Rank
these by severity. Which must be fixed or the product won\'t work? Which
are so frustrating that they could drive away users? And which are mild
enough that, in a pinch, you could go ahead and market your product
without fixing them?

‚Äç

Next, go ahead and write up a report, summarizing how you conducted the
test, what your results were, and what problems (ordered by severity)
you found through analysis. Recommend solutions to each problem. Include
quotes and video clips from your testing sessions to show those who
weren\'t there what your usability problems look like in action. If you
are not going to be in charge of implementing your solutions, it will be
up to you to use the report to make your case for your recommendations.

‚Äç

## Usability testing is a must, not a nice-to-have

Businesses can no longer afford to skip usability testing. A product
should simply not be launched without at least one round of testing to
see whether users are able to interact with the products in the way you
want them to.

‚Äç

There\'s always a chance that test results will expose a serious and
hard-to-solve flaw and send your team all the way back to the drawing
board. It\'s a little intimidating. But as long as you pay attention and
plan properly, usability testing is not actually difficult to execute.
The benefits are well-worth the effort, and in fact, it's now a business
must.

‚Äç

In a best case scenario, you'll discover some aspects of your design
that can be improved, and you'll come away with an idea of how to best
make those improvements. At this point, your design and development
teams should draft some new prototypes and test those again, until
you're satisfied that your product is doing what it needs to do well
enough to launch. There are other factors, like budget, the general
urgency of your team, your pipeline of other projects, and myriad other
business concerns that factor into when a product is ready to launch (or
re-launch). But successful rounds qualitative usability testing should
move the needle in a meaningful way toward launch or continued
improvements to live products.

‚Äç

Remember that coaching users through a product, or trying after the fact
to convince a user why the product is good, doesn\'t work very well and
costs far more money in the end.

### Recruit from our panel of 700,000+ vetted participants

[Sign up for free](https://www.userinterviews.com/recruit) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/preference-testing)

Next:

Preference Testing

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[Preference
Testing](/ux-research-field-guide-chapter/preference-testing)

# Preference Testing

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

UX design is both an art and a science.

‚Äç

Like all art, the creative and emotional elements of UX design can be a
bit tricky to evaluate subjectively. If you ask your users, "which
design is best?" they might choose a design based on personal
preferences that have no bearing on the specific product and business
goals you've set out to achieve.

‚Äç

Preference testing can help you err on the side of science to ensure
your designs are not only attractive, but also usable, practical, and
profitable.

‚Äç

## What is preference testing?

###### Preference testing (also called desirability testing) is used to compare the aesthetic or emotional appeal of a design or concept, ¬†in order to understand how people perceive and respond to different variants. The goal of this UX¬†research method is to learn more about how each design influences participants' perceptions of things like ¬†trustworthiness, or whether or not a design does a good job of communicating a particular message or idea. This method is most effective during the early stages of product development.

‚Äç

At the most basic level, preference tests ask study participants the
simple question, "this one, or that one?" Handled carefully, that simple
question can uncover useful insights about which designs resonate most
deeply with an audience, which in turn can inform definition decisions
that help guide further design development.

‚Äç

Preference testing output may include qualitative data, quantitative
data, or a combination of both. Researchers analyze this data to create
a summary, which provides specific recommendations for the next phase of
designs.

‚Äç

### Preference testing vs A/B testing

People often confuse preference testing with [A/B
testing](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing),
but the two are actually very different. Preference testing is done very
early in the design process, usually with sketches, wireframes, or
preliminary designs. A/B testing, on the other hand, comes much later in
the process when the design is close to final and the product or website
is interactive, allowing participants to perform various tasks.

![An example of preference test with 4 logos to choose
from](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/624f49c4b5823be367b72b65_pref-test-example.jpeg)

An example of a simple preference test about logo design.
[Source](https://uxplanet.org/a-b-testing-v-s-preference-testing-d36786525c68)

Preference and A/B testing also study different aspects of a design.
Preference testing focuses on perceptions and opinions while A/B testing
focuses on behaviors. Preference testing data, therefore, tends to be
more qualitative, while A/B results are tied to KPIs related to defined
user goals.

‚Äç

### Drawbacks and criticisms of preference testing

Some researchers have pretty strong reservations about the value of
preference testing. While it's meant to help designers progress a design
forward in a way that aligns with user preferences, the nature of the
process can work against that goal.

‚Äç

As [author, entrepreneur, and Carbon Almanac Founder Seth Godin
explains](https://seths.blog/2022/03/testing-new-ideas/):

‚Äç

"Some objective measures of new names and concepts are worth knowing
about before you launch. Seeing what search results look like,
understanding the trademark register, having insight about pronunciation
and language issues.

But general 'how does this make you feel' feedback on a new concept is
almost certain to give you exactly the wrong feedback.

‚Äç

That's because the idea isn't going to work because it's objectively,
obviously and completely better. It's going to work because the network
effects and cultural dynamics behind it push it forward."

‚Äç

Although it can seem like a simple task to get people to tell you
whether they prefer Design A or Design B, it's really easy to wind up
with inaccurate or incomplete data. And if design iterations are based
on faulty findings, they can go off the rail pretty quickly.

‚Äç

Here are three of the top challenges intrinsic to preference testing:

-   **It can become a popularity contest.** Because preference testing
    focuses on visual appeal rather than functionality, the results can
    turn out to be superficial.
-   **Participants need a crystal ball to make a judgment.** Because the
    designs in a preference test are not functional, they cannot reflect
    real-world use cases. Instead, participants need to be able to
    project themselves into the future and imagine themselves
    interacting with the design (something most people aren't good at).
-   **Responses are often vague and unhelpful.** While most people can
    choose which design they prefer, they can't always articulate the
    'why' behind their choice. They may not want to invest the energy in
    figuring out why, preferring to give a gut response; they may not
    feel comfortable sharing their reasons; or they may simply have no
    idea.

‚Äç

The bottom line is that no one should rely solely on preference testing
to make critical design decisions. Preference testing can,
however---especially when combined with other research methods---be a
helpful way to gain initial design insights during the early stages of
development.

‚Äç

### So... why bother?

Despite its potential weaknesses, there's one very good reason to
conduct preference testing: desirability.

‚Äç

Desirability and usability are like the two sides of the UX coin, both
of which are necessary in a successful product.

‚Äç

Usability focuses on the functional side of the user experience. It's
all about whether and how easily users can complete various tasks.
Desirability encompasses all the intangible elements of the user
experience---the "something extra" or "wow factor" that makes the
experience more pleasurable and can help to create and sustain an
emotional bond with the user.

‚Äç

In competitive markets, desirability is not just a nice-to-have, it's an
essential part of a winning growth strategy. First, it provides an
advantage with first impressions since a design with high desirability
often correlates to a more positive perception of usability and overall
credibility. This halo effect can give a product a critical leg up with
prospective users to drive adoption, and can even play a role in
persuading existing users to forgive usability flaws.

‚Äç

Second, high desirability is one of the attributes that gives a company
the ability to charge a premium for its product. It's the part of the
experience that people will pay extra for because it enhances their
experience in a way that evokes an emotional response.

‚Äç

### When to use preference testing in the product development cycle

One of the biggest benefits of preference testing is the fact that you
can use it very early in the design process. It can be performed with
fairly simple renderings of design variations, or you can use it to
compare a proposed design to a competitor's.

‚Äç

The strength of preference testing is its ability to provide quick input
that can help determine the most viable design direction to pursue, and
also provide insight into why users prefer that design over other
options. Preference testing can also be done iteratively as a design
evolves, acting as a checkpoint at key junctures.

## How to conduct preference tests

The key to getting the most out of a preference test is to go beyond the
basic, "which one do you like better?" question. You want to dig deeper
by asking follow-up questions that get below the surface quantitative
data into the qualitative responses that help you unearth the 'why'
behind participant preferences.

‚Äç

So, when you're designing a preference test, there are three elements to
consider:

1.  The question you're asking
2.  The designs you're presenting
3.  The follow-up questions ¬†

‚Äç

Specificity is crucial in all three of these areas.

‚Äç

### Identify your research goals

The purpose of preference testing isn't to get an answer to the
question, "which is the best design?" First of all, unless you have
recruited a panel completely composed of expert designers, your study
participants won't likely be qualified to answer that question. All they
will be able to provide is their opinion about which design they like
better.

‚Äç

Even the question, "which design do you prefer?" is not always extremely
helpful, at least not on its own. While it does put the participant back
on solid ground---asking them about their own preferences, about which
they are an expert---it's still too general to offer much constructive
feedback.

‚Äç

Instead, think about what question you're really trying to answer in the
context of what you're trying to accomplish with the design. For
example:

-   If your design is meant to convey a customer-first approach, you
    might ask, "which design gives you the sense that your needs come
    first?"
-   If your design is intended to simplify complex information, you
    might ask, "which design is easiest to understand?"
-   If your design needs to stand out in a crowd, you might ask, "which
    design grabs your attention?"

‚Äç

The idea is to isolate specific points of comparison related to the
specific design challenges and objectives of your project.

‚Äç

You also want to establish early on whether you will be collecting
qualitative or quantitative feedback.

### Prepare your test

A preference test can be used to compare and evaluate different design
layouts, wireframes, color palettes, logos, sound files, videos---pretty
much any design element you can think of. You can even mix-and-match
different asset formats if that's the best way to get at the answer you
need.

‚Äç

The typical process for a preference test is to first provide
participants with an overview of all the designs in a side-by-side
format. After you've given them this high-level perspective, you then
ask them to look at each design on its own in more detail before they
make their final selection.

‚Äç

One common pitfall is asking participants to choose between very similar
designs. If the differences are too nuanced, non-designer participants
may have trouble figuring out what they are looking at unless you point
it out. In some cases---if you are at that level of design
refinement---you can, in fact, crop design images to help participants
focus on the detail in question.

‚Äç

### Plan your follow-up questions

Good follow-up questions make a big difference in the usefulness of your
preference testing data. It's one thing to know which design people
prefer, but it's much more helpful to understand exactly why they prefer
that design.

‚Äç

You can ask follow-up questions within a digital test interface, or you
can conduct quick interviews. And you can use almost any kind of
question structure, though you will get the richest responses using an
interview or open text field option.

‚Äç

Here are some of the ways you can use follow-up questions to layer
additional insights into initial findings:

-   **Ask simple, open-ended questions** about why someone prefers a
    design: Why do you like this design best? What about that design did
    you like? What part of that design jumped out at you?
-   **Use open or closed word-choice exercises** to get more specific
    input. In an open exercise, you ask a participant to choose any 3 to
    5 words to describe the chosen design. In a closed exercise, you
    provide a list of pre-defined adjectives and ask them to choose the
    3 to 5 that most accurately describe how they perceive the design.
    Words might include things like "clean," "vibrant," "traditional,"
    and "sophisticated."
-   **Have participants rate various aspects of a design on a numerical
    scale.** Using this technique, you might ask something like, "on a
    scale of 1 to 5, with 1 being not at all and 5 being strongly, how
    would you rate the way this design conveys a sense of innovation?"

‚Äç

When asking follow-up questions, whether in person or on a digital
testing platform, make sure that the participant can view the question
and the relevant design at the same time. This allows them to refer back
to the design as they formulate their answer, and will ensure more
detailed and specific responses.

‚Äç

### Other methods for assessing preference and desirability

‚Äç

#### Triading

While this method can prove a little trickier to manage in terms of
analyzing and presenting results, it can be an effective way to evaluate
design perceptions free from any researcher bias. Participants are asked
to assess three design options and select the two that are different
from the third, and explain why. The goal of this kind of exercise is to
identify which attributes participants hone in on when comparing
different designs.

‚Äç

As Chief Design Officer at Mad\*Pow Media Solutions LLC, Michael Hawley,
says in
[UXMatters](https://www.uxmatters.com/mt/archives/2010/02/rapid-desirability-testing-a-case-study.php):

‚Äç

"This process helps the researcher to understand what dimensions are
important to target users in comparing different designs. We've found
this method to be very helpful both when evaluating the competitive
landscape and for assessing different conceptual options from an
interaction design perspective."

‚Äç

However, he also warns about some limitations with this method; it may
not be the best option when you're using large sample sizes, and it can
be difficult to present the results to stakeholders and help them
understand how to use these insights to choose the best design.

‚Äç

#### Impression tests

Sometimes called "5-second tests" because that's how long participants
have to view each design, Impression tests are especially helpful for
assessing static design elements like landing pages, individual images,
or ads.

‚Äç

After the image is shown, participants answer questions about their
first impressions as well as what information they retained about the
content. This type of test is often used to validate that an asset is
able to convey a clear message quickly and consistently.

‚Äç

#### Reaction cards

In 2002, two Microsoft researchers shared a technique they developed to
measure desirability using a deck of 118 cards with different adjectives
on them. Sometimes called "The Microsoft Reaction Card Method," [this
approach](https://www.nngroup.com/articles/microsoft-desirability-toolkit/)
to preference testing is a useful method for gauging participant
responses to a design's aesthetic qualities in a way that's easier to
analyze because it uses a defined vocabulary for all participants.

‚Äç

The process involves selecting a subset of the 118 adjectives (usually
about 25 or so) that are relevant to the design(s) being tested. The
goal is to include a variety of words---positive, negative, and
neutral---some of which you believe are applicable to your design,
others that you believe don't apply.

‚Äç

In the test, participants are asked to sort the cards into two columns,
one containing the words they believe apply to the design, one
containing the words they think do not apply to the design. You can
analyze the results using a word cloud or frequency chart to highlight
trends.

![A venn diagram with words, showing the results of a microsoft reaction
card
study](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/624f496ab5823b38d5b6e836_venn-diagram-3.png)

A Venn diagram depicting the words different groups used to describe
flat design. Source:
[NN/g](https://www.nngroup.com/articles/microsoft-desirability-toolkit/)

‚Äç

#### Markup tests

The markup method is an interesting technique that borrows some elements
of co-designing in a more interactive test format. Used primarily for
designs that lean on both visuals and text to communicate value, this
method involves having a participant review a design and then mark it up
with symbols or colors to indicate which elements work for them, and
which elements do not.

‚Äç

In addition to having participants physically mark up a design, it's
important to have them use a "think aloud" approach to verbalize why
they are putting certain marks in certain places.

‚Äç

After the test is complete, you can use a heatmap to aggregate responses
and identify a design's weak and strong points. For more information
about the markup method and other preference test methods, check out
[this resource by Researcher David Peter Simon on Dropbox
Design](https://dropbox.design/article/do-you-like-it-how-we-evaluate-preference).
¬†

‚Äç

#### Physiological indicators

While less frequently used, researchers are learning more about how
physiological indicators can provide insight into a participant's
genuine emotional response.

‚Äç

This type of research requires expensive equipment that measures brain,
muscle, and other physiological activity that can be correlated to
different emotional states. For example, Electromyography (EMG) measures
muscle activity related to excitement levels, and Blood Volume Pressure
(BVP) measures blood vessel dilation, which relates to arousal. These
types of techniques are most often used in combination with a
self-reporting method.

‚Äç

## Recruiting participants for preference tests

To ensure that results have statistical significance, preference tests
should be run with approximately 20 to 30 participants. The panel should
not only reflect your usual target audience, but also consider the
specific context and mindset that will be relevant to the design in
question. So, for example, if you are testing a design that is intended
to appeal to new prospects, you may want to recruit non-customers who
still fit the profile of your typical user.

‚Äç

For an end-to-end guide on recruitment, [check out the Research
Recruiting chapter of the UX Research Field
Guide](https://www.userinterviews.com/ux-research-field-guide-module/recruiting).

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

## Measuring and analyzing data

If you've collected only [quantitative
data](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods),
analysis is a quick and simple task of tabulating responses to discover
which are most common. If you have collected qualitative data, the
process is a little more time intensive, involving text analysis to
group responses into categories and identify patterns that point to
specific insights.

‚Äç

In either case, if there is not enough difference in the preference for
one design over another, you can repeat the test with a modified version
of the design to see if you can achieve more definitive results.

‚Äç

In cases where you are looking at quantitative data, there are a couple
of ways to [analyze the
data](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
to get a statistically significant result:

-   **The binomial confidence interval** looks at the most-selected
    preference and adjusts for a margin of error, allowing you to
    determine how certain or uncertain you can be in the test results.
    [Here's an online
    calculator](https://measuringu.com/calculators/onep/) to help you
    measure this.
-   **The chi-square goodness of fit test** factors in chance by
    comparing the distribution of the sample data to the expected
    distribution of a larger population, allowing you to determine
    whether or not your test results are truly representative of your
    target audience. [Here's a
    calculator](http://vassarstats.net/csfit.html) to help you measure
    this.
-   **The confidence interval method** takes a more conservative
    approach that calculates the degree of certainty or uncertainty for
    sample data without taking the within-subjects nature of a
    preference task into consideration.
-   **The McNemar exact test** helps you determine the differences in a
    dichotomous (having two options) variable between your two sample
    groups. ¬†

## Tools for conducting preference tests

Here's a list of specialized tools for preference testing:

-   [Maze](https://maze.co/blog/preference-testing/): Maze is a product
    research platform that enables you to collect qualitative and
    quantitative user feedback to inform design decisions and create
    better user experiences.
-   [UXtweak](https://www.uxtweak.com/preference-test-tool): UXTweak
    offers preference testing tools, so you can ask participants which
    design from a group they prefer most to learn about their
    perspectives and the deciding factors.
-   [UsabilityHub](https://usabilityhub.com/product/preference-tests):
    UsabilityHub's preference testing tools allow participants to choose
    from multiple design options in response to your specific questions,
    with detailed follow-up tools for collecting more information.
-   [Proven By
    Users](https://provenbyusers.com/provenbyusers-preference.php):
    Proven By Users provides distinct preference testing tools, as well
    as tools for first click, 5-second click, card sorting, surveys, and
    tree tests.
-   [Useberry](https://www.useberry.com/preference-test/): Useberry
    offers easy-to-use tools for building preference tests, asking
    follow-up questions, and enriching your results with other data.
-   [User
    Testing](https://www.usertesting.com/solutions/teams/product-design):
    UserTesting offers a robust set of tools to facilitate user
    research. You can quickly build studies across platforms based on
    existing templates or from scratch.
-   [Lookback](https://www.lookback.com/usability-testing-with-lookback?hsLang=en):
    Lookback provides tools for testing prototypes, betas, live apps and
    websites to understand user preferences.

‚Äç

You can pair these tools with your core tech stack and conduct many
types of preference tests with these more general moderated research
tools:

-   [User Interviews:](https://www.userinterviews.com/) User Interviews
    is the fastest and easiest way to recruit and manage for research
    participants. [Sign up
    today](https://www.userinterviews.com/lp/rorpaccount?promo_code=3FREE&source=navbarSignup)
    and get your first 3 participants free.
-   [Miro](https://miro.com/): Miro is a collaborative whiteboard
    platform that enables distributed teams to work effectively
    together, from brainstorming with digital sticky notes to planning
    and managing agile workflows.
-   [Google Workspace:](https://workspace.google.com/) Google Forms,
    Surveys, and Sheets can help you easily create, conduct, and
    collaborate on a variety of research projects, including preference
    tests.

‚Äç

For a closer look at the tools researchers are using for preference
tests and other methods, see the toolkit results of our [State of User
Research 2022
Report](https://www.userinterviews.com/state-of-user-research-2022-report#tools-trade).

## Hybrid research: Combining preference tests with other methods

Because preference testing is inherently subjective and can deliver
superficial insights, it's best to pair it with other methods such as
interviews and/or questionnaires in order to capture more in-depth
qualitative data that can help clarify the reasons behind participant
choices. It can also be paired with A/B tests and behavioral analytics
to provide additional quantitative data.

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/qualitative-usability-testing)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/surveys)

Next:

Surveys

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[Surveys](/ux-research-field-guide-chapter/surveys)

# Surveys

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

[Erika Hall,](https://medium.com/mule-design/surveys-up-891c3de4154b)
co-founder of Mule Design, describes surveys as "the most dangerous
research method."¬†

‚Äç

Why? Because although surveys are one of the easiest research methods to
conduct, they're also one of the easiest methods to mess up.¬†

## In this chapter:

-   What are surveys?
-   When, why, and how to use surveys for UX research
-   How to design an effective research survey
-   Examples of effective survey questions
-   Recruiting for UX research surveys
-   Analyzing survey results and reporting findings
-   Tools for conducting surveys
-   Hybrid research: Combining surveys with other methods

## What are surveys?

‚Äç

A survey is a set of questions you use to collect data from your target
audience. In the words of survey expert [Caroline Jarrett, a survey
is:](https://www.effortmark.co.uk/surveysthatwork-extras-and-additions/definitions-chapter-what-is-a-survey-and-the-survey-octopus/)¬†

‚Äç

"A process of asking questions that are answered by a sample of a
defined group of people to get numbers that you can use to make
decisions."

‚Äç

Surveys are appealing because they're cost effective while having the
potential to reach large numbers of people quickly and easily. You can
ask almost anything, and the results are easy to tally.¬†

However, these are the exact same reasons why surveys are so dangerous;
surveys are deceptively simple. Although they're relatively easy and
inexpensive to implement, you can't let this ease fool you into cutting
corners. Getting valid and valuable data from a survey still requires
strict adherence to best practices.¬†

### Surveys vs. questionnaires vs. polls

‚Äç

What's the difference between a survey, a questionnaire, and a poll? The
terms 'survey' and 'poll' can be used interchangeably, while a
questionnaire refers to the content of the survey/poll you're
conducting:¬†

-   **Survey (aka Poll):** The task or process of collecting data in
    order to gather insights from a specific set of respondents.
-   **Questionnaire:** The content---a list of questions---that you are
    asking respondents to answer.¬†

## Using surveys for UX research

‚Äç

In UX research, surveys are typically used as an [evaluative research
method](https://www.userinterviews.com/ux-research-field-guide-module/evaluative-methods),
but they can also be used in [generative
research](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)
and as a [continuous research
method](https://www.userinterviews.com/ux-research-field-guide-module/continuous-research-methods).
In-product surveys, for example, are an easy and effective way to
automate ongoing data collection.¬†

There is a variety of approaches you can take to designing and
implementing a survey. Here's an overview of the different types of
survey methods in UX research.

‚Äç

### Types of survey methods in user research

‚Äç

#### Quantitative vs qualitative research surveys

‚Äç

**Quantitative surveys** collect a large number of responses to
questions that can be answered using checkboxes or radio buttons. These
types of surveys are designed to answer "how many" questions; like all
[quantitative research
methods](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods),
these types of surveys are meant to deliver statistically meaningful
results representative of the broader population.¬†

Quantitative survey types include **descriptive** and **causal**:

-   **Descriptive** **surveys** provide insight into behaviors,
    attitudes, or opinions.¬†
-   **Causal surveys** are designed to define the cause-and-effect
    relationship between two or more variables.

**Qualitative surveys** use open-ended, **exploratory** questions to
collect more detailed comments, feedback, and suggestions. While these
types of responses cannot be as quickly and easily tallied as the data
from quantitative surveys, the insights they provide can be very
valuable. Researchers often run a qualitative survey with a small group
to gain a deeper understanding of the respondents and identify the best
questions and answers to include in a quantitative survey aimed at a
larger group.

‚Äç

#### Cross-sectional vs. longitudinal vs retrospective surveys

‚Äç

**Cross-sectional surveys** look at a specific, isolated situation and
solicit a single set of responses from a small population sample over a
short period of time.The aim is to get quick answers to a standalone
question. This method is purely observational, and does not measure
causation.

**Longitudinal surveys** collect a series of responses from a larger
group of participants over a longer period of time (from weeks to
decades). This observational method helps researchers study change over
time, and includes three types of studies: trend, cohort, and panel.
These long-term studies are most successful when designed around short,
frequent sessions, instead of lengthy interviews that can be burdensome
for participants.

**Retrospective surveys** combine longitudinal and cross-sectional
elements by looking at change over a long period of time via a one-time
survey. This approach helps reduce the time and money needed to perform
the survey, but can introduce accuracy issues depending on participants'
memory recall.¬†

Ultimately, [choosing the right research
method](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-choose-a-research-method)
for you will depend on your goals and the questions you're hoping to
answer.¬†

‚Äç

### The advantages and disadvantages of surveys for user research

‚Äç

Surveys are a popular and advantageous research method for many reasons:

-   They are inexpensive.¬†
-   They are scalable.¬†
-   They are usually less susceptible to the [Hawthorne
    effect](https://www.interaction-design.org/literature/article/light-up-your-user-research-understanding-the-hawthorne-effect)
    (the phenomenon of study participants changing their behavior based
    on the knowledge that they are being observed and tailoring
    responses to meet assumed expectations).
-   They give your team confidence in making survey-informed design
    decisions.¬†
-   They provide statistically meaningful data that is reassuring to
    business stakeholders.

‚Äç

#### The biggest downside to surveys is how easy they are to run.¬†

‚Äç

As Erika Hall explains,¬†

"It is too easy to run a survey. That is why surveys are so dangerous.
They are so easy to create and so easy to distribute, and the results
are so easy to tally. And our poor human brains are such that
information that is easier for us to process and comprehend feels more
true. This is our cognitive bias. This ease makes survey results feel
true and valid, no matter how false and misleading. And that ease is
hard to argue with. It's much much harder to write a good survey than to
conduct good qualitative user research. Given a decently representative
research participant, you could sit down, shut up, turn on the recorder,
and get good data just by letting them talk. ... But if you write bad
survey questions, you get bad data at scale with no chance of recovery."

‚Äç

That's why it's critical you take the time to [create a thorough and
effective user research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
when designing a survey.¬†

‚Äç

### So, when should you use surveys in UX research?

‚Äç

It can be tempting to use surveys for all kinds of quantitative
research, but that's not always the best use of the method. While
surveys are undeniably a relatively fast and low-cost way to compile a
lot of data on a lot of people, there are many ways that data can be
skewed to deliver biased or otherwise compromised results.¬†

A better use of a survey is as a qualitative tool that helps you explore
and define the area of investigation. Using open-ended survey questions
as a starting point can help you gain a much deeper understanding about
the subject at hand and the end users you're surveying. And that
understanding is invaluable for mitigating the risk of designing subpar
solutions as well as increasing your ability to design better products
more efficiently.

‚Äç

## How to design an effective research survey

‚Äç

Thorough and thoughtful [planning and
preparation](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)
are crucial to survey success. You need to be clear and explicit about
your goals. One of the most common mistakes new researchers make is to
cast a wide net, asking for responses to a wide range of questions, and
then try to reverse-engineer a central goal from the resulting data.

A strong survey explores a very specific and clearly defined research
question via [well-written, bias-free survey
questions](https://www.userinterviews.com/blog/how-to-write-ux-research-interview-questions-to-get-the-most-insight)
and an optimized survey flow.

‚Äç

### Defining the research question and scope

‚Äç

The research question is different from the individual questions that
you eventually include in your questionnaire. A research question
defines the topic you are exploring. It is the 'big idea' at the heart
of your survey.

Identifying your research question typically starts with brainstorming
to develop a list of all the possible suggestions. From there, you
refine the question to its essence. [Caroline
Jarret](https://www.effortmark.co.uk/surveys-that-work-excerpt-chap1/)
does this by running each possible question through a series of four
challenges:

-   What do you want to know?
-   Why do you want to know?
-   What decision will you make based on the answers?
-   What number do you need to make the decision?

![defining your research question based on 4 key
challenges](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61f2b19baad95dfdb48f76f7_yZELTXXyGw5zHvVMdaFKwz2xredJ4rlQdZcm1_K_BwqGV-7hEHRRnLp4fVDjQWVWIM_rEFXCJ2PiaM9G4ths9CJXklHXU7V2g0KLoukDTvgVuVdmarJD70CgRicAsrLPK0N06dXp.png)

#### Look for your most crucial question (MCQ)

‚Äç

As you run your various questions through this 4-part challenge, you're
looking for your Most Crucial Question (MCQ), which Caroline defines as,
"the one that makes a difference. It's the one that will provide
essential data for decision-making." She suggests stating your question
in two parts:

‚Äç

-   "We need to ask \_\_\_\_\_\_\_."
-   "So that we can decide \_\_\_\_\_\_\_\_\_\_\_."

‚Äç

And don't stop there. Before you settle on your MCQ, you want to really
pick it apart by questioning what you mean by each word. You want to
wind up with something that is incredibly clear and doesn't require any
interpretation. For more info on how to "attack" your MCQ in this way,
check out [this article by
Effortmark](https://www.effortmark.co.uk/surveys-that-work-excerpt-chap1/).¬†

Remember, in order for your research to make a meaningful impact, it
needs to be designed to enable decisions for your company, product, or
service. [Roberta
Dombrowski](https://www.userinterviews.com/author/roberta-dombrowski),
VP of User Research at User Interviews, has created a framework for
doing [decision-driven research, which you can read
here](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research).¬†

‚Äç

### Writing great survey questions

‚Äç

Clarity and specificity are the two most important characteristics of
effective survey questions. With that in mind, here are our top tips for
creating questions that help you get the answers you need:

‚Äç

-   Use the first person to encourage people to focus on their
    experience rather than their opinions.
-   Replace UX jargon with simple, familiar words.
-   Use language that a child could understand.¬†
-   Use straightforward syntax.¬†
-   Choose words with clear, unambiguous meanings that don't require any
    interpretation.
-   Be as specific as possible with your wording.
-   Eliminate any double-barreled questions that ask two questions at
    once.
-   Avoid the use of single or double negatives.

‚Äç

‚Äç

#### Types of survey questions

‚Äç

Mixing up the types of questions on your survey can help you collect the
most insightful data. There are two main types of questions: open and
closed.

**Open-ended survey questions** allow participants to respond in their
own words. This type of question typically generates a great deal more
qualitative detail and can uncover unexpected responses. Open-ended
questions help you get at the "why" behind people's answers. However, it
can be difficult and time-consuming to analyze and draw conclusions from
open-ended responses.¬†

**Closed survey questions** have pre-populated response options that
participants choose using tools like checkboxes or radio buttons. Closed
survey questions have higher response rates since they require less
effort from the respondent. Because the response options are
standardized, closed questions deliver data that is easier to analyze
and which provides statistically significant findings.¬†

There are several different types of response options for closed survey
questions:

-   Multiple choice (radio buttons)
-   Checkbox (select as many as apply)
-   Rating scale
-   Ranking order
-   Dichotomous (Yes/No)
-   Matrix
-   Image Choice
-   Likert scale (e.g., strongly disagree to strongly agree, never to
    always, very dissatisfied to¬† very satisfied, etc.)

‚Äç

#### Avoid bias and leading questions

‚Äç

It is very easy to [accidentally insert
bias](https://www.userinterviews.com/blog/on-psychology-and-user-research-with-lorie-whitaker-of-rackspace)
into your survey questions. And it's also possible for participants to
be biased in their responses. We already mentioned the Hawthorne effect,
which causes people to change their behavior when they know they are
being observed. There is also **acquiescence or agreement bias**, which
causes survey respondents to agree with research statements in an effort
to be more agreeable or to give the answer they think you want.¬†

**Here are a few different kinds of bias that can sneak into your
questions:**

-   **Confirmation bias** happens when all your questions are geared to
    support your existing hypothesis.¬†
-   **Implicit bias** relates to subconscious and/or unspoken attitudes
    and associations about different stereotypes.
-   **Framing effect** has to do with how question presentation can
    influence responses.
-   **Hindsight bias** can distort memories by giving people the sense
    that they "knew it all along" and could have easily predicted events
    that have already happened.
-   **Clustering bias** is a cognitive bias that causes people to see
    patterns where none exist.
-   **Serial position effect** refers to how it's easier to remember the
    first and last items in a list.

### Examples of effective survey questions

‚Äç

Here are a few examples of poorly-worded survey questions and how to fix
them [from Miro](https://miro.com/guides/ux-research/surveys-questions):

**INSTEAD¬†OF:** \"What do you like about the current banking app?\"¬†

-   This is a bad question because it assumes a positive experience.¬†

‚Äç

**TRY:** \"Tell me about your experience using your current banking
app.\"

**INSTEAD¬†OF:** \"Was using the app for the first time easy?\"¬†

-   This is bad because it\'s a yes or no question and it assumes a
    positive experience.¬†

‚Äç

**TRY:** \"What were your impressions of the onboarding experience
within the app?\"

**INSTEAD¬†OF:** \"Was this feature confusing?\"¬†

-   This example assumes a negative experience.¬†

‚Äç

**TRY:** \"What does this feature mean to you?\"

The 'right' questions here are all better because they're more
open-ended and they don't make assumptions about the respondent's
experience. Instead of leading respondents to the answer you're looking
for, let them lead you to the details and experiences that actually
matter to them.¬†

‚Äç

### Other survey tips to consider

-   **Test your survey** by having colleagues answer draft questions,
    iterating, having a small group of participants answer draft
    questions, iterating, and so forth.¬†
-   **Keep the survey as short as possible** (especially if you are not
    compensating respondents).
-   **Consider allowing anonymous responses** to encourage honesty.
-   **Include a quick introduction** that includes context, how to ask
    for help, and---if applicable---information on any [research
    incentives](https://www.userinterviews.com/lp/ux-research-incentive-calculator?source=navbarIncentiveCalcResearcher)
    you are offering.
-   **Use logic functionality and filter questions** to eliminate
    irrelevant questions. For example, if one of the questions asks
    about respondents' employment status, anyone who responds that
    they're unemployed or a student shouldn't get a follow-up question
    asking about their role or seniority.¬†
-   **Place the most important questions at the start** of the survey.¬†
-   **Ensure that early questions are easy to answer.** By making the
    first part of the survey as smooth an experience as possible, you
    help build rapport with the participant and encourage them to follow
    through with the rest.¬†
-   **Group related questions together, ordered from most general to
    most specific.** This allows for a smoother experience for the
    survey participants.¬†
-   **Make your list of response options as comprehensive as possible**
    to ensure that all participants have the ability to answer them
    honestly.¬†
-   **Ensure that response options are mutually exclusive;** e.g. you
    shouldn't make "marketing" and "digital marketing" two separate
    options.¬†
-   **Include an "other" option** as often as possible.
-   **If possible, include a progress indicator** to manage
    participants\' expectations about the time to completion.¬†
-   **Allow people to comment on the survey itself** to collect
    additional feedback about anything they think is relevant that
    wasn't included in the survey, or any concerns with the survey
    design.¬†¬†

## Recruiting for UX research surveys

‚Äç

Since it's impossible to survey every person who currently uses or may
someday use your product, survey research relies on the statistical
concept of sampling to select and survey certain individuals from a
broader target population.

There are two main types of sampling:

-   **Probability sampling** uses randomization to select participants,
    and is usually used when you need a large group of respondents.
    However, it does not guarantee a truly representative selection,
    especially if you're running a qualitative survey.
-   **In non-probability sampling,** survey participants are selected
    based on a specific set of criteria, typically in order to gain
    insight into a very specific persona. The risk with this type of
    sampling is that by sorting people into artificial categories---that
    don't necessarily influence behavior---a researcher may
    unintentionally impose their own biases.

In addition to determining the type of sampling most appropriate for
your research, you also need to identify the right number of
participants.¬†

The right number of participants for you will depend on a number of
factors, including the scope of your research, the type of study you're
running, and the available resources like budget and time. As a general
rule, [NN/g
recommends](https://www.userinterviews.com/blog/9-tips-from-uxr-pros-to-help-you-recruit-participants-for-research)
5--10 participants for qualitative studies and at least 40 participants
for quantitative studies.¬†

‚Äç

### How to find participants

‚Äç

Your approach to
[recruitment](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
will depend on the type of survey you're running.¬†

-   **For quantitative surveys** that require a certain number of
    respondents to deliver statistical significance, you'll usually use
    probability sampling to recruit a large, random, representative
    sample.¬†
-   **For qualitative surveys,** which require a smaller number of more
    specific respondents, non-probability sampling will provide the best
    solution.¬†

‚Äç

There are many sources that can help you find large numbers of
respondents to participate in broad surveys designed to deliver
quantitative data. Online survey tools such as SurveyMonkey and
Pollfish, for example, offer such panels. It is also often possible to
source respondents by sharing your survey link in a relevant group on
Facebook, LinkedIn, Slack, or other social platform.¬†

If you are looking for more targeted, qualitative responses from a more
closely defined type of respondent, User Interviews can help you achieve
the best results. Our [Recruit
tool](https://www.userinterviews.com/recruit?source=navbarRecruitResearcher)
allows you to source from a pool of more than 700,000 participants
tailored to your exact specifications, and our [Hub
tool](https://www.userinterviews.com/research-hub?source=navbarHubResearcher)
allows you to build and manage your own in-house panel.

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

### Screener surveys

‚Äç

Your survey results won't be useful if you fail to survey the right
people. [Screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
help ensure that you're recruiting high-quality participants who can
provide the information and insights you need to make relevant
decisions.¬†

Here are a few quick tips for building effective screener surveys:

-   **Get your participant criteria "just right."** Criteria that is too
    niche can severely limit your ability to find enough people for your
    research. Criteria that is too broad can leave you with a group
    that's not focused enough to deliver the specific answers you need.
-   **Steer clear of demographic and geographic restrictions.** Unless
    you have a very specific reason (such as needing to establish
    availability to do a follow-up study in person), avoid focusing on
    things like geographic location, age, ethnicity, income, education
    level, etc. Instead, pay more attention to behavioral traits---how
    people think and feel.¬†
-   **Keep your questions neutral.** It's really easy to accidentally
    ask a leading question---one that influences a person to answer in a
    particular way. Be careful to avoid language that might offer a hint
    about the answer you're hoping to get, or inadvertently try to sway
    a respondent with framing.
-   **Take advantage of skip logic.** Skip logic allows you to make your
    survey more personal by customizing questions based on previous
    responses.¬†

‚Äç

## Analyzing survey results and reporting findings

‚Äç

[Analyzing and
synthesizing](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
your data is the final step in survey research. For larger
surveys---more than 100 respondents---it makes sense to do quantitative
analysis using mathematical and statistical methods. In addition to
looking at which responses were most popular, you should also look for
patterns in how different types of users answered various questions.¬†

If your survey includes qualitative, open-ended questions, your review
of the results will involve sentiment analysis. This approach looks at
whether a response is positive or negative as well as looking at the
specifics of the response.¬†

To effectively summarize sentiments so you can identify action steps,
organize your results based on each question rather than each user. By
grouping all the responses to each question together, you'll easily be
able to identify sentiment themes. You can then associate those themes
with specific UX opportunities.¬†

‚Äç

## Survey Tools

‚Äç

There are lots of different survey tools available, many of which we
have captured in our [2021 UX Research Tools
Map](https://www.userinterviews.com/blog/ux-research-tools-map-2021).¬†

Here are just a few of the most popular survey tools:

-   [SurveyMonkey](https://www.surveymonkey.com/)
-   [Google
    Forms](https://surveys.google.com/warm-welcome?dest=%2Fyour-surveys%3Fcategory%3Dexample)
-   [Typeform](https://www.typeform.com/research/)
-   [Optimal Workshop](https://www.optimalworkshop.com/)
-   [Qualtrics](https://www.qualtrics.com/)
-   [Medallia](https://www.medallia.com/)
-   [Maze](https://maze.co/?utm_source=userinterviews&utm_medium=referral&utm_campaign=tools-map-2021)
-   [GetFeedback](https://www.getfeedback.com/en/)
-   [Confirmit](https://www.confirmit.com/)

‚Äç

## Hybrid research: Combining surveys with other methods

‚Äç

Surveys are an extremely flexible research method and particularly
effective as part of hybrid and mixed methods approach to research.¬†

For instance, you can combine a quantitative survey with qualitative
[interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews).
Or you could use a structured survey to complement [observational field
work](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography).
You can also use surveys to compare participants' self-reported data to
their actual behavior. The possibilities are nearly endless.

And there you have it---the "most dangerous research method," made safer
and simpler with intentional survey design and best practices.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/preference-testing)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/tree-testing)

Next:

Tree Testing

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[Tree Testing](/ux-research-field-guide-chapter/tree-testing)

# Tree Testing

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Tree testing means testing the architecture of your website, or anything
else that has a branching (tree-like) menu. The method is relatively
simple, can be done early in the development process, and can save you
lots of time and effort later on.

## What Is Tree Testing?

Tree testing is one of several methods for getting the feedback you need
to design a functional website, or anything else with menu options
nested inside each other, like an automated messaging system (\"for
Employee Services, press one. For Customer Services, press two\") or the
options on a DVD (are subtitle options under \"Play Movie\"?). It is
sometimes described as \"backwards card sorting,\" and bears a certain
resemblance to first click testing, so it\'s difficult to describe tree
testing without also discussing these other methods.

‚Äç

### Tree Testing vs. Card Sorting vs. First Click Testing

The first thing to understand about tree testing is that it isn\'t card
sorting, nor is it first click testing (though first clicks can be
important here, too). All three methods are closely related and
superficially quite similar, but serve very different functions. In
fact, you might find yourself doing all three at different points in the
same project. To recap:

‚Äç

#### First Click Testing

First click testing means giving the tester a task---like looking up
lobby hours on a bank\'s website---and recording whether the first place
the user clicks is actually on the correct path to accomplish the task.
Finding the lobby hours, or whatever else, would usually involve several
more clicks, so the object is just to see whether the user can tell
where to start. Failure to click in the right place first, or taking a
long time to click there, suggests that something is wrong with the
site\'s layout. Either the structure of the site is counterintuitive, or
the appearance of the page is in some way confusing or distracting.
Perhaps the correct place to click has been accidentally hidden or
obscured.

‚Äç

First click testing can be done to check a new design, or to investigate
possible problems in an existing design. The test can be done on a
wireframe, or even a sketch, provided that all the potentially
helpful\--or potentially confusing\--elements of the layout are present.

‚Äç

#### Card Sorting

Card sorting involves giving a participant a group of cards (in real
life or on a computer screen) each labeled with a concept, and asking
the participant to organize the cards in a way that makes sense. While
the method has several possible applications, it is often used as an
initial step in designing the structure of a website. If most
participants place the card labeled \"hours of operations\" under
\"services,\" rather than under \"locations,\" then it makes sense to
design the site with hours as a subheading under services. There are
open card sorts where users define the categories the cards go into, or
closed ones where the researcher defines the categories.

‚Äç

#### Tree Testing

Tree testing involves showing the tester the architecture of your site
(or your answering service, or whatever else) and asking them where they
would click in order to accomplish a goal. However, unlike first click
testing, the test doesn\'t end at the first click. The tester actually
has to follow the entire pathway, from the first page to the final,
triumphal click. Although the first click is disproportionately
important, it is possible to get the first click right and still get
lost before accomplishing the task. You need to know if your structure
is getting your users lost.

‚Äç

The other big difference between tree testing and first click testing is
that tree testing involves only the structure, not the content or the
layout. With click testing, wrong clicks could be the result of buttons
being too large or too small or in the wrong place or the wrong color,
even if the basic architecture of the site is correct. But with tree
testing, none of those other variables are at issue. The tester does not
see your layout, only a diagram of which headings contain which
subheadings.

‚Äç

Tree testing is often called backwards card sorting, because both focus
very closely on the architecture of a site, its branching \"tree\" of
options. In card sorting, you ask your participants to create trees for
you. In tree testing, you\...you guessed it, test those trees.

‚Äç

![an example of a tree
test](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5c1aca6a31b798acae57165b_tree-test-mark-correct-answer.png)

An example of a tree test

‚Äç

### When to Use Tree Testing

Tree testing can be done very early in the design---or
redesign---process, because the site doesn\'t need to exist yet, even as
a concept sketch. All you need is the tree. If your tree fails the test,
the problem is relatively simple and cheap to fix because, even if you
have to go back to the beginning, you don\'t have to go back very far.
You won\'t have lost much.

‚Äç

There is no rule that says you have to use all possible testing types on
the same project. Especially if your resources are limited, you might
choose to simply use your judgment for some aspects of the design
process and only test places where you suspect there might be a problem.

‚Äç

But if you have lots of time, questions, and resources, you might begin
with a task assessment (to figure out what your product or website needs
to be able to do), then do an open card sort to find out what kind of
structure your users might find most intuitive. Create your structure,
then double-check it with an open card sort. Then refine that structure
into the architecture you plan to use, your tree. Test your tree. Make
any necessary changes, then test again. Then start designing your site
around that tree and use several rounds of first click testing to make
sure your layout and content add to, not detract from, the usability of
the site.

‚Äç

### Disadvantages of Tree Testing

Tree testing focuses on site architecture and nothing else, which is
great because if the test reveals a problem, you know exactly where the
problem is in the tree. But since there are many other things that could
go wrong to impact overall usability, you can\'t use tree testing alone.
You need sources of information about the other aspects of your project,
too.

‚Äç

The other potential drawback of tree testing is that since it is nearly
always an automated, remote process, you don\'t get the qualitative data
that could show you why your testers are having the problems they are.
Moderated tree testing would fix that problem, but generally is not
practical.

‚Äç

You can get some of that qualitative material by polling your testers
after the fact, or by doing a moderated trial run. More on these options
below.

‚Äç

## How to Conduct a Tree Test

As with many types of testing, the difficult part for you as the
researcher comes before and after, not during.

‚Äç

### Designing Your Test

Tree testing is logistically fairly simple, since you generally don\'t
need to travel, gather supplies, or coordinate any more people than you
normally have on your team. You do need to design your test, though.

‚Äç

#### Choosing Methods

While you could conduct tree testing with a handwritten site map (and a
note-taker standing by), most people use specialized tools. These vary,
but generally you load your categories and subcategories and
sub-subcategories (etc.) onto a spreadsheet, and then the tool creates a
clickable tree suitable for testing. The tool will track where testers
click, how long they take to click, in what order they click on things,
and how many of them click in the right places. Your job is to choose
the tool you want to use and familiarize yourself with it.

‚Äç

Most tree tests are conducted online. The tester will get a link to your
test and complete the assignment. They can do this in an unmoderated
setting, from the comfort of their own computer, or from a moderated
setting, where you can watch the action. The easiest and cheapest way to
do tree testing in in an unmoderated, remote setting.

‚Äç

#### Creating Your Tree

You will have to design your tree before you test it. You will also need
to decide how much of your tree you want to test. If your site is
extremely complex, you might not want to test all of it at once. If you
are adding new material to an existing site, you don\'t necessarily need
to retest the older parts. However, you do need to include all the
options a user might consider taking. For example, if you have six menu
items on your landing page, you need to include all six of them in the
test, even if you are only testing pathways involving two of them.
Don\'t make the test easier by eliminating wrong answers, as this will
skew your data. If your site has seven levels, but you only need to know
if users can navigate the first five, then you don\'t need to include
the extra two.

‚Äç

You may want to test two different trees to see which one works better.
In this case, you are essentially doing an A/B test. Don\'t show both
versions to the same tester. Do recruit twice as many testers, so that
each version will still get thoroughly tested. In some cases, you can do
a comparison within a single tree. For example, if you want to know
whether you should put cucumbers under \"fruit\" or \"vegetables,\"
simply include both options in your tree and see which one testers click
on.

‚Äç

#### Writing Your Tasks

Don\'t simply ask your testers to \"find the lobby hours listing,\" or
something equivalent. First, it is important to avoid biasing the test
by using the same wording as the menu label of the right answer. Second,
it\'s important to get your tester in the same frame of mind as a real
user---the mind works differently, depending on whether a person is
taking a test or trying to solve a real-world problem (such as
depositing a check before the lobby closes). Give the tester a realistic
scenario, rather than a simple test question, to set the right tone.

‚Äç

Don\'t make your scenarios too complex either. You\'re not writing flash
fiction here, and too many irrelevant details would just be confusing.
Remember that many testers will skim the questions, rather than reading
them carefully, and could mistake a supporting detail for the central
point. You only need one or two sentences.

‚Äç

The same test can and should include multiple tasks, so you get a larger
and more nuanced picture of how well your tree works. But don\'t include
more than ten tasks. After ten scenarios, your tester is going to start
getting tired or bored---and after ten trips through your tree, they are
going to start learning their way around, thus biasing your test.

‚Äç

If you need to test more than ten tasks, run more than one test. For
example, if you want to ask about twenty scenarios, you can double your
number of testers and then randomly assign ten to half your testers and
the other ten to the other half.

‚Äç

You are not going to be able to ask about every task that can possibly
be accomplished on your site. Focus on the ones that are most important
and any that you suspect might present a special problem.

‚Äç

Finally, be clear about what the right answer actually is. There is no
reason to tell your testers whether they got it right, but your testing
tool needs to know so it can give you the results you need.

‚Äç

### Recruiting Your Testers

The two most important things in recruiting testers for a tree test is
that you get enough people for statistical significance and that you get
representative users\--that is, people who are similar to the people who
will actually use your site. If your target usership is retirement-age
women, then that\'s who you need in your study. If your target usership
is single fathers of pre-school-aged children, then that\'s who you need
to recruit. You won\'t get good results otherwise. You can hire a
company to provide you with paid test-takers, or you can find your own.
Remember that some of the people who agree to help you out will not
follow through, or will not complete the test, so you may need to do a
second wave of recruiting if you don\'t reach your target number the
first time.

‚Äç

Get a minimum of 50 people. Less, and you run the risk of having your
results biased by the small number of testers who don\'t put any effort
into the exercise. Also, you want to clear the threshold for
statistically meaningful results by a healthy margin, not an anemic
squeak.

‚Äç

Be sure that your testers are properly compensated, either through fair
pay or through a nice thank-you gift, and be sure to explain why their
contribution is valuable and that you are grateful.

‚Äç

In your communications with your testers, be very clear that they are
testing your tree. You are not testing the testers. Most people slip
back into \"school mode\" very easily and become very anxious about
whether they have gotten the question right and earned the teacher\'s
approval (even if they know better intellectually). As much as possible,
avoid language that could exacerbate the problem and bias your test.

‚Äç

### Minimizing Your Drawbacks

You can minimize some of the drawbacks of tree testing by what you do
both immediately before and immediately after the test itself.

‚Äç

Do a small-scale moderated pilot test first, both to make sure your
instructions make sense, that your testing tool works, that the whole
test does not take longer than about 20 minutes, and so forth, and in
order to collect some qualitative data you otherwise wouldn\'t have.
Besides a moderator, you will need a note-taker for this phase, as the
same person cannot perform both roles.

‚Äç

For the main, unmoderated test (and in the moderated pilot), after the
test itself is complete, show each tester a list of the category and
subcategory (etc.) labels used in the test and ask if any were
confusing. Then ask for any further feedback, questions, comments, or
concerns (if anyone asks questions, answer them in a reasonable
timeframe). The object here is to capture some of the qualitative data
you otherwise wouldn\'t get, as well as to solicit information you
didn\'t think to ask about.

‚Äç

Surprises are important.

‚Äç

## How to Analyze and Use Tree Testing Results

![An example of tree test results from
Treejack](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5c1acab11c28c1978d760b89_tree%20test%20treejack.png)

An example of tree test results from
[**Treejack**](https://www.optimalworkshop.com/treejack?gclid=CjwKCAiA9efgBRAYEiwAUT-jtOsWEr1Ajp1MQSbOMWRay45LA-1MNTZ5iG_zYfxjdsZT7AKmdmXckBoC54EQAvD_BwE)

‚Äç

### What You\'re Looking For

Your testing tool will likely give you results in the form of the
following numbers:

-   The percentage of testers who successfully completed each task
    (\"success rate\")
-   The percentage of testers who successfully completed each task
    without making wrong guesses first (\"directness\")
-   The average time needed for each task (\"time)
-   Where most testers clicked first for each task (\"first click\")
-   Where most people finished for each task, their final answer,
    correct or otherwise (\"destination\")

‚Äç

The relative importance of each of these measures will vary from one
test to another. You\'ll also get a lot of information from the
relationships between these numbers. More on that shortly.

‚Äç

You might not be able to compare results from different tasks, let alone
merge the numbers to get, say, an average success rate of all ten tasks
in the test. For example, if one task requires a minimum of five clicks
and the other requires only two, of course their times should not be
comparable. Compare only the results of comparable tasks or, better yet,
different versions of the same task. For example, if you have cucumbers
under both fruit and vegetables, and both paths require a minimum of
three clicks, is time lower and directness higher for one path than the
other?

‚Äç

### Defining Success

The success rate of a tree test will always be lower than the success
rate for the finished website, assuming you make improvements based on
your learnings from tree tests and other research. Additionally ¬†a
finished website offers contextual cues, drop-down menus, a search
feature, and other such details that make navigation easier. The
difference can be huge\--a success rate in the sixties on a tree test
can be comparable to a success rate in the nineties on a finished site.

‚Äç

Also, the success rate for a task that requires many clicks is going to
be lower than for one requiring few tests (in tree tests or otherwise).

‚Äç

The point is that you can\'t grade a tree test the same way you\'d grade
a spelling test. The numbers are going to be lower and they are going to
be variable. Experience will teach you what results can reasonably be
considered \"good\" results in different circumstances. You can also
look at relative results\--does this tree have higher success rates than
the previous version? Is one task consistently taking longer than other
tasks that should be similar?

‚Äç

Finally bear in mind that not all tasks are equally important. Depending
on what your site is for, there will be some tasks that absolutely have
to be clear and straightforward or the user will get frustrated and
leave. Other tasks might be perceived as worth the extra effort, or
users might decide that even if that task is a headache, other parts of
the site are worth sticking around for. Ideally, the entire tree would
work perfectly, but a passing grade for one pathway might not be a
passing grade for another.

‚Äç

### Making Use of Results

It is important to consider the relationship between the various
numbers. For example, if the directness is low for a given task, that\'s
a problem, even if the success rate is high; users who accomplish their
goal only after a lot of false starts and backtracking are going to be
frustrated, even angry. Likewise, if directness and success are both
good, but time is very long, that means the users are getting confused
by something.

‚Äç

First clicks are important, that\'s why first click testing is a thing.
Users who get the first click wrong are much less likely to accomplish
their goal (even with backtracking) than those who get that first click
right (even if they get off track for a while later). In tree testing,
that means wrong first clicks should have a greater bearing on a task\'s
\"grade\" than wrong turns later. Conversely, if the first click is
right but the destination is wrong, that helps you localize the problem
so you can fix it.

‚Äç

The location of wrong first clicks can also suggest how you can change
the tree to make it more intuitive for users. If the wrong clicks
cluster, change the tree so that the cluster is right. If the wrong
clicks are scattered, then the destination for that task might better
belong to multiple headings\--unless scattered wrong first clicks turn
up for many tasks, in which case your options may be poorly
differentiated. Consider doing a card sort to develop more clearly
defined categories.

‚Äç

It\'s worth noting that although the data from a tree test are
quantitative, and the results are numbers, interpreting the results
requires the type of judgment calls more typical of qualitative tests.
You can also dramatically improve the value of the test by including the
[**(properly analyzed) qualitative
data**](https://www.userinterviews.com/blog/how-to-analyze-qualitative-data-with-the-design-gym)
from the pilot study. For example, if a given task took a very long
time, the qualitative results might tell you what testers were spending
all that time doing.

‚Äç

## Conclusion

Tree testing has the advantage of being easier to set up and run than
most of the other tests, thanks to modern tree testing tools. To create
a new test, you just edit a spreadsheet. Tree testing is no panacea, but
no type of testing is. For best results, use tree tests in conjunction
with other testing types, to get a full picture of the progress of your
development process.

‚Äç

### Manage your own participant panel

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/surveys)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/first-click-testing)

Next:

First Click Testing

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[First Click
Testing](/ux-research-field-guide-chapter/first-click-testing)

# First Click Testing

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

First click testing =¬† testing to see where users click first.

‚Äç

The end. Thanks for reading!

‚Äç

Just kidding---although that is the long and short of it, there's lots
more to know: like why the first click for each task is so essential,
when it makes sense to explore where and why users are clicking, and how
to conduct your own first click test.

### In this chapter:

-   What is first click testing
-   When to use first click testing for UX research
-   How to conduct a first click test
-   Analyzing and interpreting first click data
-   First click testing tools
-   Combining first click testing with other methods

## What is first click testing?

[First click
tests](https://www.nngroup.com/articles/navigation-ia-tests/) are a
quick research method that can be used for any product with a user
interface, including websites, apps, or mobile web pages. They're used
to evaluate whether or not your page's navigation and linking structure
is effective in helping users complete their intended task.

‚Äç

The idea is pretty simple: You show participants a wireframe or design
of a page and ask them where they'd click to perform a specific task. By
recording and analyzing wherever they click first, you can answer
questions like:

-   Which buttons, content, language, and other navigational elements
    are most intuitive for users?
-   Which navigational elements do users not notice, misuse, or avoid
    altogether?¬†
-   Where is the best place to put things like buttons, shopping cart
    icons, menus, and other navigational elements?
-   What is the optimal path to take to accomplish a task, and how does
    your design support or interfere with that path?¬†

‚Äç

The results of a click test often take the form of a heatmap (a.k.a, a
'click map' or 'dark map'), which illustrates the most common click
locations. Analyzing where users clicked can help you understand whether
or not your design is supporting the optimal user experience.¬†

## Why is the first click important?

The first click dictates overall session success. Getting the first
click right is a critical milestone in designing a user-friendly site.¬†

‚Äç

In 2006, Bob Bailey and Cari Wolfson conducted [one of the most
influential usability
studies](http://webusability.com/firstclick-usability-testing/) out
there. Their findings are still relevant today, and will probably stay
relevant for years to come. Their study revealed that when users had
trouble executing the very first thing they wanted to do on a website,
"they frequently had problems finding the overall correct answer for the
entire task scenario."

‚Äç

Meaning when the first click fails, the rest of the session tends to
tank as well. More specifically, when the first click is incorrect, the
chance of eventually getting the overall scenario correct is about
50/50. Participants are about twice as likely to succeed in the overall
mission when they select the correct response on their first click.

‚Äç

This finding has been validated in a variety of other studies as well:

-   When people get their first click right on a website, they're [2--3
    times more
    likely](https://www.optimalworkshop.com/learn/101s/first-click-testing/#writeTasks)
    to find what they're looking for than if their first click was
    incorrect.
-   Participants who click down the right path on the first click [will
    complete their task successfully 87% of the
    time](https://www.usability.gov/how-to-and-tools/methods/first-click-testing.html),
    whereas participants who click down the wrong path tend to only
    complete their task 46% of the time.¬†
-   If the first click is correct, the chances of getting the whole
    scenario correct is 70%---but if the first click is incorrect,
    [those chances drop to
    24%](https://blog.optimalworkshop.com/does-the-first-click-really-matter-treejack-says-yes/).

## When to use first click testing for UX research

Because first click testing is inexpensive and the information gleaned
is usually relatively simple to take action on, you can use first click
testing for a wide variety of use cases. It's effective at almost every
stage of product development, as well as after launch to enhance and
improve functionality.

‚Äç

First click testing is usually discussed in terms of testing web pages,
but the technique can work equally well for any product with a user
interface. The idea is simply to find out if users can figure out how
the product works on their own. If they can access the information they
want (or execute a given task) in a sequence that makes sense, in a
timeframe that makes sense, then your design is successful.¬†

‚Äç

For example....

-   **You can test on a wireframe.** One advantage of first click
    testing is that your website doesn\'t actually have to exist yet at
    the time of testing---the \"click\" doesn\'t actually have to do
    anything. The user just has to demonstrate where they would click,
    if the button were active.
-   **You can test every version of a page, from concept to
    completion.** While testing literally every every step is probably
    not necessary, early tests can catch problems before they get
    expensive. You can take advantage of first click testing on initial
    designs.
-   **You can learn from prior tests to improve future designs.**
    Earlier feedback will inform how users perceive website elements and
    how they expect pages to function, so you can use this information
    in building your next wireframe.¬†
-   **You can improve your site once it's up and running.** If analytics
    or user feedback suggests issues with your navigation, you can use
    first click testing to identify the problem.

Other example scenarios that make sense for first click testing:

-   A news site wants to know where users might click to share an
    article on social media.
-   A retail site wants to see how a user might select their shoe size
    while browsing for heels.
-   A poetry app wants to know how you'd find a poem written by a
    certain poet.
-   A ride-sharing app wants to know how easy it is to lodge a complaint
    about another user.
-   A food-ordering app wants to see how users might switch from mobile
    to web in the middle of an order and continue their request.

## How to conduct a first click test¬†

A first-click test is relatively simple to design, requiring two basic
elements: The page, screenshot, or wireframe you're testing and the
tasks you want to test on that page.¬†

‚Äç

First click testing has a pretty simple order of operations:

1.  **Create your tasks (or 'scenarios')**. Ex: A bank website wants to
    know where a user would click to find out when tellers are
    available.
2.  **Determine the best path toward accomplishing the task.** Ex: From
    the homepage, the user should click "info ‚Üí hours."
3.  **Observe where users click** (info on how to do this is below). Ex:
    User clicked services ‚Üí bank ‚Üí info ‚Üí hours.
4.  **Record how long it took them to click** (info on how to do this is
    below). Ex: It took 12 seconds for the user to travel from the
    homepage to the hours page. Aka, too long!
5.  **Take note of the level of difficulty and the user's confidence
    level.** Ex: They clicked on the right menu buttons after two tries,
    but "info" seemed like a best guess, not a confident choice.

‚Äç

Along with the basic click test, you can also collect more nuanced data
by collecting pre- and post-study survey responses for participant
segmentation and in-depth analysis. In performing this type of analysis,
you can improve your page's usability with a better understanding of how
different types of users expect to interact with a design.

### Define your research objectives

The logistics of first click testing are simple, especially if you
already have functioning software---so [preparing your research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan)
is primarily going to be about defining your goals and understanding how
and why you'll use the insights you glean from the test.¬†

‚Äç

You likely already have a goal in mind regarding your site, or you've
identified areas of concern from places like:

-   Analytics or prior user tests.
-   Questions or priorities from stakeholders.
-   Common support tickets.
-   Sales or engagement data.

‚Äç

Using this information, **get clear on what you want to learn:**

-   Which pages are you concerned about?
-   Which tasks do you want to test?
-   What are the important things you want your users to be able to
    accomplish?

‚Äç

Clear research questions will help you determine what pages, or parts of
pages, to include in your test. It will also inform how many tasks to
assign to your testers. For example, you can ask many questions about
one page, or you can ask the same few questions about many different
pages; your exact approach will depend on the information you're trying
to collect.¬†

### **Determine your hypothesis:**

In your research plan, **define the ideal path** for accomplishing a
given task, as well as any other correct paths to task completion.
Although there may be many right answers, you'll need to choose one
'ideal' path that you'd like users to follow.¬†

The 'ideal' path you choose amounts to your hypothesis. Users will
either affirm or disprove your hypothesis as they click toward the
conclusion. In the end, if more than one path works, you'll decide
whether to steer users toward your preferred path, or if both are
equally valid.¬†

### Decide which pages to test

Determining the right pages to test will depend, again, on your research
goals and objectives. In some cases, you might test multiple pages for
the same types of tasks (e.g. testing the navigation bar on multiple
pages), while more specific tasks may only require one page (e.g.
testing a feature in the shopping cart or on a sign-up page).¬†

‚Äç

As we mentioned earlier, your page doesn't have to be fully functional
for the test to work; instead of using working buttons, you can just
present users with a screenshot of the existing page or a wireframe of a
planned page.¬†

‚Äç

Additionally, you can isolate parts of the page for more focused
testing. Here are some ideas for page tests from [Optimal
Workshop](https://www.optimalworkshop.com/learn/101s/first-click-testing/#writeTasks):

-   Screenshots of whole web pages (like the homepage, product pages,
    pricing pages, knowledge base pages, shopping cards, and so on)
-   Screenshots of parts of web pages (like top or side menus,
    mega-menus, account options, any part of a webpage you want to focus
    on in particular)
-   Wireframes created using products like Axure and Invision
-   Wireframes created using the back of the nearest piece of paper to
    you right now
-   App designs
-   'Internet of things' things (like remote controls, game consoles,
    and so on).

### Write clear tasks

Once you've identified your primary research questions and tasks, it's
time to write the questions and instructions you'll use to guide your
participants.¬†

‚Äç

With click tests, it can be a little tricky to get participants to
behave naturally; people are inclined to behave a bit differently when
they know they're being tested, and significant influences on their
behavior during the test can skew your data. You can help combat this by
being intentional about the language you use and the way you present
your instructions---for example, by giving users goals or 'scenarios'
instead of simply asking questions.

‚Äç

**Instead of asking:** Where would you click to find the bank\'s lobby
hours?

‚Äç

**Try:** You want to add someone as a signatory on your checking
account, and you know this needs to be done in person because you must
present an ID. You want to find out whether the tellers will still be
working when you get off work. Where would you click to get that
information?

‚Äç

**Instead of asking:** Where would you click to choose your shoe size?

‚Äç

**Try:** Here's a page full of formal shoes. How would you go about
buying a pair for prom?

‚Äç

**Instead of asking:** Where would you click to find out which dates are
available for concert tickets?

‚Äç

**Try:** You want to buy Jane's Addiction tickets for April 30th. How
would you do that?

‚Äç

By writing each task as an action-oriented scenario, with a clear goal
and an authentic voice, you encourage users to follow their natural
thought processes and problem-solving behaviors throughout the task (as
opposed to simply clicking the button they think you want them to
click).¬†

#### **Other tips:**

-   Avoid using words that could give away the answers. Don\'t ask
    \"where would you click to get help\" if the right answer is a
    button that says \"HELP."
-   Avoid technical language or other terms your target users might not
    know.
-   Don\'t assign more than ten tasks per test. You don\'t want your
    tester getting confused or tired.

### Recruit participants

[Recruiting
participants](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)
is often one of the most daunting steps in any research project; it can
be difficult to determine how many participants to recruit, who the best
participants would be, and where to find participants who are both
qualified and willing.¬†

‚Äç

(Psst---shameless plug: If you're struggling with recruitment, User
Interviews can help. [Sign up free for
Recruit](https://www.userinterviews.com/accounts/signup?promo_code=3FREE)
to source from a pool of more than 700,000 participants or [check out
Research Hub](https://www.userinterviews.com/research-hub) for building
and managing your own participant panel.)

‚Äç

You can find more in-depth tips for recruitment in the [recruiting
chapter of the Field
Guide](https://www.userinterviews.com/ux-research-field-guide-module/recruiting),
but the most important things to remember are:

-   **Your testers should be representative of your target users.**
    Depending on your study, testers can be recruited from a lookalike
    audience, or you could source from an established panel of your
    current users.
-   **Aim to recruit roughly 50--100 participants.** That's not to say
    you can't gain meaningful insights from tests with fewer people
    (especially if you're also collecting qualitative data in surveys or
    questions during the test), but 50+ completed first-click tests
    should give you the most reliable data.¬†
-   **Offer fair incentives for participation.** Incentives aren't only
    for the participants' benefit; they encourage participants to take
    your study more seriously, allowing you to feel more confident about
    the data you collect.
-   **Don't tell the participants they're taking part in first-click
    testing**, unless absolutely necessary.

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit)

### During the test

You may not always have the luxury of observing first-click tests in
real time, but doing so can provide you with additional insights about
participants' thoughts and behaviors.¬†

‚Äç

If you're able to observe users while they test, consider the following:

-   Watch users' facial expressions and body language as they test; if
    they make gestures or expressions you don't understand, ask them to
    walk through their thought processes.
-   Ask follow-up questions, such as why users clicked where they did,
    why they hesitated before clicking, or why they changed their mind
    about where to click.¬†
-   After they've clicked, don't tell the tester whether or not the
    click location was the right one. Participants need to feel like
    there's no right or wrong answer in order to behave naturally.¬†

‚Äç

The qualitative answers you receive from follow-up questions like these
can be just as valuable as the quantitative data of click location and
timing. If you're conducting tests remotely or asynchronously, you can
use automation tools or in-test surveys to source additional information
while users are testing.¬†

## Analyzing and interpreting first click test data

Every basic click test will provide you with a similar set of data,
including:

-   How many participants clicked where you wanted them to?
-   When participants clicked in the wrong place, where did they click?
-   When there's more than one 'right' place to click, where did most
    people click first?
-   How long did it take people to click?¬†

‚Äç

Typically, first-click test data will be presented in a clickmap,
augmented by information about the participants, survey responses, and
any other relevant links and resources. As with any study, there are a
number of different approaches to analyzing this data, but the best
place to start is by revisiting your original research goals and
questions. Check out the [Analysis and Synthesis section of the Field
Guide](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
for more details.¬†

‚Äç

When interpreting first-click data, here are some things to keep in
mind:**‚Äç**

‚Äç

#### **1. Take 'wrong' clicks seriously.¬†**

You might be disappointed to find that your hypothesis about where
people would click was wrong---but instead of attempting to force users
where you want them to go, it might just make more sense to rearrange
your design to allow users to travel to wherever they're naturally
drawn.

‚Äç

If a heat map shows wrong answers clustered together, that suggests
testers are being distracted by what looks like the right answer.
Clusters inform you of where participants are attracted, and how they
expect your website to work.

‚Äç

If the wrong answers are scattered, testers may be confused and choosing
randomly.**‚Äç**

‚Äç

#### **2. Measure in percentages.**

Figure out how many clicks are possible on the page. This way you'll be
able to measure clicks, and the areas that were clicked on, in
percentages.

‚Äç

For example, if there are 10 buttons on a page, those 10 buttons make up
100% of the clickable possibilities. At the end of the test you'll be
able to see what percentage of all clicks each area got. Using
percentages rather than just a count of clicks allows you to compare
tests that collected different numbers of results.**‚Äç**

‚Äç

#### **3. Measure times, too.**

Task completion ‚â† UI effectiveness.¬†

‚Äç

If testers are taking an excessively long time to figure out the right
answer, your design isn't doing its job. On the other hand, if testers
reach the wrong conclusion very quickly, that suggests something looks
so much like the right option that they never stop to look at the right
option.

‚Äç

However, be mindful that task time is a sensitive metric; as Jeff Sauro
says in [MeasuringU](https://measuringu.com/first-click/):

"Users may be finding the right spot during the evaluation (because
you're observing them or they're getting paid) but both long task times
and high task variability are indicative of problems in the navigation."

#### **4. Task completion ‚â† UI effectiveness.**

If users are finding the right location but feeling uncertain about
whether or not it's correct, that can signal a navigation problem;
you'll want to make the right answer more obvious.¬†

‚Äç

Likewise, if participants find the right location but rate it as being
highly difficult, you may need to make changes to your design to remove
barriers and streamline the process for users.¬†

‚Äç

#### **5. Compare against a benchmark.¬†**

In many cases, you'll be performing a click test to understand whether
or not a new design performs better than an old one---and this research
won't be useful unless you test your original design as well.¬†

‚Äç

If you do a click test with every iteration of the design, you'll have
prior tests to compare and contrast. But if not, be sure to test the
original design as well; you'll need this benchmark in order to draw
meaningful conclusions.

## First click testing tools

If you're able to observe click tests in person, it's possible to track
clicks by hand---but the most efficient (and accurate) option is to use
one of the many click tracking tools out there:¬†

-   [UsabilityHub](https://usabilityhub.com/) is a remote user research
    platform that offers features for first-click testing, as well as
    preference tests, five second tests, and design surveys.¬†
-   [Optimal Workshop](https://www.optimalworkshop.com/) offers tools
    for a variety of UX research methods, including card sorting, tree
    testing, and online surveys. [Here's their first-click testing tool,
    Chalkmark](https://www.optimalworkshop.com/chalkmark/).¬†
-   [UserZoom's Click Testing](https://www.userzoom.com/click-testing/)
    feature allows you to conduct remote click tests on multiple design
    variants, ask follow-up questions, and visualize results in
    heatmaps, darkmaps, or click clusters.¬†
-   [Useberry](https://www.useberry.com/) offers remote UX testing tools
    for a variety of user testing methods, including first-click
    testing.¬†
-   [Proven by Users](https://provenbyusers.com/) is a user research
    platform that allows you to test all aspects of your UX and design,
    with tools for first-click testing, as well as card sorting, tree
    testing, surveys, and other methods.¬†
-   [UXTweak](https://www.uxtweak.com/) offers a variety of UX research
    tools, including first-click testing tools.¬†
-   [HotJar](https://www.hotjar.com/) allows you to track and analyze
    user behavior on a live website, with heatmaps for visualization and
    remote recordings of user behavior.

‚Äç

If you don't see what you're looking for, many usability tools offer
first-click features;
[here](https://maze.co/guides/usability-testing/tools/) and
[here](https://www.userbrain.com/blog/free-usability-testing-tools) are
two good lists to choose from.¬†

## Hybrid research: Combining first click testing with other methods

As with any type of UX research, we recommend pairing your first-click
tests with other methods to gain a more complete and accurate picture of
user behavior. In general, first-click testing data tends to pair well
with task analysis, card sorting, and tree tests, as well as qualitative
methods like follow-up surveys and questionnaires.¬†

‚Äç

One way to pair first-click tests with other methods is to use the [Top
Task
Methodology](https://digital.gov/2014/07/02/using-top-tasks-to-be-top-notch-federal-reserve-board-usability-case-study/),
a 5-step process that goes as follows:

![top task methodology
diagram](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61e1809452dae011f0d83752_mRnfU1Le4Fpc-muO0BSubln5p_8Ou0x_IGj9z3SccA5DqCA6iTna83eHsDyrNCzn9XS5cRAGBIwTCzyYLbcVjs3RGOOjnDwpWhxx9UW9pJfX0qpUpE-92FcU3zitA2gBpkVNb_ob.png)

1.  **List tasks.** This step should be taken care of during the
    planning stage; starting from the homepage, list all of the possible
    tasks a user can perform on your website. Try to keep it to 100
    tasks or fewer if possible.¬†
2.  **Rank tasks.** Survey your users and ask them to pick and rank
    their top 5 most important tasks. This step, paired with step one,
    functions as a [task
    analysis](https://www.userinterviews.com/ux-research-field-guide-chapter/task-analysis).¬†
3.  [**Card
    sorting**](https://www.userinterviews.com/ux-research-field-guide-chapter/card-sorting)**.**
    Pulling from the 30--50 most highly rated tasks, present users a set
    of cards with separate tasks listed on each, and ask them to sort
    those tasks into 4--8 buckets. These buckets should form your
    initial navigation structure.¬†
4.  **First-click test.** Perform a first-click test on specific tasks
    to validate or invalidate your navigation structure. By doing this
    in the wireframe/prototyping stage, you can catch issues with your
    navigation before they've done too much damage.¬†
5.  **Homepage test.** Finally, perform an additional first-click test
    with a full-color screenshot of your homepage to test the usability
    of your site along with the design.

‚Äç

This 5-step process should provide you with a solid foundation for a
pleasing and intuitive user experience.¬†

### First click testing tips

TL;DR---quick tips for first-click testing include:

-   Make sure your participants are representative of your target
    audience.
-   When writing tasks, give participants a problem to solve and avoid
    using language that would give the answer away.
-   During the planning stage, be sure to document the ideal path to
    complete each task, as well as any other 'correct-but-not-ideal'
    paths.¬†
-   Along with recording click locations, time how long it takes users
    to make their first click and complete the intended task.¬†
-   Ask users about their level of confidence that they made the right
    click, as well as the level of difficulty it was to find the click
    location.¬†
-   Use first-click testing tools to record each session, create
    heatmaps and more easily analyze and synthesize your data.¬†

## A final word

First-click tests are a quick, simple, and relatively inexpensive method
for understanding and improving the user interface of your product.¬†

‚Äç

Remember: When users get the first click correct, they're **2--3 times
more likely** to complete the entire task than if their first click is
incorrect. By testing and optimizing the first click, you're doubling or
tripling the success of your user interface.¬†

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/tree-testing)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/task-analysis)

Next:

Task Analysis

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[Task Analysis](/ux-research-field-guide-chapter/task-analysis)

# Task Analysis

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

If you were not a ballerina, and you had to guess at how a ballerina
might put on a brand new pair of toe shoes, what would you guess?
Perhaps you'd imagine that she gets into her tights, slips on her shoes,
ties those pretty ribbons around her ankles, and gets to it. You
wouldn't know, unless you asked, that a ballerina will first decide,
then label, which goes on the left foot and which on the right. (They
don't come marked.) A ballerina will measure and indicate on the shoes
where their own arch will land, and then go through a process of
breaking the shoe in ¬†that area. They rip off tags and laces. They
sometimes pull out insoles and add their own. A ballerina will sometimes
sew an extra elastic band onto the front, or add their own ribbon. They
might glue a piece of leather to the tip for traction. They stuff the
toe with protective cushioning. And on it goes, until they're ready to
be used.

‚Äç

Task analysis is the research method whereby the steps in a process are
revealed to someone who's not in the know. The challenge can sometimes
be that product-builders believe they're in the know when they're not,
and so they think this sort of research isn't necessary. In reality, how
we think people do things is often not how they actually do them at all.

‚Äç

## What Is Task Analysis?

Task analysis is an effective way to find out what people who you hope
will use your product are trying to achieve, how they go about achieving
it, and how effective they are.

‚Äç

Some of the questions you can answer with task analysis include:

-   What personal or cultural experiences do users bring to the task?
-   How does the prior knowledge of each user influence how they
    approach the task?
-   How does the physical environment influence what users do?
-   Where and when do they begin a task?
-   How long do they expect it (the task, whatever it is) to take?

‚Äç

\... and more.

‚Äç

\"The task\" can be any series of goal-directed behaviors involving your
product, from the simple to the complex. Most tasks can be broken up
into sub-tasks. Determining what counts as a task, and which tasks you
want to analyze, will be your first order of business.

‚Äç

### When to Conduct Task Analysis

Short answer: before you create your user flow.

‚Äç

If users end up not using some feature of your product the way you
anticipated or hoped, or if they can't finish a process or achieve a
certain goal, there's a chance you missed something in task analysis.

‚Äç

Task analysis should be done near the beginning of the design or
redesign process. It makes sense to understand the problem (which
happens in the discovery phase) before creating the tasks to solve it.
So, task analysis is a great approach to use in the early in the
prototyping or research validation stage.

‚Äç

Once you find out a user's most likely path from point A to B, you can
base your design on their expectations rather than your own.

‚Äç

## How to Conduct Task Analysis

### Preparing for task analysis

The data you'll use to conduct task analysis can come from user
interviews, observational studies, or some other method. You may be able
to use data originally collected for another phase of the product
development cycle, or you may have to target your research towards
preparing for the task analysis specifically.

‚Äç

If you can answer the following questions, then you have enough
information to begin a task analysis:

-   What makes users begin the task?
-   How do users know when the task is complete?
-   What do users have to know in order to complete the task?
-   What tools do users need during the task?

‚Äç

### Identify the flow

When it's time to conceive of, design, or build a segment of user-flow,
you might consider applying task analysis to that particular project.

‚Äç

### Pick an Analysis Type

There's more than one approach, and none are wrong. The simplest to
describe may be a Hierarchical Task Analysis. Choose that option, and
you\'ll do the following:

‚Äç

#### **Hierarchical Task Analysis**

##### Identify the task and its subtasks

If there's one major goal (the task), break it down into subtasks. Each
subtask needs its own goal.

‚Äç

To test it out, let's make a peanut butter and jelly sandwich!

‚Äç

Goal: satisfy hunger and indulge childhood snack sentimentality

-   Subtask: select jelly flavor from vast array
-   Subtask: stir oil into peanut butter without staining shirt
-   Subtask: lightly toast bread for optimal texture experience
-   Subtask: cover all corners of bread to the edges with peanut butter
-   Subtask: cover all corners of bread to the edges with jelly

‚Äç

\...and so on.

‚Äç

Tip: If your task contains more than eight subtasks, you are probably
trying to analyze something that is too broad or complex. Drop down a
level; promote your subtasks to tasks in their own right and do multiple
analyses.

‚Äç

You might also be tackling a task that is too vague. For example, if the
user\'s goal is \"to be a good partner,\" that could mean almost
anything and is thus impossible to study. Be aware that most people are
really bad at articulating their own goals; they have their goals, and
may know intuitively how to pursue them, and will certainly know when
the goal is reached, but might not be able to state the goal coherently
when asked. You might have to do some in-depth [**qualitative data
analysis**](https://www.userinterviews.com/blog/how-to-analyze-qualitative-data-with-the-design-gym)
in order to extract usable goal statements from what your subjects have
told you.

‚Äç

##### Draw a Diagram

Your next step is to create a diagram of all the actions required for
the task and each of its subtasks. Do not exhaust yourself by taking
\"all\" too literally---use your judgment and the guidance of your data
to determine which steps are pertinent. Your diagram should show how the
tasks relate to each other and in what order (if it matters) they need
to be done.

‚Äç

![task analysis of a pb&j
sandwich](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5c1962b72f0717e54b1951c6_PB%20%26%20J%20Task%20Analysis.png)

‚Äç

For example, with that peanut butter sandwich, subtask 1, \"ingredient
assembly,\" must go before subtask 2, \"light toasting,\" otherwise you
won\'t have any bread to toast. Within subtask 1, it doesn\'t matter
whether you find the bread or the peanut butter first, but in subtask 2,
the bread must go in the toaster before you turn the toaster on.

‚Äç

You can draw your diagram any way you like, provided it works for you
and your team. There is no established standard. Sticky notes, perhaps
stuck to a white board and connected by drawn lines, have the advantage
of being easy to shuffle around as you develop your ideas.

‚Äç

##### Write the story

Diagrams all by themselves don\'t tell the whole story and won\'t be
useful to anyone who isn\'t already familiar with the task you are
analyzing. So, as a companion to the diagram, write out the whole story
in narrative form. Then each version of your output will complement the
other.

‚Äç

##### Ask for outside input

Now, go share your diagram and your story with someone (or several
someones) who aren\'t on your team but are familiar with the task you
are analyzing. Get feedback on whether your description of the task and
all its subtasks matches their understanding, and also on whether your
description is clear and consistent. For example, are all your subtasks
described to the same level of detail, or was one left vague? This is
where you find out so you can fix it.

‚Äç

### Other Task Analysis Types

‚Äç

#### **Cognitive task analysis**

The other main type of task analysis is cognitive task analysis, which
is like hierarchical, except in addition to looking at how the different
steps relate to each other, you will also be examining how the user
makes decisions at each step, how much cognitive challenge is involved
in each step, and how the process might differ depending on the
experience and knowledge level of the user.

‚Äç

#### **Parallel analysis**

You could also do a parallel analysis, meaning the same task is analyzed
multiple times (by either method, or by both methods) to reflect the
perspectives of different user groups, which you represent in your
analysis by different personas. Perhaps one persona is a type 2 diabetic
who uses sugar free jelly, and the other persona has a serious texture
aversion to soggy bread, but likes honey. Sandwich making could look
very different for each persona, and your product has to work for both
of them. Another reason to do parallel analyses is to get the input of a
second team. Each of you can do your own analysis and then compare.

‚Äç

Either way, you then write a final analysis that is informed by both
versions.

‚Äç

### What Next?

Having created your diagram and written your story, what do you do next?
How do you use the completed analysis to inform your design?

‚Äç

Basically, you look for places in the steps you have defined where you
can help. With the peanut butter sandwich example, you could recommend
spreading peanut butter on both slices of bread, to protect it from the
jelly in the middle. Then, you can eliminate the entire light toasting
subtask, if the purpose is to protect the bread from getting soggy.
You've solved that problem another way.

‚Äç

Unless your user likes toast.

‚Äç

This is where some of the caveats come into play. The analysis must be
from the perspective of your users (as revealed by your data), not from
your own perspective.

‚Äç

Looking for places to help might be both easier and more rigorous if you
develop a consistent method of annotating your diagram. For example, you
might note which steps present problems for the user and which don\'t in
your current solution, or which steps must, by their nature, be done by
the user personally and which could be automated. Once your annotation
is complete, you can clearly see which design challenges you have to
tackle and which you can and should ignore. Cleaning the excess jelly
off the knife could be automated, but the user does not regard having to
lick the (dull) knife clean as a problem, so your annotation should make
clear you don\'t need to build a de-jelly machine. A functional \"light
toast\" setting on the toaster would be nice, though, if you're making
the toaster (partnership potential if not!)

‚Äç

### Things to watch out for

Task analysis done wrong isn\'t helpful. Unfortunately, it\'s one stage
of the product development cycle that many people like to do wrong
(unintentionally, of course) or skip altogether. With that in mind,
watch for the following common tendencies:

‚Äç

#### Don't assume you already understand the problem

Many people skip or undervalue task analysis because they believe they
already understand the problem the product has to solve. It\'s an
incredibly common error in all sorts of contexts; assuming you know how
another person thinks and feels, what they want and need, and what helps
or hinders them, when you haven\'t bothered to ask. The reality is that
feeling confident you know something and actually knowing it are two
different things, and if you didn\'t ask or observe, then you don\'t
know.

‚Äç

For example, online storefronts often have \"shopping carts\" because
someone has assumed that online shopping works the same way a trip to
the grocery store does. Actually, online shoppers use shopping carts in
other ways than intended---to collect several items to be purchased at
once. Instead, most people use shopping carts to assemble wish lists or
to facilitate side-by-side comparisons. The typical shopping cart can
therefore be a great solution to a problem most people don\'t have---and
a poor solution to the problem they do have.

‚Äç

#### Relying on informants who already understand your product

If you're doing a product redesign, don\'t rely on established users for
your task assessment. Established users have learned how to make your
product work and won\'t give you much information on how it isn\'t
working. Their muscle memory is not useful to you.

‚Äç

#### Don't assume you already know

This is the most common pitfall to be found in standard approaches to
mapping user workflows. Approach assessment with a neutral mind. "But
this is how I would do it!" isn't useful, even if you're deeply enmeshed
in the topic at hand. If you already have a favorite solution, you\'ll
tend to design your research so as to confirm your opinion. The best
thing for your customers and your company might be very different from
what you think is the best way.

‚Äç

#### Focusing on your product, not the task

Focusing on the task means looking at how users try to accomplish a
goal, not how users try to use an existing product. That means that
sometimes you\'ll be studying the use of an earlier version of your
product, or maybe an analogous product made by someone else, but in
other cases you won\'t. You might instead look at how people use a
brick-and-mortar equivalent of your online store, for example. Or if
you're very early on, how they accomplish a goal without anything like
your solution.

‚Äç

## Conclusion

Task analysis itself is comparatively easy. The difficult part is
collecting the necessary data to begin with and avoiding all the
downfalls covered under \"Caveats.\" It is worth remembering that the
reason the common mistakes are common is that intelligent,
well-intentioned people make them, sometimes even after having been
warned. Do not underestimate their allure. But, if used properly, task
analysis can be the critical factor that will allow you to design a
product people will want to keep using.

[](#) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/first-click-testing)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/a-b-testing)

Next:

A/B Testing

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Evaluative Research
Methods](/ux-research-field-guide-module/evaluative-methods)

\>

[A/B Testing](/ux-research-field-guide-chapter/a-b-testing)

# A/B Testing

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Should your app have five menu options or just three? Should you use a
still image, or a GIF on the main screen? Which copy works better when
you're trying to move a customer through the funnel? For these types of
either/or decision, it's best to just wing it.

‚Äç

We're kidding! Don't do that!

‚Äç

That's what A/B testing is for. If you're new to it, it's likely easier
than you think. It's now an industry standard as part of a larger
experimentation program for most growth oriented companies. And it's
kinda fun.

‚Äç

## What Is A/B Testing?

The simplest way to explain A/B testing is to describe it as confirming
which does better: this version or that version? Where one is A and the
other is\...B.

‚Äç

As long as your research question has this same basic structure, it
doesn\'t matter what your A and your B are (fonts? colors? flavors?
styles?) or what \"better\" means (more durable? sells better? higher
conversion rate?), you can use essentially the same research design and
the same types of statistical analysis.

‚Äç

You do have to define what \"better\" means, and define it in a way that
is simple, straightforward, and measurable.

‚Äç

![a/b testing
example](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5c1acd305c6133fd339b7d25_ab%20testing.png)

‚Äç

### When to Use A/B Testing

A/B testing can be used on
[prototypes,](https://www.userinterviews.com/blog/best-prototype-templates-examples)
in product development and to build marketing and promotional
strategies.

‚Äç

A couple of hypothetical research questions appropriate for A/B testing
could be along the lines of:

-   Which version of your website or aspects of your website (or app)
    have a better conversion rate?
-   Which drives more sales on a certain type of product: a discount or
    a promotional gift?
-   Of two differently-worded push notifications, which drives more
    engagement with your app?

‚Äç

#### **Single variant v. multi variant tests**

In a true A/B test, the comparisons should be kept as simple as
possible. For example, don\'t compare two completely different versions
of your website, because you\'ll have no idea what factors actually made
a difference. Instead, test two different header styles, or perhaps two
different locations of the call-to-action button.

‚Äç

There's a name for testing a bunch of stuff all at once, and that's
called multi variant testing. In a mutli variant test, you'll look at
three or more versions of something at once. A/B testing, as a term, can
be used synonymously with the term "single variant testing." This
article focuses just on A/B testing, which tests two versions of a
single thing at a time, which it's safe to say produces the most
straightforward results.

‚Äç

A super-simple way to understand the difference between these types of
testing:

‚Äç

**Single variant test or A/B test**: Is this button more effective when
it's green or white?

‚Äç

**Multi variant test**: Is this button more effective when it's green or
white or blue or red, and how about when the headline is "Get ready!"
vs. "Test now!"

‚Äç

#### **Support A/B tests with other methods and industry insights**

Since you can\'t and shouldn\'t test every little thing, you will have
to depend on other forms of research to identify what your users prefer.
You'll also utilize your team's knowledge of how your industry works to
identify which variations are worth the time and expense of an A/B test.
Part of the benefit of an A/B test is that it's quick, simple, and
cheap, But, rule of thumb? If you don't already have a hypothesis around
an idea, don't waste your time on the test.

‚Äç

Here's an example of how you might build a test that combines methods.

‚Äç

Say your website has a poor conversion rate, which you know [**through
continuous review of your web
analytics**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics).
You're confident you can do better. But how? You decide bring testers in
to use your site in a lab setting. You observe their behavior, and
discuss their experience with them afterward. Then you analyze the
results. You realize that your menu tab labels are confusing, which
means users don\'t stick around to shop. Your website designer suggests
an alternative based on her wealth of experience. It's now time to
implement an A/B test to compare the new menu tab labels with the old
ones.

‚Äç

You can run your A/B test in the lab as well, but you will likely get
more information, more conclusive data, faster and at a lower expense,
if you run a remote, unmoderated study. That is, use a service that
allows you to post two different versions of your website that are
identical to each other except for the menu tab labels, and randomly
assign half of all visitors to the test version. Then you can see which
version of the site has a better conversion rate.

‚Äç

#### **Speed is relative**

A/B tests can be quick, but not always. You may have to run the test for
several weeks before you get enough data to analyze, or you may get all
the information you need in a matter of days or hours. The length of
time you'll need will depend on a number of factors, from the intensity
of your site traffic to how important the decision is. It will feel
obvious to you when the data is conclusive.

‚Äç

A/B testing is great for taking the guesswork out of major and minor
decisions that can impact your bottom line. A/B testing can and should
be built into project budgets.

‚Äç

So, bottom line: when do you use A/B testing?

‚Äç

When you have a hypothesis grounded in other research and observations,
and you want to efficiently validate that you have the right solution.
A/B testing is good for making incremental gains. It is not the testing
solution to launch a new project or flip the script. A/B testing will
not get you there.

‚Äç

## How to conduct your A/B test

This process provides a framework you can use to organize your work.

1.  **Identify your problem.** Don\'t just guess; use appropriate
    analytics tools to be sure you have a problem in the first place and
    to find where exactly it is. Does the landing page of your website
    turn people off? Do your ads leave readers cold? Know what you're
    trying to prove or disprove. Name it.

```{=html}
<!-- -->
```
1.  **Know what users are already doing in the problem zone.** You want
    them to go left, but they're going right. You want them to click
    here, but you're losing them. Find out where the process breaks
    down. Where are they going instead? Your regular analytics should be
    able to answer these questions. It's best to have a detailed
    understanding of the problem. This way, when your gorgeous and
    conclusive test results come in, you can paint a picture. For
    example: Before the test, we'd lose users at X stage, but we changed
    the copy and the positioning of the CTA item, and increased
    click-through by X percent. In order to do this, you need to know
    definitively what it was like in the "before."

```{=html}
<!-- -->
```
1.  **Form a hypothesis about how to fix the problem**. A hypothesis is
    an educated---and testable---guess. It's generally formulatable as
    an if/then statement. \"If the header is in 22 pt font, rather than
    18, conversion will go up.\" Scientists test hypotheses in order to
    find out if their best guesses are right, and that's exactly what
    you'll do in your test.

```{=html}
<!-- -->
```
1.  ‚Äç**Define your goal.** For example, you want X more users to click
    through, you want to prevent X% of users from leaving, closing the
    app, clicking away.

```{=html}
<!-- -->
```
1.  **Define statistical validity**. This is your threshold for
    improvement. For example, if a GIF improves conversion by 2% over a
    still image, do you care? How much improvement do you need to see
    for the alternative to count as the better option? What gives a
    version statistical validity? Have an idea as to the answers to
    these questions before you go into the test. ¬†

```{=html}
<!-- -->
```
1.  **Define your volume for results**. What number of users will offer
    statistical validity? What percentage of your daily/weekly/monthly
    user base/subscriber list/active members will make these results
    conclusive?

```{=html}
<!-- -->
```
1.  **Create the B version, and test your hypothesis.** More on how to
    technically run the test below. Meanwhile, try not to peek at your
    data until you have collected enough for statistical validity.

```{=html}
<!-- -->
```
1.  **Analyze and act on your results.** If your B version meets your
    threshold for effectiveness, and if it proves your hypothesis, go
    with it! (Or, tell the appropriate colleague that you recommend
    doing so). If not, stay with version A, or create and test a new
    hypothesis. If the answer you get is a maybe, but maybe isn\'t good
    enough, try a different hypothesis. Also, double-check your methods.

‚Äç

### Other things to consider

There are a number of factors to keep in mind when designing an A/B
test. The following list is not exhaustive, but should give you an idea
of the limits and possibilities of the method.

‚Äç

#### Don\'t alienate your search engines

An A/B test on a website involves altering your site\'s code in order to
make a parallel site with the same address that a randomly selected half
of all your visitors go to. Unfortunately, doing the alteration
incorrectly could have a negative impact on SEO. Fortunately, Google
publishes [**current
guidelines**](https://support.google.com/webmasters/answer/7238431?hl=en#)
on how to run tests without causing problems for yourself. [**Google
also offers testing
services**](https://www.google.com/analytics/optimize/) themselves, if
you want to be extra safe. If you have any doubts about other search
engines, it's probably covered in their literature. Or, go with a
trusted provider (like us!) who know what they're doing.

‚Äç

#### What is your control?

There are two basic forms of A/B tests. You can test two new versions of
whatever it is (your website, your marketing email, the feed mix for pet
lizards) against each other or against a control, or you can test one
new version and compare it to the old version. Both are A/B tests.

‚Äç

#### Do test your options at the same time

The validity of your test depends on minimizing variables. You want to
avoid any circumstance wherein something irrelevant might be changing
your results. For example, if you run one version of your ad this month
and the other version next month, seasonal variability in your industry
could make the weaker ad look better than the stronger one. Unless
you're running the whole test in a lab, your A and your B must run
concurrently.

‚Äç

#### Don\'t let your test run too short or too long

Run your test too briefly, and you won\'t get enough data for
statistical validity. Run your test for too long, and you run a greater
risk that something will happen out in the real world to skew your
results. If necessary, you can retest, but the problem is best avoided
by stopping when it's time to stop. No need to guess about timing:
calculate how many users must interact with your test for statistical
validity and how long that will take given your current traffic flow.
Then test for that length of time.

‚Äç

Most A/B testing software companies have employed statistical models
that will decide for you what the optimal duration of a test is, but in
general 7+1 days or 14+1 days are suggested. That's either a week and a
day, or two weeks and a day. The extra day picks up for any errors, in
case something goes wrong.

‚Äç

#### One at a time

Let\'s say you want to test the header of your website and its menu
labels and the text of your call to action, and the new parallax scroll
on your homepage. That\'s fine, except if you put all three variables in
the same test it won\'t be an A/B test anymore, you\'ll need
multivariate testing methods. If you want to stick with A/B, you\'ll
need to do three different tests---and you\'ll need to do them at
different times. Remember that if you're testing two conditions of one
variable, half your visitors will get each condition and you will
accumulate test results at a rate equal to half your normal visitation
rate. Run three tests simultaneously, though, and only one sixth of your
visitors will get each test condition and you'll accumulate enough data
for statistical validity some time in the middle of the 23rd century.

‚Äç

Likewise, you can test how different variables interact with each other,
for example, if you have two different email texts and two different
page layouts, you can test whether email A or B produces more traffic to
web page version A, then test both emails again with web page version B.
But again, don\'t run both tests at once or you will divide your
audience too finely and not get enough data.

‚Äç

#### Know what you\'re looking for

With A/B tests, as with most other forms of research, the better and
more specific your question, the better and more useful your answer will
be. And, as with anything else involving statistics, your answers won\'t
take the form of a simple yes. You'll get a qualified \"maybe.\" A
mathematically defined level of confidence. Decide what confidence level
you\'re going to accept as a \"yes\" from the beginning. 95% is the
standard, but under some circumstances, you\'ll want to be more sure an
option is really better before you go with it.

‚Äç

## Drawbacks and Pitfalls of A/B Testing

A/B testing works very well if it\'s done right. Read on to learn how to
(not) get it wrong.

‚Äç

### The difference between scientists and usability professionals

Usability professionals often stop tests prematurely, either because
they think they already have the results they need or because they
decide the test isn\'t worth doing after all. Such sloppiness leads to
less bang for the same (or greater) research buck.

‚Äç

From a scientific perspective, sloppy testing is simply wrong. That\'s
because, in science, accuracy is the most important thing. Researchers
who later have to issue a lot of retractions can take their careers for
a long walk off a short pier---not only because accuracy matters in an
absolute sense, but also because scientists check and recheck each
other\'s work and if sloppiness occurs, somebody will notice and care.

‚Äç

In business, accuracy is just as important in an absolute way, but what
your colleagues and supervisors care about is the bottom line.
Realistically, a slight loss in accuracy is acceptable if it buys you
significant savings in time and money. The problem is that if you don\'t
thoroughly understand your testing methods and the statistical
principles that underlie them, you won\'t know which corners can be
safely cut and you might end up with a large loss in accuracy instead.
Neither you nor your supervisors and colleagues will notice how much
money you\'re wasting.

‚Äç

### Run your A/B test as a scientist would

As a general rule, you can get still good results from A/B testing for
less time and money by following certain principles:

-   If you don\'t have a definite reason to cut any corners, don\'t cut
    corners.
-   Be conservative. Whatever you\'re doing now is obviously at least
    ok, so staying with what you\'ve got is your default option. The
    risk is in making a change that looks like an improvement but
    actually makes things worse. When you cut tests short, this risk
    gets bigger. Counter the risk by looking for 99% confidence, not the
    standard 95%, before you accept that an alternative really is
    better.
-   If you are likely to often cut tests short, plan to do a lot of
    tests. Requiring a higher confidence level means you will stay with
    what you\'ve got more often. To keep your strategy innovative, you
    therefore have to test more options, giving yourself more chances to
    find something that improves your bottom line.

‚Äç

## Conclusion

A/B testing is fairly technical. Statistical literacy is a must simply
to design the test (the actual analysis will be done by computer). But
as technical tests go, it is a simple and straightforward method.
You\'re just comparing two alternatives. That simplicity makes the
results easy to discuss and to apply. At the very least, you\'re just
trying to find out which of your available options will make your
product better.

### Recruit from our panel of 700,000+ vetted participants

[Sign up for free](https://www.userinterviews.com/recruit) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/task-analysis)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/continuous-research-methods)

Next:

Continuous Research Methods

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Continuous Research
Methods](/ux-research-field-guide-module/continuous-research-methods)

![a person comparing another person\'s profile to metrics represented by
graphs and
charts](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f2f26da11cd0e5f83399_UI_CHAPTER_07_ARTWORK.jpg)

07\.

# Continuous Research Methods

A new edition of this module is coming soon! Subscribe to get notified.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

The need for answers about user needs, preferences, and pain points
doesn't go away after you launch a product---and that means the need for
UX research doesn't go away, either.

Things break, new features need to be launched, customer needs evolve.¬†
All these things require research.

Continuous research (or ongoing research) is an important part of
maintaining a great customer experience. Ongoing listening methods like
NPS surveys, user analytics, continuous customer interviews help keep
your product useful, relevant, and valuable to users.

In this chapter, you'll learn about:

-   **How to use product analytics** like in-app behaviors, user flows,
    dropoff rates, activation rates, and other product metrics to
    support your research and keep track of changes over time.
-   **Continuous feedback surveys**---like net promoter score (NPS),
    customer satisfaction score (CSAT), customer effort score (CES), and
    custom intercept surveys---and how they can help you stay on the
    pulse of user sentiment.
-   **Using** **sales, support, CS, and product data** in user research.
    Support tickets, bug reports, customer quotes, and first-hand
    knowledge of customers can be a goldmine of both qualitative and
    quantitative data if you know how to use it
-   **Continuous user interviews**---or regular, 1-1 meetings with your
    customers---to augment one-off studies with fresh insights,
    prioritize your product roadmap, contribute to agile functioning
    throughout your org, and create a research-first culture on your
    team.

‚Äç

[Start reading](/ux-research-field-guide-chapter/user-analytics)[Start
reading](/ux-research-field-guide-module/research-analysis-synthesis)

In this module:

New edition arriving January 2022!

[User Analytics](/ux-research-field-guide-chapter/user-analytics)

How to connect a continuous stream of quantitative data to insights and
actions.

[Continuous Feedback
Surveys](/ux-research-field-guide-chapter/continuous-user-feedback-surveys)

On a scale from 1 - 10, how likely are you to recommend continuous
feedback surveys to your friends and colleagues?

[Sales, Support, and Product
Data](/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)

Your product and customer-facing teams are sitting on a mountain of
quantitative data and user feedback. Here's how to tap into it.

[Continuous User
Interviews](/ux-research-field-guide-chapter/ongoing-customer-research)

New

New

New

How to make a habit of talking to your customers.

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### User Analytics

How to connect a continuous stream of quantitative data to insights and
actions.

##### Continuous Feedback Surveys

On a scale from 1 - 10, how likely are you to recommend continuous
feedback surveys to your friends and colleagues?

##### Sales, Support, and Product Data

Your product and customer-facing teams are sitting on a mountain of
quantitative data and user feedback. Here's how to tap into it.

##### Continuous User Interviews

New

New

New

How to make a habit of talking to your customers.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/research-analysis-synthesis)

08\.

### UX Research Analysis and Synthesis

[](/ux-research-field-guide-module/research-deliverables-reporting)

09\.

### UX Research Reports & Deliverables

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Continuous Research
Methods](/ux-research-field-guide-module/continuous-research-methods)

\>

[User Analytics](/ux-research-field-guide-chapter/user-analytics)

# User Analytics

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Launching a new product or experience is exciting, especially if you
expect that it will boost you business in a substantial way. But after
you've launched, it's time to assess how users are actually responding
to what you\'ve put out there, in real life.

‚Äç

How long are visitors staying on your site or in your app? How long does
it take for them to complete key tasks? Are they stumbling on the same
things over and over again? Are they buying the stuff you want them to
buy? The stuff they indicated they would buy in your previous research?
Are they generally picking up what you're putting down?

‚Äç

Many of these questions can be answered by reviewing user and web
analytics.

‚Äç

## Start with user goals

Begin with understanding your user's goals. For example, if you've
created an experience within a fitness app for someone who wants to get
lean, you want to understand which actions are the most important for
meeting this goal, then track the ease with which folks can complete
those actions.

‚Äç

So, how do you know when someone's having trouble? Sometimes users give
you feedback directly through [**a
survey**](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys)
or [**support
interaction**](https://www.userinterviews.com/ux-research-field-guide-chapter//integrating-support-sales-and-product-feedback).
Other times the writing is on the wall in the form of quantitative
analytics---like Google Analytics for web, Mixpanel for product events,
or other tools in your analytics stack.

‚Äç

## Understand why reviewing analytics matters

Quantitative analytics are important to all organizations, with
different departments and functions monitoring what is most relevant to
their needs. The C-Suite is likely watching top line metrics, like
daily, weekly, and monthly revenue, plus whatever key metrics drive that
revenue. Marketers are focused on metrics that drive revenue throughout
the entire funnel. Product teams are focused on product usage and user
centric metrics that help drive that usage, and ultimately revenue.

‚Äç

Whoever the person or team, the beauty of rallying around quantitative
metrics is everyone can speak the same language in a pretty objective
way. In the context of ongoing listening following a product release,
you probably have some historical benchmarks to watch post launch,
focusing in on the areas you were seeking to impact. Mapping user goals,
to product goals, to revenue goals, to quantitative metrics is an
important part of aligning goals across an organization.

‚Äç

Note that often, pairing quantitative methods with qualitative methods
like [continuous user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/ongoing-customer-research)
can reap the best, most well-rounded results.

## Determine the essential analytics you want to measure

Depending on the goals of your product launch or feature updates, you
may want to focus on some of the below common quantitative metrics.

‚Äç

### Survey analytics

‚Äç

![Fictional NPS data over time via
Promoter.io](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae75ed9b318ed9e6c62ebed_dashboard-compressor.png)

Fictional NPS data over time via Promoter.io

‚Äç

-   **NPS, CSAT, or CES scores** - As outlined in [**Chapter
    1**](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys),
    these survey metrics give you an idea of how your customers feel
    about your company and particular touchpoints with your company,
    such as the support experience. If these scores are changing
    (positively or negatively) following a launch, this can be an
    indication of how your changes are being received. Drilling into
    your data with a focus on key segments and cohorts, and validating
    with further data will help you uncover insights.
-   **Qualitative survey data** - Often the above surveys include a
    free-form question that can help you understand some of the whys,
    the motivations behind the positive or negative scores. As you
    combine quantitative data with qualitative and segment it by
    meaningful customer groups, you should start to from hypothesis you
    can then validate through testing and further research.

‚Äç

### Product analytics

‚Äç

![Example of retention data from
Mixpanel](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae75fb7fc4f3036a7f8c7ef_mixpanel%20retention.png)

Example of retention data from Mixpanel

‚Äç

-   **Feature use -** Which features are used and the most? Are your new
    features, or updates, getting used?
-   **Recency and frequency -** How recently did someone use your
    product? How frequently do they return?
-   **Value of use -** Are people who use a given feature more valuable,
    happy, or otherwise positively impacted by using it?

‚Äç

### Web analytics

‚Äç

![High level web analytics data from Google
Analytics](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae75ff8ee38f1b1a7b76e23_google%20analytics.jpg)

High level web analytics data from Google Analytics

‚Äç

-   **Time on site -** This can be a great area to drill into,
    especially for a content driven experience, or one where the revenue
    model is closely tied to visit duration.
-   **Visits -** How many people visited your experience overall? How
    are visits changing over time? More isn't always more, but all
    things being equal, it is.
-   **Unique visitors -** How many different users are interacting with
    the experience?
-   **Goal completion -** From leads generated, to purchases completed,
    to buttons clicked, if you can tag it, you can track it.
-   **Pages visited -** Which pages did an individual or group of
    individuals visit? Are those pages connected to key buyer/user
    journeys?
-   **Traffic source -** How did the user enter your experience? Was it
    from a certain campaign, organic traffic, or another source?
-   **Path to conversion -** Before converting, which pages do users
    visit? How long do they stay on site? Is this path as direct as
    possible? Is there an opportunity to improve your site navigation?
    Evaluate across different personas, lifecycle stages, or user
    stories. Not every user has the same goals.

‚Äç

By understanding and tracking your baseline against the metrics that
matter to your goals, and your users goals, you'll quickly notice where
a product update or launch is having an impact.

‚Äç

## Set up a system for measuring analytics

Once you\'ve determined the metrics you need to track, find what teams
may already be using, then what you may need and don\'t have. Some user
researchers build out custom dashboards, integrating Google Analytics
with Microsoft Excel, or taking advantage of one of the many business
intelligence tools now available. Whatever you can do to automate your
dashboards so you can spend less time collecting your data, and more
time analyzing and acting on it, is great. Make sure to share your
dashboards with other stakeholders too!

‚Äç

#### A good dashboard:

-   Prominently highlights the most important data
-   Illustrates change, anomalies, data worth noticing
-   Is connected to deeper data for drilling in where necessary to
    understand what's "really going on."

‚Äç

## Create a cadence for reviewing analytics

Perhaps you have a weekly department meeting where key metrics review is
a recurring agenda item. Or maybe you have a monthly OKR meeting. Or
maybe you are the lead researcher on a particular project you're very
invested in, and you need to know what's happening by the day or hour on
something that has just launched. Depending on your individual, team, or
company situation, set up a regular cadence for reviewing the metrics
that matter to you the most. Of course, it may make sense to review
different metrics at a different cadence. We recommend a weekly check-in
of your top level key metrics at a minimum, and then build from there
based on your needs. Give yourself a recurring task or calendar event to
make this ongoing review a habit or take advantage of automated email
reports for your services that offer them.

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/continuous-user-feedback-surveys)

Next:

Continuous Feedback Surveys

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Continuous Research
Methods](/ux-research-field-guide-module/continuous-research-methods)

\>

[Continuous Feedback
Surveys](/ux-research-field-guide-chapter/continuous-user-feedback-surveys)

# Continuous Feedback Surveys

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Once you've launched a new experience, you may feel as though you can
kick back, put up your feet, and wait for the positive feedback to roll
in. However, your work is far from over. In fact, in many ways, it's
just begun.

‚Äç

Post-launch is a critical time to gain user feedback. That's because
your product/design is now in the wild, and real users are going to be
clicking buttons, navigating to new pages, and generally interacting
with everything you've created. This is yet another key time to listen
to your users---where are they having wins? Where are the stumbling
blocks? What works? What doesn't?

‚Äç

Ongoing surveys are a great way to collect user feedback post product
launch. Here's how to get started from scratch, or more likely build on
systems you may already have running within your organization.

‚Äç

## Decide which survey methods you'll use

While there are countless survey tools and methods to choose from, the
good news is that you don't need a lot to set up a system that helps you
gain user feedback in a pretty automated way. Of course, you need to
make sure you're choosing a survey system that provides you with
feedback that you can act on.

‚Äç

Here are some things to do as you assess survey methods:

‚Äç

### 1. Align your efforts with business goals

When evaluating survey assessment options, start with knowing your goal.
Consider the overall goals of your product, business, and users, goals
that have probably been identified in prior research. Do you want to
improve customer satisfaction, increase conversions, or reduce customer
churn? Ongoing customer surveys can help you track metrics and
qualitative feedback related to how your users feel about the
experience. When it comes to metrics like churn, LTV, conversion rate,
we\'ll dive into those in our [**analytics
chapter**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics).

‚Äç

### 2. Decide which ongoing assessment methods are right for you

Many organizations like Net Promoter Score (NPS) which divides your
users into promoters (those who would recommend the experience),
passives (those who are neutral), and detractors (those who have
substantial problems). Other options are Customer Satisfaction (CSAT)
and Customer Effort Score (CES).

‚Äç

Here's an overview of some common assessments that user researchers use:

‚Äç

#### Net Promoter Score (NPS)

Net Promoter Score segments users based on how likely they are to
recommend your product to a friend. It's a simple way of assessing
whether your experience can spread word of mouth, which counts for a
lot. Often users will also see an option to include why they scored a
particular way. A little quant, a little qual. Nice.

‚Äç

![user interviews NPS
survey](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae7325551d4ae15fa60881b_Screen%20Shot%202018-04-30%20at%2011.11.39%20AM.png)

This is the NPS survey we send via email when someone completes a
project at User Interviews

#### Customer Satisfaction Score (CSAT)

The Customer Satisfaction Score (CSAT) measures customer satisfaction by
asking users to rate their experience based on a predetermined scale.
CSAT is simple and easy to use, but since the question is so broad, the
reason behind the responses can be hard to decode. Still, in some ways
it is a more direct question than NPS and can help gauge overall
satisfaction in a more straightforward way.

‚Äç

![A sample CSAT survey from Hubspot
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a69b9d467790c3e978f800_GoR7ffK-U_zsoxAQNiy_uQ9pcBlCuW1bz_DpT0stQ-5pclCTC_DtG6mjYPNueDDU7Qvqf_CBQ64iO6Wph51jRvPFyFEuyHUxLq8XSpLeUAQaCJnzlwNA96ccQIoEQRz2Lbwo1frP.png)

A sample CSAT survey from Hubspot

‚Äç

#### Customer Effort Score (CES)

CES measures how much effort it takes for users to complete certain
tasks, such as contacting support to resolve an issue.

‚Äç

![5ae738c27359c4301d04e1ff_nicereply%20ces](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae738c27359c4301d04e1ff_nicereply%20ces.png)

Nicereply shows what a CES survey looks like through its platform

‚Äç

#### Website Intercept Surveys

Website intercept surveys are essentially modals or similar that appear
at key points in the user journey to assess sentiment. This may seem
like an annoying addition to your site, but when implemented properly,
they can be relatively frictionless for your user, and provide key
ongoing feedback for you.

‚Äç

Some common tools businesses use to support gathering these types of
surveys are Wootric, Promoter.io, GetFeedback, SurveyMonkey,
SurveyGizmo, Nicereply, and Zendesk.

‚Äç

It\'s very possible someone or some team in your organization has
already established a tool or process of gathering one more of the types
of feedback you\'re interested in reviewing. You may be able to use what
they\'re already doing, or work with them to get the functionality
you\'d ideally want out of those tools.

‚Äç

## Make it easy for users to give feedback

As in many things user experience, when it comes to deploying an ongoing
user feedback survey, friction is your enemy. Here are some guidelines
to consider:

‚Äç

### 1. Keep your surveys short and focused

Ask only a small handful of questions for your best response rate, and
to keep your analytical attention focused on the key goals you've set.
NPS, CSAT, and CES typically include 1-2 questions for a reason. If
you're building your own custom survey, make sure you're tracking a
consistent quantitative metric, while allowing for an open response that
gets at the "why" behind the what. ¬†

‚Äç

### 2. Pick a good time to solicit feedback

Is there an ideal moment in your user journey where it makes sense to
ask for feedback?

‚Äç

For example, it makes sense for Google Maps to ask for a restaurant
rating shortly after you've added the restaurant as a destination in the
app or for Uber to prompt a driver rating right after a ride. Ask for
feedback while the experience is still fresh in the user's mind.

‚Äç

Depending on your goals, you might ask at different times. If you\'re
focused on gaining adoption of a new feature, you might ask people who
are using it about how they found your app and their initial impressions
after using it. You might also proactively survey users to find out why
they haven't adopted it yet.

‚Äç

Go back to your goals, and your status against any targets you've set
for launching a new product, then identify the users and events that
will give you the most insight to reach those goals. Finally, make sure
your surveys are deploying at the right time to achieve that.

‚Äç

### 3. Consider where you make your ask

Next comes where to deploy your survey. Again, your options may be
limited to the services you're using, but here are a couple things to
consider when you decide where to deploy surveys.

‚Äç

#### Keep it contextual

If there's a key moment to get feedback when someone is actively using
your web or mobile app, ask them directly in the app through a modal or
similar experience. If they miss prompt, you could follow up with an
email, judiciously.

‚Äç

Email based support conversations are naturals for email feedback follow
ups, and in the same way a chat or messenger conversation can easily end
with a chat or messenger feedback request.

‚Äç

#### Consider user preference

If you're sending proactive, versus user behavior triggered, surveys,
try to send them in the channels your users prefer. Email is a classic
choice here! But for your users who aren't subscribed to email, or those
who are more responsive via chat, in-app messaging, push, or other
channels, those may be more appropriate. Keep in mind push is likely
your most aggressive option, and you should watch your negative
KPIs---like opt-outs---closely when using it to request feedback.

‚Äç

### 4. Ask for feedback early and often

The best way to do this is to take the key moments and channels you've
identified, then automate the delivery of the survey based on those
rules. Depending on the platform(s) you're using for your survey(s),
your ideal state may be seamless, or may take a little clever
Zapier-ing, but you should be able to get these kinds of ongoing surveys
to a largely autopilot state, freeing you to spend more time uncovering
insight and making better product and business decisions.

‚Äç

And please make sure you're not berating your users. Look at your
ongoing survey program holistically, and take advantage of any frequency
capping or other options available to you through the platforms you\'re
using to make sure you are not overwhelming anyone.

‚Äç

This seems simple enough, but in many organizations these surveys may be
owned by a variety of teams like support or marketing, so you'll need to
work with them to make sure your surveys are implemented in the best way
possible to get you valuable feedback, which is what everyone wants.

‚Äç

In some cases, you may want to pair continuous feedback surveys with
other continuous methods like [continuous user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/ongoing-customer-research)
for better insights.

## Build a system for implementing results

There's no point asking users to take a survey you can't analyze and
take action on. Ongoing survey data can help you find issues you didn't
know existed, separate signal from noise, understand the why behind user
behaviors, and more. Make sure you have a system in place to continually
analyze data and implement improvements. Here are our top
recommendations.

‚Äç

### 1. Get the right people on board

Whether your research team acts as a service arm or your organization,
or works hand-in-hand with product to make decisions, it's essential
that you get the right people on board from the beginning. Work together
to assess the biggest priorities and determine how you will address
ongoing survey feedback in general.

‚Äç

### 2. Decide on a schedule for analysis.

The thing about ongoing listening methods is that they're running all
the time, so when should you stop and analyze what's happening? If
you've rolled out a brand new experience for the first time, you should
be checking in very frequently, whatever that means for you. If you
haven't released anything huge recently, you might review on a less
regular cadence. Many services now integrate with email or Slack, so you
can stay on top of the day-to-day somewhat passively, while doing a
deeper dive on a more set, less frequent cadence.

‚Äç

### 3. Implement changes based on what you've learned.

Make sure you have a way to bubble up the strong signals you're getting
from ongoing feedback. You may also identify quick wins in the form of
bugs or small usability issues that can make a big difference to the
user experience. In either case, building processes and relationships to
turn insight into action is critical to the success of your ongoing user
surveying initiatives. Make sure to document how the changes you\'ve
made based on ongoing survey feedback have improved the key metrics
you\'re tracking both regarding customer satisfaction, and broader
business goals (like retention or revenue).

### Talk to your users in 75% less time

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/user-analytics)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)

Next:

Sales, Support, and Product Data

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Continuous Research
Methods](/ux-research-field-guide-module/continuous-research-methods)

\>

[Sales, Support, and Product
Data](/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)

# Sales, Support, and Product Data

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Your support and sales teams are on the front lines, interacting with
users on a day-to-day, hour-by-hour basis. Because of this, your
customer facing teams are a great ongoing source of qualitative user
insight. Developing ways to access their knowledge, build relationships
with them, and align your interests are important aspects of managing
your ongoing listening, post-launch research.

‚Äç

## Build connections with sales and support

We talked a bit about ongoing surveys, like NPS, CSAT, and CES, in a
[**previous
chapter**](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys).
You may already be working in conjunction with your support and sales
teams to collect and analyze that data. Great, you have a leg up. This
data is great because once you have the processes set up, it keeps
coming to you in a pretty automated way, and you have a single metric or
two you can track over time to baseline against. For those reasons,
quantitative data is really useful for ongoing listening, but
[**qualitative data plays an important
role**](https://www.userinterviews.com/blog/how-to-analyze-qualitative-data-with-the-design-gym)
too in understanding why users are reacting positively or negatively to
your product.

‚Äç

Much of the data you can get from your sales and support teams will be
qualitative, based on the stories and feedback they hear each day. A
great way to encourage the exchange of this qualitative data is to build
relationships with customer facing teams. This will facilitate the
organic passage of knowledge, as well as help lay the foundation for
more systematic processes. If you're at a large organization, start by
identifying who has the information you need. Then, make friends with
them! Figure out how your work can benefit each other, and start coming
up with ways to make those things happen.

‚Äç

## Implement a system for collecting and organizing feedback

One of the biggest stumbling blocks when it comes to collecting
qualitative feedback is making sure there's a system of record for
organizing it all. If someone on your sales team tells you that everyone
struggles with a certain feature, how are you going to document that?
How will everyone access it when it\'s most relevant and actionable?

‚Äç

You can do this via a spreadsheet, project management tool, and/or via
regular meetings where someone takes notes, and adds the insights to the
company wiki say, to name a few examples. Recently, many organizations
are using [**Airtable to capture
\"nuggets,\"**](https://medium.com/@WeWorkUX/the-atomic-unit-of-research-insight-17d619583ba)
or small units of user insight that can be accessed on demand, when
building a product that addresses that situation for instance. We
actually use this solution at User Interviews!

‚Äç

![5ae766b241c712ebdbdddece_Screen%20Shot%202018-04-30%20at%202](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae766b241c712ebdbdddece_Screen%20Shot%202018-04-30%20at%202.55.18%20PM.png)

Nuggets in Airtable

‚Äç

Another recommendation is to break up the kinds of feedback that are
useful to various teams in the company (sales, support, marketing, etc).
Different teams can filter based on which team submitted the feedback,
or which team it is most relevant to. The point is, often user feedback
is relevant to many teams, so keeping that feedback together in one
place for all to see makes a ton of sense, and marks meaningful progress
for many organizations toward democratizing research and the user
experience in general. Make sure to discuss this data on a regular
cadence, so it doesn't fall into the ether.

‚Äç

## Analyzing support and sales experiences

An essential aspect of UX research, and [ongoing
listening](https://www.userinterviews.com/ux-research-field-guide-chapter/ongoing-customer-research)
in particular, is analyzing user interactions with your support and
sales teams across your website, email, chat, demos, or call center.
Work with your sales and support leadership to find ways to evaluate
this data. Perhaps sales or support puts together a weekly or monthly
report on what they\'re hearing on the frontlines, with an emphasis on
trends. Or, maybe you set up a recurring one-on-one with the same, of
different members of these teams to accomplish a similar goal. Perhaps
representatives from each team come together for a \"voice of the
customer\" session.

‚Äç

If your system for organizing feedback includes the key kernels of
insight gathered across email, chat, and phone, that may be enough for
your needs. But take the time to understand where the data is, what kind
of data is available, and make sure you have access to what you need to
stay close to the user after a product has launched.

‚Äç

### Go directly to the knowledge base

Your company likely has a self-service knowledge base where users can go
to ask questions and get the answers they're looking for. Using your web
analytics data, you'll be able to understand which articles get the
most/least views and which ones are marked as the most/least helpful.
You can look at what people search for most frequently, where they
click. This data can give you insights into where improvements can be
made in your product. If people have a lot of questions about a
particular topic, is it because the product experience could be more
seamless in those areas?

‚Äç

Because a knowledge base is sort of an extension of the product and
support team, you may also uncover opportunities to improve the
knowledge base in this process. Creating content for searches that
return no results, or even running further qualitative usability testing
to make sure people can find and understand the content they need. Work
with your support and product teams to tackle the best opportunities on
a regular cadence here.

‚Äç

## On bugs

Bugs stink. But when you're building new products, and constantly
iterating on them, bugs happen. Some bugs are relatively
harmless---they're mildly irritating but don't ultimately prevent users
from accomplishing key tasks. But there are also bugs that can cause
major interruptions, driving users away.

‚Äç

Before releasing a new experience, you do everything you can to find and
squash bugs. Often, QA teams get involved, as well as other software
developers. Even so, bugs crop up. As a UX researcher, bug reports can
be useful in your ongoing listening methods toolkit.

‚Äç

Take it from [**Itamar
Turner-Trauring,**](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback#)
Founder of [**Code Without
Rules:**](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback#)

Your software has bugs. Sorry, mine does too. Doesn't matter how much
you've tested it or how much QA has tested it, some bugs will get
through. And unless you're NASA, you probably can't afford to test your
software enough anyway. That means your users will be finding bugs for
you. They will discover that your site doesn't work on IE 8.2. They
clicked a button and a blank screen came up. Where is that feature you
promised? WHY IS THIS NOT WORKING?!

‚Äç

Thankfully, as a user researcher, you can make use of what your users
are telling you.

‚Äç

### Why getting bug feedback from users matters

If a user interacts with your experience and consistently finds bugs,
this is obviously a problem. The user will not feel positively about
your brand, even if they are still able to complete the tasks in
question. According to Turner-Trauring, users have only [**two options
when they confront
bugs.**](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback#)They
can:

‚Äç

![5ae74a47ee38f17b89b74bb8_Screen%20Shot%202018-04-30%20at%2012](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5ae74a47ee38f17b89b74bb8_Screen%20Shot%202018-04-30%20at%2012.53.50%20PM.png)

‚Äç

If you constantly fix your bugs, users are likely to be happier. They'll
stick around. However, it's not fixed bugs that make users loyal to an
app or experience. What's most important is that these users feel heard.

‚Äç

### Implementing a bug feedback system for users

A good bug feedback system means users are able to report bugs as
quickly and as easily as possible, and then feel that your team hears
their feedback, responds to it, and follows up.

‚Äç

Ask yourself:

-   How do users currently report bugs?
-   How often are users reporting bugs?
-   When users report bugs, do they get a customized reply, an
    auto-generated reply, or nothing at all?
-   Are users ever notified when the bugs they report are fixed?

‚Äç

### Tips for reviewing bugs

Do you have an internal Slack channel, dedicated email, or software that
helps you identify and share news of bugs? Probably your product or
engineering team has some systems in place you can take advantage of as
a source of data for your ongoing listening efforts. ¬†

‚Äç

FAQ and support desk reporting can similarly help you understand where
users are getting caught up or confused in the product experience,
reflecting usability issues that might not actually be bugs---someone
internally may have even thought they were features!

‚Äç

Users don\'t always know if they're encountering a bug or a usability
issue. Your \"bug reporting\" system therefore likely straddles several
of the above types of reports. Work with your support and engineering
teams to find the right sources of data to uncover key bugs and
usability issues, even if everything isn't always clearly delineated in
exactly the right place.

‚Äç

### What to do with bug reporting

We'll make the assumption that someone on your product or engineering
team is actively working to improve bugs, but this reporting has other
value too beyond fixing what's broken. If certain tasks or areas of your
product have had a history of bugginess, that's good insight to be aware
of when you're evaluating how to improve that experience. It may be the
at the experience itself is pretty good, it was just riddled with bugs
in the past. If NPS drops in a given week, it may be connected to a
string of bugs, and not that you built the wrong feature the wrong way
on a broader level.

‚Äç

The best way to use bug reporting for post launch ongoing user research
is to keep an eye on the volume of bugs coming in comparatively over
time, and the nature of those bugs. This will add a layer of useful
context to your analysis of a product\'s rollout and success as you look
to make constant improvements.

‚Äç

## Putting it All Together

Sales, support, product, and perhaps even marketing, have user data you
can use. You probably have data they can use too. Understand who has
what, where and how they\'re collecting it, and seek to keep your
insights accessible, organized, and actionable. The more all departments
share a common language and insights about user feedback, the more your
organization can march forward on a cohesive mission to improve the user
experience across every touch point. There are infinite ways to get
there, but the underlying principles are the same.

‚Äç

### Manage your own participant panel

[Try Research Hub free](https://www.userinterviews.com/research-hub)
[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/continuous-user-feedback-surveys)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/ongoing-customer-research)

Next:

Continuous User Interviews

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Continuous Research
Methods](/ux-research-field-guide-module/continuous-research-methods)

\>

[Continuous User
Interviews](/ux-research-field-guide-chapter/ongoing-customer-research)

# Continuous User Interviews

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Aristotle said,¬†

"We are what we repeatedly do. Excellence, then, is not an act but a
habit."

Likewise, excellence in UX research is not achieved with a single study,
but with habitual acts of research. Of course, one-off studies are still
incredibly important, and we're not suggesting you drop them in favor of
continuous research. Instead, combining one-off studies with continuous
research can take your UXR practice to a whole new level.¬†

‚Äç

When you [make it a habit to interview
customers](https://www.userinterviews.com/blog/4-tips-to-make-ux-research-a-regular-habit)
on a weekly, biweekly, or monthly basis---whatever cadence works best
for you---you can build your research muscle and use fresh, relevant
customer insights to drive your decisions.

### In this chapter:

-   What are continuous user interviews?
-   Benefits and challenges of continuously interviewing
-   Why does continuous research matter?
-   How to [build a participant panel for continuous
    research](https://www.userinterviews.com/blog/build-manage-research-participant-panel)
-   Tips for conducting continuous interviews, from planning to sharing
    insights
-   Helpful tools for continuous user interviews
-   Mixed methods for continuous research

## What are continuous user interviews?

**Continuous user interviews** are frequent 1-1 meetings with customers
for the purpose of collecting ongoing insights. Unlike [user
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
conducted as part of a dedicated study, continuous user interviews are
quicker, recurrent, and open-ended in nature. They're an important part
of the [continuous UX research
framework](https://www.producttalk.org/2021/05/continuous-discovery-habits/)
and, more broadly, the [continuous delivery
framework](https://www.userinterviews.com/blog/the-7-step-framework-pluralsight-uses-to-ship-customer-centric-product-continuously-that-you-can-steal-too)
used by agile product teams.

‚Äç

Specifically, continuous user interviews fall into the 'continuous
exploration' stage of the continuous delivery process, as demonstrated
in [this graphic by Scaled Agile,
Inc](https://www.scaledagileframework.com/continuous-exploration/):¬†

![continuous exploration - hypothesize, collaborate and research,
architect, synthesize, continuous integration, continuous
deploymentm](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6331e12cc08f95b9550876a2_MAgFqfoc562KrmLnKAqNSdQMuerd_USFAurPtT8ccqw1-_hEvlqGGhM8cSBAO6ntkmmF-XY4FJCwRPSMiGH0xP9NQPiWHQUNKIKs8eyRbwLDIA2BImzqr5n9Nv9kSYwsvIkHBuam9s8nu_6om-fL4tiqp3BedApQdzPVdlVcMvOmFUA89XS3-LX0AQ.png)

‚Äç

[Product Discovery Coach Teresa
Torres](https://www.youtube.com/watch?v=_KkDXQw7kqg) describes
continuous research as like "putting money in a bank"---in other words,
recurring interviews allow you to collect insights, like coins, which
can have a compounding effect over time.¬†

‚Äç

#### Types of continuous interview programs

Continuous interviews can take many different forms, including:

-   **Broad customer feedback interviews**, done on a weekly basis and
    focused on general discovery.¬†
-   **Team-based** [**customer
    interviews**](https://www.userinterviews.com/blog/the-ultimate-guide-to-doing-kickass-customer-interviews),
    done on a weekly basis by individual teams, focused on themes
    specific to that team.
-   **Structured user interviews**, occurring during specific stages of
    the design and development process and focused on answering targeted
    questions.¬†
-   **Recurring advisory board interviews**, occurring on a regular
    basis to build long-term relationships with customers and streamline
    future recruiting efforts.¬†

‚Äç

When you're deciding what continuous interviews should look like at your
company, focus on your goals.¬†Every organization is unique when it comes
to how their team is structured and what they\'re hoping to accomplish
with continuous discovery, so it may or may not be the right approach
for you.

‚Äç

For example, if you'd like to generally create more opportunities for
your team to interface with customers and boost empathy across the org,
you might lean toward broad or team-based interviews. If you'd like to
simplify recruiting for one-off studies, you can build an advisory board
to have the infrastructure in place when you need to access a pool of
participants.¬†

‚Äç

Or, you might choose to implement some combination of the different
types to encourage diverse and recurring conversations with customers
throughout the organization (in addition to project-based studies for
deeper analysis).¬†

### Benefits of continuously interviewing your customers

If it weren't obvious from our name, we're big fans of user interviews.
But adding continuous user interviews into the mix? Even better.¬†

‚Äç

Here are some of the benefits and opportunities associated with
continuous interviews.

‚Äç

#### 1. Seize opportunities when they're ripe (or pivot before too much damage is done).¬†

‚Äç

Continuous user interviews allow you to discover opportunities, pain
points, risks, and other customer feedback that can lead to new ideas or
product iterations (or [stop a bad product
decision](https://www.userinterviews.com/blog/design-failure-examples-caused-by-bias-noninclusive-ux-research)
in its tracks).

‚Äç

As Laura Carroll, Sr. Design Manager at Medium, says in [her article on
implementing continuous user
research](https://medium.design/implementing-continuous-user-research-at-medium-e32825641d9b):¬†

‚Äç

"\[Continuous research---as opposed to a traditional study approach---\]
creates a deeper understanding of users by creating more space for open
dialogue than a study focused on a specific feature or problem area
would."

‚Äç

#### 2. Prioritize next steps on your product roadmap.

‚Äç

Most product teams have a long list of "wishlist" items that they'd like
to work on (exhibit A: [User Interviews\'s product
roadmap](https://www.userinterviews.com/roadmap)).¬†

‚Äç

The trouble is, it can be difficult to know for certain which projects
are worth working on, and when to tackle them. When you're regularly
checking in with customers, you'll likely hear them bring up specific
goals or pain points that help you decide what to work on next.¬†

‚Äç

Product Discover Coach and Founder of [Product
Talk](https://www.producttalk.org/) Teresa Torres describes this benefit
in [her blog on continuous
interviewing](https://medium.com/@ttorres/continuous-interviewing-the-key-to-successful-product-teams-6bf63bfc1936):¬†

‚Äç

"When a product team develops a weekly habit of customer interviews,
they don't just get the benefit of interviewing more often, they also
start rapid prototyping and experimenting more often. They do a better
job of connecting what they are learning from their research activities
with the product decisions they are making."

‚Äç

#### 3. Create a research-first culture on your team.¬†

‚Äç

Last but not least, continuous interviewing helps foster an appreciation
for---and habitual use of---research throughout your organization.¬†

‚Äç

With regular user check-ins, you can create a healthy culture of
curiosity and openness among your team. Research becomes a need-to-have
practice of its own, independent of [confirmation
bias](https://www.userinterviews.com/blog/on-psychology-and-user-research-with-lorie-whitaker-of-rackspace)
or the urge to just "check boxes."¬†

‚Äç

Gregg Bernstein, User Research Lead at Cond√© Nast, joined [the Awkward
Silences podcast to talk about healthy research
cultures](https://www.userinterviews.com/blog/healthy-research-culture-gregg-bernstein-conde-nast):

‚Äç

"A sign of an unhealthy research practice is where research is
pigeonholed into: 'we\'re only going to use research to test or validate
something that\'s already been decided.'"

‚Äç

In other words, continuous research broadens your teams'
conceptualization of research, from a step that's only taken when
specific questions arise to **a process that can spark questions no one
would've thought to ask otherwise.¬†**

‚Äç

### Challenges and risks to be aware of when developing a continuous interviews habit

‚Äç

You might be thinking, "the more research, the better, right?"¬†

‚Äç

Not necessarily. As you conduct user interviews on a more frequent
basis, you may run into some growing pains.¬†

‚Äç

Although we're a big proponent of continuous user interviews, we also
understand that they come with some challenges and risks. These
challenges can be mitigated with careful planning and effective tools,
but it's important to be aware of (and plan for) them ahead of time.¬†

‚Äç

The main drawbacks of continuous user interviews are:¬†

1.  **They take time---**but, you can minimize the time you spend on
    continuous user interviews by keeping them short and sweet, pairing
    them with unmoderated methods like in-app surveys, and allowing
    [PwDRs (people who do research outside of the core UXR team, like
    designers or
    marketers)](https://www.userinterviews.com/blog/people-who-do-research-discovery-study)
    to conduct them on their own.¬†**‚Äç**
2.  **They could cause participant fatigue**---but, you can minimize
    this risk with a panel management solution like [Research
    Hub](https://www.userinterviews.com/research-hub) to track
    participation, set contact limits, and create recruitment guardrails
    for your team. You can also pair customer recruitment with
    recruitment from an external panel to supplement your research
    without over-contacting customers.

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)

## More broadly, why does continuous research matter?

‚Äç

Continuous user research **reduces the risk** involved in product
development by grounding all of your decisions in tangible user
insights.¬†

‚Äç

![regular user research lowers risk in product development, while
opinion-driven development increases risk over
time](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6331f70f7c4b025117274fbc_9NfZ9D3WbFnmm7tVjCX3nKE4mTqp5UgEohmCT57fM72r0dnoQZXFHaxAiF8ET1pijDXRlWwjLj7AYycMpC5FfftmDx_NIi4eNZ8SX0_pIrJ8lYIjBYja8kk3CgflERwWFQqPAcUaLr_p1-Uo1l3GvrLSGP829pn1WQid5zVSRrI-eFzeQNFEHCk1Sw.png)

[Graph by Product Discovery
Methods](https://pdmethods.com/user-research/how-to-conduct-user-interviews/)

‚Äç

When Teresa Torres, product discovery coach and founder of Product Talk,
[joined the Awkward Silences
podcast](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk),
she discussed the history of user research and how it's evolved to
include continuous research:¬†

‚Äç

"We\'ve seen over the last 15, 20 years, a lot of growth in user
experience design and user research. But a lot of that growth has been
fueled by a project mindset... so there\'s this idea that research is a
phase that happens at the beginning.... I think what we\'re finding as
we move towards more of a continuous improvement mindset, both on the
delivery and the discovery side, is that there\'s always questions that
could benefit from customer feedback."

‚Äç

In other words, research has shifted from one-off projects that answer
[specific research
questions](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-questions)
to an ongoing practice that reminds us that users will always be the
best advocates for themselves. Teams are often surprised, disappointed,
or taken off guard by the insights they learn from routine interviews,
and these insights lead products and businesses in unexpected (yet
valuable) directions.¬†

‚Äç

Oyster's Lead UX Researcher Dr. Maria Panagiotidi says in [her how-to
guide to introducing continuous research
habits](https://uxpsychology.substack.com/p/from-no-research-to-continuous-research):¬†

‚Äç

"Continuous research is a form of proactive research---we constantly
schedule user interviews without having a specific project. When we
don't have a focused project, the sessions can be used to help us
discover user pain points and uncover opportunity areas. In cases we
have specific questions, continuous research allows us to speed up
recruitment!"

‚Äç

Alas, continuous research and project-based research **inform** and
**accelerate** each other.¬†

‚Äç

Speaking of recruitment....

## How to build a participant panel for continuous user interviews

‚Äç

[Recruitment](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
is consistently---across projects, teams, and industries---one of the
biggest hurdles researchers face.¬†

‚Äç

As Teresa Torres says on [the Awkward Silences
podcast](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk):¬†

‚Äç

"I think the biggest \[objection\] I hear is, I\'m not allowed to talk
to customers. I don\'t know how to find customers. Takes three weeks to
recruit customers. I really think the biggest barrier to continuous
interviewing is getting somebody to talk to on a regular basis."

‚Äç

So how do you manage this challenge? Teresa says the very first thing to
do is **automate your recruiting process**.¬†

‚Äç

üìö If recruitment is a major bottleneck for you, we've created [an
entire guide on how to break this bottleneck, speed up research cycles,
and improve the impact of
UXR](https://www.userinterviews.com/blog/how-to-break-open-the-recruiting-bottleneck).
We recommend downloading a copy of the guide to have on hand for
recruitment best practices, but here are a few tips for recruiting and
managing an internal participant panel in the meantime:

‚Äç

1.  Map out your technical requirements.
2.  Assign panel ownership, roles, and responsibilities.
3.  Define participant criteria.
4.  Develop an incentive plan.
5.  Reach out!

### 1. Map out your technical requirements.

‚Äç

Before you can start reaching out to customers to sign up for your
panel, you need to make sure that all of your technical boxes are
checked.¬†

‚Äç

To effectively [build and manage an internal participant
panel](https://www.userinterviews.com/blog/build-manage-research-participant-panel),
you'll need:

-   A sign-up form and [screener
    survey](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
    with professional branding
-   Some way to deliver the sign up form to customers (e.g. a dedicated
    webpage or social link)
-   A place to securely store, update, manage, and (when requested)
    delete participant data
-   The ability to filter, segment, and export participant lists based
    on specific criteria
-   An email for communicating with participants (we suggest creating an
    official research@ email address for an extra dose of
    professionalism and credibility)
-   The ability to easily schedule session times with participants
-   [Incentives](https://www.userinterviews.com/blog/the-ultimate-guide-to-user-research-incentives)
    redeemable wherever participants are located
-   A request/ticketing system for any mishaps that might occur

‚Äç

... as well as any other technical requirements specific to your
company, such as a means for collecting signatures for
[NDAs](https://www.userinterviews.com/blog/ndas-and-informed-consent-for-user-research).¬†

‚Äç

### 2. Assign panel ownership, roles, and responsibilities.¬†

‚Äç

Who's in charge of this thing?

‚Äç

Even if multiple teams across your company intend to recruit
participants from your internal panel, it still helps to assign a
dedicated panel manager for oversight and quality control.¬†

‚Äç

As Jeanette Fuccella, Director of Research & Insights at Pendo.io and
former Principal User Experience Researcher at LexisNexis, says in [her
article about managing an internal user research
panel](https://medium.com/lexisnexis-design/managing-a-user-research-panel-8b717ebeda47):¬†

‚Äç

"By all measures the panel has been a huge success, but we would never
have been able to achieve this success without one key critical
component: our panel manager."

‚Äç

Typically, [panel
management](https://www.userinterviews.com/blog/ethnio-alternative-user-interviews)
would fall under the umbrella of [research
operations](https://www.userinterviews.com/blog/research-ops-what-it-is-and-why-its-so-important),
and include responsibilities like:

-   Recruitment and
    [screening](https://www.userinterviews.com/blog/screening-participants-in-research)
-   Communication with participants, including session reminders and
    fielding any questions they may¬†
-   Updating panel records with changes in personal information and
    participation status
-   Controlling panel access and maintaining data security¬†

‚Äç

... in addition to the other core functions of [a Research Ops
practice:](https://www.userinterviews.com/blog/kate-towsey-on-starting-a-researchops-practice)¬†

‚Äã‚Äã

![research ops: the orchestration and optimization of people, processes,
and craft in order to amplify the value and impact of research at scale
(functions include participants, governance, advocacy, knowledge,
competency, and
tools](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6331f7106042925247f38bf6_vwaPfSsi01xYFx1rLZ8l8sHrj5MvsRBycymCcAmYP7eg-6-6A1MJj9wM5MNz1A14dYJm4nqMamoRwhpvxzcM4vHvdcndPXeKBH7foPDQi2QJ0F77fAiH26Wmz8lkq9VKCgUujvtCjm0coh8N93S4oN-gzU0mIRYgjdctpjYm9Wz1SabPPsWELcfFRw.png)

[Infographic by Nielsen Norman
Group](https://www.nngroup.com/articles/research-ops-101/)

‚ÄçHowever, if your organization doesn't currently have a [dedicated ReOps
function](https://www.userinterviews.com/blog/research-operations-supports-scaling-democratizing-ux-research),
you can assign one of your user researchers as the panel owner. Just be
mindful of how many teams and projects they're supporting at any given
time---recruitment and panel management are big jobs, so it's not
reasonable to expect a lone researcher to handle them for large, scaling
teams.¬†

### 3. Define participant criteria.¬†

‚Äç

As with any study, you'll want to be intentional about the type of
participants you recruit to be on your panel. To get the most accurate
insights, the users on your panel should be a diverse and varied group
of people, reflective of your actual user base.¬†

Consider criteria like:

-   How long the participant has been a customer,
-   Which product or pricing plan they're using
-   Whether or not the customer is high-value and engaged or a more
    casual user of the product
-   Whether or not the customer is predisposed to having a
    better-than-average opinion of your product or business (e.g. your
    parents may be 'customers', but probably aren't in the best position
    to give you unbiased insights)
-   The number of studies the customer has already participated in, and
    whether or not past participation might jeopardize the quality or
    accuracy of the interview

‚Äç

Additionally, customers who actively sign up to participate on a user
panel might have different characteristics---for example, greater
extroversion, stronger opinions, or more engagement with your
product---than those who decline your invite.

To get the best results, be sure to balance insights from your panel
interviews with other types of research, such as [A/B
testing](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing)
or NPS surveys.¬†

‚Äç

### 4. Develop an incentive plan.¬†

‚Äç

Incentives are a great way to encourage panel sign-ups and thank
participants for their time.¬†

‚Äç

But before you start doling out cash, you should think about:

-   **What type of incentives should you offer?** Common incentive types
    include monetary rewards, product discounts, charitable donations,
    or swag. Because continuous interviews happen over a long period of
    time, it might not be feasible to offer monetary incentives every
    time. Do the math to figure out what will work for you long-term.¬†
-   **What is the right incentive amount?** The right amount of
    incentive is 1) a big enough value to be worth the participant's
    time and 2) a low enough value to be affordable and sustainable for
    your company. Check out our [UX Research Incentive
    Calculator](https://www.userinterviews.com/lp/ux-research-incentive-calculator)
    for help finding the best incentive that you can reasonably afford.¬†
-   **When should you distribute incentives?** Most researchers only
    offer incentives after confirmed participation in a study, but it
    might be worth offering incentives just for signing up to your panel
    in the first place (especially in the early stages, or if you're
    struggling to [recruit good
    panelists](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants)).¬†
-   **How should you distribute incentives?** You can distribute
    incentives manually using email or gift cards, or you can automate
    incentive distribution using tools like
    [Tremendous](https://www.tremendous.com/). If you use [User
    Interviews](https://www.userinterviews.com/support/distributing-incentives)
    for recruiting and panel management, we can take care of incentives
    for you.¬†

‚Äç

üìö Incentives are a big topic, and we could talk about them all
day---but this isn't the place. [Head to the UX Research Incentives
chapter to learn
more.](https://www.userinterviews.com/ux-research-field-guide-chapter/ux-research-incentives)

‚Äç

### 5. Reach out!¬†

‚Äç

Once you have the logistics, criteria, and incentives plan nailed down,
you can start recruiting customers.¬†

![6331f710218dff39e349b2dc_pFPeMCR-XheuFqFOAxpVjIW5CBV0iNTlCIKeXRGmOkrjt7LmBec0io4YlWC1ru-Nwq6NCmuzZPFSCvMdZWngoZFwEA8rfCME8FYk3iWReTFoFXhBIx8XpHS3pw9uwdoUcs-qzgvq4aQ6jny66RS9UtpOU0qVWkPZ4NIQWAF_3uSMcYZMWTGuLlEAdg](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6331f710218dff39e349b2dc_pFPeMCR-XheuFqFOAxpVjIW5CBV0iNTlCIKeXRGmOkrjt7LmBec0io4YlWC1ru-Nwq6NCmuzZPFSCvMdZWngoZFwEA8rfCME8FYk3iWReTFoFXhBIx8XpHS3pw9uwdoUcs-qzgvq4aQ6jny66RS9UtpOU0qVWkPZ4NIQWAF_3uSMcYZMWTGuLlEAdg.png)

[Example of an email invitation using Research
Hub](https://www.userinterviews.com/support/research-hub-participant-experience)

‚Äç

Some options for soliciting panel sign-ups include:

-   **Opt-in website forms** on a static webpage or using a
    pop-up/chatbot tool like [Drift](https://www.drift.com/).
-   **Emails** sent via tools with automated communication features like
    [User Interviews](https://www.userinterviews.com/research-hub) or
    [HubSpot](https://www.hubspot.com/). You can create templated
    [recruitment
    emails](https://www.userinterviews.com/blog/recruiting-user-research-participants-by-email)
    and ask account managers to send them for you; this is a
    less-efficient solution, but common in enterprise companies where
    there's more cross-team coordination involved.¬†
-   **In-app surveys** using tools like [Sprig](https://sprig.com/) or
    [Appcues](https://www.appcues.com/).\*
-   **Direct links** to panel sign-up forms via social media or
    platforms like Craigslist.
    [SurveyMonkey](https://www.surveymonkey.com/), for example, allows
    you to collect responses with a direct link in social posts.¬†

‚Äç

\*üí° [Pro
Tip](https://www.userinterviews.com/blog/a-framework-for-continuous-research-sprig-webinar)
from Allison Dickin, Sprig's Staff User Researcher, and Paolo Appley,
User Interviews's own Senior Product Manager: In-app surveys shouldn't
interrupt an important product workflow---otherwise you risk frustrating
users.¬†

### Scale your research with powerful panel software

[Book a demo](https://www.userinterviews.com/lp/book-a-demo)

## How to conduct continuous user interviews

‚Äç

Okay, so you've built your panel. Now what?

‚Äç

Here's how to [design and conduct user
interviews](https://www.userinterviews.com/blog/the-ultimate-guide-to-doing-kickass-customer-interviews)
as a habitual practice in the continuous research framework:¬†

‚Äç

1.  Set a length and cadence that works for you (and your users).
2.  Decide which teams should be a part of the conversation.
3.  Prepare a (brief) interview guide.
4.  Make it as easy as possible for participants to schedule (and show
    up to) sessions.
5.  Be an open, active, and empathetic moderator.
6.  Follow up with participants.

‚Äç

Let's dive deeper into each step.¬†

‚Äç

### 1. Set a length and cadence that works for you (and your users).

‚Äç

One of the most common objections to starting a continuous user
interview practice (and, really, one of the most common excuses for not
doing anything in life) is: "I don't have time."

‚Äç

Here's why that excuse is bunk: Continuous interviews don't have to be
very long.¬†

‚Äç

#### How long should continuous user interviews be?

‚Äç

As we recommend in our [Continuous User Interviews Launch
Kit](https://www.userinterviews.com/launch-kit/continuous-user-interview),
one 30-minute session per week is ideal---but even just 5 minute
check-ins every week can work, if that's all you can manage.¬†

‚Äç

Continuous interviews are all about building the habit, so choose a
length of time you can realistically keep up with.

‚Äç

#### How often should you conduct continuous user interviews?

‚Äç

As far as the cadence of interviews goes, [Teresa Torres, product
discovery coach and founder of Product Talk, recommends once a
week](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk).¬†

‚Äç

If you're not there yet, challenge yourself to reduce the cycle time
between interviews throughout the year. For example, if you're doing
1/quarter, try for 1/month, then if you're doing 1/month, try for
1/week, and so on.¬†

‚Äç

üí° **Pro tip:** Focus on the frequency of interviews, not the number of
people you talk to. As [Teresa says in the Awkward Silences
episode](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk):

‚Äç

"I think the number of people you talk to is the wrong metric.... If you
have a glaring usability problem, and the first person you interview
helps identify that, well, you don\'t really need to talk to another
person.... Other things are more complex, and you might need to talk to
more people. But I think this metric of reducing the cycle time between
customer touchpoints encourages the right behavior of: 'How do we just
talk to customers as frequently as possible?'"

‚Äç

#### When should you conduct continuous user interviews?¬†

‚Äç

Whenever it works for you (and the participant). We recommend blocking
off an hour or so each week to dedicate to interview sessions.¬†

‚Äç

Outside of these regular interviews, you can schedule interviews at key
milestones in the customer lifecycle to learn more about the specific
experience of those milestones. Other opportunities for regular user
interviews include:

-   As part of the [onboarding
    process](https://www.userinterviews.com/blog/onboarding-ux-how-to-research-and-design-a-great-first-impression-pulkit-agrawal-chameleon)
-   When a customer begins using a new feature
-   After customers churn

### 2. Decide which teams should be a part of the conversation.

‚Äç

In general, it's better to involve multiple teams---not just the UX
research team---in the interview process, for two reasons:¬†

‚Äç

1.  **To capture as much insight as possible:** A product manager,
    designer, and engineer could all listen to the same interview, and,
    because of their different perspectives and expertise, will hear and
    remember different information. With more than one perspective
    represented, you can extract more value from each interview.
2.  **To reduce time and cognitive load on individual moderators:**
    Conducting sessions is a time-consuming (and sometimes
    stress-inducing) process. When you share this work, you enable each
    moderator the time and mental space to conduct [better, more
    effective
    interviews](https://www.userinterviews.com/blog/leveling-up-user-interviews-therese-fessenden-nng).¬†

‚Äç

Of course, you don't want to invite a dozen people to each
interview---how overwhelming that would be for the participant! The key
is to strike a balance between strategically sharing interviews among
teams and allowing each team to conduct interviews independently.

‚Äç

[GitLab, for example, uses a continuous interview
framework](https://about.gitlab.com/handbook/product/product-processes/continuous-interviewing/)
in which product managers lead interviews, while allowing other team
members to jump in to observe:

‚Äç

"Continuous interviews are open to all GitLab team members. The PM
should notify their team Slack channel about upcoming interviews. All
the team members and stable counterparts within a group are encouraged
to take part in the interviews from time to time, so they can have
first-hand experience listening to customer problems."

‚Äç

### 3. Prepare a (brief) interview guide.

‚Äç

You're probably familiar with [interview
guides](https://www.userinterviews.com/launch-kit/user-interview) for
project-based studies. The interview guide for a continuous practice can
be more concise, general, and open-ended.¬†

‚Äç

#### "Tell me about a time when..."

‚Äç

In fact, [Teresa Torres
says](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk)
that just one question can do the trick for continuous interviews:

‚Äç

"You might have some warm up questions, just to build rapport. But the
meat of your interview is what I think can be driven by one question.
And it\'s a 'tell me about a time when' question."

‚Äç

Why does "tell me about a time when..." work? Because it elicits a
**story** from the participant, and stories are more likely to give you
insight into the participant's decision-making process and mental
models.¬†

‚Äç

#### Follow-up interview questions

‚Äç

However, it's probably a good idea to plan out additional questions in
case the first question doesn't elicit the detailed response you hoped
for. Here's an example of how two different participants might answer
the same question, and how to probe for more information when
necessary:¬†

‚Äç

![6331f81270baaaffa06b65f7_r68hyi5mMluEycVO1nAESIJScIynhBRpRqA-nBTkRFcdMmS1V38ntKMpsfpcyjOzBIUb8-qw81qHqS5VY6Yvb8WhSce5ilDnvWZyQ7MdOvNajeS71K8LuXhh83HpWQTVp_9ncOuglwH9slg8zkZL_Qp-F8UhfWEG48BqODKA3P1OQ8GDAfib2GtJsQ](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6331f81270baaaffa06b65f7_r68hyi5mMluEycVO1nAESIJScIynhBRpRqA-nBTkRFcdMmS1V38ntKMpsfpcyjOzBIUb8-qw81qHqS5VY6Yvb8WhSce5ilDnvWZyQ7MdOvNajeS71K8LuXhh83HpWQTVp_9ncOuglwH9slg8zkZL_Qp-F8UhfWEG48BqODKA3P1OQ8GDAfib2GtJsQ.png)

[Example of probing questions by
NN/g](https://www.nngroup.com/articles/user-interviews/)

‚Äç

#### Customers aren't clairvoyant¬†

‚Äç

Additionally, it's helpful to ask questions about the past, not the
future. This tip comes from Digital Product & Technology Transformation
Leader Michaela Heigl in [her article on continuous
interviewing](https://www.linkedin.com/pulse/continuous-interviewing-6-tips-get-you-started-heigl-mphil-phd/):¬†

‚Äç

"Instead of asking 'Would you pay for this (in the future)' ask 'Have
you ever paid for something like this? How long? Why? What did you do
before? Are you still using this service? If not, what made you stop?'¬†¬†
Asking about the solutions users found in response to a problem is more
valuable than having to speculate about any action they may take in the
future."

‚Äç

By understanding how users behaved and made decisions in the past, it'll
be easier for you to predict what they might do in the future.¬†

‚Äç

### 4. Make it as easy as possible for participants to schedule (and show up to) sessions.

‚Äç

No-shows are a bummer. And, unfortunately, you can't avoid them
completely.¬†

‚Äç

However, you can take steps to [reduce
no-shows](https://www.userinterviews.com/blog/how-to-reduce-no-shows-in-ux-research)
by making it as simple as possible for participants to schedule,
remember, and show up to their sessions.¬†

‚Äç

Here are a few tips, drawn from Oyster's Lead UX Researcher Dr. Maria
Panagiotidi's [article on continuous user
interviews](https://uxpsychology.substack.com/p/from-no-research-to-continuous-research):

-   **Block off regular hours for sessions.** If you use a scheduling
    tool like [Calendly](https://calendly.com/) or panel management
    solution like [User
    Interviews](https://www.userinterviews.com/research-hub?source=navbarHubResearcher),
    you can create blocks of available time for sessions. Then,
    participants can simply schedule the time that works best for them,
    without back-and-forth communication to find a mutually convenient
    time for both of you.¬†
-   **Allow for as many different time zones as possible** if you're
    working with international users.¬†
-   **Schedule sessions no more than 3 weeks in advance.** More than 3
    weeks increases the chance of no-shows. If you're using a scheduling
    tool that allows you to create blocks of available time, avoid
    adding available blocks too far in the future.
-   **Send session reminders.** Using templates to save time, send
    reminder emails for the session after participants sign up, the day
    before, and the day of the interview.¬†

‚Äç

All of these tips can be easily implemented with [Research
Hub](https://www.userinterviews.com/research-hub), [the #1 recruitment
and panel management
solution](https://www.g2.com/products/user-interviews/reviews) on the
market. With Hub, approved participants can schedule sessions from a
calendar with your pre-set availability. You can also configure branding
and communication defaults for automated emails to ensure consistency
and professionalism as you remind participants of upcoming sessions.¬†

‚Äç

### 5. Be an open, active, and empathetic moderator.

‚Äç

Moderating interviews can be nerve-wracking, even for seasoned pros. If
we could sum up what it means to be a great moderator for continuous
user interviews in only 3 words, they would be:

-   **Open:** Open moderators show up to the interview with no
    expectations. They're ready to listen to whatever the participant
    wants to talk about, and they're [flexible enough to go
    off-script](https://www.userinterviews.com/blog/adapting-user-interviews-on-the-fly-sarah-merlin-of-invaluable)
    and let the conversation develop naturally.
-   **Active:** Active moderators aren't there to check boxes. They're
    attentive, engaged, and willing to [ask follow-up
    questions](https://www.userinterviews.com/blog/3-ways-to-make-a-potentially-awkward-user-interview-less-awkward-with-adam-sigel-of-hometap)
    to probe for more information. They show the participant that
    they're listening through encouraging body language such as nodding
    and eye contact.¬†
-   **Empathetic:** [Empathetic
    moderators](https://www.userinterviews.com/blog/active-listening-practical-empathy-babz-jewell)
    want the participant to feel safe, seen, and comfortable. They take
    the time to build rapport before diving into more sensitive topics,
    reserve judgements, and take participants seriously, even when they
    bring up details that don't seem important on the surface.¬†

‚Äç

Part of being open, active, and empathetic means giving the participant
the floor---and avoiding controlling or re-directing the conversation
too much. As [Teresa Torres describes on Awkward
Silences](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk):

‚Äç

"The key is you never want to interrupt your interview participant. And
even if what they\'re telling you is totally irrelevant, they\'re
telling you it because they care about it. And if they care about it,
you need to care about it."

‚Äç

üìö For more in-depth tips on how to effectively moderate a user
interview, check out the [User Interviews
chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
of the Field Guide. And if you're looking for a different resource
(we're a little hurt, but we get it), GitLab also provides some great
tips for moderating interviews
[here](https://about.gitlab.com/handbook/engineering/ux/ux-research-training/facilitating-user-interviews/#tips-for-interviewing).¬†

‚Äç

### 6. Follow up with participants.

‚Äç

Just because you've asked all the questions in your interview guide
doesn't mean your work is done.¬†

‚Äç

Before the interview concludes, ask the participant whether or not you
can get in touch with them in the future. This will give you the
opportunity to ask follow-up questions if they arise, address any
complaints they brought up during the interview, or update them when
you've released features that they specifically asked for.¬†

‚Äç

[Ferdinand Goetzen, CEO and Co-Founder of Reveall, explains two
reasons](https://www.userinterviews.com/blog/customer-centricity-with-ferdinand-goetzen-of-reveall-podcast)
why it's important to let customers know when you've addressed a
specific complaint:¬†

‚Äç

"Number one is that the customer is happy because you fixed the problem,
but number two, they start becoming less strict with other problems that
might arise. What we find is that when you\'re very open with the
customer, and if a customer really gets a feeling of, 'Hey, I flagged
this problem and it got fixed...' They also cut you more slack on any
potential future \[issues or requests\], be that usability problems, be
that a bug."

‚Äç

In other words, the simple step of following up with customers lets them
know you're listening, builds their trust, and improves customer
relationships in the future.¬†

‚Äç

üí∞ Don't forget to follow up in the form of **incentives**, too. We
recommend distributing incentives within 10 days of the completed
session to avoid frustrating participants.¬†

‚Äç

## Analyzing and synthesizing continuous user interview data

‚Äç

Continuous interviews aren't just a chance for you to chit-chat with
your customers---they're also an opportunity for the rest of your team
to learn, as well. For them to do so, you need to effectively analyze
and share the insights you discover from your interviews.¬†

‚Äç

üìö Your approach to analyzing continuous user interviews should be
similar to that of any qualitative data analysis you do---head to the
[Research Analysis
chapter](https://www.userinterviews.com/ux-research-field-guide-chapter/research-analysis)
to learn more.¬†

‚Äç

However, one thing to keep in mind is that the feedback you receive from
continuous interviewing might be a bit more scattered than the feedback
you collect from other, more focused [research
methods](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods).
The way you organize, distill, and share your insights will make a big
difference in how and whether they're used.¬†

‚Äç

Some quick tips to get you started are:

1.  Create snapshots of each individual interview.
2.  Remove personally-identifiable information.
3.  Add interview data to a research repository.
4.  Distribute snapshots and summaries widely.

‚Äç

Let's go into detail on each.¬†

‚Äç

### 1. Create snapshots of each individual interview.¬†

‚Äç

Because you're interviewing continuously, you won't have a set "end"
date for your interviews, signaling the time to start compiling and
organizing data.¬†

‚Äç

Instead, you need to do ongoing synthesis, ideally as soon as possible
after each interview ends. [According to Teresa
Torres](https://www.userinterviews.com/blog/how-to-interview-customers-continuously-with-teresa-torres-of-product-talk),
one great way to do this is with short, one-page interview snapshots
which provide an overview of what you learned:¬†

‚Äç

"A lot of the teams that I work with, some of them literally print these
\[snapshots\] out and put them in a binder in their workspace, so that
when they have a question that comes up, they can flip through all their
past interview snapshots and look at: How often are we hearing this?
What are the interviews we need to go back and revisit? Who do we want
to talk to, to learn more?"

‚Äç

These snapshots allow you to quickly summarize what you learned in
individual talks with customers and provide an easy jumping-off point
for doing a more comprehensive analysis of your vast archive of
interview data later on.¬†

‚Äç

üìö Although one-page snapshots are effective and efficient for
communicating interview insights, they're not the only way. Use these
[31 creative templates and examples of UX research reports and
presentations](https://www.userinterviews.com/blog/ux-research-presentations-reports-templates-examples)
as inspiration for your next report.

‚Äç

### 2. Remove personally-identifiable information.

‚Äç

Keeping your participants' Personal Identifiable Information (PII)
confidential is a good practice demonstrating respect for their safety
and privacy---and it becomes an essential practice when your NDAs or
[consent
forms](https://www.userinterviews.com/blog/how-to-write-research-participant-consent-forms)
promise that you'll do so.¬†

Before you share or archive any of the insights from your interviews, be
sure to remove all PII from the files you intend to share.¬†

‚Äç

For example, [here's a quick step-by-step guide to hiding the names of
research participants in
Zoom](https://www.userinterviews.com/blog/how-to-hide-participant-names-in-zoom-recordings).
This is just one step in ensuring the safe, ethical handling of
participants' data, but it's a great one to get started with.¬†

‚Äç

### 3. Add interview data to a research repository.¬†

‚Äç

Interview snapshots, recordings, transcripts, and other data should be
stored somewhere secure, yet accessible to others on the team.¬†

‚Äç

Typically, this storage requires you to create some sort of [insights
repository](https://www.userinterviews.com/blog/librarians-on-uxr-insights-repositories-nada-alnakeeb-joanna-perez),
or a centralized database for all of your research. If you don't already
have one, taking the time to set one up might be the single most helpful
operational task you can do.¬†

‚Äç

For smaller teams, this can take the form of a simple spreadsheet or an
interactive table in tools like [Airtable](http://airtable.com/),
[Notion](https://www.notion.so/), or [Trello](https://trello.com/). But
as your team and research practice scale, you'll definitely want to
switch to a more robust repository tool like
[EnjoyHQ](https://getenjoyhq.com/) or
[Dovetail](https://dovetailapp.com/).¬†

‚Äç

### 4. Distribute snapshots and summaries widely.¬†

‚Äç

When you've created snapshots or other types of summaries that highlight
important information from each interview, share them with the rest of
your team! The more people who know about, consume, use, and share your
insights report, the greater the impact they'll make.¬†

‚Äç

If you can, try to tailor and contextualize your
[share-outs](https://www.userinterviews.com/blog/how-klaviyos-design-research-team-improved-their-critique-feedback-process)
to each team you're sharing them with. For example, engineers are likely
to be interested in specific product-related feedback, and executives
will be more likely to engage with short, easily-digestible
deliverables.¬†

‚Äç

üìö Learn how to effectively communicate your findings in the [UX
Research Reports and Deliverables
chapter](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting).¬†

‚Äç

## What tools do you use to conduct continuous user interviews?

‚Äç

In short, the same tools you might use for regular, one-off user
interviews. These include:

-   Recruiting and panel management tools like [User
    Interviews](https://www.userinterviews.com/research-hub?source=navbarHubResearcher)
-   Video conferencing tools like [Zoom](https://zoom.com/), [Google
    Meet](https://meet.google.com/), or [Microsoft
    Teams](https://www.microsoft.com/en-us/microsoft-teams/group-chat-software)
    (or, for in-person interviews, a quiet venue)
-   Tools for recording sessions and transcription data, such as
    [Grain](https://grain.co/), [Otter.ai](https://otter.ai/), or
    [Perfect Recall](https://www.perfectrecall.app/)
-   [Qualitative research
    analysis](https://www.userinterviews.com/blog/qualitative-coding-ux-research-analysis)
    tools like
    [Aurelius](https://www.aureliuslab.com/user-research-synthesis-and-analysis),
    [Dovetail](https://dovetailapp.com/features/user-research-data-analysis/),
    or [Optimal Workshop](https://www.optimalworkshop.com/reframer/)
-   Insights management and repository tools like
    [EnjoyHQ](https://getenjoyhq.com/) or
    [Condens](https://condens.io/automated-transcription/)

‚Äç

If you're doing other types of continuous research, you could also mix
and match tools to combine insights. For example, you could use
[Research Hub](https://www.userinterviews.com/research-hub) for building
and managing your participant panel for user interviews, then follow up
with NPS surveys at certain activation moments using tools like
[Sprig](https://sprig.com/) or [Appcues](https://www.appcues.com/).¬†

‚Äç

#### üì£ Prefer to use only one tool to reach both existing customers and external audiences?¬†

‚Äç

You can easily automate all study logistics---including posting calls
for recruitment, pre-screening applicants, scheduling sessions, tracking
participant activity, and distributing incentives---with a comprehensive
panel management tool like [User Interviews\'s Research
Hub](https://www.userinterviews.com/research-hub).¬†

‚Äç

[Visit our pricing page](https://www.userinterviews.com/pricing) to
learn more about our Free Forever, Essential, and Custom plans for every
team.¬†

## Mixed methods for continuous research

As we mentioned earlier, continuous user interviews shouldn't replace
one-off studies or other [types of
research](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types).¬†

‚Äç

In addition to your weekly (or monthly, or quarterly---but for
ambition's sake, let's call them weekly) user interviews, use other
[qualitative and quantitative
approaches](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
to maximize insights from different audiences.¬†

‚Äç

üìö To get started with other methods for continuous research, check out
the chapters on [User
Analytics](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics),
[Continuous Feedback
Surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys),
and [Sales, Support, and Product
Data](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback).

[](#)

### Scale your research with powerful panel software

See why 1,700+ teams rely on Research Hub to grow their customer panel
and automate research studies.

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/research-analysis-synthesis)

Next:

UX Research Analysis and Synthesis

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research Analysis and
Synthesis](/ux-research-field-guide-module/research-analysis-synthesis)

![a person organizing abstract files of graphs, documents, and
charts](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f35d1fdbab1e60373c5d_UI_CHAPTER_08_ARTWORK.jpg)

08\.

# UX Research Analysis and Synthesis

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

User research data doesn't mean much until it's been analyzed,
synthesized, and translated into actionable insights.

Research analysis and synthesis---the process of sorting, categorizing,
and transforming raw data into valuable information---is one of the most
important and challenging steps in the UX research process.

In this module, you'll learn all about:

-   **Planning UX research analysis**---and why you should have a plan
    for analyzing data before you collect it.
-   **The key differences** between quantitative and qualitative data
    analysis.
-   **Qualitative data reduction** and organization methods.**‚Äç**
-   **How to do periodic data analysis** and synthesize your findings as
    you go.

[Start
reading](/ux-research-field-guide-chapter/research-analysis)[Start
reading](/ux-research-field-guide-module/research-deliverables-reporting)

In this module:

New edition coming soon! Subscribe to get notified.

[Analysis in UX
Research](/ux-research-field-guide-chapter/research-analysis)

New

New

New

Data without analysis is like a lamp without a lightbulb. It's just not
illuminating.

[Synthesizing User
Research](/ux-research-field-guide-chapter/user-research-synthesis)

Coming Soon

Coming Soon

Coming Soon

All your UX research, insights, and recommendations, wrapped up in a
neat, meaningful little bow.

[](#)

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### Analysis in UX Research

New

New

New

Data without analysis is like a lamp without a lightbulb. It's just not
illuminating.

##### Synthesizing User Research

Coming Soon

Coming Soon

Coming Soon

All your UX research, insights, and recommendations, wrapped up in a
neat, meaningful little bow.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/research-deliverables-reporting)

09\.

### UX Research Reports & Deliverables

[](/ux-research-field-guide-module/more-resources)

### Appendix

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research Analysis and
Synthesis](/ux-research-field-guide-module/research-analysis-synthesis)

\>

[Analysis in UX
Research](/ux-research-field-guide-chapter/research-analysis)

# Analysis in UX Research

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Congratulations, you've completed your study! Maybe you conducted
surveys with existing users, or had conversations with potential users.
Regardless of the type of study you did or [how many participants you
recruited](https://www.userinterviews.com/ux-research-field-guide-module/recruiting),
you've gathered a lot of information and data.

‚Äç

Regardless of whether your data is qualitative or quantitative, the next
step after completing any study is **analysis**.¬†

‚Äç

In this chapter, we'll go over everything you need to know about
analyzing your data, teasing out meaningful insights, and synthesizing
research to share with your stakeholders.

‚Äç

### In this chapter:

-   What is user research analysis?
-   When should you do analysis in UX Research?
-   Challenges and common mistakes in analyzing data
-   Qualitative vs. quantitative analysis
-   How to do data analysis in UX research
-   Tools and software for research data analysis

‚Äç

## What is user research analysis?

‚Äç

**Research analysis** is the umbrella term used to define the process of
classifying, organizing, and transforming raw data into valuable
information, and eventually a conclusion. When performed correctly, your
analysis will generate the building blocks you'll need to construct your
[research
deliverables](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations).

‚Äç

As [Nomensa's Director of UX Research JJ Knowles
said](https://medium.com/@jjknowles/introduction-to-ux-research-analysis-techniques-32192cfe0139):¬†

‚Äç

"It's the act of taking raw data and turning it into something useful."

‚Äç

Since data can be interpreted an infinite number of ways, part of your
job as a researcher is to decide how to analyze your data and use it to
tell a compelling story. The methods you use to analyze your data will
depend on [the methods you used to gather
it](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods).¬†

‚Äç

Qualitative
[interview](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
analysis and quantitative
[survey](https://www.userinterviews.com/ux-research-field-guide-chapter/surveys)
analysis are two very different beasts! Yet the ultimate reason for
doing research analysis is the same:¬†

‚Äç

"Regardless of whether you're dealing with a numeric dataset or a verbal
interview, you're always on the lookout for patterns and themes that can
tell you something meaningful about the user, the product, or both."¬† --
[Career
Foundry](https://careerfoundry.com/en/tutorials/ux-research-for-beginners/how-to-analyze-your-ux-research-findings/)

### Research analysis vs. synthesis

‚Äç

**Research analysis**, as defined above, is the process of sorting and
categorizing data.¬†

‚Äç

**Synthesis** involves interpreting research data and pulling out
insights and key findings that can be used to impact decisions.

‚Äç

Synthesis may follow once all the analysis is done, or the two processes
might happen more or less in tandem, depending on the methods you use at
this stage.

Together, research analysis and synthesis are key processes that create
meaning from raw data. With this meaning, you can make [better, more
informed
decisions](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research).¬†

‚Äç

![what is research analysis diagram - define disassemble, evaluate,
decide](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6352ac695c9b0f5dfb886402_1kl6FUN5z2xtCERA9jCVXBGe2Vo9RkTm88yW-ZPlBf7PXCLyq3Kb-AUcjc5C09Jj6pm56iFAXlk5f-ojcE_f6GygyMTJMzs79vUwJ4sAcvLprHhwyAYV0Rmn7-Gcu6XC_qN9zgwmwkXUkpvr-YSJQhb2rC-Z4j7bp7isjtnfMX6tmhW_ui9XHkh5CA.png)

[Source](https://www.oreilly.com/library/view/head-first-data/9780596806224/ch01.html)

‚Äç

## When should you do analysis in UX Research?

‚Äç

This chapter comes late in our [Field
Guide](https://www.userinterviews.com/ux-research-field-guide-module/ux-research-basics),
since you need to have data from [user
research](https://www.userinterviews.com/ux-research-field-guide-chapter/what-is-user-research)
in order to analyze it.

‚Äç

However, you should not be thinking about analysis for the first time
after having already collected your data. Good research analysis starts
at the very beginning of a project, before research even begins. As
you're [creating your user research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan),
you should be thinking about the types of analysis you want to do, what
you want to learn, and how you're going to use the data post-study.¬†

‚Äç

Conducting some analysis and synthesis as you go will save you time at
the end of a project, and gives you valuable snapshots to share with
stakeholders.

‚Äç

In other words, analysis should occur:

-   During the planning phase of a research study
-   Periodically, as the study progresses
-   After the study is completed

‚Äç

Always be analyzing, folks.

‚Äç

### Before conducting research

‚Äç

As we've said time and time again throughout this [Field
Guide](https://www.userinterviews.com/ux-research-field-guide-module/ux-research-basics)---the
first thing you need to do is define your goals.¬†

‚Äç

What are the objectives of this study? What do you want to learn? What
are the key [research
questions](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-questions)?

‚Äç

Keep the scope of your research narrow, and then dig in. During the
planning stage, think about how you will categorize and catalog your
data. What kinds of themes do you expect to emerge?¬†

‚Äç

Brainstorm tags that you can assign to data and session notes as you
go---this will save you mountains of time at the end, and give everyone
involved in the research a shared system for coding notes and insights.

‚Äç

### During research

‚Äç

You don't have to wait until you've completed your study to begin your
analysis. In fact, it's often helpful to think about what your data
might look like, and what it is starting to look like, as it's being
collected.

‚Äç

Periodic analysis may help you discover that you're asking the wrong
questions or even building the wrong product or feature. Analyzing your
data, your variables for analysis, and the assumptions behind them means
you'll be able to catch mistakes and anomalies early on---which can end
up saving the whole team a lot of time and money.

‚Äç

Analyzing and synthesizing as you go is also more efficient. It ensures
that you don't miss important details that might become the bedrock of
your work's final quality.

‚Äç

The things you jot down during a session identify what was most
important to you, the client, and other stakeholders in the moment. Use
your predefined list of themes and tags pre-defined to code your notes
and data in real time. Then, give yourself a buffer of 15 minutes or
more after each participant to review, analyze, and discuss the
session.¬†

‚Äç

By the time you sit down to complete the final deliverable, you will
have already created much of the framework for your entire analysis.¬†

‚Äç

To go beyond real-time coding, [Roberta
Dombrowski](https://www.userinterviews.com/author/roberta-dombrowski),
VP of User Research at User Interviews, suggests the following workflow
for analyzing, synthesizing, and sharing findings over the course of a
research project:

-   After each user interview, create a snapshot of the interview in a
    collaborative tool like [Miro](https://miro.com/app/dashboard/).¬†
-   Share the snapshot and key takeaways in a project Slack channel to
    give stakeholders visibility as the study progresses.
-   Once you've concluded your interviews, do a "final synthesis" using
    the takeaways you put together along the way.¬†
-   This synthesis can be shared with stakeholders as a slide deck,¬† a
    written summary, or both.¬†

‚Äç

### At the end of a project

‚Äç

Most research analysis happens at the end of a project. This is when you
have all your raw data and (if you've followed our advice) tagged notes
and initial analysis from individual sessions in hand.

‚Äç

At this stage, you're looking for patterns and themes that exist between
participants and data sets. If you've been synthesizing as you go, this
will be a lot easier! Either way, you'll still need to synthesize the
results of your project, look for answers to your initial research
questions, and provide stakeholders with actionable insights that enable
further decision making.¬†

‚Äç

## Challenges and common mistakes in analyzing UX research data

‚Äç

Before you begin analyzing your data, you should be aware of some of the
most common mistakes people make during analysis, including:

-   **Presenting a large volume of unassimilated and uncategorized
    data** in an effort to be "perfectly objective".
-   **Withholding initial biases or assumptions** about the study focus,
    and thus misrepresenting the relevant and important data.
-   **Over-reduction, or "flattening" of the data** collected into
    close-ended survey responses (i.e. binary "yes or no" questions).
-   **Jumping to decisions based only on statistical numbers** (e.g.
    redesigning a full page because of a high bounce rate---when the
    real issue might be as small as a poorly-placed button).
-   **Getting lost in the details** and simply rehashing information
    collected during the study, without applying any real analysis to
    that information.¬†

‚Äç

Of course, analysis is challenging. With large quantities of rich,
sometimes contradicting data, you're bound to mishandle the analysis
process without taking an informed, systematic approach.¬†

‚Äç

Let's dive deeper into that analysis approach, and how it differs based
on the type of data you're working with.¬†

‚Äç

## Qualitative vs. quantitative research analysis

‚Äç

[Qualitative and quantitative
data](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
are two very different beasts---and for that reason, the analysis
frameworks you apply to them will be quite different as well.¬†

‚Äç

![comic about quantitative vs qualitative methods: quantitative (1 in 30
take the free ice cream), qualitative (what did you feel when you saw
the free ice
cream)](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6352ac6995503d29044fd890_zqfRpLeTakr5pLnqfEfr_bx-cEQFTVYwqYfeyPs6E2DYZUBLj7zEJpptD06YqZ2WdJyx_G8Z-YanJ6kCAa-N8AWhf_aFYCtmU9prNy2xQ-a8q0tSBRgIO9AI9AssHICZU1235h7PpHa5ZDnaTOFtjcofdaMhFb1usTxD4QQztHCGSf4aSCju8RjjVg.png)

[Source](https://www.ikoninternational.org/news/2018/2/26/qualitative-vs-quantitative-research)

‚Äç

### Analyzing quantitative UX research data

‚Äç

In quantitative UX analysis, you are looking to develop insights,
through patterns in that data you've collected, about the how and the
why of people using that product. You might also have, as part of your
project, the task of gauging the quality of the overall user experience
through survey or behavioral UX data.

‚Äç

Large datasets are often analyzed with tools like R, Python, or SPSS, or
(for smaller datasets) in a spreadsheet. Common variables that are
analyzed in quantitative UX data include:

-   Success rates
-   Task times
-   Error rates

‚Äç

In addition to answering questions about how people are using a product,
you might also have the task of gauging the quality of the overall user
experience through attitudinal surveys or behavioral UX data.

‚Äç

Demographic and geographic data is then layered into the analysis, in
case they are helpful in determining patterns among certain groups of
users.

‚Äç

It's a lot of number crunching---but what you are doing at heart is
trying to understand how people use a certain product, what problems
they may be experiencing, and where improvements could be made.¬†

‚Äç

#### Questions that qualitative analysis can help to answer include:

1.  How long does it take the average user to complete a certain task?
2.  What features do they use?
3.  Are there any user needs not being met by the product?
4.  What features need the greatest attention for improvement? Why?
5.  Do certain users have different experiences using the product? How
    so?

‚Äç

### Analyzing qualitative UX research data

‚Äç

Because qualitative data can be wildly diverse in format and subjective
in nature, there are very few hard-and-fast, agreed-upon rules as to how
this data should be handled.¬†

‚Äç

We'll discuss some of the different data reduction methods in the "How
to do data analysis in UX research" section below, along with a
framework for doing qualitative analysis.

‚Äç

But regardless of which methods you use to collect and analyze
qualitative data, there are some questions and practices that will make
the process more focused and a lot less daunting.

‚Äç

#### When analyzing qualitative data, ask yourself the following questions:

1.  What are the major patterns and common themes in users' responses?
2.  Did any findings surprise you, your colleagues, and/or the client?
    How so?
3.  In what context did users express the greatest emotional response to
    questions?
4.  What interesting user stories emerged from the responses?
5.  How do people view this product overall and how does it fit into
    their daily lives? How indispensable is this product to them? Why?
6.  What features were most important to these users?
7.  What did they like most about this product? What did they like least
    about this product? Why?
8.  What values are most important to these users?
9.  How are these users different from other users?
10. Are there any use-cases not adequately supported by the current
    interface?

‚Äç

These questions should be in the back of your mind the second you start
collecting data. You may even want to make yourself a little print out
or index card to keep on you as a reminder.¬†

‚Äç

## How to do data analysis in UX research

‚Äç

In this section, we'll go over everything you need to know about
analyzing your data and using it to [tell a meaningful
story](https://www.userinterviews.com/blog/how-to-write-better-user-stories-using-ux-research).
Specifically, we'll discuss the following process for conducting UX
research analysis:

‚Äç

1.  Make a plan and set objectives for analysis.
2.  Take notes immediately after sessions.¬†
3.  Review all the data upfront.¬†
4.  Organize your data.¬†
5.  Identify trends and synthesize your findings.¬†
6.  Write recommendations.¬†

‚Äç

The following steps and recommendations are geared more toward
qualitative research than quantitative---for example, quantitative data
may not require any kind of thematic coding. However, many of the basic
principles (setting objectives, identifying significant trends,
synthesizing, and writing recommendations) still apply. We'll make note
of essential differences where applicable.¬†

‚Äç

### 1. Make a plan and set objectives for analysis.

‚Äç

Setting goals and analysis objectives ahead of time helps focus your
study---and prevents you from collecting too much "noise."¬†

‚Äç

[Lucy Denton, Product Design Lead at
Dovetail](https://www.userinterviews.com/blog/generative-research-action-dovetail),
experienced this overload of "noisy" data while running a large-scale
research project:¬†

‚Äç

"We decided to interview 45 people.... I\'m not sure in hindsight if
speaking to so many people was the right approach. It made the analysis
process really overwhelming and difficult."

‚Äç

If she could do the project over again, she thinks she'd find ways to
narrow the scope of the project---and much of that scoping could've
taken place during the [planning
phase](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research)
of the project.¬†

‚Äç

By setting learning goals and carefully designing your study, you can
collect just enough data to find meaningful insights without
overwhelming yourself during analysis.¬†

‚Äç

üí° Great plans lead to better analysis. [Head to Module 2 of the Field
Guide to learn more about Planning for User
Research](https://www.userinterviews.com/ux-research-field-guide-module/planning-user-research).

‚Äç

### 2. Take notes immediately after sessions.¬†

‚Äç

If you're conducting data analysis for
[interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews),
multiple rounds of [focus
groups](https://www.userinterviews.com/ux-research-field-guide-chapter/focus-groups),
or [ethnographic
fieldwork](https://www.userinterviews.com/ux-research-field-guide-chapter/ethnography)---you
can improve your efficiency by reviewing notes, videos, transcripts, or
other materials from each session and jotting down initial impressions
immediately after.¬†

‚Äç

This process is called **periodic analysis** and its benefits include:

-   Preventing the wasted time and effort of redundant work¬†
-   Preventing your memory of different sessions from blending together
-   Reducing the risk of you missing important details that might become
    the bedrock of your work's final quality
-   Identifying what was most important to you and other stakeholders in
    the moment

‚Äç

Ultimately, these benefits help you answer important research questions
as efficiently and thoroughly as possible. [Work smarter, not
harder!](https://www.userinterviews.com/blog/user-research-recordings-analysis)

‚Äç

If you're conducting user interviews with other team members, reconvene
with your team after each conversation. Have a discussion about how your
participants' responses fit into your research questions. Does the whole
team agree? Maybe you missed something that your teammate picked up on.¬†

‚Äç

![6352ac69569b960f5f1d3135_NeOU1VjE5msUggwpd7-2wMJe6P15AHGhRE1Lu_ezk1wYRkSJeRucmqYEOx0OdUtvjWi5JtW3ww7C-89neKMRdXCl9heEoUhtKbnXVxWTvomFL2SKsPnQABI586x7asEBVRI43P0dEqR6ASO50WSHNNaxvV4mkAXXxRml08gbz7CvefqHSmV2U8hprg](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6352ac69569b960f5f1d3135_NeOU1VjE5msUggwpd7-2wMJe6P15AHGhRE1Lu_ezk1wYRkSJeRucmqYEOx0OdUtvjWi5JtW3ww7C-89neKMRdXCl9heEoUhtKbnXVxWTvomFL2SKsPnQABI586x7asEBVRI43P0dEqR6ASO50WSHNNaxvV4mkAXXxRml08gbz7CvefqHSmV2U8hprg.png)

[Team Interview Notes Using The Rainbow
Spreadsheet](https://www.smashingmagazine.com/2013/04/rainbow-spreadsheet-collaborative-ux-research-tool/)

‚Äç

**üìå Pro tip:** Give yourself a buffer of 15 minutes or more after each
participant to review, analyze, and discuss the interview. Scheduling
this time as part of your interview process will help reinforce analysis
as part of your regular research practice, and before you know it, it
will be second nature.

‚Äç

#### Periodic analysis for quantitative research

‚Äç

Periodic analysis is also useful in quantitative research, as going into
a study with the wrong questions, metrics, or ranges can lead to big
headaches down the line during analysis. By analyzing your variables for
analysis, the assumptions behind them, and your data, as you go, you'll
be able to catch mistakes and anomalies early on, some of which may lead
you to adjust your study.

‚Äç

For example, say your final data should be a bimodal distribution like
the graph below.¬†

‚Äç

![Bimodal Distribution
Graph](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/6352ac69e8268f27834ddc74_xXO2_fu527A5zo2a8ccAZ-vUF_mEstrCKUZKLXlj0H7XB_mCm7iESustQ4J70_azQlyIX1HHHffewTKdcY6-tmYehoeU8qMJ1Ujgy14Gi_fbSJgtjr7e03OX-HvZBAHtHUm4Vrtg-rof7y28KPOiCsjVZljFTzfBKX5Cl9ZiwU-ZjvK0ppMoLVFvrQ.png)

Bimodal Distribution Graph

‚Äç

See how the graph has two peaks with a range of -4 to 4? Well, what if
you assumed that the range you should be testing is -4 to 0? You would
just have a normal distribution curve and be missing one of your peaks
because you limited your range from the get-go.

‚Äç

Considering the implications of certain anomalies and outliers early on
in the process can save you lots of time and money. But the only way to
catch these things early on, or sometimes at all, is if you are
analyzing your data at each phase of the study.

‚Äç

### 3. Review all the data upfront.¬†

‚Äç

Before tagging, organizing, or analyzing anything, scan through the
entirety of your dataset to see what jumps out at you.¬†

‚Äç

Just looking through your data ‚â† analysis. But taking a moment to slow
down and orient yourself to what's there can make a massive difference
in your ability to understand and apply analytical frameworks to the
data.¬†

‚Äç

Once you've gotten familiar with what's there, you can start to sort it
into an easier, more manageable form.¬†

‚Äç

### 4. Organize your data.¬†

‚Äç

Qualitative data tends to yield a wealth of information, but not all of
it is meaningful to your research goals. As the evaluator, it's your job
to sift through the raw data and find patterns, themes, and stories that
are significant in the context of your research question.

‚Äç

This process of organizing your data is known as "qualitative data
reduction."

‚Äç

#### What is qualitative data reduction?

‚Äç

Data reduction is the process of thickening and intensifying the flavor
of a qualitative data by simmering or boiling.

‚Äç

Oh wait, no... that's how you make a reduction sauce. Let's try that
again\...

‚Äç

Data reduction is the process of transforming raw data into a
simplified, ordered, and categorized form.¬†

‚Äç

Basically, you're reducing the volume of data into a summarized and more
meaningful format... kind of like turning juice into a flavorful syrup
by boiling away all the boring water.

‚Äç

There are several common ways to organize qualitative research data. The
most common methods in a UX research context are thematic analysis,
content analysis, and narrative analysis. Discourse analysis, framework
analysis, and grounded theory, while less commonly used in user
research, are two other methods worth noting.

‚Äç

#### Thematic analysis¬†

‚Äç

Thematic analysis is a systematic approach to grouping data into themes
that represent user needs, motivations, and behaviors. In some cases,
these themes may be directly adapted from your learning goals and
research questions, while in others, you may see these themes emerge
after the data is collected.¬†

‚Äç

![Thematic Analysis process and examples for UX
research](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/635c0b775099b2a4c5b6aec6_Colorful%20Process%20Pie%20Chart%20(2).png)

Thematic analysis: Process and examples

‚Äç

#### Content analysis

‚Äç

Content analysis is a structured organization of large amounts of
textual data using codes for certain words or themes. By assigning codes
to different pieces of qualitative data (in a process called
[qualitative
coding](https://www.userinterviews.com/blog/qualitative-coding-ux-research-analysis)),
you can begin to identify patterns and interpret their meanings.¬†

‚Äç

For example, if you're doing a study about how college students choose
their majors, you might create codes for passion, salary considerations,
and family ties, and identify how often these themes come up in
participant responses.¬†

‚Äç

#### Narrative analysis

‚Äç

Narrative analysis is a framework for understanding the stories people
tell and the ways in which they're told. For example, you could use
narrative analysis to understand the importance of specific content to
their participant, their motivations behind certain actions, and their
perspectives.¬†

‚Äç

**‚ö†Ô∏è Pro tip:** Be mindful of the biases you might bring with you in the
narrative approach. Although bias can influence the results of any
analysis, it's particularly a risk in narrative analysis because of the
broad, human, and subjective nature of storytelling.¬†

‚Äç

#### Discourse analysis

‚Äç

Discourse analysis is a method for drawing meaning from conversations,
either in written or spoken language. As opposed to content analysis,
which may involve analyzing textual data from a participant's written
survey responses, discourse analysis looks at text within its social
context.¬†

‚Äç

For example, analyzing the way an entry-level employee speaks to an
executive (and vice versa) can tell you about the culture and power
dynamics of the company.¬†

‚Äç

#### Framework analysis

‚Äç

Framework analysis is an advanced, systematic method which involves five
stages: familiarizing, identifying themes, coding or 'indexing' themes,
charting, and interpreting.¬†

‚Äç

Because framework analysis is more systematic and prescriptive than
other types of analysis, it's popular for applied research and
researchers who need to adhere to high, strict quality standards.¬†

‚Äç

#### Grounded theory

‚Äç

Grounded theory is an analysis method which involves analyzing a single
set of data to form a theory (or theories), and then analyzing
additional sets of data to see if the theory holds up. Instead of
approaching the data with an existing theory or hypothesis, grounded
theory analysis allows the data to speak for itself---requiring the
analyst to develop their theory from the "ground" up.¬†

‚Äç

#### Synthesis frameworks

‚Äç

You can also organize your data using various [synthesis
frameworks](https://www.userinterviews.com/blog/how-to-analyze-qualitative-data-with-the-design-gym)---structured
analysis methods that help you visualize your raw data to find common
themes. Some common synthesis frameworks include [affinity
mapping](https://www.userinterviews.com/blog/affinity-mapping-ux-research-data-synthesis),
matrices, and spectrums.

‚Äç

### 5. Identify trends and synthesize your findings.¬†

‚Äç

Regardless of whether you are analyzing your data quantitatively,
qualitatively, or both, you will be looking for trends and keeping a
count of problems or themes that occurred across participants.

‚Äç

Each theme and finding should be prioritized by severity and importance.
You should always go back to the original research objectives at this
point---hopefully you took notes about what's most important for this
project to address. Use that overall understanding of project objectives
as the backdrop for your data, as you rank the most meaningful patterns,
themes, and stories you've found thus far.

‚Äç

Synthesis is the process of breaking down everything you learned into
small, bite-sized insights (sometimes referred to as 'atomic research
nuggets') that can be easily shared with your team.¬†

‚Äç

Keep in mind [the 3 parts of a key insight and how to communicate
them](https://www.uxbooth.com/articles/a-guide-to-user-research-analysis/):¬†

‚Äç

1.  **A statement of what you learned:** As succinctly as possible,
    communicate an important takeaway from your analysis.¬†
2.  **Tags that describe the insight:** You likely used tags or codes to
    organize your data during the analysis. Include these tags with the
    insight, so folks can search for other, related insights if
    necessary.¬†
3.  **Supporting data and evidence:** Provide links to the data, notes,
    videos, or other materials that demonstrate what you learned.

‚Äç

For example, a key insight from a project about college students'
motivations for picking majors might be: Students who prioritize earning
potential are worried about being able to pay off student loans. #salary
#student-loans --- with links and attachments to the data which supports
this claim.¬†

‚Äç

You can take several approaches to synthesizing data, including:

-   **Telling stories (or 'user scenarios')** to break down how
    participants think and behave. Stories are a great way to humanize
    and contextualize user behavior.
-   **Building empathy maps or mental model diagrams** to demonstrate
    participants' thought processes, values, and feelings.¬†
-   **Creating comics or storyboards** to visualize (and empathize with)
    the participants as they move through a user flow.¬†
-   **Running brainstorming sessions or workshops** with your team to
    collect other ideas and perspectives.¬†

‚Äç

### 6. Write recommendations.¬†

‚Äç

You've analyzed the data and boiled it down to several key
insights---now, what do you actually do with those insights?

‚Äç

The final step of analysis is providing insight-backed recommendations
for next steps. Final recommendations take your analysis one step
further and allow your stakeholders to quickly understand the big
takeaway from this project, and take the appropriate actions in response
to those findings.

‚Äç

It would be a shame, after all, if stakeholders funded a whole study,
and then didn't do anything with it, because they simply didn't know
what they were supposed to be doing with that information.

‚Äç

Your recommendations might look like these:

-   Place the "SHOP NOW" button in the top ‚Öì of the page, and use
    greater color contrast between the button and background, as
    customers have a hard time locating it.
-   Eliminate the error window that pops up during the form, as it is
    preventing participants from completing the registration process.
-   Offer a search bar in the upper right corner of the landing page, as
    people often look for obscure content that is not relevant for other
    site users.

‚Äç

## Tools and software for UX research data analysis

‚Äç

Analysis, whether qualitative or quantitative, takes time---and many
busy researchers do not have the capacity to spend as much time as
they'd like on analysis. Fortunately, there are special tools and
programs built to help you accelerate and improve the analysis process.¬†

‚Äç

These programs can help you do things like organize your data sets based
on demographics or descriptors, code your data to help with organization
and pattern recognition, and collaborate with other researchers on your
team.

‚Äç

Some of the most popular analysis tools include:

-   [Dovetail](https://dovetailapp.com/)
-   [EnjoyHQ](https://getenjoyhq.com/)
-   [Delve](https://delvetool.com/)
-   [Aurelius](https://www.aureliuslab.com/)
-   [Nvivo](https://www.qsrinternational.com/nvivo-qualitative-data-analysis-software/home?creative=583204651106&keyword=nvivo&matchtype=e&network=g&device=c&gclid=CjwKCAjwuYWSBhByEiwAKd_n_ve6QcbY-b7AXBzie4FPWx1iDRBeVzXlDRl0B9IZURiGTZessVATmhoCYRIQAvD_BwE)
-   [Dedoose](https://www.dedoose.com/)¬†
-   [MAXQDA](https://www.maxqda.com/qualitative-analysis-software?gclid=CjwKCAjwuYWSBhByEiwAKd_n_vugvI0r2EeQK0mNY0_dVf4i-8ktS65qXLe_NkFrSHjN_9OwIIpQQhoCMacQAvD_BwE)

‚Äç

üõ† ‚ú® For a deep-dive into these and other important tools in the UXR
toolstack, check out our [2021 UX Research Tools
Map](https://www.userinterviews.com/blog/ux-research-tools-map-2021).

‚Äç

Since every research team and project is unique, we recommend looking
into the different software options to determine which program or
combination of programs would best fit your research, team structure,
and workflow.

‚Äç

## In a nutshell

‚Äç

Your approach to analysis can make or break your overall [impact as a
user
researcher](https://www.userinterviews.com/blog/how-to-track-the-impact-of-ux-research).
From raw data to actionable insights, the process can be complicated and
sometimes overwhelming. We hope you use this chapter of the Field Guide
as a reference while you dig into your next dataset---and remember,
always be analyzing!

‚Äç

Head to the next module to move onto the next step in your research
journey: [Creating effective research reports and
deliverables](https://www.userinterviews.com/ux-research-field-guide-module/research-deliverables-reporting).¬†

### Find legit participants for your research study

[Sign up for free](https://www.userinterviews.com/recruit) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/research-deliverables-reporting)

Next:

UX Research Reports & Deliverables

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research Reports &
Deliverables](/ux-research-field-guide-module/research-deliverables-reporting)

![a person standing to the left of a collection of organized data,
represented by line graphs, pie charts, and
documents](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f378005fb9e20aa5ef57_UI_CHAPTER_09_ARTWORK.jpg)

09\.

# UX Research Reports & Deliverables

A new edition of this module is coming soon! Subscribe to get notified.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

You did it! You conducted a study and analyzed the data. Now what?¬†

How should you communicate user research findings with your stakeholders
and wider team? What's the best format for sharing UX research results?
How do you write a report that stakeholders will actually read?

You have questions, and this module has answers. You'll learn about:

-   **How to write effective UX research reports** and summaries, with
    templates.
-   **Tailoring your research reports** and presentations to your
    audience for greater impact.
-   **Different types of research deliverables**, including affinity
    diagrams, atomic research nuggets, and case studies.
-   **Customer journey maps**---why you need one, the different types,
    and how to do user journey mapping, step by step.¬†**‚Äç**
-   **User personas**---the pros and cons, alternative methods, and
    strategies for creating useful personas that your team will really
    use.
-   **Atomic research nuggets**---what they are, when to use them, and
    how to create and record them for flexible, evidence-based
    decision-making.

[Start
reading](/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)[Start
reading](/ux-research-field-guide-module/more-resources)

In this module:

[Writing UX Research Reports and
Presentations](/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)

A great idea communicated poorly will never be implemented. Here's how
to write reports that resonate.

[Sharing User Research
Findings](/ux-research-field-guide-chapter/communicate-user-research-findings)

Coming Soon

Coming Soon

Coming Soon

The best format for communicating user research results is the one that
stakeholders will actually use.

[Personas](/ux-research-field-guide-chapter/personas)

How to create and use personas to promote empathy and align around user
needs.

[Customer Journey
Maps](/ux-research-field-guide-chapter/customer-journey-maps)

A journey of a thousand miles begins with a single well-researched
customer journey map.

[Atomic Research
Nuggets](/ux-research-field-guide-chapter/atomic-research-nuggets)

New

New

New

Research-backed user insights, broken down into their smallest parts.

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### Writing UX Research Reports and Presentations

A great idea communicated poorly will never be implemented. Here's how
to write reports that resonate.

##### Sharing User Research Findings

Coming Soon

Coming Soon

Coming Soon

The best format for communicating user research results is the one that
stakeholders will actually use.

##### Personas

How to create and use personas to promote empathy and align around user
needs.

##### Customer Journey Maps

A journey of a thousand miles begins with a single well-researched
customer journey map.

##### Atomic Research Nuggets

New

New

New

Research-backed user insights, broken down into their smallest parts.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/more-resources)

### Appendix

[](#)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research Reports &
Deliverables](/ux-research-field-guide-module/research-deliverables-reporting)

\>

[Writing UX Research Reports and
Presentations](/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)

# Writing UX Research Reports and Presentations

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

‚Äç

Communicating your findings is arguably one of the most important (and
difficult) skills to hone as a User Researcher.¬†

‚Äç

Yes, you've done the difficult work of moderating interviews, analyzing
months of diary study entries, or scouring spreadsheets for significant
trends---but all that work withers away when stakeholders never hear
about it, understand it, or use it.¬†

‚Äç

Research reports and presentations are your opportunity to showcase the
results and significance of your work for the rest of your team.¬†

‚Äç

Let's talk about what reports and presentations entail, and how to get
them right.¬†

‚Äç

## In this chapter:

-   What a UX research report is (and is not)
-   Good research reports: templates and examples
-   How to write an effective research report
-   Tips for presenting a report
-   Templates and examples of presentations

‚Äç

## What a research report is (and is not)

‚Äç

A **research report** is a document that summarizes all the details of a
research study, including the research questions, methodology, notable
insights, and recommended next steps. The main purpose of [reporting in
UX
research](https://www.userinterviews.com/blog/better-ux-research-reporting-habits-framework)
is to communicate findings to stakeholders and provide accurate,
objective insights that inform next steps.¬†

‚Äç

You've probably written some form of research report in other settings
like school or more formal scientific environments, but the reports
you'll write as a UX researcher are a little different. Traditional
reports, like the kinds academic researchers write, are typically long,
text-based, highly detailed documents, which makes them less-than-ideal
for communicating your findings with busy stakeholders.¬†

‚Äç

In the context of UX research, the report you share outside your
research team¬† will likely be closer to a **summary**: a shorter,
top-level document with a greater emphasis on next steps and business
application than on
[methodology](https://www.userinterviews.com/ux-research-field-guide-module/user-research-methods).¬†

‚Äç

#### A UX research report **is**:¬†

-   A summary of the data and findings of a study
-   Well-written with a standardized structure
-   Informative, often with links, charts, images, and other data
    sources
-   A data-backed basis for decision-making

‚Äç

#### A UX research report **is** **not**:¬†

-   A lengthy, dissertation-style paper¬†
-   An opinion-based essay
-   Something that should require deep UXR expertise to interpret

‚Äç

### Written reports vs. live (or recorded) presentations

‚Äç

[Synthesizing](https://www.userinterviews.com/ux-research-field-guide-module/research-analysis-synthesis)
and sharing your findings is only one half of the communication
equation. The recipients of that information also need to listen and
remember.

‚Äç

Tailoring the format of your research summary can help your audience
process and retain the information more effectively. Common formats
include:

‚Äç

#### **Written reports**

Written reports work well for when you're speaking to small groups, a
geographically distributed team or technical stakeholders like engineers
or other researchers.¬†

‚Äç

They're also great for when you need to keep a comprehensive account of
the study on record; some researchers always create them for the
[research
repository](https://www.userinterviews.com/blog/librarians-on-uxr-insights-repositories-nada-alnakeeb-joanna-perez).¬†

‚Äç

Written reports may take the form of:

-   PDFs
-   Emails
-   Pages in tools like Confluence or Notion
-   Slack updates

‚Äç

However, many researchers complain that stakeholders don't read them or
are overwhelmed by the sheer volume of information.¬†

‚Äç

#### **Presentations**

Presentations work well for when you're speaking to large audiences,
especially when ¬†meeting synchronously (although recorded presentations
can be effective too).¬†

‚Äç

Presentations may take the form of:

-   Slideshows
-   Pre-recorded videos
-   Decks¬†
-   Workshops (more on these below)

‚Äç

According to [the State of User Research 2022
Report](https://www.userinterviews.com/state-of-user-research-2022-report),
most researchers (87%) still share their results synchronously, despite
being fully remote. This is likely due to the more engaging nature of
live presentations for non-technical stakeholders, designers, or visual
thinkers. They force you to be precise and focus on only the most
important information.¬†

‚Äç

![when to use reports vs presentations; use reports when you\'re
presenting to small groups, technical stakeholders, or you need a
comprehensive record of the study on file; use presentations when
you\'re presenting to large groups, non-technical stakeholders, or you
only need to include the relevant
information](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62e059d7e3823b0c2b1500a8_3cmCZVV4BtV1D69JNQyweQPg_3HPs7EB4g5YrZUa3sUJ9yPy7Rz7ifpYaoj4GvysQ9dldRg4YyzdMGDvgcT6o8t1i3GUlnLdbl9jNfEZB1q8JyPikKFKvQaTZ35-M4SOZUvrsUTglkohzK02BNY.png)

When to use reports vs. presentations

‚Äç

Although each has its pros and cons, we recommend doing both! Creating
both a detailed report and a presentation ensures that different types
of audiences can access and appreciate your findings in the future.¬†

‚Äç

#### **üí°** Workshops, for when presentations aren't quite engaging enough

When it comes to capturing (and keeping) stakeholders' interest,
workshops are a great option.¬†

‚Äç

**Research workshops** are group exercises designed to make the
information more "sticky" or memorable for stakeholders. By sharing an
overview of your key findings and then leading a workshop---for example,
a group brainstorming session or [card
sorting](https://www.userinterviews.com/ux-research-field-guide-chapter/card-sorting)
activity based on the study's findings---you can collect feedback from
stakeholders and keep them engaged throughout the presentation.¬†

‚Äç

As [Lucy Denton, Product Design Lead at Dovetail, says in an episode of
our Awkward Silences
podcast](https://www.userinterviews.com/blog/generative-research-action-dovetail),
workshops can also be an effective choice when you aren't sure what next
steps to take based on the insights:¬†

‚Äç

"I think some of us had some gut feels around which ideas made sense for
us to investigate further. But we couldn\'t really articulate that....
So we decided to pause on the ideas and get a few of us in a room and
run a product strategy workshop. And in that session, we looked at
competitors in the market and thought about our current product and
where we wanted to grow. And we didn\'t really come up with anything new
in that workshop, but it was a useful exercise to sit down and all get
on the same page and document that and play it back to the team so that
we were all aligned. And then it was easier to come back to the ideas
and say, well, which of these ideas are going to help us grow in the
ways that we want to grow. And we landed on three big ideas, and that
has been our focus for 2021."

‚Äç

### Different types of research reports (and when to use them)

‚Äç

Research reports can take many forms, usually aligning with the type of
study you conducted. Usability studies, for example, will require a
usability report, while competitive analyses will result in a
competitive analysis report, and so on.

‚Äç

Here are some of the most common types of research reports:

-   **Usability reports** are documents that outline the background and
    methodology for a [usability
    test](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-usability-testing),
    as well as key findings about users' behavior, expectations, and
    challenges.¬†
-   **Analytics reports** use [qualitative and quantitative
    data](https://www.userinterviews.com/ux-research-field-guide-chapter/qualitative-vs-quantitative-vs-mixed-methods)
    to analyze past performance, summarize insights, and provide
    recommendations.¬†
-   **Market research (competitive analysis) reports** evaluate data
    related to customer perceptions of your brand and product, the
    competitive landscape, industry trends and overall outlook.¬†
-   **Qualitative research reports** are reports written for studies
    using qualitative methods, such as [1-1
    interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/user-interviews)
    or [diary
    studies](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies).¬†
-   **Quantitative research reports** are written for studies with
    quantitative methodology, such as [first click
    tests](https://www.userinterviews.com/ux-research-field-guide-chapter/first-click-testing)
    or [A/B
    tests](https://www.userinterviews.com/ux-research-field-guide-chapter/a-b-testing).¬†

‚Äç

You may also pair your report with other types of research deliverables,
such as
[personas](https://www.userinterviews.com/ux-research-field-guide-chapter/personas)
or [customer journey
maps](https://www.userinterviews.com/ux-research-field-guide-chapter/customer-journey-maps),
but these deliverables are meant to augment---not replace---the report.¬†

‚Äç

As [UX Researcher Katrya Hott
notes](https://uxdesign.cc/perfecting-the-art-of-the-ux-research-report-d48e77da14a8),
the most impactful type of report depends on the maturity of your
research organization:¬†

-   **In newer research practices with less trust in research**, you'll
    want to provide stakeholders with fun, collaborative reports to
    increase engagement.¬†
-   **In more mature research practices with higher trust in research**,
    you can take more care in writing rigorous reports (for posterity)
    with insights at the forefront (for efficiency).¬†

‚Äç

![In newer research practices with less trust in research, you'll want
to provide stakeholders with fun, collaborative reports to increase
engagement.¬†In more mature research practices with higher trust in
research, you can take more care in writing rigorous reports (for
posterity) with insights at the forefront (for
efficiency).¬†](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62e059d7745ec792a92bc03f_5RjS8A7bcZ8ZiV8KwG_HMVyEnZ-aVXaMDYXQEkOBac7AIAL0DEFKxUBogN1T9A_qfEesf_CydcuVp-TZozdIWwurG7cD-fK1EEvTskQDz0UZGP8l4Yqj84cSOZQjaFZ_wbPmw62sLwSeaDpzCPzqwQA.png)

Report type matrix by [UX Researcher Katrya
Hott](https://uxdesign.cc/perfecting-the-art-of-the-ux-research-report-d48e77da14a8)

‚Äç

## Good research reports: templates and examples

‚Äç

"Good" is a bit of a loaded term, no matter the context---so before we
provide examples of "good" research reports, let's break down what that
actually means.¬†

‚Äç

### First of all, what makes a research report "good"?

While the format and content will vary, good research reports all share
[four fundamental
qualities](https://dscout.com/people-nerds/choosing-research-deliverables).
They are:

‚Äç

1.  Attention-grabbing.¬†
2.  Actionable.
3.  Tailored to the audience.
4.  Easy to access and understand.¬†

‚Äç

#### Good reports are attention-grabbing.

Like the proverbial unwitnessed tree falling in the woods, the report
that nobody reads never makes a sound. Want to make an [impact as a
researcher](https://www.userinterviews.com/blog/how-to-track-the-impact-of-ux-research)?
Your reports need to capture stakeholders' attention.¬†

‚Äç

Whether your report is shared synchronously or asynchronously, you can
spark engagement by including:

‚Äç

-   Alternative formats like videos and audio clips
-   Direct quotes from participants (with or without identifying
    information, depending on the nature of your study)
-   Interactive content, such as workshops, live data visualizations, or
    [high-fidelity
    prototypes](https://www.userinterviews.com/blog/best-prototype-templates-examples)
    with working components

‚Äç

If you master the art of engaging stakeholders, you might notice reports
being shared and referenced more often, as well as a [growing demand for
research](https://www.userinterviews.com/blog/research-operations-supports-scaling-democratizing-ux-research)
throughout your organization. Highly engaging reports almost evangelize
themselves.¬†

‚Äç

#### Good reports are actionable.

Actionable reports should relate back to the initial research question:
How do your findings influence the decisions you mapped out in your
research plan?¬†

‚Äç

When stakeholders finish digesting your report, they should have a clear
understanding of what actions they need to take based on the insights.
As you're writing, be specific about the insights you've discovered and
the tangible implications they have on the company.¬†

‚Äç

For example, "users are unhappy" is not an actionable insight. Although
this might be a true observation from your study, it's not specific
enough about the context or application of the insight. You could
rephrase "users are unhappy" to be a more actionable insight in the
following ways:

-   **"Users are unhappy with the information architecture of our
    website; they're struggling to find the support pages."** --- From
    this insight, we can brainstorm logical next steps: Feature the
    support pages more prominently on the website, or do a [tree
    testing](https://www.userinterviews.com/ux-research-field-guide-chapter/tree-testing)
    exercise to figure out the best place to put them.¬†
-   **"Users are unhappy with the onboarding experience, but it's
    unclear which aspects of the onboarding experience are most
    frustrating for them."** --- This insight doesn't tell us much about
    what to do with our product or service, but it does provide a clear
    entryway into next steps for research: Conduct another study digging
    specifically into user perceptions of the onboarding experience.¬†

‚Äç

In other words, actionable reports provide:

-   Recommendations for product or business decisions
-   Concrete next steps for stakeholders
-   Suggestions for what kind of research needs to happen next
-   Compelling insights that illuminate unanswered questions

‚Äç

Although you should be objective and unbiased while conducting and
[analyzing
research](https://www.userinterviews.com/ux-research-field-guide-chapter/research-analysis),
know that it's okay to offer your opinion after the research is done. As
the researcher who led the project from start to finish, you're in the
best position to interpret the data and make recommendations for how it
should be used.¬†

‚Äç

#### Good reports are tailored to the audience.

By tailoring your report to fit the communication style and the areas of
interest for your audience, you increase the chances of them listening,
remembering, and referencing your findings later on.¬†

‚Äç

When creating your report, ask yourself:

-   **Who's your core audience for the report?** If it's only
    executives, you'll probably want to focus the report around strategy
    and business application. If you're speaking to your immediate
    research team, you'll probably want to include more of the minute
    details.
-   **Do you have a mixed audience?** If your report needs to speak to
    more than one type of stakeholder---or be included in repositories
    where future team members might access it---you might choose to
    present the report in different formats to target everyone's
    communication style.¬†
-   **What does their time and schedule look like?** Busy stakeholders
    won't always have time to sit down and read a full report. Present
    only the need-to-know info in the most time-effective format
    possible, while linking out to other decks, documents, and resources
    for them to reference if they're curious.¬†
-   **What kind of information do they care about?** Not all of the
    insights you discover in a study will be relevant to every type of
    stakeholders. Executives are more likely to be interested in how and
    why the insights impact the bottom line, while product managers and
    designers will want to understand how the insights impact their
    day-to-day roles.¬†

‚Äç

#### Good reports are easy to access and understand.

Finally, good reports should be easy to access and understand.

‚Äç

If your reports are engaging, actionable, and effectively tailored to
the audience, then they're already in a good position to be easily
understood. But in order to be easily accessible, they need to be housed
somewhere stakeholders can (and will) access.

‚Äç

The [common industry format
(CIF)](https://www.nist.gov/publications/common-industry-format-usability-test-reports)
for a usability report provides universal guidelines for the research
community, helping folks read reports more efficiently. If your audience
is other researchers (who also read and write this type of report
regularly), then the CIF format works great (and although it's only
intended for usability tests, you can draw from a similar rough outline
when writing reports for other types of studies).¬†

‚Äç

However, this format tends to be quite lengthy, making it
less-than-ideal for sharing with stakeholders. You'll want to take a
similar structure and condense or reorganize it in such a way that
stakeholders can quickly, easily glean the information that's relevant
to them.¬†

‚Äç

In the next section, you'll find some inspiration for doing so---using
condensed versions of written reports, interactive research repositories
using tools like Notion, or visual presentations.¬†

‚Äç

### Templates and examples of engaging, actionable, tailored reports

‚Äç

Looking for inspiration for your next report? Here are some resources to
reference:

-   [31 Creative UX Research Presentations and Reports -- Templates and
    Examples](https://www.userinterviews.com/blog/ux-research-presentations-reports-templates-examples):
    Here's a big list of report templates and examples, including User
    Interviews's very own text-based report template to download or copy
    and adapt as needed.
-   [Research Repository Report Template --- By Sheylla
    Lima](https://medium.com/ladies-that-ux/how-to-use-notion-to-document-your-research-process-and-findings-711b155fa713):
    In this Medium article, UX Researcher Sheylla Lima outlines how she
    uses Notion to create research findings reports while building a
    research repository. She also links to a template directly within
    Notion.¬†
-   [Research Report (Slides) Template --- By Decoding
    Research](https://docs.google.com/presentation/d/1Mws3RkJyfYS5iW_3G8O0tFQc3j3vw2Mpg_50bCLUPPI/edit#slide=id.gd5395719c2_1_14):
    Here's an example of an in-depth research report in the form of a
    Google Slides presentation.¬†

‚Äç

## How to write an effective research report

‚Äç

Now that you know what a research report is and what a good one looks
like, how is a research report written?

‚Äç

The basic outline of a research report is:

-   Introduction
-   Research goals
-   Business value
-   Methodology
-   Key learnings
-   Recommendations

![ux research report outline and checklist: tips and what should be
included in the report\'s introduction, research goals, business value,
methodology, key learnings, and recommendations
sections](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62e16679d4e6d730b0181130_ux-research-report-graphic2x.png)

UX¬†Research Report & Checklist --- By User¬†Interviews

‚Äç

Here are some tips for each section.¬†

‚Äç

### Introduction

‚Äç

Beginnings matter. The introduction of your report is your opportunity
to set the stage for your audience, to capture their attention and
convince them that the information you're about to share is valuable.¬†

‚Äç

#### What should the introduction of a report include?

-   A brief overview of the parameters of your study
-   The company goals and pain points you've been studying
-   The direct business application of the insights

‚Äç

### Research goals

‚Äç

Next, you'll need to outline your specific research goals and questions
for the study. Luckily, you mapped this out ahead of time in your [UX
research
plan](https://www.userinterviews.com/ux-research-field-guide-chapter/create-user-research-plan),
so you might be able to get away with a bit of copy-and-pasting in this
section.¬†

‚Äç

#### What should the research goals section of a report include?

-   The key decisions on which you based your research.¬†
-   The [research
    questions](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-questions)
    you'd asked as the catalyst for your study.
-   Your hypotheses and expectations prior to conducting the research.¬†

‚Äç

### Business value

‚Äç

Great UX researchers are always mindful of the business implications of
their work---and they make sure stakeholders understand those
implications too. In this section, delineate [how your research impacts
top-line business
metrics](https://www.userinterviews.com/blog/showing-the-value-of-user-research)
and overall growth goals.¬†

‚Äç

#### What should the business value section of a report include?

-   The company, product, and/or team goals related to your work.
-   Any other outcomes this research contributes to, including decisions
    it will affect.¬†

‚Äç

### Methodology

‚Äç

Although you've carefully evaluated and [chosen your research
methodology](https://www.userinterviews.com/ux-research-field-guide-chapter/how-to-choose-a-research-method)
during the planning process, your stakeholders likely don't need to hear
all the thinking that went into that decision. Explain your approach in
clear language, tailored so that non-researcher stakeholders can
understand.¬†

‚Äç

#### What should the methodology section of a report include?

-   The [research
    methods](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-types)
    you used to answer your research questions.
-   A brief explanation of why you chose those methods.¬†

‚Äç

### Key learnings

‚Äç

The learnings section is the "meat" of your report---the insights and
observations that make your research worthwhile. Present your findings
as clearly, concisely, and with as much context as possible to help
stakeholders make sense of the data.

‚Äç

#### What should the key learnings section of a report include?

-   Recurring themes or trends that you noticed during your analysis.
-   Relevant quotes, audio clips, or other artifacts that illustrate
    compelling insights, pain points, common experiences, or aha
    moments.¬†
-   Links to more resources, including full [session
    recordings](https://www.userinterviews.com/blog/user-research-recordings-analysis),
    transcripts, notes, or other data.¬†

‚Äç

### Recommendations

‚Äç

Finally, the recommendations section makes up the "actionable" part of
your report. Based on the insights you observed, share potential
solutions or answers to the questions your research was meant to
investigate.¬†

‚Äç

#### What should the recommendations section of a report include?

-   Clear, specific solutions and next steps to solve pain points or
    answer pending decisions.¬†
-   Any specific recommendations brought up by users during interviews
    or in
    [surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/surveys).¬†
-   Suggestions for future research studies, if applicable.¬†

‚Äç

üí° **Pro tip:** In some cases, you might choose to create an example or
a rough outline of a [project
roadmap](https://www.userinterviews.com/blog/dovetail-atomic-ux-research-to-roadmap)
to make it as easy as possible for stakeholders to implement your
solutions. If you can guide stakeholders through the process of
brainstorming and launching a new, high-value initiative based on your
research, you'll leave them with no question of the value of UX research
for the organization.¬†

‚Äç

## How to present a research report (without putting stakeholders to sleep)

‚Äç

When you finish creating your report, you don't just tuck it away in a
Google Drive folder and never mention it again---you have to let
stakeholders know, firstly, that it exists, and secondly, why it's
valuable.

‚Äç

Here's how to present research findings.¬†

‚Äç

### 1. Understand your stakeholders.

‚Äç

At this point, you'll have already conducted [stakeholder
interviews](https://www.userinterviews.com/ux-research-field-guide-chapter/internal-stakeholder-interviews)
during the planning process to learn more about their needs and goals.
Based on those interviews, you should have a good understanding of what
they'll expect from your presentation, including:

‚Äç

-   Which types of findings are most relevant to them
-   How the findings could (or should) affect their day to day lives
-   How they prefer to receive and process information¬†

‚Äç

Marketers and product managers, for example, will have different needs
and expectations regarding the research you've done. Do your best to
tailor your presentation to each different group of stakeholders---but
also provide people with multiple formats and ways to interact with your
report just in case.¬†

‚Äç

### 2. Define your goals.

‚Äç

At the beginning of your presentation, remind yourself and your audience
why you did this research. What were your learning goals? How will you
use the information? Which decisions will it inform?

‚Äç

Goals are, of course, something you've been continuously referencing
throughout your study. Their value is probably clear by now: By tying
your research to top-level goals and objectives, you leave stakeholders
no room to doubt the importance of your work.¬†

‚Äç

üí° **Pro tip:** For more on mapping goals to insights, check out "[A
Framework for Decision Driven
Research](https://www.userinterviews.com/blog/a-framework-for-decision-driven-research)"
by our VP of User Research ([and Class Member of the 2022 UX Research
Yearbook!](https://www.userinterviews.com/yearbook-profiles/roberta-dombrowski)),
Roberta Dombrowski.¬†

‚Äç

### 3. Explain your methods.¬†

‚Äç

You've carefully chosen your methods to support your learning goals.
Here's your chance to show stakeholders how (and why) you approached the
study this way.¬†

‚Äç

Explain (as concisely as possible):

-   The methods you used for
    [recruitment](https://www.userinterviews.com/ux-research-field-guide-module/recruiting)
-   How you conducted sessions
-   Your approach to analysis¬†
-   Why you chose the methods you used

‚Äç

**üí° Pro tip:** Try to avoid using too much jargon. If you're sharing
with non-researchers, they don't need a deep-dive into the most
technical components of your study---just a healthy overview!

‚Äç

### 4. Choose the right presentation format.¬†

‚Äç

The format you choose will have a big impact on whether or not your
stakeholders understand the information and how much of it they
remember.

‚Äç

In most cases, your stakeholders won't have the time or expertise to
digest sheets of raw data. Although it's great to provide and archive
the raw data to show your work, your stakeholders will often only need
and want a summary of key insights, translated into a format that
they'll find relevant, actionable, and easy to understand.¬†

‚Äç

As for the 'best' format, it's the one your stakeholders will actually
use.¬†

‚Äç

### 5. Tell a story (instead of throwing raw data at your stakeholders)!

‚Äç

No matter which format you use---a slide deck, a diagram, a
theatrically-performed monologue---it's great to use storytelling arcs
and elements to keep your audience engaged.¬†

‚Äç

Storytelling is communication that moves people. That's why we cry while
watching The Florida Project on the flight back from a work conference,
or laugh when we remember [the name of that whimsical
book](https://www.goodreads.com/book/show/10336.The_Last_of_the_Really_Great_Whangdoodles)
from our childhood.¬†

‚Äç

To incorporate storytelling into your presentation, consider structuring
your narrative like [Joseph Campbell's Hero's
Journey](https://libguides.gvsu.edu/c.php?g=948085&p=6857311):

-   **The Inciting Incident (Decision-Driven Research):** Name the
    preceding changes or observations that sparked your research
    question.¬†
-   **The Hero Takes Action (Study Methodology):** Now that your
    stakeholders know what caused you to ask your research question,
    tell them how you took action to answer that question.¬†
-   **Tease the Promised Land (Data and Analysis):** Instead of going
    straight from questions to answer, show stakeholders the path
    (analysis) you took to get there. Tease the solutions to product
    problems by revealing the data and how you interpreted it.¬†
-   **Magic Gifts (Results):** Give your stakeholders the 'magic
    gifts'---the results and conclusions you drew from the data---that
    will help them solve their challenges.¬†
-   **Reaching the Promised Land (Solutions):** Make actionable
    recommendations to your stakeholders about what to do next.¬†

‚Äç

If you're curious about using storytelling structures for UX research
presentations, you might enjoy:

-   [The Missing Ingredient: How Storytelling Can Make User Research
    More Impactful with Harrison Wheeler, UX Design Manager at
    LinkedIn](https://www.userinterviews.com/blog/the-missing-ingredient-how-storytelling-can-make-user-research-more-impactful-with-harrison-wheeler-ux-design-manager-at-linkedin)
-   [Why No One's Listening to Your UX Research Report and How to Get
    Them to
    Listen](https://www.userinterviews.com/blog/why-no-ones-listening-to-your-ux-research-report-and-how-to-get-them-to-listen)

‚Äç

### 6. Include research snapshots and artifacts.¬†

‚Äç

As you conducted your study, you might've collected research artifacts
in the form of:

‚Äç

-   Videos
-   Audio clips
-   Transcripts
-   Diaries
-   Emails
-   Screenshots
-   Photos
-   Graphs

‚Äç

(**üí° Hint:** You may also want to share clips, highlights, and other
artifacts with your team to maintain engagement as your study
progresses---more on that in ["Making Research A Team
Sport."](https://www.userinterviews.com/blog/making-research-a-team-sport-5-key-takeaways))

‚Äç

Include these artifacts where relevant (and when allowed, given the
privacy and [consent
terms](https://www.userinterviews.com/blog/how-to-write-research-participant-consent-forms)
of your study) in your presentation to help illustrate your findings
more clearly.¬†

‚Äç

### 7. Recommend next steps.¬†

‚Äç

This is the section of your presentation where you can add the most
value to your stakeholders---and likely where they'll be paying the most
attention.¬†

‚Äç

Based on the data you've presented, provide clear, specific, data-backed
recommendations for moving forward, including future research if
needed.¬†

‚Äç

To make it as easy as possible for stakeholders to understand your
recommendations, you may want to explicitly write out the teams (and/or
team members), takeaways, and actions, like in the example below.¬†

![Recommendations and next steps by team; Product: make the current
onboarding experience easier to understand for users by creating an
interactive walkthrough; marketing: revisit messaging around onboarding
to manage user expectations by scheduling a brainstorming session;
research: investigate areas for improvement in the onboarding experience
by creating a UXR study
plan](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/62e059d7052b8a6bb59d8ba0_JFYn3WDt-C0AcutzDVCDTMTW_81QhatMcQkP31qKI8Z1Es9lot2E1g9vE4xqoGLrkdQbREsgPIPT3l5SUwQef9bn3hescyMiT9BDj_pED7lQ869mVFLD22lLUbSEhQgfgBMiOMXW6UUEAu0eDmc.png)

Example of per-team recommendations and next steps following a study.

‚Äç

In the example above, the researcher has recommended next steps for the
Product and Marketing teams to improve the current onboarding experience
for users, while acknowledging that additional research is needed to
reveal specific pain points and areas for improvement.¬†

‚Äç

**üí° Pro tip:** Use linguistic mirroring (a fancy term for 'use the same
language') to increase stakeholder buy-in for your recommendations.
[Learn more about this simple but effective
technique.](https://www.userinterviews.com/blog/linguistic-mirroring-stakeholder-buy-in)¬†

‚Äç

## UX research presentations: templates and examples

‚Äç

Before you tackle your next presentation, why not check out some
examples to make sure you're on the right track?

‚Äç

Here are some sample presentations to draw inspiration from:

-   [User Research Findings Presentation (Slide Deck) Template --- By
    User
    Interviews](https://docs.google.com/presentation/d/1N8qpXAMiwi-yYEneIZFCBy1_kqQ7KWE1dwSUPRsq948/edit#slide=id.p):
    Slide decks are one of the most popular ways to report user research
    findings, chosen for their flexibility as both synchronous and
    asynchronous documents, ability to host mixed-media elements like
    charts and videos, and as in-depth or lightweight as needed.¬†
-   [User Research Report (Debrief) Example --- By Steve
    Bromley](https://docs.google.com/presentation/d/1hbQnfh1KMJaGEY-vKo9p3cZM_XHGmJ0LjDxQLrW7f9g/edit#slide=id.g887135914a_2_0):
    Here's an example of a presentation used to debrief stakeholders on
    report findings by User Researcher ([and Awkward Silences
    guest!](https://www.userinterviews.com/blog/games-user-research-and-playtesting-steve-bromley))
    Steve Bromley.
-   [Summary of Findings Template (with Examples) --- By
    Condens](https://condens.io/user-research-presentation/): This blog
    from Condens outlines an effective outline for a research findings
    presentation, with a downloadable example deck.¬†¬†

‚Äç

## In a nutshell

‚Äç

Nothing's more disheartening than working hard on a study and
discovering compelling insights, only to have stakeholders ignore or
overlook those findings.¬†

‚Äç

Save yourself the disappointment by presenting engaging, actionable
reports to stakeholders.¬†

‚Äç

Your work matters---and it deserves to be seen.¬†

### Recruit from our panel of 700,000+ vetted participants

[Sign up for free](https://www.userinterviews.com/recruit) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/personas)

Next:

Personas

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research Reports &
Deliverables](/ux-research-field-guide-module/research-deliverables-reporting)

\>

[Personas](/ux-research-field-guide-chapter/personas)

# Personas

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

## What is a persona?

A persona is a way to illustrate the key audiences your work will
impact. Personas can take on many different forms, but typically they
are [**one-page
documents**](https://creativecompanion.wordpress.com/2011/05/05/the-persona-core-poster/)
that outline who your persona is, including demographic information and
details about their life and context. Personas can be used by people in
many different disciplines, including marketing, design, product
management, and user research. Because they are such flexible tools,
different departments within an organization may have different sets of
personas, or may create personas that look entirely different from each
other.

‚Äç

Most teams use a few different personas to provide details about key
audiences. These different personas help teams and stakeholders
empathize with users and keep the correct users in mind when creating
products and campaigns.

‚Äç

## Do I need a persona?

There's a lot of debate around personas in design and research
communities. When, where, and how you use personas depends heavily on
your team's situation and goals, so it's important to understand your
goals and how your team works before creating personas.

‚Äç

The first question you need to ask yourself and your team is whether or
not you have time to maintain your personas. Personas require research,
both quantitative and qualitative, to get right. After the initial
research, your team will need to maintain and update your personas
regularly in order for them to remain effective.

‚Äç

Next, consider what you'll do once you have your personas in hand. Will
your design team use them to come up with new ideas? Will your
stakeholders refer to them when evaluating the validity of a new
product? Will the marketing team use them to create new campaigns?
Thinking about what your personas will help you achieve at the outset
can help you create personas that are more useful to your team.

‚Äç

If you can't think of good, concrete ways in which having personas in
hand will help your team, don't create personas. Creating personas
simply because it seems like the right thing to do, unfortunately, won't
be a good use of your time. Personas don't work for every team or every
context, so it's very possible personas aren't the right tool for your
right now. Some teams find other methods to be more helpful, like [**the
Jobs to Be Done
framework**](https://www.nngroup.com/articles/personas-jobs-be-done/).
Many use both for different things.

‚Äç

## The key elements of personas for design and product teams

There are [**many different schools of
thought**](https://www.smashingmagazine.com/2014/08/a-closer-look-at-personas-part-1/)
on personas. Some have created [**types of
personas**](https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/personas#heading_Four_different_perspectives_page_12414),
which are helpful for learning more about the history of personas and
their different goals. They are also helpful as jumping-off points if
you're stuck thinking about how your team can use personas. They aren't,
however, very helpful when attempting to build your own personas, so
we've broken it down into some of the key elements of personas, and
outlined how they can help you build personas that work for your team.
You may not need every element, or need to complete every available part
of every element, but there are a few must-haves. We've added a little
‚úÖ to help you find them.

‚Äç

A quick note about demographics and naming your personas: Try to stay
away from cheesy names like "Sassy Stacy" and "Marketing Manny." This is
a good way to turn people off to the seriousness of your personas, and
creates an empathy barrier that makes it hard to see your personas as
representations of real people. As for demographic information, think
about every piece that goes into your persona. Do you really need to
know their salary, exact age, or hair color? Maybe, but for most use
cases, it's likely that these things aren't actually adding to your
understanding of the persona. Ditch any unnecessary information and
spend more time focusing on the parts of your persona that help paint a
better picture.

‚Äç

### Goals ‚úÖ

These are the goals the users represented by your persona are trying to
achieve. Goals are pretty integral to your persona, in fact,
[**goal-driven
personas**](https://www.smashingmagazine.com/2014/08/a-closer-look-at-personas-part-1/)
were the very first personas. They were [**thought up by Alan
Cooper**](https://www.cooper.com/journal/2008/05/the_origin_of_personas/)
as a way to empathize and analyze the users he was designing for.

‚Äç

These user goals should be user-centric, not product-centric. Since no
one logs on to an app and says to themselves "I want to complete this
flow successfully," it's important to think about what the user's actual
goals are when they come to your site or product. Do they need to buy a
new hat? Why? You can use frameworks like [**the 5
whys**](https://www.userinterviews.com/blog/what-ux-researchers-can-learn-from-children-with-noam-segal-of-wealthfront)
to uncover these goals through [**user
interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/generative-interviews).
Try to get to their root motivations for taking action, as these will
help you consider how this persona might act in different situations.

‚Äç

### Skills

Different people approach problems with different skill sets, and your
personas should too. For example, some users may be less tech-savvy than
others, or less familiar with your product. Taking note of this can help
you build something that takes their skills into account.

‚Äç

This section can also be used to help build out the character of your
persona. Adding skills like creativity, empathy, or self-sufficiency can
help paint a better picture of who your persona represents and how they
may approach a new problem. Keep your list of skills concise to avoid
overloading your persona and making them [**seem less
realistic**](https://www.cooper.com/journal/2008/05/perfecting_your_personas/).

‚Äç

### Attitudes ‚úÖ

Attitudes dig in to the existing attitudes your users may have when they
approach your product. Attitudes can help you learn more about how a
persona would approach a new situation, and are best illustrated in
short statements. If you've found some particularly illustrative quotes
through your research, this may be a good place to add them in. Your
personas attitudes will also illustrate more of their life outside of
your product. For example---

‚Äç

Loren is pretty self-sufficient. She knows how to get things done on her
own, but doesn't get too worked up if something doesn't go her way. She
believes that life is what you make it and will step back to try to find
a different solution rather than continuing on with something that
doesn't work.

‚Äç

### Pain points ‚úÖ

Where do these users typically run into problems? What does their
journey look like, and why do they need the thing that you're building?
These pain points are things you can potentially help your users with,
and at the very least, they can help you understand your users more
deeply.

‚Äç

Think about how these pain points may present themselves to your users,
and consider writing a small paragraph about your persona's pain points
to help put them in context. For example---

‚Äç

John is a high school student, he's excited to go to college but is
struggling to choose a school. He **feels overwhelmed by the number of
choices** available to him, and **does not know how to sort through them
all**. Between academics and extracurriculars, he **does not have enough
time** to research schools.

‚Äç

Writing out pain points in context like this helps your team to
empathize with John, and think of good solutions to help solve his
problems. Maybe some sort of college recommendation engine? Or a
searchable sorting tool?

‚Äç

### Environment

Environmental factors help build the world around your personas. Since
people don't act in a vacuum, it's important to understand what goes on
around them. This is an element of your personas that will vary widely
from team to team. You may need some of these environmental factors, but
it's unlikely you'll need them all. For example, if you're building a
sales pipeline tool, it may not be important to include that the user
has two cats. Likewise, if you're building an app to share photos of
cats, it may not be important to include that your user has a
deadline-driven job. Use your best judgement when deciding what to
include and do your best to keep it to the necessities, adding just
enough color to make your persona feel real without going overboard.

‚Äç

#### Personal Life

You may need to know things about your user's personal lives. This could
range from their relationships to how often they order in, depending on
your product and what you're building. As with every part of your
persona, be sure to describe this part of your persona in a way that is
illustrative and engaging.

‚Äç

#### Professional Life

What does your user do for work? Who do they work with? Are they
passionate about their job? Questions like these will help you build out
your persona's professional life. This is especially important if you're
building a tool for their work life. For example, if you work for a B2B
SaaS tool, what your persona does for a living is incredibly important.
Their budget, the way they work with their team, and the way their boss
thinks about their performance (and thus, their budget), will have a big
effect on whether or not they end up using your product, and may be
important to include in your persona descriptions.

‚Äç

#### Workflow/Journey

This is potentially the most integral part of your persona's
environmental factors. Their workflows or journeys are what happens
around the use of your product. For the cat photo-sharing app, where do
they take pictures of their cat? Are they avid users of other social
media? Are they sharing cat photos to build community or simply to let
everyone know their cat is the cutest? For the B2B SaaS app, how does
your product help them do their job? Do other members of their team need
to use the product too? Do they use other tools before or after yours to
complete the job? Questions like these will help you build out potential
workflows or journeys for your personas, making them more useful for
your design and product teams.

‚Äç

## How to build personas for design and product teams

Once you've decided that personas are the right tool for you and your
team, the next step is to start building them. You'll need to gather
your team, chat about what you already know and assume about your users,
decide how you want to use your personas, do some research, and sit down
and actually create your personas.

‚Äç

Since our [**Field
Guide**](https://www.userinterviews.com/ux-research-field-guide) is all
about user research, we'll focus on creating personas for design and
product teams. If you're using your personas primarily for marketing,
check out [**Hubspot's guide to buyer
personas**](https://blog.hubspot.com/marketing/buyer-persona-research#sm.0000081dvitpkyf60wjmqwdt7b3jd).

‚Äç

### 1. Gather your hypotheses

First things first, you'll need to take some time to sit down with your
team and think long and hard about why you need personas and what you
hope to learn from them. Think about what you already know about your
users, from previous research, product data, or a ¬†gut feeling you and
others have developed over time. Together, come up with a hypothesis (or
a few hypotheses) about what your user segments, and eventually your
personas, may look like. In this stage you're looking for clusters of
users that behave in similar ways.

‚Äç

Also consider what you're trying to do with this persona---is it to
develop a new product, create new features, or to design a better
experience? This will help you find good jumping off points for the next
two steps.

‚Äç

It's important to come out of this phase with a hypothesis. This means
you're not going into your data-collection and research phases trying to
validate an idea, you're going in to them to try to learn. It's
possible, even probable, that your hypotheses will be wrong and you'll
end up with a persona that looks quite different from what you
originally imagined. That's ok. That's why you're doing this in the
first place.

‚Äç

### 2. Conduct user interviews

Now it's time for the fun part, talking to people. Your user interviews
are a key part of building your personas, because it's when you actually
get to see the more human aspect of it all. It's best to start off
talking to 5-10 people who represent your user base at large, to make
sure that your hypotheses are on the right track. After you complete
these interviews, take a moment to sit down and establish who your
personas are. Once you've established patterns or clusters of users that
define your personas, interview a few more people that fall into that
persona. This can help you build out your personas even more and ensure
you're on the right track. These interviews will give you an opportunity
to get into the real goal of building personas---writing a story that
helps your team connect with your users, keep their needs in mind, and
prioritize which users need which things.

‚Äç

Need a little help thinking of questions to ask during your user
interviews? Check out our chapter all about [**generative
interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/generative-interviews),
or read up on [**how to write great interview
questions**](https://www.userinterviews.com/blog/how-to-write-ux-research-interview-questions-to-get-the-most-insight).
When putting together your interview script, try to ask open-ended
questions that ask the participant to remember a specific experience.
People [**are pretty
bad**](https://www.npr.org/templates/story/story.php?storyId=15073430)
at self-assessment, which means if you simply ask them exactly what you
want to know, you may not get an answer that gives you good insight.
Instead, ask open-ended questions like, "Walk me through the last time
you used our product." Questions like this allow you to make
observations about their process, and ask follow-up questions that help
you dig in to the details.

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)

### 3. Back up your personas with data

The next step is to make use of any data you already have. This can be
[**analytics**](https://www.userinterviews.com/ux-research-field-guide-chapter/user-analytics),
[**sales and support
data**](https://www.userinterviews.com/ux-research-field-guide-chapter/integrating-support-sales-and-product-feedback),
or [**user feedback
surveys**](https://www.userinterviews.com/ux-research-field-guide-chapter/continuous-user-feedback-surveys).

‚Äç

Determining which of your personas make up which % of your overall user
base and what their lifetime value is can help you decide which personas
to prioritize, and which ones aren't actually doing well for your
business. This data can also help bring more detail to your final
personas, beyond what you learned in your interviews.

‚Äç

### 4. Create your persona

Time to make some personas üéâ! Your personas will help tell the story of
your users, and will help your team empathize with them every step of
the way. So it's important to [**spend some quality time creating your
personas**](https://www.smashingmagazine.com/2014/08/a-closer-look-at-personas-part-1/).
Try to build out their stories to [**make it easier to remember
them**](https://medium.com/swlh/the-science-of-storytelling-why-we-love-stories-fceb3464d4c3)
next time a project comes up. We've created [**a
template**](https://docs.google.com/document/d/1LUN3zez4OtoAktr7ZEzvqDN05CjsRB-W4DXWYsOXVHw/edit?usp=sharing/copy)
to help you build out the basics of your personas, but have left it
pretty bare-bones to leave room for imagination. Feel free to start with
our template, but build something that represents your personas in a way
that's digestible and accessible for your team.

‚Äç

‚Äç

You can also get creative with other assets to help reinforce your
personas with your team, like [**these cool persona
posters**](https://www.flickr.com/photos/jasontravis/8866767289), or
these [**persona trading
cards**](https://dribbble.com/shots/2255352-Persona-Cards-Updated). It's
important to note that assets like this are secondary to your persona
documents, which should be more detailed.

‚Äç

## How can I make my design and product personas more effective?

After spending all this time and effort on your personas, make sure
they're as effective as possible.

‚Äç

### 1. Keep your personas up to date

This is one of the biggest reasons personas fail. Just like our products
and services, users can change and evolve over time. Using personas that
are outdated can lead you down paths that don't actually help you build
a better product.

‚Äç

Be sure you keep a good update cadence to get the most out of your
personas. What does that mean? Well, it depends. If your product or
market is evolving slowly, every year or two may be a fine update
schedule. If your product or maket is moving at a faster pace, consider
scaling it up with your research and development efforts, potentially to
every half or every quarter.

‚Äç

[**NNg ran a
survey**](https://www.nngroup.com/articles/revising-personas/?lm=personas-jobs-be-done&pt=article)
to determine how often most people update their personas and how
effective those personas were. Most of their respondents updated their
personas once every 1-4 years, but the 28% of people who updated their
personas quarterly or more often consistently rated their personas
highly impactful.

‚Äç

Updating your personas doesn't have to be a chore. Take a look at the
data that you're using in your current personas, and check to see if
there's any new data you can make use of. This data can include things
like lifetime spend, % of overall users, NPS scores, or churn rate. If
you're seeing a lot of discrepancies in your data and any other research
you may have conducted, do a few (3-5) generative interviews to learn
more about how your personas are doing well and how they can be
improved.

‚Äç

Lastly, make your tweaks and distribute your updated personas to your
team.

‚Äç

### 2. Integrate your personas into your workflow

Ensure that your personas a part of every product and design decision
you make. Creating secondary persona assets (like those
[**posters**](https://www.flickr.com/photos/jasontravis/8866767289) and
[**cards**](https://dribbble.com/shots/2255352-Persona-Cards-Updated))
can help your team think about your personas more often. It's even more
helpful, though, to integrate your personas into your existing
workflows, establishing them as an important part of the process.

‚Äç

Consider attaching a relevant persona to each of your team's projects.
Who are you building this thing for? How will they use it? Asking these
questions will help you choose the right persona and prioritize projects
more effectively. Elizabeth Bacon and Steve Cooper have some good tips
on integrating your personas into your workflow in [**their slidedeck
all about
personas**](https://www.slideshare.net/ebacon/death-to-personas-long-live-personas-presentation/52-Keep_them_datadriven_Conduct_design)
(skip to slide 56 for their tips).

‚Äç

‚Äç

## TL;DR

Personas can be a great tool for your design and product workflows, but
only if you use them carefully and correctly. Like any other research
tool, they require a bit of care and attention to get right. Once you
have them, though, they can help your design and product teams think
more actively about your users and incorporate them into the decision
making process.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/how-to-write-effective-reports-and-presentations)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/customer-journey-maps)

Next:

Customer Journey Maps

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[UX Research Reports &
Deliverables](/ux-research-field-guide-module/research-deliverables-reporting)

\>

[Customer Journey
Maps](/ux-research-field-guide-chapter/customer-journey-maps)

# Customer Journey Maps

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Learning more about what your customers experience is the best way to
improve your product. But you already know that üòâ. In this chapter,
we'll show you how you can use customer journey maps (CJMs) to increase
empathy across your organization and improve customer experiences.

‚Äç

In this Field Guide chapter, we'll explain how customer journey maps can
help you build a better product, walk you through exactly what you'll
need to create an effective CJM, and give you the tools and templates to
get started (or take your current map up a notch).

‚Äç

## What is a customer journey map?

A customer journey map is a visual representation of your customer's
experience with your company. Customer journey maps are diagrams that
typically include touchpoints, customer sentiments, pain points, and
actions, plotted in sequential order. But the goal of journey mapping
isn't just to create a timeline---a good customer journey map promotes
empathy and provides a clear vision for improving your customer's
experience.

‚Äç

There are no hard and fast rules about what a customer journey map has
to look like. It can be something as simple as a table, or it can be a
large-scale diagram reflecting multiple user personas and customer
pathways. The best customer journey map for your company is the one that
helps your team align your customers' needs---and how to exceed them.

‚Äç

![Example of a customer journey map with spaces for the persona,
scenario, goals and expectations, steps, touchpoints, emotional range,
and
opportunities.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94a1198cfc64ae2613319_9WLTcjvpnflkRjJaCxhk5IQNZv0dqQP6jyGIFqAdLM7hTc-ahEcI_J5K3R6pYrcHoqnhC7hqY9I-FYgqoIlwWSc8v9BhDZZ2PTpKJA3-lfnfdKMFXQ6VZwch1ad0OAKuRA2ci7af.png)

A breakdown of a customer journey map from [**Nielsen Norman
Group.**](https://www.nngroup.com/articles/customer-journey-mapping/)

‚Äç

## What is the difference between a customer journey map and a user journey map?

Not a whole lot. Sometimes, [**user journey
maps**](https://uxdesign.cc/user-experience-mapping-alice-emma-walker-868259547ba8)
refer to specific maps UX designers make during the design process to
understand potential points of friction in the customer journey. But
typically, the difference is semantic: The terms "user journey map" and
"customer journey map" are largely interchangeable and can depend on the
context---user journey maps are typically used in UX design, while
customer journey maps have more wide-reaching business applications.

‚Äç

## What is the difference between customer journey mapping and customer experience mapping?

These terms are also sometimes used interchangeably, but there is a real
difference between the two. A customer journey map is focused on your
customer's experience with your company. It can include moments,
thoughts, and decisions leading up or following that experience---but at
some point in the map, the customer will interact with your company.

‚Äç

A customer experience map, on the other hand, is a visualization of a
"typical" experience, regardless of whether or not it involves your
company.

‚Äç

For example, a customer experience map for a language-learning app like
Duolingo would show the generic experience of learning a new language,
whereas a customer journey map would depict a user's path to learning a
language using the Duolingo app.

‚Äç

## Why you need a customer journey map

A customer journey map gives everyone on your team a single, shared
source of truth to work with. A CJM can help your team see the customer
journey as a whole, and understand the problems they're trying to solve
clearly and contextually.

‚Äç

Empathy is perhaps the biggest pro to building customer journey maps.
Without empathy, it can be all too easy to forget that customers are
real people with real problems. [**Studies have
shown**](https://phys.org/news/2019-05-power-empathy-product.html)that
people who feel empathy towards customers build more creative things.
Customer journey maps make that empathy easier to come by since they
give your team a window into the customers experience.

‚Äç

Reinforce empathy by having your team revisit your customer journey map
often and at the beginning of each project. Knowing which parts of the
customer journey their work will affect will give your team important
context and help keep the real people on the far end of business and
design decisions in sharper focus.

‚Äç

### Improve internal alignment and break down silos

After creating empathy, [**team
alignment**](https://www.userinterviews.com/blog/how-alignment-can-speed-up-your-work)
is perhaps the second-most important reason to create a customer journey
map.

‚Äç

It's easy to get tunnel vision and see only what is relevant to the
parts of the customer experience you work on, instead of looking at the
bigger picture. A customer journey map provides a single source of truth
across your company and can help your team get on the same page about
what you're building, why you're building it, and how you're going to
get there.

‚Äç

"By showing how customers feel throughout their journey, customer
journey maps invite stakeholders to enter the world of customers and
share in their experience. In turn, stakeholders are better able to
convey their story to management, fellow colleagues, and the teams who
are responsible for improving the service and product experience." -
[**Joel
Flom**](https://www.uxmatters.com/mt/archives/2011/09/the-value-of-customer-journey-maps-a-ux-designers-personal-journey.php),
Senior Manager, Product Design, Enterprise Design System at Aetna

‚Äç

Let\'s look at a sample customer journey map [**from
UXHints**](https://uxhints.com/ux-research/customer-journey-map-template/)
to see how different teams can use CJMs:

‚Äç

![Example of a customer journey map from UX Hints. Includes stages of
the customer journey: Awareness, Consideration, Acquisition, Service,
and Loyalty. At each stage, in the column is step of the customer
journey, followed by customer\'s thinking, doing, feeling, and pain
points. In the last row is opportunities for the
company.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94aa3a0fdc854f625b388_7kXRh9NL3K95Htihocxg-9WQg1-i3m4vLH9kR5eCp6-6Iy8q6SLMPpwWW7U5hlQ3LOXpwH-SUpMeSjJH5YEBl0RvfoQGzF_d1lepZIPlZMunx438_vn_4Qgtoq81a6czlPE81PEI.png)

‚Äç

**Marketing and sales teams** could use this map to identify how they
can help customers learn about the different cable providers. They can
use the "thinking" portion to create new marketing campaigns or sales
processes. For example, marketing could build specific awareness
campaigns around pricing and features.

‚Äç

**Product and UX teams** could use this map to improve the experience
throughout the customer journey. They could build an onboarding
experience that helps new users through common pain points, add support
for additional payment methods, or focus on improving streaming quality.

‚Äç

‚Äç**Customer service and success teams** could use this map to identify
pain points and places customers may need extra help. For example, they
might create a way for potential customers to chat with someone about
pricing during the "consideration" phase, or they may invest in a chat
tool that automates certain support responses.

‚Äç

### Understand multiple customer pathways and personas

No customer experience is exactly the same, but customer journey maps
can help us understand where the similarities (and important
differences) lie.

‚Äç

How does the experience of a user who was invited by a friend differ
from someone who found your product on Google? How do different user
personas interact with your company along their journey? Are there
certain moments in the journey that trip up certain customers more than
others?

‚Äç

Customer journey maps can help you not only answer these questions, but
also target different personas and solve their problems more
effectively.

‚Äç

For example, a research team of one may be able to launch a project with
User Interviews as soon as they have a research idea. A researcher at a
large enterprise, on the other hand, may need to consult with additional
researchers and stakeholders.They may need to use additional
features---like allowing their teammates to comment on their research
project draft or syncing multiple calendars to the research schedule.

‚Äç

Customer journey maps can help your team visualize which pain points are
shared by all your customers and which ones are specific to certain
personas. An understanding of which personas and customer types are most
important to your business will allow you to then prioritize product and
service improvements based on which ones will have the biggest impact.

‚Äç

If your user experience is exceptionally complicated or lengthy (and
[**according to
McKinsey**](https://blogs.perficient.com/2016/06/09/infographic-7-benefits-of-customer-journey-mapping/),
¬†56% of customer interactions happen during a multi-event, multi-channel
journey), it can be helpful to create multiple journey maps for
different personas. Alternatively, you can create a more detailed
customer journey map of just one section of the experience. For example,
you could create a map showing all the ways someone could convert from a
visitor into a lead. This would allow you to dig into more of the nuance
within that process.

‚Äç

### Uncover and prioritize new problems

Everyone has blind spots. After working on something for years, it's
very possible that you're working off of old assumptions about what your
customers want and how they interact with your product. These
assumptions could be based on research you did when a project started,
analytics you looked at a long time ago, or even just a gut feeling
rooted in past experience.

‚Äç

We are, unsurprisingly, big advocates for using research to make better,
data-based decisions about what to build and where to spend your team's
energy. Customer journey maps are a great way to make sense of the
research you've done. CJMs can help you audit your current efforts and
ensure they align with your customer's current needs. They can also help
work towards building the experience you **want** your customers to
have.

‚Äç

Assuming you already have a product and customers, you'll want to create
a current state customer journey map to help you understand what your
actual customer journey looks like, with all its flaws and areas of
improvement.

‚Äç

From there, you can use future state mapping to get your whole team on
the same page about what you want your customer journey to look like.
Additional tools like service blueprinting can help you see exactly
where you can improve your existing processes to better serve your
customers.

‚Äç

Service blueprints, like the example below, show all the things that
happen behind the scenes of your customer journey.

‚Äç

![Dark service blueprint customer journey map example showing the
backstage support processes behind theater ticket
purchase.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94ac291fb52fba1abc424_wk6w6VUJAkpFSPCbPxKlj8bc6gkoC3Kmv4k55n401EFcRFQYoSZsBJKPoNOA0KnQ_dEnTUNvI6e5Ac41hEjQqbkNa6O-AtwEfwSt150GyOcsqScKAdI_W7Zgo8BRvy_qEIxETC_t.png)

‚Äç

Service blueprints can be especially useful when you are trying to
optimize the customer service experience, or find the best way to solve
a specific pain point.

‚Äç

For example, in the diagram above we can see that if there were
complaints about customers not receiving the promised Uber discount, the
problem is likely caused by poor communication between your customer
database and the 3rd party email system. This insight gives us a
reliable starting point for investigating and solving a shared point of
friction.

‚Äç

## How to build your customer journey map

Now that we know how customer journey maps can help you build better
products, let's dive into how to actually build one!

‚Äç

At a high level, this process will be fairly similar regardless of which
type of customer journey map you decide to create. In this next section
we'll go over how to:

1.  Conduct stakeholder interviews with your cross-functional team.
2.  Decide on which user personas to include.
3.  Flesh out your ideas with user research.
4.  Create an empathy map for each persona.
5.  Sketch your customer journey map.
6.  Choose which type of customer journey map is right for your needs.
7.  Assemble your customer journey mapping tools.
8.  Build your customer journey map!

‚Äç

### 1. Conduct stakeholder interviews with your cross-functional team.

First things first, you'll need to learn how your team will actually use
the customer journey map you create. Your journey map won't be effective
if your team doesn't use it, so this is a time to understand what each
team member would need to get from a journey map in order to consider it
truly useful.

‚Äç

Your stakeholder list may change depending on your organization, how you
plan to use your journey map, and the scope of your current undertaking.
Stakeholders could include people from product, UX, customer
support/success, sales, marketing, and data. The main goal here is to
understand how journey maps would be actually useful across the team and
to identify the key touchpoints you will be mapping.

‚Äç

#### Questions to ask during your customer journey map stakeholder session

We'll talk more about the [**types of customer journey
maps**](https://www.userinterviews.com/blog/best-customer-journey-map-templates-examples)
later in this chapter, but asking questions rooted in current experience
is helpful regardless of whether you're making a current or future state
map. Both maps rely on having a deep understanding of your current
customer's journey right now. What's more, people tend to bend the truth
or offer a rosier view if you ask them about their future plans.

‚ÄçLike great interview questions, the questions you use to start
conversations in your stakeholder sessions should be rooted in past
experiences.

‚Äç

A few general questions you can ask everyone:

-   Which parts of the customer journey do we understand the least?
-   Where are the moments of greatest friction?
-   What workarounds do customers use to get around product limitations?
-   Are there certain actions that correlate with stickiness or
    retention?
-   Why do customers churn?

‚Äç

In some cases, stakeholders from different teams will be more equipped
to answer specific questions. For example, a sales stakeholder can tell
you more about the buying process than a UX one.

‚Äç

Here's a few team-specific questions you can ask\...

‚Äç

Product stakeholders:

-   What does the signup process look like?
-   What features are most popular? Which are least popular?
-   What do we use right now to make everyday product decisions?

‚Äç

UX stakeholders:

-   What do we use right now to determine which projects need UX work?
-   How does the UX team approach a new project? What inputs do they use
    to make decisions?

‚Äç

Sales/marketing stakeholders:

-   What parts of the customer journey are most important to a
    purchasing decision?
-   What does our lead generation process look like?
-   What touchpoints do sales and marketing use after someone has signed
    up for our product?
-   How do we decide on new messaging for marketing campaigns or sales
    outreach?

‚Äç

Customer service/success stakeholders:

-   What are the most commonly asked questions right now?
-   How do we handle new features or if an element of the product has
    changed?
-   At what points does a customer reach out to your team?
-   What parts of our product are customers most passionate about?

‚Äç

Data stakeholders:

-   What data do we have access to? What platforms do we use?
-   What reports have we already created involving the customer journey?

‚Äç

#### Identify touchpoints from each stakeholder

You may have a relatively good idea of what touchpoints customers
encounter as they move through your journey. Still, creating a concrete
list of what those touchpoints are can help you and your team see gaps
you may not have caught otherwise. Asking stakeholders to identify these
before their interview gives you a good foundation of understanding and
ensures you're not taking up too much of their time.

‚Äç

Touchpoints are anywhere a customer might interact with your brand or
product along their journey---they can include social media ads created
by marketing, cold emails from sales, and tooltips from the product
team. If you're doing a customer journey map of the buying process for a
SaaS product, for example, you'll have to coordinate with a few
different departments to get a full list.

‚Äç

You can ask about touchpoints in your stakeholder interviews, or create
lists for each stakeholder or team to review. Creating a list of
touchpoints takes some of the stress off of your stakeholders, allowing
them to edit instead of starting from scratch. It can also help keep the
focus of your interviews on digging deeper instead of running through a
checklist.

‚Äç

For example, your list for a SaaS buyer's journey could look something
like this:

‚Äç

![SaaS buyer\'s
journey](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a6a6b99956e4bf08c89e8a_Screen%20Shot%202021-11-30%20at%203.33.19%20PM.png)

‚Äç

Ask each department to identify which touchpoints they think are the
most common or important. This will help you identify any gaps between
team thinking and reality once you've done your research and started
building your customer journey maps.

‚Äç

#### How to turn all those insights into clear objectives

Next, you'll want to identify the main objectives for your customer
journey map. These will help you stay focused throughout the building
process and serve as reminders about what you're actually trying to
achieve by customer journey mapping.

‚Äç

Here are some examples of objectives you could have for your customer
journey mapping:

-   Define how marketing can improve messaging early in the buying
    process.
-   Understand what turns customers into advocates for our company.
-   Learn more about how current pain points affect decision making
    throughout the journey.
-   Identify concrete improvements the UX team can make to our product.

‚Äç

Your objectives can be more specific than the ones above---they can
focus on a single team and one sliver of the customer journey---or they
can be broad and encompass the bigger picture. What's most important is
that you understand concretely how this customer journey map will help
your team move forward. Remember: You're not a cartographer--the end
goal here is not just to create a map, but to glean actionable insights
that will help make the customer experience better.

‚Äç

### 2. Decide on which user personas to include

The next step is to identify whose customer journey you'll be mapping
out. To do this, you'll need to decide on which user personas to
include.
[**Personas**](https://www.userinterviews.com/ux-research-field-guide-chapter/personas)
are representations of key audience segments for reference.

‚Äç

You may already have personas you can use to create your customer
journey maps. If so, fantastic! You'll be able to choose from existing
resources instead of doing persona work as a part of this process.

‚Äç

If you don't have personas ready and available, you can either make your
own by conducting a round of research at this stage or by using existing
data to identify key or ideal users in your customer base. Creating user
segments based on the data you already have available is likely the
easiest route to take at this point. This data may come from past
research, or from the quantitative data you collect about your users.

‚Äç

For example, if you're conducting research about the buying process, you
can look at what segments your current customers most often fit into. At
User Interviews, we break it down by company type and job type. So a UX
researcher at an enterprise company will have a different journey and
goal than a product manager at a small business. Both are customers, but
we can quantify how many of each of these types of people exist in our
current database, which gives us a good place to start when creating our
empathy maps.

‚Äç

Defining your personas or customer segments at this stage will also help
you narrow down your participant pool for the next step: user research.

‚Äç

### 3. Flesh out your ideas with user research

This is the fun part! üéâ.

‚Äç

While you'll already have done some research at this point---you started
off with stakeholder interviews, looked at known touchpoints, and dug
into your data to decide on your personas---now it's time to get serious
with dedicated customer journey mapping research.

‚Äç

There are a few ways to do user research for customer journey maps.
Choosing a method mostly boils down to how much time you have on your
hands.

‚Äç

![Graph showing different research methods for customer journey maps.
Methods are shown ranked from \"minimum research\" to \"maximum
research\". Methods are, in order: existing customer data (ex. Google
Analytics), user interviews, session recordings, unmoderated usability
tests, custom data reports, diary studies, and ethnography
studies.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94b15ba91e0b0b56f0e90_NRgaxrEYNL38QApqjLMiHx1o1XknDi32JT3gqytbN57NXOa7L7pH5aZGaW8eyXB8q7g2Sd66mOvZPbyGLz8gj6oVyMGShm5PEXJly9ZvvVf9FlW6j4whpPP0SrE-bJV7ScgAnMCh.png)

‚Äç

However you choose to create your customer journey maps, you'll want to
use a combination of qualitative and quantitative research. ¬†

‚Äç

If you need to create customer journey maps quickly, you can use
customer data you already have, combined with some quick user interviews
to learn more about the more intangible parts of the customer journey.
For example, you can use analytics to identify which touchpoints a
certain segment of users has come into contact with, and then combine
that information with what you hear in user interviews to build a
comprehensive customer journey map.

‚Äç

User interviews can help you answer questions like:

-   How do you users **feel** at certain points in the customer journey?
-   Why do users decide to act a certain way at a particular moment in
    their journey?
-   Are there pain points for customers that you can't see in the data?
-   Which parts of the journey stand out to your customers? Are they the
    same as your team's focus?

‚Äç

Need some help getting started with user interviews? We have some tips
to help you [**get
started**](https://www.userinterviews.com/ux-research-field-guide-chapter/generative-interviews),
[**write amazing interview
questions**](https://www.userinterviews.com/blog/how-to-write-ux-research-interview-questions-to-get-the-most-insight),
and [**recruit the right
people**](https://www.userinterviews.com/blog/the-total-guide-to-user-research-recruiting).

‚Äç

Want to get a seriously comprehensive view of the journey your customers
take? A [**diary
study**](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies)
is one of the best ways to learn. Diary studies involve following a user
through a specific process and asking them to document their experience
along the way. This makes it easier to understand exactly what happens
at each step of the journey, instead of asking users to recall events
after the fact.

‚Äç

Diary studies can help you:

-   Track a customer's emotions and thoughts at particular moments.
-   Get more detailed, contextual insights about the entire customer
    journey.

‚Äç

You can answer the same questions with diary studies as with user
interviews, but diary studies can help you get even more granular and
contextual insights into a customer's thoughts, feelings, and actions as
they occur.

### Start doing customer research today

[Try Research Hub free](https://www.userinterviews.com/research-hub)

### 4. Create an empathy map for each persona

Now it's time to use the insights you gained from your user research
sessions to fill out some ¬†empathy maps.

‚Äç

To borrow a definition from Nielsen Norman Group:

An [**empathy map**](https://www.nngroup.com/articles/empathy-mapping/)
is a collaborative visualization used to articulate what we know about a
particular type of user. It externalizes knowledge about users in order
to 1) create a shared understanding of user needs, and 2) aid in
decision making.

‚Äç

The goal of an empathy map is to learn more about how a certain persona
experiences things---to make them a little more human instead of just a
list of demographic data and job title.

‚Äç

For each persona or user segment, you'll need one empathy map. So, if
you're creating customer journey maps for more than one type of user,
you'll also need to create multiple empathy maps.

‚Äç

Empathy maps are typically split into 4 quadrants---Says, Thinks, Does,
and Feels.

‚Äç

The **Says** quadrant covers what users actually say during research.
Ideally, these are direct quotes from sessions.

‚Äç

The **Thinks** quadrant includes what users are thinking during the
process. What's going on in their minds that they may not actually
vocalize? What matters to them? Keep in mind that there may be some
overlap between the Thinks and Says quadrants.

‚Äç

The **Does** quadrant includes the actual things the user does. What
physical or mental actions do they take?

‚Äç

The **Feels** quadrant shows the user's emotional state. Think about
what worries or excites the user. What emotions guide this process for
them? ¬†

‚Äç

![An example of an empathy map from Nielsen Norman Group. The map is a
square divided into four parts with a circle in the middle. The circle
shows the user. The top left corner of the square is labeled \"says\",
the top right is \"think, the bottom left is \"does\", and the bottom
right is
\"feels\".](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94b15c4afb32e335b2d73_FxfmqSZGf8S8EHtr2uA9Qls0Wn0iDTWmflBUDempPtLrLOJIYNXn7lN873d_YZNN2QqO_TiBm1-FzUW3ezLlPfL3cAPiy649WdkYo7UAi5Cfam4aEql1thFkzr9RO0micyK2mq_-.png)

‚Äç

Here are some examples of how you can fill out each of the quadrants,
again from
[**NN/g**](https://www.nngroup.com/articles/empathy-mapping/):

‚Äç

![An example of an empathy map from Nielsen Norman Group. The map is a
square divided into four parts with a circle in the middle. The circle
shows the user. The top left corner of the square is labeled \"says\",
the top right is \"think, the bottom left is \"does\", and the bottom
right is \"feels\". The \"says\" quadrant includes examples like \"What
do you think?\" and \"I was expecting something different\". The
\"thinks\" quadrant shows examples like \"Do they think I\'m stupid?\"
and \"Too many acronyms\". The \"does\" quadrant shows examples like
\"Checks the website\" and \"Compares products\". The \"feels\" quadrant
includes examples like \"Overwhelmed\" and
\"Excited\".](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94b1598cfc63a276265a4_IboG0Dk7-1qaPo620OO6XViedX5rmaJWrXRnlLNSBRFHtwDujUeftDyugo4Qv8dQdw5_-uU_Z7H569kJ47xn5lNYlb7GqJ4BStAxouwjwA4WEKdjMta7fuEN9cN6-OUWEfKZKSOP.png)

‚Äç

You may already have qualitative information about your personas to help
you build this empathy map. If you don't, it's time for some [**user
interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/generative-interviews).
You can keep these short and sweet---oftentimes just [**5
interviews**](https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/)
with each persona or user segment can help you get the insight you need!

‚Äç

Once you have your research results in hand, you can start empathy
mapping. This process is best done with a few people, to avoid
unconscious bias. Start by reading through each of the interviews and
tagging specific moments or insights. Then, each person on your team can
start building an empathy map of what they think this persona says,
thinks, feels, and does. When that's done, you can get together as a
group and put everything together into one final empathy map.

‚Äç

### 5. Sketch your customer journey map

At this point, you have enough information to make a rough sketch of
your customer journey map. Doing this now will help you build a more
complete final map and focus your user research on the areas where it
will make the greatest impact. Nobody gets it right the first time,
especially with something this complex, so this step serves as an audit
of your process so far, and helps direct the final steps.

‚Äç

This version of your customer journey map doesn't have to be very
detailed---it just needs to give you a good idea of what you're working
with. A rough draft also helps highlight areas where you may be filling
in information based on what you think vs. what you know from research.

‚Äç

![5fb6e0b2deaf5af7a123c178_P1j6NBqG2uqmDbetG6t-xNBNIgspu_g\_e8GRbK54OI7Jj1Yx9DSsYc09ycje61YyHCUwDS-9GM8LaCx1AeP1nj3r59r_o1wRlsv_jjZiHqo3N-0K72pqS9l7Kub2ePCPGPnzCQi1](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fb6e0b2deaf5af7a123c178_P1j6NBqG2uqmDbetG6t-xNBNIgspu_g_e8GRbK54OI7Jj1Yx9DSsYc09ycje61YyHCUwDS-9GM8LaCx1AeP1nj3r59r_o1wRlsv_jjZiHqo3N-0K72pqS9l7Kub2ePCPGPnzCQi1.png)

This is an example of a pretty simple customer journey map. It includes
touchpoints, actions, and a small description of the customer. Your
sketched map could look like this, or you could pare it down further to
a simple grid. Tools like
[**Miro**](https://miro.com/templates/customer-journey-map/),
[**Lucidchart**](https://www.lucidchart.com/blog/how-to-build-customer-journey-maps),
or even
[**PowerPoint**](https://office.live.com/start/powerpoint.aspx)/[**Google
Slides**](https://www.google.com/slides/about/) can help you create an
effective V.1 customer journey map with minimal effort.

‚Äç

Once you have your sketched map, think about the touchpoint lists you
put together. Are there important touchpoints missing from your map? Are
there touchpoints there that shouldn't be? These questions will help you
identify things to look for in your user research.

‚Äç

You can also ask questions at this stage about the steps on your map. Is
there anything that happens in between steps? Is it helpful to get more
granular or should you zoom out a bit? Look back at your initial
brainstorming notes. Is there anything people identified as important
that this version of your map doesn't cover?

‚Äç

Take note of opportunities for improvement. If there are things you're
not sure about, you'll be able to validate them in the next step.

‚Äç

### 6. Choose which type of customer journey map is right for your needs

Depending on what you want to accomplish, there are a few different
types of customer journey maps you can choose from to get the job done.

‚Äç

#### Current state customer journey maps

‚Äç

Current state customer journey maps are fact-based maps that show what
your customer's journey looks like today. This is the most common type
of customer journey map. Current state maps help your team identify,
document, and think of ways to fix customer's current problems.

‚Äç

Choose a current state customer journey map when you need to...

-   Communicate pain points to stakeholders and persuade them to take
    action.
-   Align your team around a shared understanding of and empathy for the
    customer experience.Explore new research and product opportunities
    based on the current reality.

‚Äç

Here's an example of a real-life current state journey map, from
[**USA.gov**](https://digital.gov/2015/08/12/journey-mapping-the-customer-experience-a-usa-gov-case-study/).

‚Äç

![Example customer journey map from USA.gov showing the customer journey
of learning about government
grants.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94b15c50299dd8d217394_18ozpNZpA4GQtuu1JtgChPi0iGIPSsamim3rLcCYc010MGwy2H47rGlaKnKRMyjElwJElfuNclfj6JbRjVWXUXzUHbUM1FF6hgwa-MwjbFxMYnDb-thInhkcXHNLaUvTeb-hsIJP.jpeg)

This journey map follows the customer journey in detail, which gives the
teams using it specific opportunities to improve. It also shows
stakeholders exactly how the current product is not meeting customer's
needs, which can help the product team make a case for improvements.

‚Äç

#### Future state customer journey maps

Future state customer journey maps visualize what an ideal future
customer journey would look like. These maps help your team align around
a shared vision of what your product or service can and should be.

‚Äç

It is generally helpful to start by creating a current state map, since
much of the same data goes into a future state map. For the latter,
however, data is just the foundation---future state maps involve a lot
more creativity and hypothesizing about what your team wants the
customer journey to be, rather than reporting on what things look like
today.

‚Äç

Choose a future state customer journey map when you need to...

-   Align your team around a shared vision of where your product is
    going.
-   Explore possible customer reactions, hopes, and expectations.
-   Create a roadmap for a totally new product or experience.

‚Äç

Here's an example of a future state customer journey map from [**Bright
Vessel**](https://www.brightvessel.com/how-to-build-a-customer-journey-map-example-pdfs/).

‚Äç

![Example of a future customer journey map from Bright Vessel. At the
top is the phases of the customer journey, in different colors. In the
second column is customer thoughts and feelings, then customer actions.
Then touch points and devices, people and environments, proposed
changes, and possible
scenarios.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94b1566bb975cded1a5e8_nh3sthD-R8ZP1e3hKrBC400vNZkNfhPCDgTGksR3ndaqXFEXUGC-sdCJ8v4uoGm5yGZy_kBZMrfdPgzXz5f4mYgsXo2GBcXpwNSGhpAbRSGG3_hVcTHwUjMQjGlrRpJzHQ-Aigss.png)

‚Äç

This map envisions what a future customer journey could look like. It
includes everything a current state map might have---like thoughts,
feelings, and actions---but these are hypothetical, rather than
reported. Note: Your future state map doesn't have to be this detailed.

‚Äç

#### Day in the life customer journey map

A day in the life customer journey map follows someone through their
entire day. It documents everything they do---from their morning coffee
to their dinner plans---regardless of whether or not those things are
related to your product. Day in the life maps are different from current
or future state customer journey maps in that their scope is not limited
to touchpoints with your company.

‚Äç

Choose a day in the life customer journey map when you need to...

-   Understand how other parts of your customer's life affect their
    experience with your product.
-   Identify moments ¬†which your product can be most useful to your
    customers.

‚Äç

Here's an example of a day in the life customer journey map, from
[**Treasure
Data**](https://blog.treasuredata.com/blog/2019/08/15/how-to-create-four-different-customer-journey-maps-and-why-you-might-need-them-all/).

‚Äç

![Example of a day in the life customer journey map showing what a
frequent business traveler\'s day looks
like.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fc94b15242c40867bbda85b_f-9P7yKJOI3lwp9yBVdk7gjOMVUlxnU-kzQS7rAN2buZ-I9ztaoKOLR1PBrImoxMNIvEAbHtCqmEbAW2S4e9yGf_CeDUdjGRFQ0CWwVxtbNCov3mm48v1k4elItkgRDF_jX6NSKF.png)

‚Äç

This day in the life customer journey map follows a frequent business
traveler through a travel day. It shows the opportunities a product or
service may have to improve his experience at the airport and throughout
his routine.

‚Äç

#### Service blueprints

A service blueprint is a useful companion to a classic customer journey
mapping project. Service blueprints outline all the little things that
make a successful customer journey happen.

‚Äç

From [**Nielsen Norman
Group**](https://www.nngroup.com/articles/ux-mapping-cheat-sheet/):

Blueprinting is an ideal approach to experiences that are omnichannel,
involve multiple touchpoints, or require a cross-functional effort (that
is, coordination of multiple departments).

‚Äç

Choose a service blueprint when you need to...

-   Understand the behind-the-scenes actions that affect your current
    customer journey.
-   Pinpoint structural changes you can make to improve your customer's
    experience.
-   Plan for procedural or organizational changes.

‚Äç

Here's an example of a service blueprint from [**Nielsen Norman
Group**](https://www.nngroup.com/articles/ux-mapping-cheat-sheet/).

‚Äç

![Example of a service blueprint from Nielsen Norman Group. At the top,
the time of each stage is shown, followed by a row showing the evidence
from each step. In the third row the customer journey is shown, with
additional rows showing frontstage and backstage
actions.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fb6e0b4f757610989c9f1ce_FnQMB1JJi6dTmsBtPfWmA7hW1TITh_K0RiPOAr0jJBhEs6_TKvatABDCLHta5RZ3YA0hj5n__b8-zigdfNTD6sZ2D8iAyTWGPEeTfeps2QD7k-P2dNeErjePSiKO3KZ74TicczNA.png)

This service blueprint shows all of the actions that take place behind
the scenes to make an appliance retailer's customer journey happen.
Identifying active frontstage employee actions and backstage processes
can help the product team make decisions about what levers they can pull
to improve the customer experience.

‚Äç

### 7. Assemble your create your customer journey mapping tools

You're in the final stretch now! It's time to assemble your tools. There
are tons of [**different customer journey mapping
tools**](https://www.userinterviews.com/blog/tools-for-customer-journey-mapping)
out there---just choose the one you find easiest to use. That may sound
simplistic, but customer journey maps can be ¬†a whole lot of work
already.And remember: the point of journey mapping is to gain a shared,
accurate understanding of your customer's experience, not create a work
of art. If you're not design savvy, focus on substance over style.

‚Äç

#### Simple customer journey map tools

**Paper**: Remember paper? Turns out it's a crazy useful tool for
getting your ideas down. That includes creating customer journey maps.
You can print out [**this
template**](https://media.nngroup.com/media/articles/attachments/JMTemplate.pdf)
from [**Nielsen Norman
Group**](https://www.nngroup.com/articles/customer-journey-mapping/) to
get started.

‚Äç

**PowerPoint/Google Slides**: Slides are a great way to create customer
journey maps without venturing into unfamiliar design tool territory.
You can easily create shapes and add text where you need it on a slide,
without any graphic design skills. [**This template from Kerry
Bodine**](https://kerrybodine.com/free-journey-mapping-template/) is a
great resource for PowerPoint fans, while [**this one from
YouExec**](https://youexec.com/presentation-templates/customer-journey-maps)
is perfect for Google Slides users. Either will help you create
something dynamic and interesting without too much design work.

‚Äç

**Miro**: You may not have used Miro before, but it's simple enough for
most people to catch on pretty quickly! Plus, they have tons of customer
journey map templates, so you won't have to start from scratch. You can
use ¬†[**their own**](https://miro.com/templates/customer-journey-map/),
or borrow from ¬†research practitioners like [**Alex
Gilev**](https://miro.com/miroverse/category/workshops/practical-customer-journey-mapping/)and
[**the team at
Atlassian**](https://miro.com/miroverse/category/strategy-and-planning/atlassian-team-plays-customer-journey-mapping/).
Miro offers a free tier with 3 editable boards, which should be enough
to create your first journey map!

‚Äç

**LucidChart**: LucidChart is very similar to Miro. It's simple enough
that most people can learn it quickly, and offers a free tier that
allows you to create 3 editable charts. [**Their
templates**](https://www.lucidchart.com/blog/how-to-build-customer-journey-maps)
cover basic customer journey mapping and service blueprints, along with
more in-depth journey maps.

‚Äç

#### Prototyping tools for customer journey maps

**Sketch**: Sketch is [**not a free
tool**](https://www.sketch.com/pricing/), but your team may already be
using it to create prototypes and designs. If so, you can also create
your customer journey maps in this powerful vector-based design tool.
There are journey map templates to help you get started with [**current
state customer journey
maps**](https://www.sketchappsources.com/free-source/3131-journey-map-templates-sketch-freebie-resource.html),
[**empathy
maps**](https://www.sketchappsources.com/free-source/3958-empathy-map-template-sketch-freebie-resource.html),
and
[**more**](https://www.sketchappsources.com/free-source/3803-user-journey-map-template-sketch-freebie-resource.html).
¬†

‚Äç**‚Äç**

**AdobeXD**: If you're a UX designer, you may already be working in
[**AdobeXD**](https://www.adobe.com/products/xd.html). It has a starter
version that's free to use, but you'll need to upgrade for the more
robust features. There are a few templates to help AdobeXD users create
customer journey maps, like [**this one from Bometon
Lucas**](https://www.behance.net/gallery/78065675/Free-customer-journey-map).

‚Äç

**Figma**: Figma is a popular design tool with [**a powerful free
version**](https://www.figma.com/pricing/). If you have some design
chops but aren't a full-time designer, Figma may be the easiest design
tool to use. They've created a [**useful customer journey map
template**](https://www.figma.com/file/TIgdMsi93xMZzSH9ynF5pY/CX-Journey-Map-Template-For-Public/duplicate?node-id=0%3A1)
that you can adapt to your needs. Members of the community have also
created templates, like [**this one from
Detour**](https://www.figma.com/file/FkGTV5u050q8c9n27JaCcP/Detour-Customer-Journey-Map-Template?node-id=0%3A1)
and this [**exceptionally detailed one from
Theorem**](https://www.figma.com/community/file/812358656900783385). ¬†

‚Äç

**AxureRP**: AxureRP is the most traditional prototyping tool on this
list. If you're already using Axure for prototyping and wireframes, it
may be a great tool for your customer journey mapping. There's [**no
free version**](https://www.axure.com/pricing), so Axure is best for
teams that already pay for it. Check out [**this
template**](https://haloux.com/UX-Starter-Kit-Axure/UX%20Starter%20Kit%20Demo/index.html#g=1&p=user_journey)
from HaloUX to start building a customer journey map in Axure.

‚Äç

#### Dedicated customer journey map tools

**UXPressia**: UXPressia is all about customer journey maps. You can
build one for free, then upgrade to [**the paid
plan**](https://uxpressia.com/pricing) if you're a real customer journey
map machine. UXPressia is all about customer journey mapping, the
software is easy to use for this purpose. ¬†And there are a lot of
templates to choose from---check out their huge [**library of templates
here**](https://uxpressia.com/templates).

‚Äç

**FlowMapp**: FlowMapp is also built specifically for customer journey
mapping. Their free plan gives you access to one map, and you can
[**upgrade if you need more**](https://www.flowmapp.com/pricing). Like
UXPressia, they have an easy-to-use interface and [**templates to help
you get
started**](https://www.flowmapp.com/features/customer-journey-map).

‚Äç

Again, the right tool for you will be the one you find easiest to use
without sacrificing too much detail. If you're a designer, the
prototyping tools may be right in your wheelhouse, but if you're in
marketing something simpler might be more comfortable and therefore more
efficient.

‚Äç

### 8. Build your customer journey map

This step is actually the simplest of them all, since you're really just
putting all your carefully prepared ingredients together.

‚Äç

Start by looking at the sketch you made of your customer journey. Did
you properly fill in all the holes you wanted to with your research? Is
there anything left to examine? Do you need any more information to make
a complete map?

‚Äç

If the answer to all of those questions is 'no', you can move on to your
brainstorming session notes. Have all of the objectives of your customer
journey map been met? Is the final product going to be something usable
for your team members and stakeholders?

‚Äç

Once you've answered those questions affirmatively, it's time to put pen
to paper (or more likely, mouse to screen). It's time to actually create
your customer journey map.

You can start from scratch and build something completely unique, but
you don't have to. There are tons of amazing [**customer journey map
templates**](https://www.userinterviews.com/blog/best-customer-journey-map-templates-examples)
that can help you get moving faster and spend more time ensuring your
customer journey map is accurate, rather than worrying about the design
itself.

‚Äç

Finally, walk through your finished customer journey with your team to
make sure it's clear, accurate, and useful.

‚Äç

## Customer journey map templates and examples

Creating a customer journey map involves lots of collaboration,
research, organization, and time. Why reinvent the wheel while you're at
it? We put together [**31 customer journey templates and
examples**](https://www.userinterviews.com/blog/best-customer-journey-map-templates-examples)
to help you create beautiful, effective journey maps faster and easier.

‚Äç

Here are just a few from the list:

![An example of a customer journey map. This includes a column with a
picture of the customer, their goals, pain points, and expectations. The
middle column shows a circular representation of the customer journey,
with touchpoints at the bottom. The last column shows insights including
consideration opportunities, evaluation opportunities, closure
opportunities, and post-purchase
opportunities.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fb6f7ecd0ab9cd7f3c89458_customer_journey_flywheel_touchpoints.jpg)

A totally free customer journey map template from
[**SiteImprove**](https://siteimprove.com/en/blog/how-to-create-personalized-content-for-every-step-in-the-customer-journey/).

‚Äç

![A detailed customer journey map template. This includes rows for
customer activities, customer goals, touchpoints, experience, business
goals, KPIs, organizational activities, responsibilities, and technology
systems.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fb6f99479da0084fd6c1857_Customer_Journey_Map_editable_pdf.jpg)

A more detailed, but still totally free customer journey map template
from [**Columbia
Road**](https://www.columbiaroad.com/blog/why-and-how-to-create-a-customer-journey-map-download-free-template).

‚Äç

![An example of a day in the life of a dyslexic child. It includes the
places, people, and activities that fill a child\'s day to help
companies learn more about
them.](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5fb6f3ca3412b9816420ca3f_dyslexicchild_day-in-life-CJM.jpg)

A creative day in the life customer journey map example from [**Chiara
Galiano**](https://www.behance.net/gallery/12142829/Customer-Journey-Map).

‚Äç

## Customer journey map checklist

Let's take a minute to review what you'll need to do to create a
fantastic customer journey map:

1.  Conduct stakeholder interviews with your cross-functional team.
2.  Decide on which user personas to include.
3.  Flesh out your ideas with user research.
4.  Create an empathy map for each persona.
5.  Sketch your customer journey map.
6.  Choose which type of customer journey map is right for your needs.
7.  Assemble your customer journey mapping tools.
8.  Build your customer journey map!

‚Äç

Creating a customer journey map doesn't have to be difficult, but it
likely will take you some time. Making a checklist can help you get
organized.

‚Äç

There you have it! A comprehensive guide to creating your very own
customer journey map to build empathy, increase stakeholder engagement,
and create a shared source of truth.

‚Äç

Next up, we discover the tools you need for a superpowered research
stack. We dig in to each tool's pros and cons and show you how to pick
the ones that will work best for your team.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/personas)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](/ux-research-field-guide-module/more-resources)

Next:

Appendix

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Appendix](/ux-research-field-guide-module/more-resources)

![a person navigating a collage of browser windows and graphs
](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a4f0a74b421176517ca6ef_UI_CHAPTER_INTRO_ARTWORK.jpg)

# Appendix

A new edition of this module is coming soon! Subscribe to get notified.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

But wait, there's more!¬†

This is the Appendix, where all sorts of useful general knowledge about
UX research lives (or will live---we'll be expanding this list of
resources as we continue to refresh the UX Research Field Guide).

In the Appendix, you'll find a:

-   **Guide to UX research tools** and software.
-   **Glossary** of key terms and user research vocabulary.
-   **Collection of templates** and exercises found in this Field Guide.
    (Coming soon!)¬†
-   **List of further resources** for each chapter. (Coming soon!)¬†

[Start
reading](/ux-research-field-guide-chapter/user-research-tools)[Start
reading](/ux-research-field-guide-module/user-research-fundamentals)

In this module:

New edition arriving February 2022!

[UX Research Tools and
Software](/ux-research-field-guide-chapter/user-research-tools)

From recruiting, to testing, to storing insights, we\'ve got the
software rundown for any team

[Glossary of UX Research
Terms](/ux-research-field-guide-chapter/user-research-terms)

Brush up on your UX research vocabulary with this glossary of common
terms and definitions.

[](#)

[](#)

[](#)

[](#)

[](#)

[](#)

**Coming Soon** To this module:

##### UX Research Tools and Software

From recruiting, to testing, to storing insights, we\'ve got the
software rundown for any team

##### Glossary of UX Research Terms

Brush up on your UX research vocabulary with this glossary of common
terms and definitions.

##### Subscribe to the Field Guide for fresh lessons delivered right to your inbox!

[Subscribe](#)

don't see what you're looking for?

## Explore other modules

[](/ux-research-field-guide-module/user-research-fundamentals)

01\.

### UX Research Fundamentals

[](/ux-research-field-guide-module/planning-user-research)

02\.

### Planning UX Research

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Appendix](/ux-research-field-guide-module/more-resources)

\>

[UX Research Tools and
Software](/ux-research-field-guide-chapter/user-research-tools)

# UX Research Tools and Software

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

If there's anything I've learned from working with user researchers,
it's that they're incredibly resourceful. Recruiting through Craigslist,
scheduling through back and forth emails, conducting interviews over
Zoom, distributing incentives via PayPal. It's an endless parade of
tools and tips and tricks, and researchers navigate them all almost
seamlessly. Keyword: almost. While researchers are incredibly
resourceful people, there are some tools that can help make their lives
a little easier. And if you're new to research, or missing a few key
time savers, these tools are a great way to build out your research
toolkit.

‚Äç

Here\'s a quick overview of the types of tools you\'ll need for
different types of research:

‚Äç

![5f147090c71662d1daaaf8f5_tools%20table%201](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5f147090c71662d1daaaf8f5_tools%20table%201.svg)

![5f146c31e6e35228aab3285f_tools%20table](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5f146c31e6e35228aab3285f_tools%20table.svg)

‚Äç

Need to brush up on your research types? Check out [**this
module**](https://www.userinterviews.com/ux-research-field-guide-module/discovery-methods)
for an overview of discovery methods and [**this
one**](https://www.userinterviews.com/ux-research-field-guide-module/validation-testing-methods)
for an overview of validation methods.

‚Äç

And, just to give you a taste of what\'s to come, here\'s our [**2020 UX
Research Tools
Map**](https://www.userinterviews.com/blog/ux-research-tools-map-2020).
Not all of the tools in this image are covered in this chapter, but this
may help you get an idea of what kinds of tools you may need and where
some overlap.

‚Äç

If you want a deeper dive into the map after scrolling through the
version below, you can [**download the full
image,**](https://assets-global.website-files.com/59ace8427353c50001765cbd/5efe21fd3eca52d4086e743c_Map-7-2-Header.png)
or or [**head to our
blog**](https://www.userinterviews.com/blog/ux-research-tools-map-2020)
for more download formats and a full rundown of how we built the map and
what\'s new in this version.

‚Äç

![5f159bbf1a91800f27133881_Map-7-16-Header%20small](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/5f159bbf1a91800f27133881_Map-7-16-Header%20small.svg)

‚Äç

#### UX Research Tools Maps by year

-   [**2020**](https://www.userinterviews.com/blog/ux-research-tools-map-2020)
-   [**2019**](https://www.userinterviews.com/blog/the-2019-ux-research-tools-map)

‚Äç

ü§î **Curious about which tools were the most popular in 2020?** Between
Dec \'20 -- Jan \'21, we surveyed 525 people who do research for
‚ú®[**The State of User Research 2021
Report**](https://www.userinterviews.com/blog/state-of-user-research-2021-report)‚ú®---read
the report to find out which tools UXR teams are using to build
prototypes, collaborate remotely, conduct sessions, and more.

‚Äç

## In this chapter

-   User Recruitment Tools
-   Dedicated Scheduling Tools/ Video Conferencing Tools
-   Note-Taking/Transcription Tools
-   Survey Tools
-   Usability Testing Tools
-   Analytics & Heatmapping Tools
-   Research Ops & Insights
-   Tools for the Field

‚Äç

## User Recruitment Tools

Don't want to deal with the hassle of finding your own research
participants? Don't panic. These companies will help you find
participants for your research studies. Many of them include extra
research goodies like scheduling tools, surveys, or video conferencing
tools.

‚Äç

If you do want to recruit your own participants, tools like Craigslist
and TaskRabbit can be great resources. You can even combine some of the
scheduling tools above with an email service like Mailchimp to recruit
participants from your own customer list. Or you could use [**Research
Hub from User
Interviews**](https://www.userinterviews.com/research-hub).

‚Äç

### [User Interviews](https://www.userinterviews.com/)

#### How it works:

PSA: This is a User Interviews Field Guide and therefore, I, the writer
of said Field Guide and person currently employed by User Interviews, am
just a teensy weensy bit biased. Only a little bit though.

User Interviews is a one-stop shop for recruiting participants from your
current pool of users and its pool of over 350,000 ready, willing, and
vetted research participants. You can also target over 500 different
professions. If you incentivize your participants with Amazon gift
cards, we'll manage the incentives for you.

User Interviews also includes screener surveys, scheduling for
interviews, and participation tracking for your existing users. The
median turnaround time to match you with your first participant is 2
hours, though it can vary based on the project. If you're looking for a
solution to manage your own participant population, we can do that too!
Our [Research Hub Free Forever
plan](https://www.userinterviews.com/research-hub) stores up to 100 of
your own participants and lets you keep track of when they last
participated and even how much you've paid them in incentives.

#### What people love about it:

"My new team couldn\'t bear to spend what they thought they\'d have to
for recruiting for our UX research. I introduced them to
UserInterviews.com and we were off to the races! They were in LOVE with
being able to move and pivot so quickly. In just a few months, I
calculated that we saved \$10k in costs which allowed us to complete our
project in budget. I\'m VERY grateful!" - [Toni
R.](https://www.g2crowd.com/products/user-interviews/reviews/user-interviews-review-879546)

"Super easy to use interface made it great to set my numbers and pick my
participants. I was really amazed they managed to find people matching
my required profile which was a fairly technical person. They were also
really affordable. I really appreciate too how they put together a list
of potential people based on the questionnaire and don\'t just
automatically schedule people." - [Mari
F.](https://www.g2crowd.com/products/user-interviews/reviews/user-interviews-review-1160515)

#### What people don't love about it:

"I have very few complaints about User Interviews, but their messaging
system needs a bit of work. It\'s annoying to get communications from
users via email and then have to go back to the tool to respond rather
than just replying like you can in most ticketing systems." - [Max
G.](https://www.g2crowd.com/products/user-interviews/reviews/user-interviews-review-719824)

"The only downside I have seen is that I\'ll have repeat participants
apply for projects I post, after I\'ve already deemed them \"not a fit\"
from previous projects. I can sift through them pretty quickly though so
it\'s not that huge of an issue." - [Christine
S.](https://www.g2.com/products/user-interviews/reviews/user-interviews-review-3408951)

#### [Pricing](https://www.userinterviews.com/pricing)

User Interviews pricing does not include participant incentives.

*Recruiting from User Interviews' participant base:*

Pay As You Go: \$40 per completed session

Recruit Essential: \$250 a month for 15 sessions

Add-ons:

\$40 per completed session/ \$250 a month: recruit B2B participants
based on job titles, industry, work email, etc.

\$20 per completed session/ \$125 a month: double screening over the
phone with potential participants

*Recruiting from your own user base with User Interviews:*

Research Hub Free Forever: \$0 a month for up to 100 contacts in your
research CRM.

Research Hub Essential: \$125 a month for up to 5,000 contacts in your
research CRM.

Enterprise Tiers available

Since this is a User Interviews article, we\'re throwing some free
credits your way! Click the button below to get 3 free participant
credits when you launch your first project.

### Want to grab 3 free participant credits for your first study? Sign up here üëá\*

[Get my 3 free participant credits](https://www.convertcalculator.com)

#### Best for:

People who don't want to deal with the hassle of recruitment or giving
out incentives.

### [Respondent](https://www.respondent.io/)

#### How it works:

Respondent allows you to post your research study and gain participants
from their participant pool. You can then choose who you want to
participate in the study, and schedule them for a session through
Respondent's platform. You can also pay your participants through
Respondent's platform. Their average recruitment time is 3 days.

#### What people love about it:

"This platform is FAST. I love how I can set up my project at the end of
my work day and come back the next morning and already have all my
qualified participants ready for me to recruit from. In the past, when I
used traditional recruiting agencies, I had to give them 2-3 weeks of
lead time and pay so much more per head. Respondent changed that game
for me and allowed me to be quicker in my research and analysis and
stretch my company dollars further. Add an excellent customer service
and you got yourself a winning platform." - [Michal
C.](https://www.g2crowd.com/products/respondent/reviews/respondent-review-860143)

"I definitely like the ease in which recruitment campaigns can be
scheduled. Especially the ability to add constraints to the type of
person who gets recruited is pretty awesome as well.Recently they
launched the ability to re-invite past respondents which is amazing!" -
[Sai Shyam
G.](https://www.g2crowd.com/products/respondent/reviews/respondent-review-608099)

#### What people don't love about it:

"The ratio of actually qualified respondents to \*technically\*
qualified respondents is skewed a bit too far toward the \*technically\*
qualified." - [Deb
M.](https://www.g2crowd.com/products/respondent/reviews/respondent-review-849558)

"The hike in fees per incentive has affected how much we\'re relying on
external research and putting more burden on customer research. I would
love a way to utilize the service for contacting our own customers, but
there\'s PII risk and so can\'t take full advantage. Wish that the NDA
was simpler - those running studies have told me they opt not to send
one because of usability." - [Danielle
C.](https://www.g2.com/products/respondent/reviews/respondent-review-3410339)

#### [Pricing](https://www.respondent.io/pricing)

*Recruiting from Respondents' participant base:*

50% service fee: paid after you complete your study and pay your
participants their incentives.

*Recruiting from your own user base with Respondent:*

3% transaction fee for credit card payments

#### Best for:

People that only need to recruit people to participate in their studies
and are willing to pay high incentives. Respondent's lowest recommended
incentive is \$100 per hour.

### [Ethnio](https://ethn.io/)

#### How it works:

Ethnio allows researchers and product teams to integrate studies
directly into their websites or native apps. It can add small surveys to
your website or app and even asks users if they are available for a more
formal interview. Researchers can pay incentives, schedule meetings, and
track research activity within Ethnio. Ethnio also offers worldwide
recruiting, so you can grab insights from China to California. Ethnio
does not have a recruitment turnaround time because they are recruiting
from your users, not finding outside participants.

#### What people love about it:

"The best part of Ethnio is how much time my research team saves
recruiting participants. Prior to using Ethnio, our team would spend
days trying to track down and screen people for user testing. With
Ethnio, I\'m able to target specific types of users and contact
respondents almost instantly! Such a game changer not only in saving
tons of time, but its enabled my team to advocate more the value of UX
research to stakeholders. Now stakeholders are beginning to understand
UX from our perspective." - [Verified
Reviewer](https://www.g2crowd.com/products/ethnio/reviews/ethnio-review-753854)

"Ethnio lets us intercept and recruit real users doing real activities
on our website and app, in a way that feels natural to them, and
well-integrated to our brand and visuals. I cannot stress enough how
much of a difference it makes to have this quality of participants over
traditional recruitment methods, like panels and e-mail. It is also very
easy to integrate the user and session information to minimize the
number of questions we need to screen participants. E.g. phone OS,
number of purchases, which we could then use to only schedule android
participants with little experience in buying goods with us." -
[Guillermo
E.](https://www.g2.com/products/ethnio/reviews/ethnio-review-3171787)

#### What people don't love about it:

"I HATE how unreliable it is. I feel like there\'s always bugs.
Additionally, there\'s many small, hidden settings that are critical to
set correctly in order to have the screener work appropriately." -
[Verified
Reviewer](https://www.g2.com/products/ethnio/reviews/ethnio-review-3721106)

"I wish it was easier to add people that we recruited outside of Ethnio.
For example, from time to time, we use different recruiting services to
find people who are outside of my company\'s customer base. It\'s a
little tricky to add them. Additionally, there is a learning curve, and
I\'m still having the most trouble, admittedly, with the Pool feature
(which helps you keep track of participants and potential participants).
It\'s still more confusing than I would like it to be, considering it\'s
supposed to make it easy for me to keep track of people who responded to
my emails or screeners, and people who participated in research." -
[Verified
Reviewer](https://www.g2crowd.com/products/ethnio/reviews/ethnio-review-741542)

#### [Pricing](https://ethn.io/pricing)

\$79 per month (monthly)/ \$66 per month (annually): 5 screeners, 500
responses, 1 team member, 100k pageviews a month, self-service support

\$179 a month (monthly)/ \$149 a month (annually): unlimited screeners,
1000 responses, 3 team members, 500k pageviews a month, email support

\$349 a month (monthly)/ \$289 per month (annually): unlimited
screeners, 2000 responses, 5 team members, 1m pageviews a month,
variables, targeting, email support

Enterprise Tier

#### Best for:

People that get a lot of their research from their existing users and
want to conduct more research directly on their website or app.

‚Äç

## Dedicated Scheduling Tools/ Video Conferencing Tools

### Dedicated Scheduling Tools

If you're going to be scheduling your research sessions yourself, you'll
most likely want a calendar tool to keep yourself organized. These tools
offer an alternative to emailing back and forth with your participants
trying to pick a time that works for everyone.

### [Calendly](https://calendly.com/)

#### How it works:

Calendly integrates with your Google, iCloud, Outlook, or Office 365
calendar to help you schedule meetings without the back and forth
emails. You just set your available times within Calendly, send the link
to your Calendly calendar, and the person you want to schedule a meeting
with can choose a time that is right for them. A calendar event will be
created automatically and you can edit it within your calendar itself.
In our [State of User Research
Report](https://www.userinterviews.com/blog/the-state-of-user-research-report-2020),
we found that 26% of respondents used Calendly to schedule research
participants from their own customer base and 14% use it to schedule
participants from outside their user base.

#### What people love about it:

"Calendly is like having a personal virtual assistant and registration
desk and email follow-ups all in one. Easy to set it up and use it to
coordinate calendars, signups, payments, integrations, etc. It connects
and synchronizes across my multiple calendars and it allows me to avoid
double bookings etc. In addition, I\'m using it for bookings, scheduling
appointments, organizing webinars, coordinating my volunteering work, my
team meetings, virtual networking, etc. I love the flexibility to set up
my sign up forms and integrate seamlessly with Zoom and other video
platforms. I also use features such as text reminders, email follow-ups,
etc." - [Svetlana
D](https://www.g2.com/products/calendly/reviews/calendly-review-4253844%20target=).

"I love how Calendly is super easy to use. You can quickly create an
account, connect it to your calendar, and then update your meeting
settings. On the free account, you can\'t create multiple \"events\" for
people to schedule. It\'s just one. That was honestly fine for my use
case because I wanted customers to schedule a standard 30-minute meeting
with me. I like how people can quickly see the days available and select
a time. Very simple for them." - [Tyson
M.](https://www.g2.com/products/calendly/reviews/calendly-review-4245498)

#### What people don't love about it:

"I would like to be able to accept or decline some of the things that
get scheduled or create an expiring link. The use case for this would be
when your calendly link is given out by mistake you could decline and
for the expiring link, it would be nice to give a time frame in which
they could use the link for certain events.

Another thing I think would be helpful is if you could transfer events
to another person in your organization more seamlessly or cancel events
on your Google Calendar if someone else takes it without it notifying
the customer that it canceled the event." - [Whitney
B.](https://www.g2.com/products/calendly/reviews/calendly-review-4199212)

"I\'ve had some times where it didn\'t sync up well with my Outlook
calendar\... so I had to reset the program. Also, integrating it with
exchange probably takes 10x as long as doing it with Google Calendar or
something similar. Updates to Exchange may throw it off as well, and
that makes me consider using Microsoft\'s competitive product. Some
customers seem to be confused by the timezone if we\'re not aligned. For
the purposes of not totally trusting the tool, I do ask for people to
confirm their time via email or message." - [Reid
B.](https://www.g2.com/products/calendly/reviews/calendly-review-478970)

#### [Pricing:](https://calendly.com/pages/pricing)

Free: Calendar integrations, unlimited events, 1 event type,
personalized Calendly page for scheduling

\$10 a month (monthly)/ \$8 a month (annually): Calendar integrations,
unlimited events, unlimited event types, personalized Calendly page for
scheduling, remove Calendly branding, group events, automatically add
links to events, Zoom/GoToMeeting/Salesforce integrations

\$15 a month (monthly)/ \$12 a month (annually): Calendar integrations,
unlimited events, unlimited event types, personalized Calendly page for
scheduling, invitee redirect, remove Calendly branding, group events,
automatically add links to events,
Zoom/GoToMeeting/Salesforce/Stripe/PayPal/Google Analytics integrations

#### Best for:

People who need a simple and free scheduling tool that integrates with
their existing calendar and use Google, iCloud, Office 365, or Outlook
calendars.

### [Doodle](https://doodle.com/en/)

#### How it works:

Doodle allows users to find multiple available times to meet. You send
someone your Doodle link with your availability and they can mark time
slots as "yes", "no", or "if-need-be". Invitees can then select times
that work for them and the owner of the event can choose a time that
works for everyone. Doodle works best when trying to find a time to meet
with more than one other person. So if you're a researcher who
constantly schedules focus groups, interviews with more than one
participant, or stakeholder meetings with people from multiple
organizations, Doodle is a good choice.

#### What people love about it:

"I\'m still blown away by this software and so happy that I discovered
it. My biggest headache when scheduling meetings, lunches, dinners, etc.
is everyone\'s super busy schedule. With Doodle, all I have to do is
send out date and time options and get everyone\'s availability. I love
that it\'s a visual chart, so that I can easily see which date/time has
the most people available, and then boom we have a meeting scheduled. No
more, \"Ok, Jan can make it Tuesday what about Thursday?\" then another
\"Mike can\'t make it at 8:00am what about 7pm?\" I just send out a
Doodle calendar and I\'m done!" - [Lauren
L.](https://www.capterra.com/p/142620/Doodle/)

"The free version of this software is all you need. As a project manager
that is constantly trying to schedule meetings with large teams this app
cuts the need for constant email chains. I throw my dates and times,
then pick the day/time that has the most votes easy. Gone are the days
of endless emails and still not getting a good day." - [Greg
C.](https://www.capterra.com/p/142620/Doodle/)

#### What people don't love about it:

"I dislike that it takes a long time to make polls, especially if I have
many options available and open. It takes time to make each individual
time slot, so I hope they implement a system to automatically add
multiple time slots at once." -[Kimberly
C.](https://www.g2crowd.com/products/doodle/reviews/doodle-review-1188905)

"Doodle works great, but I wish it had a notification option for people
who haven\'t filled it out yet. Like, I should be able to send out a
notification if I plunk in some emails or something like that. I don\'t
have a definitive plan, but chasing people down to answer a Doodle poll
is one of the downfalls of Doodle itself." -[Maggie
B.](https://www.g2crowd.com/products/doodle/reviews/doodle-review-1158598)

#### [Pricing:](https://doodle.com/premium)

Free: Connect your calendar, share a link with your availability,
ad-supported

\$4.49 per month: 1 user, connect your calendar, share a link with your
availability, ad-free, one user, ask participants for additional
information, see who hasn't responded, export your results, Zapier
integration

\$5.99 per month: 1 user, connect your calendar, share a link with your
availability, ad-free, one user, ask participants for additional
information, see who hasn't responded, export your results, Zapier
integration, custom logo and branding, custom URL.

\$30 per month: 5 users, connect your calendar, share a link with your
availability, ad-free, one user, ask participants for additional
information, see who hasn't responded, export your results, Zapier
integration, custom logo and branding, custom URL, Slack integration.

#### Best for:

People who regularly need to coordinate meeting times with more than one
other person.

### [YouCanBookMe](https://youcanbook.me/)

#### How it works:

YouCanBookMe is very similar to Calendly, but with more robust features
for large teams. This includes the ability to sync multiple team
members' calendars from different places. For example, if you have one
person that prefers Google Calendar and another that prefers Outlook,
you can sync up both their calendars with YouCanBookMe. This makes it
easy to get that one guy who is still really attached to his Yahoo
calendar on the meeting. YouCanBookMe also offers customization features
for your booking pages, which you can use to keep everything on-brand.

#### What people love about it:

"Love the layout and design with this application. Nice modern and sleek
templates. I am able to create a schedule, customize colors and layout
design, and then share a link out with others to be able to book times
with me. There are some settings customization options that help. For
me, I used YouCanBookMe so that teachers can schedule meeting times with
me without the need to go back and forth through email. Love that it
syncs to Google Calendar that way I can stay on top of everything via my
mobile phone." -[Nick
A.](https://www.capterra.com/p/163194/YouCanBookMe/)

"What is not to love about youcanbookme! In fact, I have recommended
this software to fellow colleagues who are now using it. I was able to
create appointment slots that carry over several months. I use the link
provided in my email signatures and it allows everyone from upper
management to my volunteers to be able to book an appointment or meeting
with me. This software saves time and allows for better accountability!"
-[Joe L.](https://www.capterra.com/p/163194/YouCanBookMe/)

#### What people don't love about it:

"I like to be able to pick up the phone and call someone, but they only
provide email support. (They are based in UK.) They do a great job of
responding by email though, and provide helpful screenshots to guide
you." - [Michael Lee
M.](https://www.g2crowd.com/products/youcanbook-me/reviews/youcanbook-me-review-827769)

"The admin interface is a bit overwhelming and required some getting
used to. Although the services team walked us through most of the
set-up, there are lots of options and a lot of work can go into setting
up your system effectively." -[Jessica
M.](https://www.g2crowd.com/products/youcanbook-me/reviews/youcanbook-me-review-568975)

#### [Pricing](https://youcanbook.me/pricing/):

Free: basic functionality

\$10 per calendar per month/ \$108 per calendar per year: basic
functionality, remove YouCanBookMe's branding, reminders, custom booking
pages, unlimited booking fields, priority email support.

#### Best for:

People who want to coordinate calendars with team members who use
different calendars.

‚Äç

### Video Conferencing Tools

If you're conducting interviews of any kind, chances are you'll want to
catch the whole thing on video. Many people use things like Google
Hangouts, Google Meet, or Skype to conduct basic one on one video
interviews. If you're looking to upgrade your video conferencing, these
tools all offer something a little more advanced that can help you make
video interviews even easier for you and your participants.

### [Zoom](https://zoom.us/)

#### How it works:

Zoom allows up to 100 people join a video conference hosted in a
personal "room". So if you regularly conduct focus groups or large
shareholder meetings, Zoom may be a great tool for you. Zoom also
supports screen sharing, chat, recording, calendar integrations, and
transcriptions. We use it every single day for our remote watercooler
chats and (mostly) love it. More importantly, we use it for our Research
@ UI efforts and it (almost) never lets us down. Researchers seem to
agree, 48% of respondents in our [State of User Research
Report](https://www.userinterviews.com/blog/the-state-of-user-research-report-2020)
use it for their research. It is important to keep in mind that the
people you're chatting with will need to download the Zoom client ahead
of time to video chat.

#### What people love about it:

"Zoom has a clean user interface and generally works very well. I like
how easy it is to switch between camera modes or presenting your screen
or a specific program or documents (or your view of your iPhone!). No
unnecessary bells and whistles - just a sleek, minimal web conferencing
tool." - [Megan
T.](https://www.g2crowd.com/products/zoom/reviews/zoom-review-1207892)

"It makes video calling with large groups super easy, allows for video
call record, easy invite with a link to call, scheduling calls. I use
the Desktop app most the time, but the mobile app has been very handy
for calls on the go. I\'ve never used a video conferencing app that can
support so many callers in one session, makes for a pretty magical
experience to bring your whole team together from literally across the
world." - [Todd
B.](https://www.capterra.com/p/157062/Zoom-Video-Webinar/)

#### What people don't love about it:

"While conferencing via a browser is possible, when a first time user
(typically a participant) clicks on the meeting link, the site
automatically attempts to download a widget for local installation. It
would be better to provide up front the choice between browser vs app.
This is particularly an issue for users on a low bandwidth connection,
and first time non-tech users." - [Narayanan
P.](https://www.g2crowd.com/products/zoom/reviews/zoom-review-1176886)

"Zoom pulls a lot of bandwidth, particularly when sharing screen, so if
you are trying to run too many programs at once it will kick you out and
restart. This is usually fine for a team call, but can be embarrassing
during a client meeting." - [Ashlee
B.](https://www.capterra.com/p/157062/Zoom-Video-Webinar/)

#### [Pricing:](https://zoom.us/pricing)

Free: up to 100 participants in a meeting, 40 minute limit on group
meetings, unlimited number of meetings

\$14.99 a month per host: up to 100 participants in a meeting, no time
limit, unlimited number of meetings, admin feature controls, custom
personal meeting ID

\$19.99 a month per host (min 10 hosts): up to 100 participants in a
meeting, no time limit, unlimited number of meetings, vanity URL, SSO,
custom emails, company branding

\$19.99 a month per host (min 100 hosts): up to 200 participants in a
meeting, no time limit, unlimited number of meetings, vanity URL, SSO,
custom emails, company branding, unlimited cloud storage, dedicated
customer service manager

#### Best for:

People who regularly host video calls with more than two people.

### [Google Meet](https://apps.google.com/meet/)

#### How it works:

Google Meet was the second most popular video conferencing tool among
researchers in our [State of User Research
Report](https://www.userinterviews.com/blog/the-state-of-user-research-report-2020).
25% of people who do research used it for their video conferencing
sessions. It's convenient for people who use their Google Calendar a
lot, since it\'s natively integrated with Google apps.

#### What people love about it:

"I really love how Google Hangouts Meet very easily goes with all my
google apps. Especially since I use gmail and GCalendar on a daily
basis. It really helps that I can simply pop a chat and call without the
need to download anything else (which means I can use it on any unit
without much setup!). Its GCal integration is superb at keeping my focus
on only the call, and not need to think about what to download or where
the link is." - [Daniel Kent
F.](https://www.g2.com/products/google-hangouts-meet/reviews/google-hangouts-meet-review-4259933)

"It makes meeting easier. Especially when it comes to vendor partners
that are out of state, it makes it easy to connect face-to-face instead
of on a call. Additionally audio is sooooo much crisper. I don\'t have
the issues I typically do on phone calls saying \"Hey, I missed that.
Can you repeat yourself?\" over and over and over again." - [Jason
N](https://www.capterra.com/p/176572/Google-Hangouts/reviews/1860631/).

#### What people don't love about it:

"Google\'s messaging and meeting platform is full of confusion. The fact
that I started out thinking I was writing a review for Google Hangouts
and then I ended up on the Google Meet review page is a good summary of
this bungled world of messaging. Google is not a reliable company when
it comes to communication. They have gone back and forth on Hangouts,
Meet, Messenger, Wave, Plus, Duo, Allo\... you name it, they have it,
and nothing has really lasted forever. Google Meet works for now, but
who knows where it will be in a year!" - [Nadir
S](https://www.capterra.com/p/176572/Google-Hangouts/reviews/2243434/).

"I don\'t like that in the invite you have to choose the Google meet
button. It doesn\'t automatically have a screen share link. You have to
initiate it when setting up the invite. I had trouble at first
customizing my day/times for repetitive meetings. I wish this feature
was separated out and more defined to the user. I wish there was an
option for the chat to be sent to you after the meeting so you don\'t
lose the conversation altogether. I don\'t like that there doesn\'t seem
to be a way to sync your phone if you call in by phone and then, enter
the google meet by email. I wish this was a smoother process. At the
present time, I\'ll hang up once in the google meet and have the session
dial me back in. Otherwise, it is confusing to see a coworker\'s name in
the google meet and a no-name phone number." - [Kathryn
W.](https://www.g2.com/products/google-hangouts-meet/reviews/google-hangouts-meet-review-4300903)

#### [Pricing](https://apps.google.com/meet/pricing/):

Free: Unlimited meetings up to 1 hour long, 100 participants, self-serve
support

\$10 per user per month: Unlimited meetings up to 300 hours long, 150
participants, 24/7 chat support, part of G Suite Essentials, so it
includes Docs, Calendar, Drive, etc.

\$20 per user per month: Unlimited meetings up to 300 hours long, 250
participants, 24/7 chat support, part of G Suite Enterprise Essentials,
so it includes Docs, Calendar, Drive, etc.

#### Best for:

People who use primarily Google apps and are looking for a low-cost
solution.

### [Skype](https://www.skype.com/en)

#### How it works:

Skype is one of the most common video conferencing services around.
Researchers seem to like it too, and 20% of our respondents in the
[State of User Research
Report](https://www.userinterviews.com/blog/the-state-of-user-research-report-2020)
used it for their research. It has a robust phone calling feature set,
which allows users to call from a Skype number and place calls around
the world. It's also owned by Microsoft, and a part of Microsoft teams.
If your company is on Microsoft teams, Skype may be the most convenient
option for you.

#### What people love about it:

"I love that I can use Skype across all of my devices. Unlike Facetimme,
it\'s not limited to an Iphone or Android. They also make it easy to use
at work and for business purposes. It\'s pretty cool to be able to
participate in business meetings around the country without even having
to physically be there." - [Anna
P.](https://www.g2.com/products/skype/reviews/skype-review-3530774)

"Skype has been able to integrate some great features into its platform
(screen sharing, call history, missed call log, etc). The user interface
is also appealing and easy to navigate to find the features you need. It
is also sometimes helpful to be able to use Skype to make a regular
call, and add them to a conference call" - [Gary
H.](https://www.g2.com/products/skype/reviews/skype-review-707080)

#### What people don't love about it:

"I dont like that in Skype when you do calls the background noise is not
removed and everything can be heard from the receiving call. In Mobile
the chat sometimes stays stuck in my Iphone X, its a glitch that really
hurts the mobile experience. Another bad experience would be with the
international call rates, the rates vary throughout different countries,
like I mentioned I need to make calls for marketing research purposes
and the different rates affect my experience, the latest done was on
Peru and Chile, this impacted the budget we had established." - [Oscar
Leonardo
R.](https://www.g2.com/products/skype/reviews/skype-review-3550261)

"The video quality is mediocre at best. Skype used to be the go to
program for video chatting and video conferencing but has seemed to lag
behind in the last few years. Now to be fair, this can be an issue
related to the network within your company but overall it is not my
first choice." - [Verified
User](https://www.g2.com/products/skype/reviews/skype-review-3001128)

#### Pricing:

Skype is free for personal use, but there are many different pricing
options depending on what you use Skype for.

[Skype for phone
pricing](https://support.skype.com/en/faq/FA331/what-are-the-different-types-of-skype-subscriptions-and-pay-as-you-go-options)

[Microsoft teams
pricing](https://www.microsoft.com/en-us/microsoft-365/microsoft-teams/compare-microsoft-teams-options)

#### Best for:

People who use Microsoft products or Microsoft teams for work.

### [Blue Jeans](https://www.bluejeans.com/)

#### How it works:

BlueJeans is another option for people who want to conduct their video
interviews entirely in their browser. BlueJeans offers the ability to
join a meeting by clicking on a link, and you can integrate directly
with your calendar apps so you can add BlueJeans meetings directly to
your events. It allows you to share your screen with other meeting
members and record and store your meetings in the cloud.

#### What people love about it:

"The quality if the call, meaning both audio and video calls are
excellent. Particularly the video is crisp and fine quality compared to
other video conferencing applications. Bluejeans is compatible with most
AV equipment in our organisation and has a stable platform to support
both audio and video meetings. The customer service team is great and a
live assistance when needed the most is an advantage for our
organisation where help is just a click away when needed." -[Selvin
J.](https://www.g2crowd.com/products/bluejeans/reviews/bluejeans-review-894264)

#### What people don't love about it:

"The meeting can\'t be started unless the organizer joins. At times this
becomes a constraint and wastes a lot of time of many people in case
organizer gets late due to some reason. Also, if my headphones are
already connected, a lot of times I have to unplug and plug them again
to make them work with Blue Jeans." -[Tapan
J.](https://www.capterra.com/p/122054/BlueJeans-Video-Communications/)

#### [Pricing](https://store.bluejeans.com/):

30 Day Free Trial

\$12.49 per month per host (monthly), \$9.99 per month per host
(annually): meet with up to 50 participants, unlimited 1:1 meetings,
unlimited meeting time, dial-in number

\$17.49 per month per host (monthly), \$13.99 per month per host
(annually): meet with up to 75 participants, unlimited meetings, dial-in
number, 25 hours of recording per host, BlueJeans Command Center
Analytics

Enterprise Tier

#### Best for:

Teams who need to host large 10+ people meetings regularly and record
their meetings.

### [GoToMeeting](https://www.gotomeeting.com/)

#### How it works:

GoToMeeting allows you to schedule meetings, record calls, share your
screen, and get transcripts of your meeting's audio. For people who
prefer in-browser conference calling, GoToMeeting is a favorite. It has
all the features of a downloadable software like Zoom without you or
your participants needing to download anything.

#### What people love about it:

"I\'ve been using GoToMeeting for at least a decade and it is still the
gold standard for web conferencing for companies of all sizes. Our
entire organization (sales, marketing, success, and support) all have
licenses for scheduling screen shares and web conferences with leads and
customers. You can share your screen, allow another person to share
their screen, and even take control of another user\'s screen for
troubleshooting issues, or training purposes. It is easy to use for
those setting up and those connecting to a web conference. It has a
number of wonderful integrations - the most useful being the Google
Calendar plug in - which enables you to easily schedule GoToMeetings
directly from a calendar event. You can also record sessions for replay
later (helpful for training or demos)." - [Michael
J.](https://www.capterra.com/p/163332/GoToMeeting/)

#### What people don't love about it:

"It is good to be mindful that your computer\'s updates can conflict
with GoToMeeting\'s function. When my computer conducted certain
updates, the volume on GoToMeeting would work for a minute or two during
the beginning of the session and then it would stop working. So, if you
incur an issue with GoToMeeting, keep in mind it could be something
external to the actual software. It also takes a sequence of steps to be
able to show attendees a recording during your session\--the audio
settings must be changed to allow for audio to be heard from the
recording rather from your microphone." [-Paige
E.](https://www.capterra.com/p/163332/GoToMeeting/)

"There is no ability to lock individual meetings. If we are scheduled
back to back, and we are not using one of our unique meetings (which
sometimes has to be the case) then there is a risk that someone hops
into the meeting early and interferes with our current call. Also, the
tool is slightly expensive for what you get." - [Perry
F.](https://www.capterra.com/p/163332/GoToMeeting/)

#### [Pricing](https://www.gotomeeting.com/meeting/pricing):

Free 14 day Trial

\$14 a month (monthly)/ \$12 a month (annually): Unlimited meetings,
dial in line, no meeting time limits, meeting lock.

\$19 a month (monthly)/ \$16 a month (annually): Unlimited meetings,
dial in line, no meeting time limits, meeting lock, integrations with
Slack, Office 365, Google Calendar, and Salesforce, transcription,
note-taking within GoToMeeting.

Enterprise Tier

**Best for:**

People who want an in-browser conference calling software. GoToMeeting
has extra features like transcription and in-app note taking that make
it a good choice for researchers in particular.

### [Whereby](https://whereby.com/)

#### How it works:

Whereby is a lightweight, in-browser solution for video conferencing. It
has simple meeting links that are unique to you and easy to share with
others. It offers custom branded rooms for professional accounts, making
it a good solution for teams that want something that feels custom.

#### What people love about it:

"I love how my clients do not need to download any pesky software, the
meeting room is instant meaning - you do not have to let people in. I
can\'t tell you how tedious this can be if you are the meeting host and
in the middle of the meeting to only realise there is a queue of
latecomers.

It is really nice that they simply click the link and are instantly in
the meeting room. It\'s fast, it\'s easy and I swear by whereby. I have
tried Zoom, google meet/hangouts as well as go to meeting in the past.
My businesses serves more than 350 clients hosting video coaching
sessions and it\'s the backbone of our business and we couldn\'t do it
without whereby." - [Nadia
B.](https://www.g2.com/products/whereby/reviews/whereby-review-4283090)

"I have had numerous issues with my research participants dropping off,
not being able to connect or getting frustrated because of the video
call software. Not having to to explain in entire paragraphs to
participants how to connect is wonderful!" - [Iona
G.](https://www.capterra.com/p/182733/appear-in/reviews/1953183/)

#### What people don't love about it:

"The only thing I don\'t like is the fact I can not integrate with
Calendly." - [Isabel
S](https://www.capterra.com/p/182733/appear-in/reviews/1434837/).

"Sometimes the video becomes hugely delayed and sometimes the sound
drops out. It is not often thankfully." - [Justin
R.](https://www.g2.com/products/whereby/reviews/whereby-review-4267429)

#### [Pricing](https://whereby.com/information/pricing/):

Free: 1 user, 1 meeting room. Meetings with up to 4 participants,
calendar integrations, desktop and mobile access, calendar integrations.

\$9.99 a month: 1 user, 3 meeting rooms. Meetings with up to 12
participants, branded rooms, calendar integrations, desktop and mobile
access, calendar integrations.

\$59.99 a month: multiple users and admins, 10 meeting rooms. Meetings
with up to 50 participants, custom domain, meeting recordings, branded
rooms, calendar integrations, desktop and mobile access, calendar
integrations.

#### Best for:

Small to medium teams looking for a lightweight, in-browser video
solution.

‚Äç

## Note-Taking/Transcription Tools

### Note-Taking Tools

Every researcher needs a place to keep all of their notes together. Of
course tools like [Microsoft
Office](https://products.office.com/en-us/home), [Google
Drive](https://gsuite.google.com/products/sites/), or even good old pen
and paper are great for keeping notes, but these tools offer something a
little extra.

### [ConfirmKit](https://www.confirmkit.com/)

#### How it works:

ConfirmKit is a research ops platform that includes interview scripts
and field guides. It allows researchers to see responses from different
participants side by side, which makes it easier to see how different
users feel. ConfirmKit's biggest benefit for researchers is the built-in
interview guides. These allow you to standardize your interviews, keep
track of the questions you need to ask, and track all participants'
answers to specific questions in one place.

ConfirmKit is a fairly new tool and doesn't have reviews on G2Crowd or
Capterra at this time. We still thought it was cool enough to include in
this list, and it may be worth a try for people who conduct a lot of
interviews.

#### [Pricing](https://www.confirmkit.com/):

14 day free trial

\$49: 1 project, 3 users, 12 interviews, 25 observations

\$39 a month (monthly)/ \$29 a month (annually): unlimited projects,
users, interviews, and observations

#### Best for:

People who do a lot of interviews and need a tool to keep more
consistent notes.

### [Evernote](https://evernote.com/)

#### How it works:

Evernote is advanced note-taking. With Evernote you can clip things from
the web, search through handwritten notes, scan documents directly into
your notes, templates for easier note-taking, and integrations with apps
like Google Drive, Salesforce, and Slack. Evernote can be a good
resource for people who love creating handwritten notes or documents but
need somewhere to organize them all when it's time to gather insights.

#### What people love about it:

"It's a better way to save every piece of important data and find the
info I want faster. I can do a lot of good things like add links,
spreadsheet, attachments, and sound to our notes. Also, it's great that
my colleagues know what I'm doing and it works everywhere, no matter
what the conditions, with different documents." - [Donny
I.](https://www.g2crowd.com/products/evernote/reviews/evernote-review-623457)

"I love Evernote. I\'ve been a user since there were fewer than 10,000
of us so I feel like an early adopter. Evernote is my go to for keeping
track of pretty much everything I need. I use it for journaling, to do
lists, important meeting notes, organizing documents; I\'ve even used it
to store clip art (I don\'t recommend that as it takes up a lot of
space). Being a premium user, I\'ve enjoyed having access to Evernote
across all my devices. The sync is awesome. I can only remember having
two instances in more than 5 years of sync conflicts. The tagging
feature is awesome (essentially unlimited tags per note) and a powerful
search feature that makes organizing and finding notes a snap." - [Aaron
P.](https://www.g2crowd.com/products/evernote/reviews/evernote-review-885552)

#### What people don't love about it:

"I recently paid for a yearly subscription and regret doing so. I always
seem to be getting duplicate notes appearing after having updated them,
or get \'conflicting modification\' where my notes within a section are
duplicated but with some minor differences in one version (whatever you
edited). Trying to spot the difference and resolving this is far from
straight forward and I\'ve wasted a lot of time doing so. I\'ll be
transferring my notes over to google docs in future (much more reliable)
and won\'t renew my subscription." -[Neil
W.](https://www.trustpilot.com/review/www.evernote.com?languages=en&stars=1&stars=2&stars=3)

"Evernote runs on Basic (which is free) model and a Premium model. The
free version inevitably comes with its limitations like - Monthly upload
limit is extremely less especially considering the fact that, it has so
many features to save your data. Where it provides so many features, it
sets itself back with the space limitation which is minimal. The paid
version (Premium), however is pretty cheap, but feasible only if you
really are a heavy note-making user." [Aanchal
J.](https://www.capterra.com/p/154969/Evernote-Business/)

#### [Pricing:](https://evernote.com/compare-plans)

Free: note-taking, PDF attachment, web clipping, searchable notes,
notebook sharing.

\$7.99 per month: note-taking, PDF attachments and annotation, web
clipping, searchable notes, notebook sharing, email forwarding, version
history, integrations with Google Drive, email providers, and Slack.

\$14.99 per user per month: team collaboration, note-taking, PDF
attachments and annotation, web clipping, searchable notes, notebook
sharing, email forwarding, version history, integrations with Google
Drive, email providers, Slack, and Salesforce.

#### Best for:

People who need a place to keep their notes and want to enrich them with
handwritten pieces or web clippings.

### [Pear Note](http://www.usefulfruit.com/pearnote/)

#### How it works:

If you're a Mac user, Pear Note is a great choice for taking notes
during research sessions. Pear Note records audio and video from your
computer, as well as your actions so you can see exactly when you took
each note. This makes it easy to get context for notes taken during a
session. For researchers, knowing exactly when you took certain notes
can be invaluable information, especially after a long day of
interviews. When you can't remember who said what when and why, Pear
Note can be a good source of truth.

#### What people love about it:

"A very well thought out product - it works a treat. The only minor
quibble I have is that when you click on text to hear what was said at
that time, you get the tap-tap of the keyboard keys that went with the
notes you were typing as they were speaking. A minor quibble tho - this
is excellent software."
-[Macash](https://download.cnet.com/Pear-Note/3000-2075_4-205406.html)

"Pear Note is my go to note taking app. My chief complaint is that the
developers are slow to incorporate updates. What I like best is the
ability to upload an outline prior to meeting. Then I can mark each
speaker then immediately return during editing."
-[domolar](https://itunes.apple.com/us/app/pear-note/id460167120?mt=8)

#### What people don't love about it:

"I\'m a little sore about this. The developer seems to think that no
serious work needs to be done on this app since it was completed
somewhere around iOS 4. It\'s a niche app, so it\'s good enough, I
guess. I feel like I didn\'t get the value I was expecting."
-[gaelicWizard](https://itunes.apple.com/us/app/pear-note/id460167120?mt=8)

#### [Pricing:](https://www.usefulfruit.com/store/)

\$39.99 one time fee: 1 user

\$54.99 one time fee: 1+ users

#### Best for:

Mac users who need visual context for their notes.

‚Äç

### Transcription Tools

Transcription can help you keep track of what happens during your
research sessions. In our [State of User Research
Report](https://www.userinterviews.com/blog/the-state-of-user-research-report-2020),
we found that 49% of people who do research use transcription to take
notes in their sessions. While transcription used to be an expensive
add-on, AI-driven tools have made the process more affordable. We'll
cover a number of different tools you can use to transcribe your
research interviews.

### [Rev](https://www.rev.com/)

#### How it works:

Rev is a transcription service that uses real live humans to create
transcripts of your audio and video files. All you have to do is submit
your files on Rev's online portal and they will deliver your transcript
within 12 hours. Rev can also produce captions and foreign language
subtitles. Rev seems to deliver pretty accurate transcripts for people
who need transcriptions done for complicated audio recordings or
recordings with multiple speakers.

#### What people love about it:

"I used Rev.com to transcribe two focus groups. I was very happy with
the turnaround time and quality of the transcription. Using Rev.com
saved me days of work." - [Tammy
H.](https://www.trustpilot.com/review/www.rev.com)

"Very accurate and the best turnaround time. I \'upgraded\' for the
(free) rush service and it came even quicker than that! We\'ve used them
about 8 times now and never had anything other than great results." -
[David F.](https://www.trustpilot.com/review/www.rev.com)

#### What people don't love about it:

"As a professional journalist, I use Rev frequently. It's reliably fast,
but the quality is uneven, and the customer service can be terrible. If
there's a problem with your transcript, there's no way to get it fixed
that doesn't involve waiting months and sending multiple emails." - [M.
Blake](https://www.trustpilot.com/review/www.rev.com)

#### [Pricing](https://www.rev.com/services):

\$0.25 per minute of machine-generated transcriptions.

\$1.25 per minute of human-generated transcriptions or video captions.

\$3-7 per minute of foreign language subtitles

\$20 per user: live captions for Zoom meetings

#### Best for:

People who want high quality transcripts and have the budget to pay for
Rev's service.

### [Reduct](https://reduct.video/)

#### How it works:

Reduct is a transcription tool built specifically for research. It uses
human-created transcripts and allows researchers to edit, search, and
tag videos from research sessions. It stores a library of the videos you
upload and allows you to easily create highlight reels from your
sessions. Reduct is a great tool for researchers who need transcription
and repository solutions for their research projects. It's still an
early-stage company, so you'll have to chat with sales for pricing and a
lot of the features are still in beta.

#### What people love about it:

"A few months ago, we were introduced to Reduct.Video. It seemed too
good to be true! We now upload our videos to them, and they create the
transcripts. Their software allows us to view the transcript online,
highlight the relevant text, and it immediately creates a new video from
the highlighted text." - [Jim
T](https://heartofthecustomer.com/reduct-a-great-tool-for-sharing-your-customers-videos/).

#### What people don't love about it:

Since Reduct is so new, there aren't a lot of reviews out there! Some of
the potential cons could be that some of the features are still in beta,
and the pricing is not publicly available. But if Reduct sound like it
could work for you, they offer a demo so you can try it out!

#### [Pricing:](https://help.reduct.video/en/articles/2653204-what-is-reduct-s-pricing)

You have to [chat with Reduct's sales
team](https://help.reduct.video/en/articles/2653204-what-is-reduct-s-pricing)
to learn about pricing.

#### Best for:

Researchers who would benefit from a library of their videos and don't
mind chatting with Reduct's sales team to learn about pricing.

### [Otter.ai](https://otter.ai/)

#### How it works:

Otter.ai is an AI powered transcription software that allows you to
transcribe audio quickly and on a budget. The main thing that sets
Otter.ai apart from its competitors is its ability to create real-time
transcriptions that are searchable in minutes. There's a free version so
you can try it out with up to 600 minutes of transcription.

#### What people love about it:

"Otter has literally saved my rear on more than one occasion. As a
journalist, transcribing takes an insane amount of time, and Otter makes
my life that much easier by transcribing interviews not only quickly but
thoroughly. So many people in my company use it because the technology
is superior to us just taking notes. I love that it is user friendly and
I don\'t need some software for it, it\'s just there for me via the
web." - [Alexandra
R.](https://www.g2.com/products/otter-ai/reviews/otter-ai-review-4270468)

"Otter records and transcribes in real time at the same time. You
literally can see the transcription being written as you speak and are
recorded. There is not another platform that does this as Otter does.
It\'s high quality and dependable, too. I can share these recordings
with others by sending a link." - [Jan
S.](https://www.g2.com/products/otter-ai/reviews/otter-ai-review-3504749)

#### What people don't love about it:

"The voice recognition is a B-. It only sometimes realizes that a new
voice has started talking, and doesn\'t always recognize repeating
voices. But it is such an easy thing to manually fix, its a really minor
complaint." - [Kirk
W.](https://www.g2.com/products/otter-ai/reviews/otter-ai-review-4295279)

#### [Pricing:](https://otter.ai/pricing)

Free: up to 600 minutes of transcriptions, real-time transcription,
searchable and editable files.

\$8.33/\$9.99 per user per month: up to 6,000 minutes of transcriptions,
real-time transcription, searchable and editable files, import files,
custom vocabulary, bulk import and export.

\$20/\$30 per user per month: up to 6,000 minutes of transcriptions,
real-time transcription, searchable and editable files, import files,
custom vocabulary, bulk import and export, Zoom integration, time codes.

#### Best for:

People who don't have a lot of transcription to do each month and need a
free tool.

### [Trint](https://trint.com/)

#### How it works:

Trint is an audio and video transcription service that uses AI to
deliver transcripts that are searchable and editable. All you have to do
is upload the file into Trint's web-based software and wait a few
minutes for the AI to work its magic. You can also export the files into
a variety of file types. Trint seems to work best for audio that is
fairly isolated featuring only one speaker. It's powered by AI, so it's
not quite as accurate as a real live human might be, but it is much
cheaper.

#### What people love about it:

"It\'s an easy software to use even without experience in video editing
or transcription. Even when I logged in for the first time I found it
easy to navigate and do what I needed." - [Adam
B.](https://www.capterra.com/p/179896/Trint/reviews/2085041/)

"I used trint to help save time on a massive translation project I was
doing. The ability to go through multiple languages made it a dream and
saved me about 20 hours of work. There were minimal errors and overall a
pleasant interface" - [Ethan
L.](https://www.g2.com/products/trint/reviews/trint-review-3522575)

#### What people don't love about it:

"I really want this to work. As a journalist who does a lot of
interviews and features, reliable transcription software would transform
my productivity. I have given this a couple of tries and sadly it\'s not
great. I can see where they are going with it and really hope they can
improve the accuracy of the transcription. Far too many errors (many of
them completely off the wall) and far too much fixing required. It\'s
debatable as to whether it saves any time at all versus just
transcribing it myself as usual." - [James
H.](https://www.trustpilot.com/review/trint.com)

"The transcription is pretty good when you have a high quality audio,
but if you have audio quality that isn\'t perfect then the transcription
can be a bit rough." - [Stephanie
C.](https://www.g2.com/products/trint/reviews/trint-review-1525812)

#### [Pricing](https://app.trint.com/plans):

\$48 per month: 1 user, transcribe 84 files per year, access to Trint's
editor

\$60 per month: 1 user, unlimited day-to-day transcription, access to
Trint's editor

\$68 per month: 1 user, unlimited day-to-day transcription, share links
to transcripts, read-only versions, collaborative editing, access to
Trint's editor

\$68 per user per month: 2-10 users, unlimited day-to-day transcription,
share links to transcripts, read-only versions, collaborative editing,
shared workspaces, access to Trint's editor

Enterprise tier for 11+ users

#### Best for:

Teams that frequently need lots of transcriptions and don't mind doing a
few fixes themselves.

‚Äç

## Survey Tools

Whether you need [screener
surveys](https://www.userinterviews.com/ux-research-field-guide-chapter/screener-surveys)
to help you choose participants or your entire research study is based
around a survey, these tools will help you get the job done. Some of
these tools are geared towards enterprise level survey conducting, while
others can be used for smaller satisfaction surveys or even screeners
for your research participants.

### [Survey Monkey](https://www.surveymonkey.com/)

#### How it works:

SurveyMonkey is a powerful tool for creating research surveys. Their
free product allows you to create surveys and send them out to anyone
you want, but SurveyMonkey has some upgraded features that allow you to
recruit from their audience, collect NPS scores, and even collect and
manage job applications.

#### What people love about it:

"I like how easy it is to create surveys and send them out. I can fully
customize the questions to meet the needs of the data. I also like that
I can easily share the survey with my co-workers to make sure they are
satisfied before I share it with the clients. Is very easy for them to
access and I get the feedback very quickly. It\'s simple to navigate and
set up a survey, and it\'s highly accessible for participants." -[Katie
C.](https://www.g2crowd.com/products/surveymonkey/reviews/surveymonkey-review-1111880)

#### What people don't love about it:

"Survey Monkey limits the amounts of responses that the administrator
can view. Survey Monkey only allows upgrades with more features of
survey. Survey Monkey offers limited customer support with the basic
plan. Survey Monkey offers 10 questions per survey for the basic plan.
Survey Monkey offers limited data export for such files like .csv, .pdf,
.ppt, and .xls." -[Candace
E.](https://www.capterra.com/p/32728/SurveyMonkey/?sort_options=Lowest%20Rating)

#### [Pricing:](https://www.surveymonkey.com/pricing/?ut_source=megamenu)

Free: Create unlimited surveys with 10 questions each, view 100
responses, get responses via web, social, and email.

\$32 a month (annually): 1 user, create unlimited surveys with unlimited
questions and up to 5,000 responses per month, unlimited filters &
crosstabs, trended data, custom branding on surveys, skip logic,
question and answer piping, A/B testing, email support, accept payments.

\$99 a month (monthly): 1 user, create unlimited surveys with unlimited
questions and up to 1,000 responses per month, skip logic, custom
branding.

\$99 a month (annually): 1 user, create unlimited surveys with unlimited
questions and unlimited responses, unlimited filters & crosstabs,
trended data, custom branding on surveys, skip logic, question and
answer piping, A/B testing, phone and email support, accept payments,
advanced data exports, white label and multilingual surveys

\$25 per user per month (annually): 3+ users, create unlimited surveys
with unlimited questions and unlimited responses, unlimited filters &
crosstabs, trended data, custom branding on surveys, skip logic,
question and answer piping, A/B testing, phone and email support, accept
payments

\$75 per user per month (annually): 3+ users, create unlimited surveys
with unlimited questions and unlimited responses, unlimited filters &
crosstabs, trended data, custom branding on surveys, skip logic,
question and answer piping, A/B testing, phone and email support, accept
payments, advanced data exports, white label and multilingual surveys,
API access.

Enterprise Plans

#### Best for:

People who need shorter surveys or have the budget to pay for more
powerful surveys annually.

### [SurveyGizmo](https://www.surveygizmo.com/)

#### How it works:

SurveyGizmo works very similarly to SurveyMonkey, but they have more
robust enterprise-level plans at their core. SurveyGizmo offers tons of
different features at their top tiers for highly complicated surveys,
like email triggers and geo-targeting. They also offer branding and
customization at their free level, unlike SurveyMonkey.

#### What people love about it:

"SurveyGizmo\'s best feature is the user-interface and how it displays
statistics, using graphs to present clearly the outcome of the survey.
We\'re able to present at fairly high-level meetings with SurveyGizmo.
Presenting to senior staff who don\'t normally work with hard data is
always a challenge, but the various graphs and visuals really help us to
convey this. The sheer number of features and services SurveyGizmo
offers is incredible, although a lot of these you may never actually
use." - [Peter W.](https://www.capterra.com/p/72549/SurveyGizmo/)

#### What people don't love about it:

"Various functions are not obvious on how to make changes and things are
not labeled very clearly and it takes a lot of time to explore each of
the features and try to understand what they do" -[Stephanie
S.](https://www.g2crowd.com/products/surveygizmo/reviews/surveygizmo-review-607072)

#### [Pricing:](https://forms.surveygizmo.com/plans-pricing/)

Free: 3 surveys, unlimited questions, 100 responses, raw data export,
edit colors, fonts, and styles.

\$35 a month (monthly)/ \$25 a month (annually): Unlimited surveys,
questions, and responses. Email support, custom branding, limited answer
types, custom reports, limited project types, limited survey scripting
and publishing capabilities.

\$135 a month (monthly)/ \$85 a month (annually): Unlimited surveys,
questions, and responses. Email and phone support, custom branding,
limited answer types, custom reports, limited project types, limited
survey scripting and publishing capabilities.

\$240 a month (monthly)/ \$150 a month (annually): Unlimited surveys,
questions, and responses. Email support, custom branding, unlimited
answer types, custom reports, unlimited project types, unlimited survey
scripting and publishing capabilities.

SurveyGizmo also offers enterprise tiers for teams, these plans only
include one person on each account. To get an enterprise plan you can
[contact them here](https://www.surveygizmo.com/team-enterprise/).

#### Best for:

People who need a robust survey tool with enterprise level solutions.
People with the ability to pay annually will save a lot of money on this
tool.

### [Google Forms](https://www.google.com/forms/about/)

#### How it works:

Google Forms is a survey builder that's already integrated into your
Google Drive. So if you spend a lot of time on Docs or Sheets, this may
be perfect for you. You can collaborate with your co-workers just like
you would in the rest of the Google suite and create simple and easy to
use forms. Forms even includes advanced capabilities like skip logic and
customization. The best part? Google Forms is totally free.

#### What people love about it:

"The ease of use, the fact that it\'s all stored in one place, inside my
google account, I love that it\'s easy to share ownership and data
collected from Google forms with colleagues, it\'s also easy to share
data with respondents. This tool is amazing. Efficient and effective for
team collaboration and feedback collection. I love that one can
visualize the data in various forms once it\'s collected." - [Susan
N.](https://www.g2crowd.com/products/google-forms/reviews/google-forms-review-1204960)

#### What people don't love about it:

"Google Forms is very basic, and while it is user intuitive, it can also
be restrictive. There are no options to have flowchart forms, basing
future questions off already answered questions. That\'s why I would say
Google Forms is best for simple and straightforward surveys." - [Jacob
L.](https://www.g2crowd.com/products/google-forms/reviews/google-forms-review-707223)

#### Pricing:

Google Forms is free for personal accounts and, if your workplace is
already using the rest of the Google Suite, it is included in your
company's monthly fee.

#### Best for:

People who need a free solution with advanced capabilities.

### [Typeform](https://www.typeform.com/)

#### How it works:

Typeform is set apart from its competitors because of it's beautiful
interface. It lacks a few of the robust reporting capabilities and
question features of the more research-driven SurveyGizmo and
SurveyMonkey. It could be a good choice for researchers who want sleek
and easy to build surveys without a lot of complicated features.

#### What people love about it:

"We absolutely love Typeform for our business. We have created many lead
generating surveys and tools to help our users. We have even converted
our PDF applications into interactive typeforms so people can complete
applications on their mobile device.

Typeform is easy to use, the possibilities are endless, and it is fun
for users.

We like the ability to customize typeform for our business using our
business color scheme and logo. We also like that we can customize our
typeform link when sending to clients. It feels less like we are sending
them to a third party software and more like they are still on our
website." - [Candace I.](https://www.capterra.com/p/137289/Typeform/)

#### What people don't love about it:

"When you set up a quiz question it is nearly impossible to figure out
how to designate the correct answer. I looked in the Help section and
then watched 5 third party videos on YouTube. The answer is that you
click on the \"Calculator\" to add a calculation, which lets you pick
and answer." -[Erik
N.](https://www.g2crowd.com/products/typeform/reviews/typeform-review-313951)

"For me, typeform provides too much playful details and they stick on
the \"skip from one entry to the next\" approach. That means you fill
out one question and you have to click to skip to the next question. In
my opinion, this is not always the best way to provide online forms to
your folks. You have to click 10 times to fill out your name and your
address, hmm." - [Rene H.](https://www.capterra.com/p/137289/Typeform/)

#### [Pricing](https://www.typeform.com/pricing/):

Free: 3 surveys, 100 responses per month, 10 questions per survey,
metrics and reports

\$30/\$35 a month: Unlimited surveys and questions, 1,000 responses per
month, advanced question types, 3 logic jumps per survey, custom thank
you screen, calculator for quizzes and payments.

\$35/\$50 a month: Unlimited surveys and questions, 5,000 responses per
month, unlimited logic jumps, advanced question types, logic jumps,
custom thank you screen, invite other people to workspaces, import data
from hidden fields, Facebook pixel/Google tag manager.

\$59/\$70 a month: Unlimited surveys and questions, 10,000 responses per
month, unlimited logic jumps, advanced question types, logic jumps,
custom thank you screen, invite other people to workspaces, import data
from hidden fields, Facebook pixel/Google tag manager, remove Typeform
branding, priority support.

#### Best for:

People who want a sleek and modern looking short survey and don't have a
lot of money to spend.

### [Survicate](https://survicate.com/)

#### How it works:

Survicate is a great way to collect 1 question responses to surveys. It
can be embedded directly into your website to collect feedback from your
customers in-context. You can also use it to collect NPS scores. It may
not be ideal for researchers wanting to conduct detailed and in-depth
surveys, but is a great option for gathering quick feedback, especially
if you plan on using integrations with Intercom or another tool.

#### What people love about it:

"Survicate\'s simple and powerful tools and the ability to deliver these
surveys quickly to our users through their Intercom integration gave us
the ability to turn around professional qualitative and quantitative
measurement through surveys that looked native to Intercom. Engagement
is 10x that of surveys delivered through other channels, and in a matter
of hours we would gather thousands of responses to help our product and
UX teams make critical decisions." - [Michael
M.](https://www.g2.com/products/survicate/reviews/survicate-review-3906196)

"It\'s really quick and easy to get a new survey set up and customized.
The summaries are also excellent. It\'s wonderful that summaries can be
sent to different people in our organizations at different times: i.e.
that our customer service team gets alerted immediately, while other
departments receive a weekly summary. And the customer service is
top-notch. They\'re very involved with pro-active support, and respond
quickly to chats." - [Sarah
O.](https://www.g2.com/products/survicate/reviews/survicate-review-319234)

#### What people don't love about it:

"A few bugs here and there. We have trouble with the email notifications
not going out due to the thank you page \'failing\'. I have also noticed
that my survey data does not flow into Google Sheets as well as I would
hope." - [Verified
Reviewer](https://www.g2.com/products/survicate/reviews/survicate-review-3351814)

"Technical support can get a bit too slow when issues are too technical.
The documentation they have available is not the best in class." - [Raul
G.](https://www.g2.com/products/survicate/reviews/survicate-review-393566)

#### [Pricing:](https://survicate.com/pricing/)

Free: 100 responses a month, skip logic, Hubspot, Intercom, etc.
integrations, email embeddable surveys, 1 month data retention.

\$49/\$99 a month: 1,000 responses a month, skip logic, Hubspot,
Intercom, etc. integrations, email embeddable surveys, export to csv,
Google Sheets integration, answer piping, question redirect, 6 months of
data retention.

\$99/\$199 a month: 5,000 responses a month, skip logic, Hubspot,
Intercom, etc. integrations, email embeddable surveys, export to csv,
Google Sheets integration, answer piping, question redirect, Survicate
branding removed, automated recurring surveys, 2 years data retention.

\$249/\$499 a month: 25,000 responses a month, skip logic, Hubspot,
Intercom, etc. integrations, email embeddable surveys, export to csv,
Google Sheets integration, answer piping, question redirect, Survicate
branding removed, automated recurring surveys, premium integrations,
webhooks, 5 years data retention.

#### Best for:

People who want a quick embeddable survey and don't expect to have many
responses per month.

### [YesInsights](https://www.yesinsights.com/)

#### How it works:

YesInsights puts simple one-question surveys directly into your website
or email campaign. This allows users to quickly provide you feedback
where they are already interacting with your product. This allows you to
quickly gather qualitative data and learn more about why your users are
doing what they're doing.

#### What people love about it:

"I like the method that is used in this software to receive and collect
feedback through NPS surveys. It makes things easier since the customers
will be able to answer the surveys in a fast way. It\'s a software that
is amazing because of the facility to set up, you don\'t need to be a
professional in these stuff to use this software. Also, the analytics
are real." - [Skylar
M.](https://www.g2crowd.com/products/yesinsights/reviews/yesinsights-review-610764)

#### What people don't love about it:

"The price is high if you want unlimited surveys, but it will be worth
it. I think it is \$149 per month is because it has a lot of features
the other versions don\'t have." -[Lilian
A.](https://www.g2crowd.com/products/yesinsights/reviews/yesinsights-review-606974)

#### [Pricing:](https://www.yesinsights.com/#signup)

7 day free trial

\$20 a month: 1,000 responses per month, 5 surveys, YesInsights
branding, NPS surveys, website widget

\$79 a month: 5,000 responses per month, 10 surveys, no branding, NPS
surveys, website widget

\$149 a month: 25,000 responses per month, unlimited surveys, no
branding, NPS surveys, website widget

Enterprise Tier

#### Best for:

People who need to interact with users to answer quick questions or keep
their finger on the pulse of their website activity.

### [Google Surveys](https://marketingplatform.google.com/about/surveys/)

#### How it works:

Google Surveys is like Forms' older sibling. Though many think they look
the same, one is much older and wiser. Surveys allows users to create
complex surveys in a method very similar to creating a Google Form. The
fun happens afterwards, when Google gets you real answers from real
people in less than three days. Surveys even packages up your results in
easy to digest charts and graphs, so understanding results is a snap.

#### What people love about it:

"Using google surveys, it is really easy to design a new survey.
Everything is readily available from templates to designs, from contents
to publishing and sharing schemes. Each and survey can be designed as
per the way we want it to be. From choosing specific categories to
distributing it among specified group of workers , all of these is
easily sorted by google surveys." - [Shawn
W.](https://www.g2crowd.com/products/google-surveys/reviews/google-surveys-review-1050919)

#### What people don't love about it:

"I dislike the lack of visual/theme customization - I would like to
create more aesthetically-pleasing surveys and Google does not really
cut it in terms of cleanliness and being modern in appearance." -[Prem
N.](https://www.g2crowd.com/products/google-surveys/reviews/google-surveys-review-770631)

"It lacks some of the sophisticated features associated with Qualtrics,
SurveyMonkey, etc., but it\'s free! For a free product, it\'s fantastic
and accessible." -[Blake
B.](https://www.g2crowd.com/products/google-surveys/reviews)

#### [Pricing:](https://support.google.com/surveys/answer/2447244?hl=en)

Google Surveys works on a price per completed response, which can range
from 10 cents to \$1 per response. Check out their full chart
[here](https://support.google.com/surveys/answer/2447244?hl=en).

#### Best for:

People who are looking for a cheap way to create surveys and recruit
people to take them.

### [Survey Legend](https://www.surveylegend.com/)

#### How it works:

Survey Legend is a survey tool that enables researchers to create simple
surveys. It's best for researchers who want to create simple surveys and
want an easy-to-use interface to help them build their surveys. It has a
free version with unlimited questions, so if you want something that's a
step up from Google Forms and need lots of questions, Survey Legend may
be a good fit for you.

#### What people love about it:

"I was introduced to Survey Legend by a friend after having tried
without success quite a few similar products. I was quickly impressed by
the practical layout and the fact that every step was explained
thoroughly. What I like most about Survey Legend is that it doesn\'t
have a limit of questions - instead, you can include as many questions
as possible and design a personalized survey." - [Vasiliki
B.](https://www.capterra.com/p/156752/SurveyLegend/reviews/2125797/)

"I love the interface. It is very easy to navigate through the different
options and extremely easy to make a professional looking questionnaire.
It has all the potential features that one might need, all types of
questions, wide range of backgrounds and styles to choose from, and
other valuable and time sparing features (like analytics features and
automatic the making of graphs)" - [Elena
S.](https://www.g2.com/products/surveylegend/reviews/surveylegend-review-4207418)

#### What people don't love about it:

"Question types are limited and available questions are not customizable
as well. For example, I want to insert a prioritization question, but I
cannot do it with available tools. I have to compromise with my survey
and ask such questions in different ways. Also designing seperate
questions is also not available. For example, I have several likert-type
questions but I have only a carousel-type of a design for all of them. I
cannot see all the subquestions together in a table. Finally, I
couldn\'t upload all or a part of my questions at once. I had to write
them again." - [Emin √áetin
H.](https://www.capterra.com/p/156752/SurveyLegend/reviews/2087347/)

"SurveyLegend on portable devices sometimes appears to be crashy and
often freezes, so the application dedicated for Android should be more
polished and the projects may be quick developed by fixing issues and
adding new facilities. Moreover, it would be great if designers supplied
customers with more comprehensive model collection." - [Marcio
D.](https://www.g2.com/products/surveylegend/reviews/surveylegend-review-2900259)

#### [Pricing:](https://www.surveylegend.com/pricing/)

Free: 3 surveys, 6 pictures, no data export, 1 conditional logic, ads
and SurveyLegend watermark.

\$15 a month: 20 surveys, 30 pictures, data export for 1,000 responses,
10 conditional logic, ads and SurveyLegend watermark.

\$25 a month: Unlimited surveys and pictures, data export for 10,000
responses, unlimited conditional logic, SurveyLegend watermark.

\$65 a month: Unlimited surveys and pictures, data export for unlimited
responses, unlimited conditional logic, white label.

#### Best for:

People who need to create simple surveys longer than 10 questions and
need a free tool.

‚Äç

## Usability Testing Tools

[Usability testing
tools](https://www.userinterviews.com/blog/user-testing-tools) are great
for testing with prototypes or even refining fully baked ideas. You can
watch as your users interact with your website or prototype, via live
interviews that record both their screen and camera or via unmoderated
recorded tasks. These usability testing tools offer a lot of different
ways to figure out how your users are interacting with your prototypes
and live websites. ¬†

### [Lookback](https://lookback.io/)

#### How it works:

Lookback lets you see how your users are navigating your test in real
time or in recorded sessions. Lookback supports both moderated and
unmoderated sessions with your colleagues, time stamped notes, and even
highlight reels of your session. It also allows you to conduct tests on
desktop and mobile, which makes it easier for you to gather insights on
both platforms. Fun fact: we're partners. We offer [3 free participant
recruits](https://www.userinterviews.com/lp/user-interviews-lookback)
for Lookback customers new to User Interviews.

#### What people love about it:

"I really love Lookback. It\'s a great tool for conducting live, remote
usability tests. The options for watching users interact with your
website or app, while also doing a simultaneous video chat, are really
fantastic. It\'s also great that you can invite team members to observe
sessions." - [Max
G.](https://www.g2crowd.com/products/lookback/reviews/lookback-review-719446)

#### What people don't love about it:

"If users rotate the device, lookback stretches the screen and/or
records part of it. It doesn\'t record well where a user has tapped on
the screen. For unmoderated, users struggled with the splitting screen
or/and how to show again the tasks." -[Helio
C.](https://www.g2crowd.com/products/lookback/reviews/lookback-review-899475)

#### Pricing:

14-day free trial

\$59 per collaborator per month (monthly)/ \$49 per collaborator per
month (annually): Remote or in-person research tools, test with
prototypes on mobile or desktop, invite observers to watch in real-time,
create and share highlights

\$119 per collaborator per month (monthly)/ \$99 per collaborator per
month (annually): Remote or in-person research tools, test with
prototypes on mobile or desktop, invite observers to watch in real-time,
create and share highlights, export recordings and notes, priority chat
support, manage project permissions

Enterprise Tier

#### Best for:

People who want to conduct unmoderated sessions with video.

### [PingPong](https://hellopingpong.com/)

#### How it works:

PingPong focuses specifically on moderated remote user research studies.
PingPong will choose participants and schedule the sessions for you
based on your availability. They have their own secure video calling
platform for conducting your interviews, with automatic recording and
the option to invite your team members to view the interview live. You
can then analyze your videos, mark highlights, and view transcriptions.
PingPong also helps you manage the incentives, which are paid through
PayPal.

#### What people love about it:

"As a global company we consider user input the basis of everything we
do - however, before pingpong, we didn't have any options to access a
global pool of participants, without adding an administrative overhead.
Since we use pingpong, more of the teams are able to adopt the
human-centered approach and start practicing user research, as pingpong
makes it insanely easy to setup and schedule research projects, and
offers awesome functionality to conduct various types of sessions via
their video call tool. It honestly saved us researchers from going
crazy, allows the teams to learn and create valuable solutions and
allows the company to lower business risk - sounds too good to be true
but it is. üèìüôè‚ú®" - [Zs√≥fia
G](https://www.producthunt.com/posts/pingpong-2/reviews).

#### What people don't love about it:

"You cannot download your recordings at the moment (hello, vendor
lock-in) and we had quite a few no-shows from interview subjects."
-[Peter G](https://www.producthunt.com/posts/pingpong-2/reviews).

"Transcribing still needs a bit of work, it\'s hard to talk communicate
with your colleagues who could be spectating." -[Emily
H.](https://www.producthunt.com/posts/pingpong-2/reviews)

#### [Pricing:](https://hellopingpong.com/pricing/)

75 ‚Ç¨ per credit: 30 minute interview with someone from their instant
pool. A 60 minute interview is 1.5 credits. Their standard incentive is
included in this fee.

Enterprise Tier

#### Best for:

People who need immediate access to research participants in Europe and
only need to conduct remote testing.

### [UserTesting](https://www.usertesting.com/)

#### How it works:

UserTesting offers a robust set of tools to facilitate user research.
They can handle recruitment from their panel and management of
recruitment from your panel. Researchers can build studies across
platforms based on existing templates or from scratch, which can be
useful for people who need some guidance building their research
initiatives. They boast same-day turnaround on recruitment for
unmoderated studies, which can make them a good option for those looking
to do quick usability testing.

#### What people love about it:

"It's amazing to me how usertesting.com is able to find very specific
user groups, based on a set of screening questions. I\'ve used it for
several enterprise and b2b websites with very unique users, and have
been able to get results within a matter of hours or a day at the
longest." - [Gabe
S.](https://www.g2crowd.com/products/usertesting/reviews/usertesting-review-1238611)

"As one of two full-time researchers on the UX team at my organization,
I like that I can step my design peers (and others) through the really
simple platform, and with some guidance on best practices get them
experimenting and testing out their designs quickly. It\'s been really
helpful to offer this tool as a means to get answers in an Agile
setting." - [Jennifer
B.](https://www.g2crowd.com/products/usertesting/reviews/usertesting-review-830607)

#### What people don't love about it:

"Leave yourself a lot of time for contract negotiations, and getting it
set up with your purchasing department (if you work for a large
organization). Also - determine what your governance of the product will
look like. If you only have 1 seat, only that one person will be able to
launch tests for everyone added to the account - so make sure that
person is reliable and it is part of their job description.

Also - the contract can get very expensive if you are only using it for
a few tests a year. I would recommend ramping up the amount of testing
that you do or bring in other units within your organization to take
part of the contract." -[Mandee
E.](https://www.g2crowd.com/products/usertesting/reviews/usertesting-review-851203)

#### [Pricing:](https://www.usertesting.com/plans)

UserTesting requires that you set up a call with them to determine your
pricing. They do offer a free trial version of their plans so you can
test it out, though you'll also need to get in touch with them for that.

#### Best for:

People that need to recruit people quickly for their studies.
UserTesting is also great for recruiting niche audiences.

### [Validately](https://validately.com/)

#### How it works:

Validately offers recruiting from both their participant database and
your own customers. They'll oversee screening, scheduling, and incentive
payment for both moderated and unmoderated research studies. They have a
dedicated research platform that allows researchers to take notes, share
their screen, and share video. These notes can then be easily
synthesized in a research report you can share with your team.
Validately typically recruits participants in 5 business days.
Validately has mobile and desktop integrations, so it's great for people
who want to test in those contexts.

#### What people love about it:

"From my very experience with Validately, I found it simplified the
entire process of user-testing. Once I qualify for a specific panel,
Validately\'s operations manages everything else: from ensuring
schedules, invites, links to the demo, reminders and any necessary tech
support. They also ensure all parties show up on time, and that all tech
systems are a go. They also set panelists and client expectations so the
right goals are hit. The best reason for using Validately is the depth
and breadth of their resource pool of expert panelists. They help ID the
right pre-qualifying questions to ensure the best match of experts
possible." -[Jackie
B](https://www.g2crowd.com/products/validately/reviews/validately-review-625393).

#### What people don't love about it:

"The analytics and reports are leave a little bit to be desired. It\'ll
help you conduct research, but not find insights." - [Verified
Reviewer](https://www.g2crowd.com/products/validately/reviews/validately-review-954388)

"The UI was super confusing to use and some of the terminologies seemed
misleading." -[Verified
Reviewer](https://www.g2crowd.com/products/validately/reviews/validately-review-939458)

#### [Pricing:](https://validately.com/pricing)

Validately requires customers to subscribe to a monthly plan + pay a
recruitment fee for each participant recruited. Validately's prices
include participant incentives.

\$299 a month: 1 researcher seat, no collaborator seats, BYO moderated
and unmoderated testing, 2 screener questions, desktop and mobile
testing, iOS and Android native app testing, 15 studies per year,
unlimited recordings, free to test on your own users, \$15 per
unmoderated test participant, \$150 per moderated test participant

\$499 a month: 2 researcher seats, 1 collaborator seat, moderated and
unmoderated testing, desktop and mobile testing, iOS and Android native
app testing, 40 studies per year, unlimited recordings, free to test on
your own users, \$15 per unmoderated test participant, \$150 per
moderated test participant

\$999 a month: 3 researcher seats, 5 collaborator seats, moderated and
unmoderated testing, desktop and mobile testing, iOS and Android native
app testing, 36 studies per year, unlimited recordings, free to test on
your own users, insights reporting, Slack integration, transcription
service, \$15 per unmoderated test participant, \$45 per moderated test
participant

#### Best for:

People that run a lot of unmoderated testing and need to consistently
recruit participants.

### [Loop11](https://www.loop11.com/)

#### How it works:

Loop11 lets you create unmoderated usability tests that record your
participants' actions and their reactions on video. You set up the test,
customize it to answer the questions you need, invite your participants,
and gain insights. Loop11 lets you use your own participants and
provides links to recruiting providers in-platform, like User
Interviews.

#### What people love about it:

"Loop11 isn't free, but it is cheaper than moderated usability testing.
You also don't have to spend much money on incentives as users are
participating when they want, and where they want (we've written more
about this on UXbooth). We still included a small incentive as a thank
you for users spending their time completing the test, and as we made
sure the test itself wasn't long it worked out rather well for
everyone." - [Experience
UX](https://www.experienceux.co.uk/ux-blog/loop-11-our-review/)

#### What people don't love about it:

"I think possibly the biggest gripe I have with this tool is that it
blanks the screen while asking questions. During a task a small control
bar appears at the top of the browser window, reminding you of the task
and allowing users to mark the task completed or failed. Once either is
selected the task ends and the user sees a blank screen whilst they are
asked questions." - [The
Fore](http://www.thefore.com.au/the-blog/2015/4/2/review-loop11)

#### [Pricing:](https://www.loop11.com/pricing/)

14 day free trial

\$69 a month: 3 user tests per month, 10 participants per test,
recordings of screen, face, and audio, unlimited tasks and questions, 5
second and first click tests, participant report breakdown.

\$249 a month: Unlimited tests and participants, recordings of screen,
face, and audio, unlimited tasks and questions, 5 second and first click
tests, participant report breakdown, heatmaps, data export, video
download, Slack integration.

Team Plans, which offer discounts per team member.

#### Best for:

Teams who conduct a few usability tests per month and need video
recordings of each test.

### [Userbrain](https://userbrain.net)

#### How it works:

Userbrain lets you see videos of participants interacting with any live
website. The participants will leave audio feedback as they navigate
through your site but, unlike many other tools, Userbrain does not
include video of your participant's face. The videos you will receive
show your participant's screen and record their voice as they interact
with your website. The other thing that sets Userbrain apart is the
ability to set weekly recurring research sessions so you're constantly
gathering insight.

#### What people love about it:

"How simple the platform was and that it was half the price per video,
i.e. per user review, when compared to other platforms. However, most
impressive was the customer service. When there was something I
couldn\'t do I emailed them and I got quick response from Markus who
helped me sort the issue." - [Narelle
M.](https://www.g2.com/products/userbrain/reviews/userbrain-review-1683616)

#### What people don't love about it:

"HALF OF TEST FEEDBACK IS USER READING THE TASK and buggering around
with their computer or lack of IT skills eg to click on images to
enlarge. Some users just don\'t actually say much they just read it all
out again. Some users do desktop tests on mobile. This must be
prevented. English users tending to be more articulate than US. Lack of
demographic section eg income, location in more depth. User background
and preferences eg Android or iOS etc. Make sure purchase journey is
simpler and easier. To be valid we need a minimum of 5-6 so use that
methodological basis for pricing and bundling." - [Clare
M.](https://www.capterra.com/p/141082/Userbrain/reviews/1813503/)

#### [Pricing:](https://userbrain.net/pricing)

Userbrain charges per test completed, which means one of their
participants went through your entire test and completed the process.

Pay-as-you-go: \$29 per test

Pay monthly: \$19 per test

#### Best for:

People who conduct a lot of usability tests and have a hard time
actually getting in the habit of conducting sessions.

### [Userlytics](https://www.userlytics.com/)

#### How it works:

Userlytics allows you to create user testing scripts and push them out
to participants, who complete the tests as unmoderated studies.
Userlytics then allows you to annotate, download and share the videos
with your teammates. Userlytics works on both websites and mobile apps,
so you can get all the data from all the platforms. They also recruit
the participants for you, so all you have to do is set up the test.

#### What people love about it:

"I like that i can easily get feedback for my work which is done. The
video recording available to view is also good as looking at their
expressions when they interact with my design is really important for me
to get additional insights. I also like that I can choose in detail what
participants I want, the filters are really good to get good insights
for your design." - [Ansell
L.](https://www.g2crowd.com/products/userlytics/reviews/userlytics-review-902709)

#### What people don't love about it:

"Not being able to send out one link that groups varying persona groups
even though it\'s for one project. Currently, it allows me to send out a
link to each persona group, but if I\'m testing across 3 groups with
varying desktop and mobile devices, I end up having a lot more links to
share to clients for highlights and reviews than 1 central
\"collection\" for the project." - [Kat K
R.](https://www.g2crowd.com/products/userlytics/reviews/userlytics-review-899541)

#### [Pricing](https://www.userlytics.com/prices-plans):

\$49 per participant: PIP recording, branching logic, configurable
testing, prototype testing, concurrent testing, basic demographic
filtering, metrics, limited features.

\$99 per participant: PIP recording, branching logic, configurable
testing, prototype testing, concurrent testing, advanced demographic
filtering, metrics, special recruitment services.

\$69 per participant: minimum 50 participants per year, but Userlytics
offers volume discounts that can lower the price even more. Comes
complete with all of Userlytics' features.

Enterprise Tier

#### Best for:

People who want to conduct unmoderated usability tests with users
outside of their network.

### [UsabilityHub](https://usabilityhub.com/)

#### How it works:

UsabilityHub specializes in quick unmoderated tests. This can include
first click tests, preference tests, and five second tests. You can also
use UsabilityHub to create larger surveys that can help you answer
questions your team has about design or UX elements. You can choose to
recruit from either your own panel or UsabilityHub's panel.

#### What people love about it:

"I would recommend UsabilityHub for anyone that wants fast responses
from real people about the immediate effectiveness of their design,
copy, media, and buttons - especially for improving bounce rate and
navigation issues." - [Verified
User](https://www.trustradius.com/products/usabilityhub/reviews)

#### What people don't love about it:

"UsabilityHub is not suited for testing out items that require a
specialized knowledge. For example, we had headlines to test out related
to purchasing energy, but not every tester in UsabilityHub\'s pool had
the level of knowledge needed to give a qualified opinion on this
subject." -[Verified
User](https://www.trustradius.com/products/usabilityhub/reviews)

#### [Pricing](https://usabilityhub.com/pricing):

Free: limited tests (2 minutes), UsabilityHub branding

UsabilityHub offers unlimited upgraded tests starting at \$100 per user
per month. You can also recruit people from their panel starting at \$1
per panelist.

#### Best for:

People who want to conduct a lot of quick unmoderated tests.

### [UserZoom](https://www.userzoom.com/)

#### How it works:

UserZoom combines a UX research platform with recruiting and managed
research options. It allows you to build a research study in whichever
method works best for your work. This can include usability testing and
benchmarking, information architecture research, surveys, and live
intercepts. UserZoom can also provide recruitment for your studies from
their base of over 120 million participants. If you're new to research,
or don't want to handle it at all, UserZoom can handle every aspect of
your research study and just deliver you the insights.

#### What people love about it:

"We do consulting research, and use UserZoom for our client projects
when we need to capture behavioral data (i.e. clickstreams, heatmaps,
time on task). There aren\'t many tools out there with the combination
of features that UserZoom provides, including logic to direct people to
other questions or parts of the survey, the behavioral tracking
mentioned above, and easy integration with panel providers." -[Verified
Reviewer](https://www.trustradius.com/reviews/userzoom-2016-03-22-11-10-36)

#### What people don't love about it:

"There\'s some amount of rigidity in weird places that requires customer
service intervention. For instance certain screens or phrasing around
the on boarding process. It feels a tad invasive, which can make it hard
to get my customers to do what I ask them to do. These are pretty minor
though, it\'s a good tool." -[Mari
F.](https://www.g2crowd.com/products/userzoom/reviews/userzoom-review-890692)

#### [Pricing:](https://www.userzoom.com/contact-us/)

UserZoom does not list their prices on the website. If you'd like to
find out which plan works for you, [contact them
here](https://www.userzoom.com/contact-us/).

#### Best for:

UserZoom allows researchers to manage their own studies, but may work
best for teams who want to outsource the entire research process.

### [FocusVision](https://www.focusvision.com/)

#### How it works:

FocusVision offers survey tools, live video sessions, diary studies, and
qualitative research. It allows the researcher to conduct interviews
remotely, or to create focus groups with a mix of remote and in-person
participants. FocusVision also supports 360 video for remote interviews,
which makes focus groups more engaging. Each tool is sold separately, so
you can choose which tool works for you and pay for that one
specifically.

#### What people love about it:

"I like modular systems and this system is easy to use to capture
real-time human insights and analytics. The tool is full-suite of
qualitative and quantitative." - [Verified
Reviewer](https://www.g2crowd.com/products/focusvision/reviews/focusvision-review-899779)

#### What people don't love about it:

"Sometime live video does not work properly, quality also get distorted
which leaves real user frustrated." - [Ashutosh
K.](https://www.g2crowd.com/products/focusvision/reviews/focusvision-review-916675)

#### Pricing:

There are [free trials
available](https://www.focusvision.com/focusvision-trials-and-demos/)
for each tool, but ultimately you'll need to request a demo with
FocusVision to sign on for their full version.

#### Best for:

People who don't do research frequently, and only want to pay for the
tools the few times a year they use them.

### [Qualtrics](https://www.qualtrics.com/)

#### How it works:

Qualtrics is a robust tool, and could have been listed in almost every
category on this list. If you're looking for a fully stacked research
tool, Qualtrics is a one-stop shop. Qualtrics includes capabilities for
survey building, usability testing, NPS scores, reporting, and
recruitment. Qualtrics has an incredible survey tool that creates
detailed surveys for almost any market, which is why I've put it here in
the survey section. It is also expensive for many research teams and
needs.

#### What people love about it:

"I love that I can do everything in Qualtrics\' online environment. From
programming and testing the survey, distribution to my samples, and
analyzing the data. There are really intuitive controls and features
within the Research Core and you can do a lot with the built-in
reporting features." - [Jake
W.](https://www.g2crowd.com/products/qualtrics-research-core/reviews/qualtrics-research-core-review-1136968)

"I have had the pleasure of working with several Qualtrics employees
during implementation and found them to be extremely helpful and
professional. No matter what I ask, they deliver, and quickly too! Even
when I think I have a problem they can\'t solve, they come up with a
solution that works. I also appreciate that the product is constantly
evolving and making improvements based on customer feedback." -
[Virginia
M.](https://www.capterra.com/p/72396/Qualtrics-Insight-Platform/)

#### What people don't love about it:

"Some features other platforms have at standard are very pricey (like
dashboards, conjoint analysis) Would also like to see more mobile
applications like geo-fencing" - [Laury
H.](https://www.g2crowd.com/products/qualtrics-research-core/reviews/qualtrics-research-core-review-245609)

"I dislike the pricing structure. To have multiple licences or logins
for the same company it cost more money. Sometimes the little things
like resizing an image can be very tricky. Lastly, some of the reporting
while good, is a little weak. They\'ve very strong with graphical
reporting but when it\'s trying to report out to us explanations, the
format can be very messy at times when you export it." - [Sarah
N.](https://www.g2crowd.com/products/qualtrics-research-core/reviews/qualtrics-research-core-review-259718)

#### [Pricing:](https://www.qualtrics.com/)

Free Survey Tool: 100 responses, 10 outgoing emails, 7 question types, 1
active survey, 10 questions per survey, skip logic, online reporting

You'll have to talk to Qualtrics about any paid plans, just hit the
"Request a Demo" button at the top of their [home
page](https://www.qualtrics.com/).

#### Best for:

People who want all their research tools in one platform and are willing
to pay for it.

‚Äç

### Specialized Testing Tools

Specialized testing tools help you carry out specific kinds of tests
that don't fall neatly into another category. Things like card sorts and
diary studies fit here and these tools can help you expand your existing
stack for more specialized tests.

### [Dscout](https://dscout.com/)

#### How it works:

Dscout is a great platform for conducting diary studies. You create
"missions" for your participants to complete and they provide pictures,
videos, and notes about their experiences. Dscout has a participant pool
of over 100,000 people, or you can bring your own participants. Dscout
also has a live interview function that makes it easy to conduct one on
one research interviews directly in the Dscout platform.

#### What people love about it:

"One thing that really impresses me about dscout is the fun and quality
they put into what the person uses it experiences. I find that to be
surprisingly rare in the field." -[Mari
F.](https://www.g2crowd.com/products/dscout/reviews/dscout-review-912077)

"Everything about the platform is designed around providing the best
experience to the participants of the project. Missions work on mobile,
which allows people to give feedback on the go. Because it gives native
experience, very easy to do what they coin as \"in-context\" research,
where the scout is actually using your product in real time." -
[Verified
Reviewer](https://www.g2crowd.com/products/dscout/reviews/dscout-review-954828)

#### What people don't love about it:

"I don\'t like some of the admin controls. Reviewing what happens with
all of the data collected by scouts can sometimes be confusing. However,
I will say that it has been getting better\... they recently revamped
the site to make it easier to move scouts into custom groups." -
[Verified
Reviewer](https://www.g2crowd.com/products/dscout/reviews/dscout-review-899524)

#### [Pricing:](https://dscout.com/getting-started-project)

To figure out how much Dscout will cost for you, you'll have to talk to
their sales team. You can get a quote
[here](https://dscout.com/getting-started-project).

#### Best for:

People who want to conduct online [diary
studies](https://www.userinterviews.com/ux-research-field-guide-chapter/diary-studies).

### [Optimal Workshop](https://www.optimalworkshop.com/)

#### How it works:

Optimal Workshop is made up of a stack of design testing tools. Optimal
Workshop can help you design:tree tests, card sorts, first-click tests,
surveys, and qualitative research. Optimal Workshop offers bundle
pricing for all of their products as well as individual product pricing.
Their individual products are: TreeJack, OptimalSort, Chalkmark,
Questions, and Reframer. They can also help you recruit participants for
your studies.

#### What people love about it:

"Reframer improves the traceability of your research, the discovery of
patterns and themes, and the effectiveness of your team." - [Eric
W](https://www.producthunt.com/posts/reframer).

"Reframer generates an output that's useful for internal teams and for
presenting data back to clients." - [Carrie
N.](https://uxdesign.cc/reframer-review-a-qualitative-research-tool-c99b1700af0c)

#### What people don't love about it:

"You really need to understand how to use tags - for our team, we had to
decide beforehand which ones we\'d use in order to make sure that we got
relevant insights (and not a crazy mishmash). But Reframer also seemed
to create or duplicate tags by itself from our notes, which might have
been convenient but in fact complicated things a bit further and meant
we had to do some additional tag management later." - [Verified
Reviewer](https://www.capterra.com/p/174073/Reframer/)

#### [Pricing:](https://www.optimalworkshop.com/pricing/)

Free: unlimited studies, ten responses per study, 30 card sorts, 3 tree
tests, and 3 first click tests

\$199 per month per user (monthly)/ \$166 per month per user (annually):
All of Optimal Workshops features with unlimited everything.

Team plans that offer discounts for larger teams

You can also pay for individual tree tests, card sorts, or first click
studies for \$99 each.

#### Best for:

People who conduct a lot of varied research, you'll need to buy in to
all of Optimal Workshop's tools to get your money's worth.

### A/B Testing Tools

A/B testing allows you to test two versions of something to see which
one is better. You can A/B test websites, emails, app designs, or even
cups of coffee. During an A/B test, some of your users will see version
A and the other half will see version B. A/B tests are great for testing
design choices, copy, pricing, or any other single variables on your
site. Many of the other tools on this list are capable of A/B tests, but
these tools are built specifically for them.

### [Optimizely](https://www.optimizely.com/)

#### How it works:

Optimizely is all about testing. It allows you to create incredibly
advanced A/B tests, which can have many pages and variables. It offers
web and development features that allow you to test on fully-baked, live
sites, or on specific features as your development team codes them.

#### What people love about it:

"That variations are simple to setup and track. I no longer need to
coordinate with several departments and wait for the next release to
change the CTA on a button or swap out an image. I can do it all on my
own in minutes." - [Thomas
H.](https://www.g2crowd.com/products/optimizely/reviews/optimizely-review-392622)

"I have been using Optimizely for over 2 years now. In my previous role
I used another testing and targeting tool that was much more complex to
use. Optimizely\'s user interface is intuitive and the statistical
algorithms give you confidence in selecting a winner. The best part
about Optimizely is it\'s support. They have a support line and they
will work tirelessly until your issue is resolved. I recommend
Optimizely\'s platform to anyone looking to increase web conversions or
provide more personal web experiences." -[Chad
W.](https://www.capterra.com/p/147638/Optimizely/)

#### What people don't love about it:

"Preview mode is really buggy. I also wish there was a way to segment
the results by audience. For example, if I\'m running a different type
of traffic to a page I want to be able to see a separate page of data
specifically for that. The new goal setting flow is also buggy, but it
is new. Hopefully they fix all the kinks as time goes on." - [James
P.](https://www.capterra.com/p/147638/Optimizely/?sort_options=Lowest%20Rating)

"Overall Optimizely has worked well, but the pricing is a bit high.. I
suppose it\'s a case of you get what you pay for!" - [Kevin
V.](https://www.capterra.com/p/147638/Optimizely/?sort_options=Lowest%20Rating)

#### [Pricing](https://www.optimizely.com/plans/):

They have a few different plans and tiers, but you'll have to [talk to
someone at Optimizely](https://www.optimizely.com/plans/) to get
accurate pricing info for your needs.

#### Best for:

People who want to run a lot of A/B and usability tests.

### [VWO](https://vwo.com/)

#### How it works:

VWO combines the power of A/B testing with its own analytics software.
It allows users to build their A/B testing campaigns visually within VWO
to launch campaigns faster. It also provides heatmaps to show you
exactly what happened in each test and declare a winner. VWO has a
robust set of products that can cover a lot of your website testing if
you're willing to pay for it.

#### What people love about it:

"The platform is robust and yet somehow it still feels very simple to
use. I like the flexibility of testing options and in establishing
results \-- keeps it easy for us to setup and manage campaigns without
getting bogged down." -[Scott
A.](https://www.g2crowd.com/products/vwo/reviews/vwo-review-1207132)

"The most advantageous feature for me is that you can customised traffic
to different variables and have more control over segmenting the
audience; you can customise a new segment yourself should you wish to.
Another cool feature is that when setting the parameters for the
campaign, VWO takes into account the number of visitors that would be
exposed to the campaign, your current conversion rate for the original
version of the page and the minimal conversion rate that you care
about." - [Laura
W.](https://www.capterra.com/p/147639/Visual-Website-Optimizer/)

#### What people don't love about it:

"The basic solution is good but feels somewhat limited in comparison to
their top-tier optimization product. However, their pricing for all
products is expensive. Their optimization product (full suite of tools)
is far too expensive for most businesses and requires a lot of
management time - it\'s not a case of switching on a button and seeing
results, the tools only enable you to create tests and track their
progress. It\'s an ideal tool for a larger team of marketers and website
testers." - [Jamie
M.](https://www.capterra.com/p/147639/Visual-Website-Optimizer/)

"The entire quality assurance process is pretty difficult. Making edits
to dynamic pages is virtually impossible out of the box. The customer
support tends to be pretty spotty. In my experience, the heat map
functionality just doesn\'t work." - [Jed
P.](https://www.capterra.com/p/147639/Visual-Website-Optimizer/)

#### [Pricing:](https://vwo.com/plans/)

You'll have to [talk to VWO](https://vwo.com/plans/) to get all the
information on a full stack plan, but they outline plans for individual
parts of their product.

VWO Testing: from \$199 a month. A/B testing, multivariate testing,
split URL testing.

VWO Insights: from \$169 a month. Session Replays, Heatmaps, Form
Analytics & On-page Surveys.

VWO Engage: from \$99 a month. Talk to your visitors after they drop off
through web push notifications & Facebook messenger.

#### Best for:

People who want to run A/B tests and gather analytics on the same
platform.

### Automated Feedback Tools

Automated feedback tools help you gather feedback continuously.
Typically this is done through a form on your website or product. Things
like NPS scores and on-site surveys are automated feedback. These tools
combine the power of in-app messaging tools with a research focus to
bring you tools that help you gather insight about your customers
directly in your app. Many of these tools allow users to leave quick and
easy feedback on things they're already interacting with on your site.
This makes it easy to constantly gather insights and get a sense of how
your users as a whole feel about features and capabilities and can be a
great complement to moderated, qualitative studies.

### [Appcues](https://www.appcues.com/)

#### How it works:

Appcues adds a layer on top of your existing product to walk users
through onboarding processes, new features, or to collect survey
responses. This makes it easy for teams who are constantly rolling out
new features to introduce them to their users in intuitive way and to
collect their feedback directly on the site. Appcues allows teams to
collect answers to survey questions or NPS scores on your product's
website.

#### What people love about it:

"Appcues is a great tool. It is extremely user-friendly, allowing you to
create impactful flows that help deliver messages, info and helpful tips
directly to your customers. The people at Appcues have been amazing
since day 1, always checking in to ensure we found success with their
product. I have nothing but good thing to say about Appcues!" - [Jessica
G.](https://www.capterra.com/p/139216/Appcues/)

"Appcues is great, offering a simple, effective and easily set-up method
to provide in-system guidance and advice. While some small developer
effort is required to ensure that Appcues has the data on which you want
to base showing cues, the flexibility of the flows and the granularity
with which you can control who sees them is fantastic." - [Dan
M.](https://www.capterra.com/p/139216/Appcues/)

#### What people don't love about it:

"Our tool is built on AngularJS, and as a Single Page App, targeting can
be tricky. In our case, we needed to be extra careful with our
implementation of the tool to make sure that the flows fire properly, as
there are no real page changes to trigger the flows." - [Joseph
P.](https://www.g2crowd.com/products/appcues/reviews/appcues-review-978586)

"Everything is element driven (e.g. show a call-out next to this H1
heading when user is on this page). However, our site has many
\"hidden\" elements on a page, which only display when the user
interacts with the page in a certain way. It\'d be nice if you could
somehow detect these clicks/interactions, and then display tutorials
based on that (e.g. on click of this button, show this alert)" - [Robert
C.](https://www.capterra.com/p/139216/Appcues/)

#### [Pricing:](https://www.appcues.com/pricing)

Appcues tailors their pricing very specifically depending on how you
want to pay, how many monthly users you have, and which features you'll
need from Appcues. Prices range from \$159- \$999+ per month, you can
check out their [pricing tool here](https://www.appcues.com/pricing).

#### Best for:

People who need both a feature walkthrough tool and a quick survey tool.

### [Usabilla](https://usabilla.com/)

#### How it works:

Usabilla uses quick emoji surveys to gauge how your users are feeling
about elements on your site or app. Usabilla will then display your
users' reactions in an emotional trendline to help you see how users are
feeling about your website over time. You can ask your users how they're
feeling, or follow it up with a few quick questions to help you gather
data about how users are interacting with your product.

#### What people love about it:

"Setting up a campaign is quick and gets me the info I need quickly. I
also really like the tagging and filtering features so that I can
organize and make sense of all the general feedback I am getting. This
tool have been key to understanding the problems our users face." -
[Chrystal
J.](https://www.g2crowd.com/products/usabilla/reviews/usabilla-review-648137)

#### What people don't love about it:

"Last I checked the mobile experience wasn\'t very friendly, but I
almost never need to access it via mobile." - [Claire
S.](https://www.g2crowd.com/products/usabilla/reviews/usabilla-review-647773)

"Some small limitations in terms of functionality, but perhaps these
will be developed going forwards." - [Jonny
L.](https://www.g2crowd.com/products/usabilla/reviews/usabilla-review-647741)

#### [Pricing:](https://usabilla.com/pricing-policy/)

Usabilla doesn't display pricing on their website, instead they ask you
to [schedule a call with them](https://usabilla.com/request-a-demo/) to
figure out which pricing plans will work for you.

#### Best for:

People who need a customer feedback survey that is easy to understand
instantly and want to collect both qualitative and quantitative data.

‚Äç

## Analytics & Heatmapping Tools

Analytics and heatmapping tools are great for keeping tabs on what is
happening on your site daily. Many of these tools will allow you to take
deep dives into your data or allow you to see top level numbers for how
your site is performing as a whole. Heat maps will show you what users
are clicking on and how they are navigating your site. This can help you
understand your user flows and what content is driving the most user
attention on your site. Analytics and heat maps give you quantitative
data that you can use in conjunction with quantitative data collected
through other methods.

### Heatmapping Tools

### [Hotjar](https://www.hotjar.com/)

#### How it works:

Hotjar creates visual tools that make it easy to understand what your
users are doing on your website. This include heatmaps, session
recordings, conversion funnel and survey analysis, in-app feedback
polls, and in-app research recruiting.

#### What people love about it:

"HotJar is easily the best value-to-price behavior mapping software of
its kind, and I\'ve used and shopped for several of them. That pretty
much sums it up. From heat mapping to visitor recordings to polling
functionality, I simply haven\'t had to look for another solution since
I found it, and it is much more cost-effective than its competitors. Its
integrations that we have implemented have worked splendidly, as well. 5
stars, hands down." -[Justin
L.](https://www.capterra.com/p/163516/Hotjar/)

#### What people don't love about it:

"CSS configuration can get mucky, and the inability to easily leave
notes on videos on lower plan levels is really frustrating. In general,
recorded session tagging and commenting could be easier and more
robust." -[Joel
K.](https://www.g2crowd.com/products/hotjar/reviews/hotjar-review-445766)

#### [Pricing:](https://www.hotjar.com/pricing/)

Free: 2,000 pageviews a day, limited reports, unlimited users, data
storage for a year

\$29 a month: 10,000 pageviews a day, unlimited reports, unlimited
users, data storage for a year

\$89 a month: 20,000 pageviews a day, unlimited reports, unlimited
users, data storage for a year, no Hotjar branding, advanced features

\$189 a month: 50,000 pageviews a day, unlimited reports, unlimited
users, data storage for a year, no Hotjar branding, advanced features

\$289 a month: 120,000 pageviews a day, unlimited reports, unlimited
users, data storage for a year, no Hotjar branding, advanced features

\$589 a month: 400,000 pageviews a day, unlimited reports, unlimited
users, data storage for a year, no Hotjar branding, advanced features

\$989 a month: 800,000 pageviews a day, unlimited reports, unlimited
users, data storage for a year, no Hotjar branding, advanced features

Enterprise Plans

#### Best for:

People who need a great heat mapping tool.

### [CrazyEgg](https://www.crazyegg.com/)

#### How it works:

CrazyEgg is a heatmapping tool that allows you to create heatmaps of the
most-clicked areas of your website. CrazyEgg also includes a web editor
that makes it easy for you to edit your webpage directly through the
CrazyEgg platform. It also allows you to conduct A/B tests of different
versions of your site.

#### What people love about it:

"It\'s very easy to use, just a little bit of code needs to be added to
your website or landing page software and you can use it over and over.
This tool, especially the scrollmap, helped show us where people are
dropping off on a landing page and what sections need to be removed or
improved." - [Renee
P.](https://www.g2crowd.com/products/crazy-egg/reviews/crazy-egg-review-591715)

"Crazy Egg is super easy to set up and it is always well received by
team members. Additionally, it is far more user friendly and easier to
digest that Google Analytics in-page tool which is why I think it\'s
worthwhile to invest in this tool if you can." - [Lisa
M.](https://www.g2crowd.com/products/crazy-egg/reviews/crazy-egg-review-526494)

#### What people don't love about it:

"Over the past year I\'ve noticed bugs creeping in. I set up snapshots
and they just remain in \"pending\" status. It\'s happened so many time
I now have to create a calendar reminder to check back in 6-8 hours and
make sure my snapshots have all started. Customer support has not been
able to determine why this happens or provide any resolution. The other
downside is you only get data on the specific pages you track, and
they\'ve now added the ability to split out mobile vs. tablet vs.
desktop, so if you want to see how visitors on different devices act
differently, that will eat up 3 snapshots for every URL. Nice data to
have, it\'s just very limited, so you have to plan out which pages
you\'re going to track and rotate to really make headway on your
site." - [Elaine S.](https://www.capterra.com/p/163520/Crazy-Egg/)

#### [Pricing:](https://www.crazyegg.com/pricing)

30 Day Free Trial

\$24 a month: 30,000 pageviews, 100 recordings, unlimited A/B tests and
website edits, 3 months of recorded storage, 3 websites

\$49 a month: 70,000 pageviews, 500 recordings, unlimited A/B tests and
website edits, 1 year of recorded storage, unlimited websites

\$99 a month: 100,000 pageviews, 1,000 recordings, unlimited A/B tests
and website edits, 2 years of recorded storage, unlimited websites

\$249 a month: 500,000 pageviews, 5,000 recordings, unlimited A/B tests
and website edits, 2 years of recorded storage, unlimited websites,
priority support

Enterprise Tier

#### Best for:

People who are looking for an inexpensive heatmapping tool.

### [FullStory](https://www.fullstory.com/)

#### How it works:

FullStory offers recordings of your users' experiences on your site.
Rather than using a traditional heatmapping or click map tool to see
what your users interacted with while they were on your site, FullStory
allows you to actually see exactly what your customers saw while they
were on your site. How long they hovered over that button before
clicking, if they actually looked at your site's infographics or photos,
etc. It also allows you to filter sessions by what happened during them,
so you're only looking at the relevant sessions.

#### What people love about it:

"Video recording is PIXEL PERFECT - almost 100% accurate to how the
visitor really see in the website allows me to understand exactly how my
users witness the website. User interface is really flexible, enables me
to filter by every parameter exist - time, date and even more complex
like user agent." - [Rengado
D.](https://www.g2crowd.com/products/fullstory/reviews/fullstory-review-1194719)

"You can view almost anything about your site visitors using this tool.
It allows you to view their sessions, view heatmaps and clickmaps, and
analyze funnels. It\'s particularly helpful when a customer calls in
with an issue and we can look up their session and see them experiencing
the issue instead of trying to recreate it." - [Yocheved
S.](https://www.capterra.com/p/153721/FullStory/)

#### What people don't love about it:

"As a designer, it can be pretty confusing for me when it comes to
setting up segments. Because it can do so much, it means that you have
to be very very specific in what it is you actually want to see. It can
get pretty confusing sometimes." - [Paco
S.](https://www.capterra.com/p/153721/FullStory/)

"When/If you hit your limit for sessions in a month, they stop recording
sessions until you upgrade or the next month starts. Even if you upgrade
during that month, from the time it goes over the limit until you
upgrade, all those users that were recorded are not saved and and then
shown. Very frustrating that they can\'t just prevent you from watching
until you upgrade." - [Nate
M.](https://www.g2crowd.com/products/fullstory/reviews/fullstory-review-440454)

#### [Pricing:](https://www.fullstory.com/pricing/)

You'll have to have a demo [with the FullStory
team](https://www.fullstory.com/pricing/) to learn more about pricing.

#### Best for:

People who want to be able to watch session replays of their site.

‚Äç

### Analytics Tools

### [Google Analytics](https://analytics.google.com/analytics/web/)

#### How it works:

Google Analytics keeps tabs on what users are doing on your site. It
gives you detailed numbers which can help to get specific insights about
what users are doing on your site. Plus, the basic version of Google
Analytics is free, so many people use it in conjunction with other
analytics tools. Google Analytics can get pretty complicated pretty
fast, and many people obtain certificates on the [Analytics
Academy](https://analytics.google.com/analytics/academy/) to use
Google's powerful analytics features.

#### What people love about it:

"I like the ease of use and the ability to make comparisons vs. other
days, weeks or months. The app is very user friendly and has a simple
interface that gets the information I need right up front without
clicking through a bunch of commands." - [Adam
S.](https://www.g2crowd.com/products/google-analytics/reviews/google-analytics-review-1022330)

"I like how easy it is to just implement GA into your blog or website. I
was not really well versed in websites when I started and GA was
necessary for people who wanted reviews on their products, so I had to
have it. I liked that I didn\'t have to be a pro to add the HTML to my
blog and get started. It immediately started logging all the visitors to
my page." - [Erika
M.](https://www.g2crowd.com/products/google-analytics/reviews/google-analytics-review-1111952)

#### What people don't love about it:

"Insanely difficult to figure out how to extract the data we need. And
then once we\'ve figured it out, they change the interface and that way
no longer works. Also, we get tons of 0:00 \"visits\" from China and
Russia, which makes me feel paranoid\... and they also really mess up
the data set." -[Julie
Z.](https://www.g2crowd.com/products/google-analytics/reviews/google-analytics-review-484602)

"The nature of Google is that it\'s constantly changing to try and be
bigger and better but sometimes this can translate to a poor user
experience. Because the platform is constantly making updates it can be
hard to navigate. I also wish that it was more granular with some data.
Overall Google Analytics is a good overview but it\'s not easy to get a
data drill down." - [Sarah
C.](https://www.g2crowd.com/products/google-analytics/reviews/google-analytics-review-533834)

#### [Pricing:](https://marketingplatform.google.com/about/analytics-360/compare/)

Free: Basic version of Google Analytics, which should work for most
individuals and small businesses. Basic attribution models, 200 views
per property, 20 custom dimensions and metrics

Enterprise: Analytics 360, which includes extra tools and features for
large businesses. To get pricing, you'll have to talk to Google's sales
team.

#### Best for:

Honestly, all people with websites. It's free so it's a great addition
to your analytics stack.

### [Heap Analytics](https://heap.io/)

#### How it works:

Heap Analytics collects real-time data as users browse your site and
stores it for you to gain insights from. Heap automatically combines
data from the same user to build out your user profiles to the fullest.
This means even if the same person comes back to your site registered
under a different email address, their data will still be stored to the
same user profile, making some assumptions about cookies and so on.

#### What people love about it:

"The dashboard is user-friendly and offers all of our insights in one
place. We didn\'t have to wait days for data like we did with Google
Analytics we started seeing data within an hour of installing it on our
site." - [Andrew
M.](https://www.g2crowd.com/products/heap/reviews/heap-review-857076)

"Easy to implement and setup. It makes it easy for almost everybody at
my workplace from the marketing to sales, to accounting department to be
able to review data provided, even without being tech savvy." - [Naomi
T.](https://www.capterra.com/p/147216/Heap/)

#### What people don't love about it:

"Approachability - for more technical users, such as our product team,
it\'s relatively simple to dig into and start culling insights from
immediately. For other, less savvy business users (marketing, customer
success) there may be a learning curve." - [Calvin
H.](https://www.g2crowd.com/products/heap/reviews/heap-review-815100)

"I wish that there was an easier way to track events that a user did a
certain period of time after completing another defined event."
-[Patrick
E.](https://www.g2crowd.com/products/heap/reviews/heap-review-207255)

#### [Pricing:](https://heapanalytics.com/pricing)

14 day free trial

Free: 3 months data history, 1 user license, low priority support

All paid plans require you to get in contact with Heap's sales team, but
they [outline their plans here](https://heap.io/pricing).

#### Best for:

People who need a powerful analytics tool with user profiles that
combine.

### [Kissmetrics](https://www.kissmetricshq.com/)

#### How it works:

Kissmetrics combines powerful analytics tools with email campaign
automation. It allows you to collect analytics and then break your users
down into key populations so you can keep an eye on how different types
of users are interacting with your site and product. You can then use
these populations or specific action triggers to create targeted email
campaigns that reach out directly to users based on their actions on
your site.

#### What people love about it:

"The product is very simple. It gives me the data I want and is fairly
fast at doing so! It has a wide range of what it can do and analyze -
which is nice. Across the business we use it for a lot of different
things between A/B testing and population analysis." - [Micaela
W.](https://www.g2crowd.com/products/kissmetrics/reviews/kissmetrics-review-63055)

"In a world flooded with analytics tools and dashboards nobody seems to
focus on the value of simplicity and the usefulness of defining your own
specific web-based business goals. KISSmetrics is not a flood of
information, it\'s quite the opposite: a no bullshit tool that will
uncover the honest truth about the results of the your marketing
campaigns." - [Kevin
L.](https://www.g2crowd.com/products/kissmetrics/reviews/kissmetrics-review-210913)

#### What people don't love about it:

"The set up isn\'t extremely intuitive. It takes a few minutes to grasp
the difference between the \"conversion page link\" and the
\"destination link.\" I think that process could be a little simpler.
Although, I love the ability to customize the bubbles with brand colors,
verbiage & shape (to an extent)." -[Lisa
P.](https://www.g2crowd.com/products/kissmetrics/reviews/kissmetrics-review-504724)

"Integration with my company\'s database has failed over and over again,
and Kissmetrics either shows no data or inaccurate data. The company
keeps moving the platform to different URLs. The documentation for
implementing database connections has left our dev team a bit
confused." - [Nathan
A.](https://www.g2crowd.com/products/kissmetrics/reviews/kissmetrics-review-806497)

#### [Pricing](https://www.kissmetrics.io/saas-pricing/):

\$299 a month: 10k monthly tracked users, 3 user seats, 1 tracked
domain, 10 populations. Analytics dashboard, activity report, path
report, user tracking.

\$499 a month: 25k monthly tracked users, 10 user seats, 3 tracked
domains, 20 populations. Analytics dashboard, activity report, path
report, user tracking, revenue report, cohort report.

Enterprise tier

#### Best for:

People who want to combine their analytics and email messaging tools.

### [Mixpanel](https://mixpanel.com/)

#### How it works:

Mixpanel combines a mobile and web analytics tool and a customer
messaging tool so you can reach out to your users based on real time
data about how they have interacted with your site. They have a powerful
free version available, which allows you to see a lot of the analytics
Mixpanel collects from your site and message a small subset of users.

#### What people love about it:

"Interface is overall very easy to use and get started with. It does a
very good job of supporting some advanced analysis without making the
interface overly complex. Cohort analysis is very good." -[Nick
D.](https://www.g2crowd.com/products/mixpanel/reviews/mixpanel-review-843378)

"The marketing tool is INSANELY powerful you can configure marketing
messages or campaigns based on almost any data you can pipe in. The
support engineers are the nicest, best support engineers on the planet
(they have incredible depth of knowledge and explain in crazy detail).
We see our Mixpanel marketing communications perform 4-5x better on
average than our general email marketing messages." - [David
K.](https://www.capterra.com/p/158740/Mixpanel/)

#### What people don't love about it:

"Lack of flexibility in terms of bringing in other data sources which
has forced us to move towards a total data warehouse solution. Ad
blocker removes \~5 % of client side events which means you have to be
clever comparing server side to client side. No original react native
libraries, although plenty of external wrappers available. Could be more
accurate collecting initial referrer, also could be better ways to
explore your user base. New common journey tracking features would be a
great addition." -[Rich
W.](https://www.g2crowd.com/products/mixpanel/reviews/mixpanel-review-518040)

#### [Pricing:](https://mixpanel.com/pricing/#people)

Free: 1,000 monthly tracked users, all analytics features, unlimited
seats, 90 day data history.

\$89+ per month: 1,000+ monthly tracked users, all analytics features,
unlimited seats, 12 month data history.

Mixpanel plans scale based on how many monthly users you need to track,
and you'll need to [chat with
them](https://mixpanel.com/pricing/#people) if you want to track more
than 1,000 monthly users.

#### Best for:

People who want to combine their analytics and in-app messaging tools.

‚Äç

## **Research Ops and Insights**[](https://www.userinterviews.com/ux-research-field-guide-chapter/user-research-tools#TOC-Element-1)

Organizing and managing your research projects is no easy task. There
are usually many elements to record in user research; from video
recordings of the session itself to the researchers notes. There is also
the problem of sharing your research with the rest of your team, which
is imperative to your research actually impacting your company's
mission. These project management tools offer many different approaches
to planning and organizing your research.

### [Dovetail](https://dovetailapp.com/)

#### How it works:

Dovetail is a research ops platform that stores all your qualitative
research in one place. You can use Dovetail to create interactive
entries in your research database. This would allow you to upload
photos, videos, notes, or anything else from your session that may be
useful to come back to later. You can also create searchable tags to
help you find specific information in the future, like "feature request"
or "usability issues". Dovetail also creates graphs and visual elements
based off your tagged entries to help you see your data more clearly.

#### What people love about it:

"Dovetails greatest feature is how simply you can tag your content, how
you can visualize the tags each project has, and how you can look at
each individual tag to see the content you\'ve assigned that tag
to\...If you want to see all content that is tagged with the same thing,
you just have to click on that tag and it all populates. This makes
reviewing tagged content very easy!

The system of tagging they have developed is so user friendly! Dovetail
is easier to learn than many of its competitors which we have used in
the past. Dovetails interface is uncluttered, allowing for users to
easily navigate its features." -[Laurie
D.](https://www.capterra.com/p/174077/Dovetail/)

"With Dovetail, research data remains accessible long after any research
project has finished. This means valuable insights are no longer buried
in reports that get forgotten, but can be continuously reviewed and
built upon as new data is collected. Dovetail has quickly become an
indispensable tool for us." -[Sophie
E.](https://www.capterra.com/p/174077/Dovetail/)

#### What people don't love about it:

"Subgrouping is still a problem. Dovetail doesn\'t yet support copying
and pasting screenshots directly. Can be a major pain sometimes." -
[Abhilash P.](https://www.capterra.com/p/174077/Dovetail/)

"Can be a bit hard to get started - getting your head around notes/tags
and insights (they all look the same at first!)" - [Sherif
M.](https://www.capterra.com/p/174077/Dovetail/)

"Many features: cross-project search, insights, admin rights etc. are
still in development. However, when they arrive, I am 120% confident
that they will be powerful! I\'m really excited and looking forward to
them." - [Sonja B.](https://www.capterra.com/p/174077/Dovetail/)

#### [Pricing:](https://dovetailapp.com/pricing)

7 day free trial

\$100 per month: 5 contributors, unlimited viewer accounts, up to 50GB
of video and file storage, unlimited projects and notes, integrations
through Zapier, granular user permissions, project templates, encrypted
data and backups.

\$600 per month: 10 contributors, unlimited viewer accounts, up to 50GB
of video and file storage, unlimited projects and notes, integrations
through Zapier, granular user permissions, project templates, encrypted
data and backups, custom security protocols and payment terms, dedicated
customer success manager.

#### Best for:

People who want to focus on data-rich research and visualizations to
share with the rest of their team.

### [productboard](https://www.productboard.com/)

#### How it works:

productboard is a product roadmap system designed around user insight.
It makes it easy to aggregate user feedback from places like Intercom
and Slack. It's main draw is the interactive product roadmap, which you
and your team can collaborate on. At User Interviews we use productboard
to keep track of user feedback gathered by all members of our team from
Zendesk, Salesforce, all hands interviews, emails, and more. Product
owns the responsibility or organizing those insights, coding them into
themes and attaching them to product ideas and user needs. It's been a
great system for us to make better use of the research we're already
doing.

#### What people love about it:

"Makes it easy to triage new inputs and manage research; prioritize
ideas and features; plan releases; & plan/communicate my roadmap. Love
the ease of getting information into the tool (either using their paste
feature or integrations)" -[Scott
B.](https://www.capterra.com/p/160651/productboard/)

"I\'ve used many tools and techniques for product management over the
years. Most do an okay job of keeping track of features and putting them
in some kind of an order (roadmap). Where productboard stands above the
rest is helping you understand why is a feature important (or not) based
on user feedback and industry trends or news.

productboard\'s \'Research\' module is vital for me to keep track of
feedback and key insights about features which drive prioritization. In
addition, the ability to track interest in features by specific people
and companies helps my sales team because I\'m able to give them hot
leads as we implement product enhancements." - [Matt
G.](https://www.g2crowd.com/products/productboard/reviews/productboard-review-442088)

#### What people don't love about it:

"It\'s fairly expensive. The value is there for the money, but gaining
access to this much budget is a bigger process than just \"sign up and
pay\"."- [James B.](https://www.capterra.com/p/160651/productboard/)

"It is hard to tell who is doing what when there are multiple editors on
one board."- [Heather
B.](https://www.g2crowd.com/products/productboard/reviews/productboard-review-442021)

"On Firefox, there is a very slow scrolling speed when all features are
expanded, which can be frustrating. Also, the fact that there are only
one-way integrations with Trello and Github makes us create many
duplicate features." - [Victor
L.](https://www.capterra.com/p/160651/productboard/)

#### [Pricing:](https://www.productboard.com/pricing/)

15 day free trial of all plans

\$49 per month (annually)/ \$59 per month (monthly): 5 contributors, 10
viewers, 1 product, basic support

\$99 per month (annually)/ \$119 per month (monthly): 20 contributors,
unlimited viewers, 5 products, basic support

\$199 per month (annually): 50 contributors, unlimited viewers, 10
products, priority support

Enterprise Tier: Unlimited contributors, products, premium support

#### Best for:

People who need a place to organize user feedback and integrate it into
their product roadmap.

### [UserVoice](https://www.uservoice.com/)

#### How it works:

UserVoice allows your customers to leave product feedback directly.
Users can either vote on updates they would like to see or post their
own through the Feedback Portal, or they can submit feedback through a
chat widget that displays directly on your site. UserVoice also allows
your team to collect insights on their own via email or CRM. UserVoice
offers a sidebar widget that makes it easy to input customer feedback
directly into the platform from your email or CRM.

#### What people love about it:

"UserVoice is very easy to use. All the features are streamlined and
there is support always available if needed. I enjoy using this product
on a daily basis because it provides value. The dashboard is easy to
navigate as well." - [Samantha
M.](https://www.g2crowd.com/products/uservoice/reviews/uservoice-review-505901)

"The ease of use and the appearance of the software. It is easy to
navigate and operate. Use this software everyday for work and the fun
feature of keeping track of your replies, quick replies and kudos is a
fun competition at work but also to see where you stand with answering
tickets in a timely manner." - [Kayla
H.](https://www.g2crowd.com/products/uservoice/reviews/uservoice-management-moderation-review-155455)

#### What people don't love about it:

"I wish there was an easier way to merge duplicates rather than having
to do each individual one manually by hand." - [Jake
S.](https://www.g2crowd.com/products/uservoice/reviews/uservoice-review-445625)

"The back end admin panel is nice, with some solid visual
representations of support requests and feedback. But replying to
tickets from within the system is a bit cumbersome; to the point where I
usually find myself just replying directly via email to the client."
-[Nick
T.](https://www.g2crowd.com/products/uservoice/reviews/uservoice-management-moderation-review-12767)

#### [Pricing:](https://www.uservoice.com/product/#talktosales)

UserVoice doesn't list pricing or plans on their site, so you'll have to
[talk to their Sales](https://www.uservoice.com/product/#talktosales)
team to see if it's a good fit for your budget.

#### Best for:

People who want to collect feedback more traditionally and allow their
users to vote on product features.

### [Notion](https://www.notion.so/)

#### How it works:

Notion is a super lightweight project management tool. It allows teams
to collaborate on notes, spreadsheets, and projects. It also allows
teams to contribute to a common knowledge base. It even has a mobile app
that allows you to see your team\'s notes on the go. It's a great option
for people who love minimum frills, maximum power types of apps. You
could create a tasks list for everyone on your team during the planning
stage of your research, create a spreadsheet of participant data, take
notes on your sessions, and post your insights for the rest of your team
to see, all within Notion.

#### What people love about it:

"HANDS DOWN üôåüèº THE BEST PRODUCTIVITY, ORGANISATION AND RESOURCE
WORKSPACE myself or my team have ever touched üíØ

We\'re huge advocates of Trello, power-users of Slack, data-hungry
Google Sheet/Doc fanatics and unloyal downloaders of many productivity,
Wiki, task management and organisation apps. With my CTO I often mused
the idea of building an all-in-one workspace for internal use that sat
as our Pandora\'s box of goodies ranging from development wiki\'s,
onboarding information and branding resources all the way to task
management, meeting notes and even time tracking - lo and behold I
stumbled across this gem of an app." - [Rees
V](https://www.producthunt.com/posts/notion-2-0/reviews).

#### What people don't love about it:

"The pricing scheme isn\'t great - the free plan is great but the
attachment limit of 5MB is too small, and the cost per month for team
members is way too steep. I always resonate with solutions like G Suite
and MS Office, which are priced monthly for way more software. Of course
they have other means of financing but still." - [Emmanuel
R.](https://www.capterra.com/p/160671/Notion/)

#### [Pricing:](https://www.notion.so/pricing)

Free: Unlimited members, 1000 block storage, 5MB upload limit

\$4 per month: 1 member, unlimited block storage, no file upload limit,
advanced permissions, priority support, version history

\$8 per member per month: unlimited block storage, no file upload limit,
advanced permissions, priority support, version history, admin tools

\$16 per member per month: enterprise tier, can vary

#### Best for:

People who want data-rich spreadsheets, checklists, a note-taking tool,
and a knowledge base all in one tool.

### [Airtable](https://airtable.com/)

#### How it works:

Airtable is basically a smart spreadsheet web app that allows you and
your team to collaborate. It links related content to help you sort
through your data intelligently. It also integrates with tons of apps
you already use, like Slack and Google Drive. I use Airtable to keep
track of tasks that require a few different kinds of media to go along
with them. For example, this Field Guide chapter was originally just an
Airtable row, with a Google Doc linked to it, a status tag, and some
links to my notes and articles that were helpful in building this list.

#### What people love about it:

"Airtable makes it SO easy to create beautiful spreadsheets and database
that are organised intelligently! Google Sheets has nothing on Airtable
if you have any more complicated organisational needs. The ability to
group \"bases\" by various criteria, to display in different views
(Kanban view in particular), etc. make this SO powerful and useful for
businesses trying to make their data more useful. We use it for product
roadmaps, feature inventories, and conducting user research. It makes it
so easy to extract the essential information we love it!" - [Chris
V.](https://www.capterra.com/p/146652/Airtable/#reviews)

"Can\'t really just pick one thing. I love the versatility for whatever
I need to organize, whether it\'s planning an event, managing a content
calendar, or a research log. I love the ability to include photos right
in the cell. I love the sort and group functions , and the multiple
views! So many, many ways to manipulate and view all the same data!" -
[Nasrin
B.](https://www.g2crowd.com/products/airtable/reviews/airtable-review-727807)

#### What people don't love about it:

"I wish there was a way to link cells/rows to other databases (not just
tables in the same database). The workaround is to copy and paste data
(or use a linking app like Zapier), but it seems like a simple solution
to allow sources from other databases. Additionally, it would be nice to
have cell linking WITH a filter based on the data in another cell."
-[Jerry
L.](https://www.g2crowd.com/products/airtable/reviews/airtable-review-870169)

"For first time users, it can be a bit intimidating, especially if
checking out the application, casually. One great resource that Airtable
introduced is Airtable Universe, which highlights and demonstrates
working and real examples of how companies and industries are using
Airtable to track deadlines, scheduling, and a slew of other use cases.
I would recommend that as the starting point for any novice of the
application or anyone interested in giving it a try." - [Brett
W.](https://www.capterra.com/p/146652/Airtable/#reviews)

#### [Pricing:](https://airtable.com/pricing)

Free: Unlimited bases, 1,200 records per base, 2GB storage space per
base, 2 week revision history, basic features, email support

\$10 per user per month (annually): Unlimited bases, 5,000 records per
base, 5GB storage space per base, 6 month revision history, basic
features, email support

\$20 per user per month (annually): Unlimited bases, 50,000 records per
base, 20GB storage space per base, 1 year revision history, advanced
features, priority support

Enterprise Tier

#### Best for:

People who want to create data-rich spreadsheets with links to lots of
different content and share them in real time.

### [Trello](https://trello.com/en)

#### How it works:

Trello is organized around project boards and cards inspired by Kanban.
Trello allows the whole team to collaborate on projects and add cards.
It integrates with apps like Slack, Dropbox, and Evernote. I use Trello
to keep track of both work and personal tasks. Because it's so
lightweight, it's a pretty flexible tool. I've used it to keep track of
everything from content calendars to packing lists.This flexibility
makes it a great asset for researchers who want to stick to a Kanban
style layout to organize their research data. You can also use it to
visualize the different steps in your study, organize potential
participants, or to communicate your findings to the rest of your team.

#### What people love about it:

"I mainly use Trello to document research findings and synthesise data.
It helps me document the question beoforehand for interviews with
multiple personas, I love how you can color code the cards so you can
visualize all the data in one glance, the ability to move cards within
or outside the list helps me cluster the data to the right bucket. We
also use this tool for remote colloboration where different team members
from remote locations can add cards to specific topics and everybody can
view all the information at one single place. Comment feature helps us
keep the communication going on a certain topic/findings. I also love
the fact that all of the items on board can be exported in pdf format
for offline viewing and sharing." - [Ashish
V.](https://www.capterra.com/p/72069/Trello/)

#### What people don't love about it:

"It sometimes feels a little too basic. I could be as easily writing
this down on a piece of paper which could be a pro for some people. The
tiles going in a horizontal path. Couldn\'t layer tiles down. You can\'t
really delete anything. Only archive it or move it. Within the tiles, I
would like to have check off for the main topics, not just within that
particular block." - [Kathryn
W.](https://www.g2crowd.com/products/trello/reviews/trello-review-1237450)

"It does not allow to create repetitive work lists to be able to do
\"cycles\" of tasks (For example: X tasks every Monday, or the
repetitive tasks of each beginning of the month)." -[Eyemir
U.](https://www.capterra.com/p/72069/Trello/)

#### [Pricing](https://trello.com/pricing):

Free: unlimited boards, lists, cards, members, checklists and
attachments up to 10GB

\$9.99 per user per month (annually): unlimited power-ups
(integrations), attachments up to 250 GB, restricted memberships, custom
board backgrounds and stickers, priority email support

\$17.50+ per user per month (annually): unlimited power-ups
(integrations), attachments up to 250 GB, restricted memberships, custom
board backgrounds and stickers, personalized onboarding, priority email
and phone support, 2-factor authentication, custom security review

#### Best for:

People who love keeping track of their research on Post-it notes and
need a digital way to keep it all together.

‚Äç

## Tools for the Field

Regardless of what kind of research you're doing, you'll need some
researcher basics in your toolkit. If you're conducting research in
person or in the field, these tools become even more important. You may
not need all of these tools every time you do research, but they're
handy to have in your back pocket. ¬†

### Good Old Fashioned Pen and Paper

This is always, always, always a good tool to have. A pen and paper may
seem like things you'll always have on hand but in the digital age you
never really know. If your computer dies, you leave your phone at home,
or you just learn better when you write things down, a pen and paper
will always be there for you. If you're doing field studies or in-person
research, consider bringing extras for your participants.

I personally love big sketching notebooks like [this
one](https://us.moleskine.com/en/sketchbook-black/p0437) for taking
notes. Not because I'm a great artist or anything, but because I like to
be able to sort things as I write by spreading my notes all over the
page. For writing, I prefer [Bic
ballpoints](https://www.shopbic.com/products/stationery/pens/GSM609DC/),
because they're easy to find and write like a dream.

Have a favorite pen and paper? Tell me about it
[here](https://goo.gl/forms/zCo1wJVoJCg8Xc063) and I'll update this
article with the results.

### Sticky Notes

Sticky notes are a researcher's best friend. They're still a great go-to
for organizing thoughts, creating ad-hoc user flows, or helping
participants sort ideas. Grab a few packs to keep in your office and a
few to take with you on the go.

### Extra Chargers

"Does anybody have a charger?" are the dreaded words you'll hear right
before your participant can't participate in your study because their
phone or laptop died. If you have it in your research budget, pick up a
few extra chargers to lend your participants (or to use yourself) during
field research.

### Voice Recorder

When conducting in-person interviews, it's important to get all the
insights you can. And sometimes your hands (or your note-taker's hands)
just can't write fast enough. Using a voice recorder will help you focus
more on your participant and less on getting the insights down on paper.
You can either purchase a fancy journalistic recorder or, if all you
need is playback, use a recording app on your phone.

### Screen Recorder

A screen recorder can help you capture all of the insights of your
remote studies or those conducted in-person with a digital device. There
are web-only in-browser recorders, like
[Loom](https://www.useloom.com/my-videos) and
[Soapbox](https://wistia.com/soapbox?utm_type=media&utm_product=soapbox&utm_source=google&utm_medium=cpc&utm_campaign=Search-Brand-FA-Soapbox-US&utm_content=Soapbox&utm_term=soapbox&gclid=EAIaIQobChMIkYjj35Cd3wIVQZ7ACh0BrQHrEAAYASAAEgJ4WvD_BwE),
and mobile recording options. Some recorders will only capture what is
happening on the screen, while some will also capture audio.

### 360 Camera

If you're conducting field studies, focus groups, or interactive
interviews, a 360 camera may be a good way to get the whole picture.
They can be a bit of an investment, ranging from \$80-500, but if you
need to see your users' entire view they can be worth it.

‚Äç

So there you have it! A comprehensive list of the tools you'll need to
conduct great research. I've tried to make this list as comprehensive as
possible, but if I missed anything, please let me know by emailing me at
<katryna@userinterviews.com>.

‚Äç

**One last thing**. If you\'re caught between paying for an expensive
all-in-one research solution and sifting through the many options
outlined above, you might consider starting with the [UX Research Flex
Stack](https://www.userinterviews.com/lp/ux-research-flex-stack?source=fg),
a set of 8 UX research tools (including User Interviews!) that can help
you build a high-quality, affordable tool set for your entire workflow,
from recruiting to gathering insights to analyzing research.

‚Äç

[](#) [](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](#)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](/ux-research-field-guide-chapter/user-research-terms)

Next:

Glossary of UX Research Terms

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)

[The UX Research Field Guide](/ux-research-field-guide)

\>

[Appendix](/ux-research-field-guide-module/more-resources)

\>

[Glossary of UX Research
Terms](/ux-research-field-guide-chapter/user-research-terms)

# Glossary of UX Research Terms

The newest version of this chapter is coming soon! Subscribe to get the
latest content.

Email Address

Thank you! Your submission has been received!

Oops! Something went wrong while submitting the form.

Note to the reader: This part of the field guide comes from our 2019
version of the UX Research Field Guide. Updated content for this chapter
is coming soon! Want to know when it\'s released? [Subscribe to our
newsletter!](#)

Like it or love it, most fields come with their own sets of lingo,
jargon, and ways of saying things that are not immediately obvious to
the uninitiated. From industry specific terms, to hot topics of
professional debate, to new philosophies, to soon-to-be-passe buzzwords,
UX research is no stranger to such things.

‚Äç

Here are just a few terms you'll certainly come across as you build your
expertise in user research and as you work your way through our UX
Research Field Guide. Should we add something to the list? Hit me up at
[**erin@userinterviews.com**](mailto:erin@userinterviews.com).

‚Äç

## In this glossary

-   Design thinking
-   Empathy
-   Information architecture (IA)
-   Mental models
-   Panel
-   Qualitative research
-   Quantitative research
-   Usability

‚Äç

### Design thinking

Design thinking is not new, but it is having a moment.

![61a94a6b50e3d26bd375adc0_7zxM7PNz0bW9lzB-7a2YBPNJKJPOZe1hPMJeen3PKloq_D-F-tlORYbxC1v_YB6WqoLV-GJgRPX8vo_ZPVtMwgXPh0RNdrzXYxxyXdnLre5Bg6BHjo6qC1dPXTiWkn6qfykf27P1](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a94a6b50e3d26bd375adc0_7zxM7PNz0bW9lzB-7a2YBPNJKJPOZe1hPMJeen3PKloq_D-F-tlORYbxC1v_YB6WqoLV-GJgRPX8vo_ZPVtMwgXPh0RNdrzXYxxyXdnLre5Bg6BHjo6qC1dPXTiWkn6qfykf27P1.png)

‚Äç

With origins going back to the 1960s and 70s, and specifically books
like¬†The Sciences of the Artificial,¬†Visual Thinking,¬†and¬†How Designers
Think, design thinking really hit prominence within design communities
at Standard University in the 80s and 90s. Rolf Faste and David M.
Kelley were colleagues at Stanford and Kelley went on to found IDEO in
1991. As¬†[IDEO](https://www.ideo.com/)¬†describes it:

‚Äç

Design thinking utilizes elements from the designer\'s toolkit like
empathy and experimentation to arrive at innovative solutions. By using
design thinking, you make decisions based on what future customers
really want instead of relying only on historical data or making risky
bets based on instinct instead of evidence.

‚Äç

Design thinking is the center of Standford's "d.school," founded in
2004. D.school together with IDEO, the massive growth of Apple---which
puts human centered design at the forefront---and the growth of design
as a critical discipline in many hugely successful organizations like
AirBnB, have served to bring design thinking to the larger realm of
business, not "just" design and product development functions.

‚Äç

More and more we're seeing both progressive tech startups and enterprise
companies alike seek to bring design thinking to every corner of their
business. We predict this trend isn't going anywhere.

‚Äç

### Empathy

You wouldn't always know it to look at, say, the news, but empathy is
booming.

![61a94ae02729de726cac8998\_-Cc_avxPC4fbE24UDTlDPmQvmjPR11r62xhVch2YAJI_hSXDO4oSOsoZy6KG2hs44tPXDcwv-Xi1lGSoR2O-Tl1akO4uCh4rvGWTY1u8_wED2qeZwGtUxlNl_z1K7-d0dbozxdwK](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a94ae02729de726cac8998_-Cc_avxPC4fbE24UDTlDPmQvmjPR11r62xhVch2YAJI_hSXDO4oSOsoZy6KG2hs44tPXDcwv-Xi1lGSoR2O-Tl1akO4uCh4rvGWTY1u8_wED2qeZwGtUxlNl_z1K7-d0dbozxdwK.png)

You can't have design thinking, human centered design, or UX research
without empathy. Empathy is often confused with sympathy, so let's
separate those. Sympathy is about caring, about feeling, about
compassion for others. It's probably a really good quality for most
people most of the time, but it's not necessarily critical to building
great products or businesses. Empathy, by contrast, is simply about
understanding the contexts, motivations, and truths of people's actual
lives by imagining they were your own.

‚Äç

The growth of empathy in the context of product design and business
philosophy has been huge. If I can understand my user, I can build
something that will improve their lives, solve their problems, and make
me money. Much of UX research is about using various methods and tools
to uncover this understanding of users. Why do they do what they do? Who
are they, actually? Qualitative research is critical here, as is asking
"why" when evaluating quantitative data sets.

‚Äç

The very act of empathy requires imagination, and flexing those creative
muscles is like ongoing conditioning for the designer to build
innovative products.

‚Äç

### Information architecture (IA)

Information architecture is all about organizing content. Search,
navigation, labels, structures and systems can all have a place in your
site or app's IA.

![61a94afe4f1a353977711700_mIf0AlvLj37NnU4otYaaz3WlClyQbxqPC9OBlBmUxPljY7j4JTlhYaxQ9o6Sx9AHem57EkJbHV7eWGPk_kKY30ORxGNcEKRp00IQmocp8lAk_Iwg5cHhE6NCFg7eX1Ottzw3Pv3d](https://global-uploads.webflow.com/59b1667dd2e65000019d07be/61a94afe4f1a353977711700_mIf0AlvLj37NnU4otYaaz3WlClyQbxqPC9OBlBmUxPljY7j4JTlhYaxQ9o6Sx9AHem57EkJbHV7eWGPk_kKY30ORxGNcEKRp00IQmocp8lAk_Iwg5cHhE6NCFg7eX1Ottzw3Pv3d.png)

A good IA considers users, context, and the content itself. For
instance, how might a tree novice, vs a certified arborist go about
identifying some leaf damage that impacted a tree they had come across?
What if they are on their smartphone with a camera and WIFI vs desktop
without a camera? Do they have your app downloaded or are they accessing
this information via your website? Do you have a hotline perhaps? How is
that phone tree menu working out for your users? These are just a few of
the things you might consider for one job to be done: figure out what's
wrong with my tree leaf.

‚Äç

UX researchers employ a variety of methods to answer IA questions. Tree
testing and card sorting are two popular methods to help discover and
validate systems to organize content. In tree testing participants try
to find information within a hierarchy of content (trees with branches)
you share with them. In a card sort, they organize topics into groups.
Generally a card sort would be run first, with a tree test to help
validate the findings of a card sort.

‚Äç

IA is a complex and multidisciplinary field within UX that might bring
together designers, developers, product managers, and marketers to
ultimately build the right content organization systems to benefit the
user and the business in all key contexts.

‚Äç

### Mental models

Mental models are a useful tool in UX research when it comes to
describing and understanding how a user thinks. (All roads lead to
empathy). Mental models are ways we describe how people think about the
world. This could be at a very very high level, or a very granular
level. Books like [**Thinking, Fast and
Slow**](https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555)
or [**The Undoing
Project**](https://www.amazon.com/Undoing-Project-Friendship-Changed-Minds/dp/0393354776/ref=sr_1_1?s=digital-text&ie=UTF8&qid=1519789121&sr=8-1&keywords=The+Undoing+Project)
consider the role of cognitive biases in how we make decisions.

‚Äç

Regardless of the why of a mental model, defining them can be very
useful for product design. For example, imagine we've built a site
navigation for a pet store around different types of animals (cats,
dogs) and different categories of need (food, medicine). Does bringing
these systems together into one menu fit with a user's mental model, or
confuse them? Does wildly reimagining a checkout experience introduce
friction by challenging familiar patterns or mental models of doing
things? Does your product experience fit with or challenge your user's
understanding of the world?

‚Äç

Research can be a great way to uncover what some of those views are in
the context of using your product, which can be invaluable in building a
product that works with, and doesn't fight against, how they believe
things work.

‚Äç

### Panel

Your participant panel is the group of people you could potentially call
upon for research. At User Interviews we have a panel of over 75,000
participants we connect with researchers based on demographic criteria,
occupation, and custom screener survey results. You may also have a
panel of your own users, or more specialized panels for different types
of research. However you source participants or define your panels,
they're an incredibly important part of user research. You cannot run
good research with [**bad
participants**](https://www.userinterviews.com/ux-research-field-guide-chapter/find-good-research-participants).

‚Äç

### Recruit from our panel of 700,000+ vetted participants

[Sign up for free](https://www.userinterviews.com/recruit)

### Qualitative research

Long the ugly stepsister of quantitative research, qualitative research
has become an integral part to user research, with the goal of building
products people want and that make businesses successful. Qualitative
research aims to answer questions of why and address context.
Qualitative methods focus on building understanding through inquiry,
dialogue, and observation in real life scenarios or lab settings.

‚Äç

Popular methods of qualitative research include
[**interviews**](https://www.userinterviews.com/ux-research-field-guide-chapter/generative-interviews),
[**field
research**](https://www.userinterviews.com/ux-research-field-guide-chapter/field-studies),
and remote or in-person usability tests. A great advantage of
qualitative testing is that it can often yield insights quickly and
inexpensively. Simply talking to five or so people can seriously save
you from building a fundamentally wrong product, validate you're on the
right track, or help you make tweaks to improve your product's
performance and save you tons of time and heartache. ¬†

‚Äç

### Quantitative research

Our collective obsession with data often points us here. This is where
we get numbers, lots and lots of numbers. When numbers yield insights
and action, they are great. Researchers may run large surveys in the
discovery stage to better understand a market, a/b tests on prototypes
to better understand which version will perform best, or closely monitor
customer support tickets and web analytics in a post-launch phase to see
how a product is performing in the wild. When looking at large data
sets, anomalies are particularly important, as well as benchmarking
against past or anticipated results.

‚Äç

Quantitative and qualitative research work wonderfully together and most
established research programs take advantage of both.

‚Äç

### Usability

How easy is my product to use? How quickly, efficiently, joyfully can my
users complete certain tasks in certain contexts? Usability is the
aspect of UX and UX research that seeks to answer and address these
questions.

‚Äç

Qualitative usability testing is perhaps the most valuable research a
product team can do, giving tangible insights into the effectiveness of
a product while also providing the context as to why these findings are
true, making them actionable.

[](#) [](#)

[Book a demo](#)

[Explore Research
Hub](https://www.userinterviews.com/research-hub?source=fieldGuideDiscoCTA)

[](/ux-research-field-guide-chapter/user-research-tools)

![back
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f323cf885c455c76ec8e_previous.svg)

previous

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

[](#)

Next:

![forward
arrow](https://global-uploads.webflow.com/59ace8427353c50001765cbd/6197f32404193316ca4ffc92_next.svg)

Subscribe to the Field Guide for fresh lessons delivered to your inbox!

[Subscribe](#) [](#top)
